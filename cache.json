{"2024-03-27T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2403.18814v1","updated":"2024-03-27T17:59:04Z","published":"2024-03-27T17:59:04Z","title":"Mini-Gemini: Mining the Potential of Multi-modality Vision Language\n  Models","summary":"  In this work, we introduce Mini-Gemini, a simple and effective framework\nenhancing multi-modality Vision Language Models (VLMs). Despite the\nadvancements in VLMs facilitating basic visual dialog and reasoning, a\nperformance gap persists compared to advanced models like GPT-4 and Gemini. We\ntry to narrow the gap by mining the potential of VLMs for better performance\nand any-to-any workflow from three aspects, i.e., high-resolution visual\ntokens, high-quality data, and VLM-guided generation. To enhance visual tokens,\nwe propose to utilize an additional visual encoder for high-resolution\nrefinement without increasing the visual token count. We further construct a\nhigh-quality dataset that promotes precise image comprehension and\nreasoning-based generation, expanding the operational scope of current VLMs. In\ngeneral, Mini-Gemini further mines the potential of VLMs and empowers current\nframeworks with image understanding, reasoning, and generation simultaneously.\nMini-Gemini supports a series of dense and MoE Large Language Models (LLMs)\nfrom 2B to 34B. It is demonstrated to achieve leading performance in several\nzero-shot benchmarks and even surpasses the developed private models. Code and\nmodels are available at https://github.com/dvlab-research/MiniGemini.\n","authors":["Yanwei Li","Yuechen Zhang","Chengyao Wang","Zhisheng Zhong","Yixin Chen","Ruihang Chu","Shaoteng Liu","Jiaya Jia"],"pdf_url":"https://arxiv.org/pdf/2403.18814v1.pdf","comment":"Code and models are available at\n  https://github.com/dvlab-research/MiniGemini"},{"id":"http://arxiv.org/abs/2403.18807v1","updated":"2024-03-27T17:53:30Z","published":"2024-03-27T17:53:30Z","title":"ECoDepth: Effective Conditioning of Diffusion Models for Monocular Depth\n  Estimation","summary":"  In the absence of parallax cues, a learning-based single image depth\nestimation (SIDE) model relies heavily on shading and contextual cues in the\nimage. While this simplicity is attractive, it is necessary to train such\nmodels on large and varied datasets, which are difficult to capture. It has\nbeen shown that using embeddings from pre-trained foundational models, such as\nCLIP, improves zero shot transfer in several applications. Taking inspiration\nfrom this, in our paper we explore the use of global image priors generated\nfrom a pre-trained ViT model to provide more detailed contextual information.\nWe argue that the embedding vector from a ViT model, pre-trained on a large\ndataset, captures greater relevant information for SIDE than the usual route of\ngenerating pseudo image captions, followed by CLIP based text embeddings. Based\non this idea, we propose a new SIDE model using a diffusion backbone which is\nconditioned on ViT embeddings. Our proposed design establishes a new\nstate-of-the-art (SOTA) for SIDE on NYUv2 dataset, achieving Abs Rel error of\n0.059(14% improvement) compared to 0.069 by the current SOTA (VPD). And on\nKITTI dataset, achieving Sq Rel error of 0.139 (2% improvement) compared to\n0.142 by the current SOTA (GEDepth). For zero-shot transfer with a model\ntrained on NYUv2, we report mean relative improvement of (20%, 23%, 81%, 25%)\nover NeWCRFs on (Sun-RGBD, iBims1, DIODE, HyperSim) datasets, compared to (16%,\n18%, 45%, 9%) by ZoeDepth. The code is available at\nhttps://github.com/Aradhye2002/EcoDepth.\n","authors":["Suraj Patni","Aradhye Agarwal","Chetan Arora"],"pdf_url":"https://arxiv.org/pdf/2403.18807v1.pdf","comment":"Accepted at IEEE/CVF Conference on Computer Vision and Pattern\n  Recognition (CVPR) 2024"},{"id":"http://arxiv.org/abs/2403.18802v1","updated":"2024-03-27T17:48:55Z","published":"2024-03-27T17:48:55Z","title":"Long-form factuality in large language models","summary":"  Large language models (LLMs) often generate content that contains factual\nerrors when responding to fact-seeking prompts on open-ended topics. To\nbenchmark a model's long-form factuality in open domains, we first use GPT-4 to\ngenerate LongFact, a prompt set comprising thousands of questions spanning 38\ntopics. We then propose that LLM agents can be used as automated evaluators for\nlong-form factuality through a method which we call Search-Augmented Factuality\nEvaluator (SAFE). SAFE utilizes an LLM to break down a long-form response into\na set of individual facts and to evaluate the accuracy of each fact using a\nmulti-step reasoning process comprising sending search queries to Google Search\nand determining whether a fact is supported by the search results. Furthermore,\nwe propose extending F1 score as an aggregated metric for long-form factuality.\nTo do so, we balance the percentage of supported facts in a response\n(precision) with the percentage of provided facts relative to a hyperparameter\nrepresenting a user's preferred response length (recall).\n  Empirically, we demonstrate that LLM agents can achieve superhuman rating\nperformance - on a set of ~16k individual facts, SAFE agrees with crowdsourced\nhuman annotators 72% of the time, and on a random subset of 100 disagreement\ncases, SAFE wins 76% of the time. At the same time, SAFE is more than 20 times\ncheaper than human annotators. We also benchmark thirteen language models on\nLongFact across four model families (Gemini, GPT, Claude, and PaLM-2), finding\nthat larger language models generally achieve better long-form factuality.\nLongFact, SAFE, and all experimental code are available at\nhttps://github.com/google-deepmind/long-form-factuality.\n","authors":["Jerry Wei","Chengrun Yang","Xinying Song","Yifeng Lu","Nathan Hu","Dustin Tran","Daiyi Peng","Ruibo Liu","Da Huang","Cosmo Du","Quoc V. Le"],"pdf_url":"https://arxiv.org/pdf/2403.18802v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.13525v2","updated":"2024-03-27T17:47:56Z","published":"2023-05-22T22:41:49Z","title":"A 4D Hybrid Algorithm to Scale Parallel Training to Thousands of GPUs","summary":"  Large communication costs are a critical bottleneck in training\nstate-of-the-art neural networks on distributed systems. This paper introduces\nAxoNN, a novel four-dimensional (4D) parallelization approach, inspired by\nAgarwal's algorithm for matrix multiplication, for parallelizing tensor\ncomputations in deep learning, AxoNN employs two key strategies to minimize\ncommunication overhead. First, we optimize communication by overlapping\nexpensive collective operations (reduce-scatter, all-gather, all-reduce) with\ncomputations. Our experiments with a 20-billion parameter transformer model\ndemonstrate that these optimizations deliver nearly 53\\% improvement. Second,\nwe present an analytical model to assist users in identifying\ncommunication-minimizing configurations within the vast search space defined by\nour 4D algorithm. This model empowers practitioners by simplifying the tuning\nprocess for their specific training workloads. When training an 80-billion\nparameter model on 1024 GPUs of Perlmutter, AxoNN surpasses Megatron-LM, a\nstate-of-the-art framework, by a significant 26%. Additionally, it achieves 57%\nof the theoretical peak FLOP/s.\n","authors":["Siddharth Singh","Prajwal Singhania","Aditya K. Ranjan","Zack Sating","Abhinav Bhatele"],"pdf_url":"https://arxiv.org/pdf/2305.13525v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10319v4","updated":"2024-03-27T17:41:50Z","published":"2023-11-17T04:04:29Z","title":"Shifting to Machine Supervision: Annotation-Efficient Semi and\n  Self-Supervised Learning for Automatic Medical Image Segmentation and\n  Classification","summary":"  Advancements in clinical treatment are increasingly constrained by the\nlimitations of supervised learning techniques, which depend heavily on large\nvolumes of annotated data. The annotation process is not only costly but also\ndemands substantial time from clinical specialists. Addressing this issue, we\nintroduce the S4MI (Self-Supervision and Semi-Supervision for Medical Imaging)\npipeline, a novel approach that leverages advancements in self-supervised and\nsemi-supervised learning. These techniques engage in auxiliary tasks that do\nnot require labeling, thus simplifying the scaling of machine supervision\ncompared to fully-supervised methods. Our study benchmarks these techniques on\nthree distinct medical imaging datasets to evaluate their effectiveness in\nclassification and segmentation tasks. Notably, we observed that self\nsupervised learning significantly surpassed the performance of supervised\nmethods in the classification of all evaluated datasets. Remarkably, the\nsemi-supervised approach demonstrated superior outcomes in segmentation,\noutperforming fully-supervised methods while using 50% fewer labels across all\ndatasets. In line with our commitment to contributing to the scientific\ncommunity, we have made the S4MI code openly accessible, allowing for broader\napplication and further development of these methods.\n","authors":["Pranav Singh","Raviteja Chukkapalli","Shravan Chaudhari","Luoyao Chen","Mei Chen","Jinqian Pan","Craig Smuda","Jacopo Cirrone"],"pdf_url":"https://arxiv.org/pdf/2311.10319v4.pdf","comment":"Seventeen pages (incl. references), five figures, and one table.\n  (Under Review)"},{"id":"http://arxiv.org/abs/2403.18795v1","updated":"2024-03-27T17:40:14Z","published":"2024-03-27T17:40:14Z","title":"Gamba: Marry Gaussian Splatting with Mamba for single view 3D\n  reconstruction","summary":"  We tackle the challenge of efficiently reconstructing a 3D asset from a\nsingle image with growing demands for automated 3D content creation pipelines.\nPrevious methods primarily rely on Score Distillation Sampling (SDS) and Neural\nRadiance Fields (NeRF). Despite their significant success, these approaches\nencounter practical limitations due to lengthy optimization and considerable\nmemory usage. In this report, we introduce Gamba, an end-to-end amortized 3D\nreconstruction model from single-view images, emphasizing two main insights:\n(1) 3D representation: leveraging a large number of 3D Gaussians for an\nefficient 3D Gaussian splatting process; (2) Backbone design: introducing a\nMamba-based sequential network that facilitates context-dependent reasoning and\nlinear scalability with the sequence (token) length, accommodating a\nsubstantial number of Gaussians. Gamba incorporates significant advancements in\ndata preprocessing, regularization design, and training methodologies. We\nassessed Gamba against existing optimization-based and feed-forward 3D\ngeneration approaches using the real-world scanned OmniObject3D dataset. Here,\nGamba demonstrates competitive generation capabilities, both qualitatively and\nquantitatively, while achieving remarkable speed, approximately 0.6 second on a\nsingle NVIDIA A100 GPU.\n","authors":["Qiuhong Shen","Xuanyu Yi","Zike Wu","Pan Zhou","Hanwang Zhang","Shuicheng Yan","Xinchao Wang"],"pdf_url":"https://arxiv.org/pdf/2403.18795v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.17574v2","updated":"2024-03-27T17:34:57Z","published":"2024-02-27T15:09:20Z","title":"Agent-Pro: Learning to Evolve via Policy-Level Reflection and\n  Optimization","summary":"  Large Language Models exhibit robust problem-solving capabilities for diverse\ntasks. However, most LLM-based agents are designed as specific task solvers\nwith sophisticated prompt engineering, rather than agents capable of learning\nand evolving through interactions. These task solvers necessitate manually\ncrafted prompts to inform task rules and regulate LLM behaviors, inherently\nincapacitating to address complex dynamic scenarios e.g., large interactive\ngames. In light of this, we propose Agent-Pro: an LLM-based Agent with\nPolicy-level Reflection and Optimization that can learn a wealth of expertise\nfrom interactive experiences and progressively elevate its behavioral policy.\nSpecifically, it involves a dynamic belief generation and reflection process\nfor policy evolution. Rather than action-level reflection, Agent-Pro\niteratively reflects on past trajectories and beliefs, fine-tuning its\nirrational beliefs for a better policy. Moreover, a depth-first search is\nemployed for policy optimization, ensuring continual enhancement in policy\npayoffs. Agent-Pro is evaluated across two games: Blackjack and Texas Hold'em,\noutperforming vanilla LLM and specialized models. Our results show Agent-Pro\ncan learn and evolve in complex and dynamic scenes, which also benefits\nnumerous LLM-based applications.\n","authors":["Wenqi Zhang","Ke Tang","Hai Wu","Mengna Wang","Yongliang Shen","Guiyang Hou","Zeqi Tan","Peng Li","Yueting Zhuang","Weiming Lu"],"pdf_url":"https://arxiv.org/pdf/2402.17574v2.pdf","comment":"LLM-based Agent"},{"id":"http://arxiv.org/abs/2401.02009v2","updated":"2024-03-27T17:24:47Z","published":"2024-01-04T00:32:33Z","title":"Self-Contrast: Better Reflection Through Inconsistent Solving\n  Perspectives","summary":"  The reflection capacity of Large Language Model (LLM) has garnered extensive\nattention. A post-hoc prompting strategy, e.g., reflexion and self-refine,\nrefines LLM's response based on self-evaluated or external feedback. However,\nrecent research indicates without external feedback, LLM's intrinsic reflection\nis unstable. Our investigation unveils that the key bottleneck is the quality\nof the self-evaluated feedback. We find LLMs often exhibit overconfidence or\nhigh randomness when self-evaluate, offering stubborn or inconsistent feedback,\nwhich causes poor reflection. To remedy this, we advocate Self-Contrast: It\nadaptively explores diverse solving perspectives tailored to the request,\ncontrasts the differences, and summarizes these discrepancies into a checklist\nwhich could be used to re-examine and eliminate discrepancies. Our method\nendows LLM with diverse perspectives to alleviate stubborn biases. Moreover,\ntheir discrepancies indicate potential errors or inherent uncertainties that\nLLM often overlooks. Reflecting upon these can catalyze more accurate and\nstable reflection. Experiments conducted on a series of reasoning and\ntranslation tasks with different LLMs serve to underscore the effectiveness and\ngenerality of our strategy.\n","authors":["Wenqi Zhang","Yongliang Shen","Linjuan Wu","Qiuying Peng","Jun Wang","Yueting Zhuang","Weiming Lu"],"pdf_url":"https://arxiv.org/pdf/2401.02009v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18775v1","updated":"2024-03-27T17:23:39Z","published":"2024-03-27T17:23:39Z","title":"ImageNet-D: Benchmarking Neural Network Robustness on Diffusion\n  Synthetic Object","summary":"  We establish rigorous benchmarks for visual perception robustness. Synthetic\nimages such as ImageNet-C, ImageNet-9, and Stylized ImageNet provide specific\ntype of evaluation over synthetic corruptions, backgrounds, and textures, yet\nthose robustness benchmarks are restricted in specified variations and have low\nsynthetic quality. In this work, we introduce generative model as a data source\nfor synthesizing hard images that benchmark deep models' robustness. Leveraging\ndiffusion models, we are able to generate images with more diversified\nbackgrounds, textures, and materials than any prior work, where we term this\nbenchmark as ImageNet-D. Experimental results show that ImageNet-D results in a\nsignificant accuracy drop to a range of vision models, from the standard ResNet\nvisual classifier to the latest foundation models like CLIP and MiniGPT-4,\nsignificantly reducing their accuracy by up to 60\\%. Our work suggests that\ndiffusion models can be an effective source to test vision models. The code and\ndataset are available at https://github.com/chenshuang-zhang/imagenet_d.\n","authors":["Chenshuang Zhang","Fei Pan","Junmo Kim","In So Kweon","Chengzhi Mao"],"pdf_url":"https://arxiv.org/pdf/2403.18775v1.pdf","comment":"Accepted at CVPR 2024"},{"id":"http://arxiv.org/abs/2309.04381v2","updated":"2024-03-27T17:07:47Z","published":"2023-09-08T15:23:40Z","title":"Generalization Bounds: Perspectives from Information Theory and\n  PAC-Bayes","summary":"  A fundamental question in theoretical machine learning is generalization.\nOver the past decades, the PAC-Bayesian approach has been established as a\nflexible framework to address the generalization capabilities of machine\nlearning algorithms, and design new ones. Recently, it has garnered increased\ninterest due to its potential applicability for a variety of learning\nalgorithms, including deep neural networks. In parallel, an\ninformation-theoretic view of generalization has developed, wherein the\nrelation between generalization and various information measures has been\nestablished. This framework is intimately connected to the PAC-Bayesian\napproach, and a number of results have been independently discovered in both\nstrands. In this monograph, we highlight this strong connection and present a\nunified treatment of PAC-Bayesian and information-theoretic generalization\nbounds. We present techniques and results that the two perspectives have in\ncommon, and discuss the approaches and interpretations that differ. In\nparticular, we demonstrate how many proofs in the area share a modular\nstructure, through which the underlying ideas can be intuited. We pay special\nattention to the conditional mutual information (CMI) framework; analytical\nstudies of the information complexity of learning algorithms; and the\napplication of the proposed methods to deep learning. This monograph is\nintended to provide a comprehensive introduction to information-theoretic\ngeneralization bounds and their connection to PAC-Bayes, serving as a\nfoundation from which the most recent developments are accessible. It is aimed\nbroadly towards researchers with an interest in generalization and theoretical\nmachine learning.\n","authors":["Fredrik Hellström","Giuseppe Durisi","Benjamin Guedj","Maxim Raginsky"],"pdf_url":"https://arxiv.org/pdf/2309.04381v2.pdf","comment":"228 pages"},{"id":"http://arxiv.org/abs/2403.06054v4","updated":"2024-03-27T17:06:10Z","published":"2024-03-10T00:47:05Z","title":"Decoupled Data Consistency with Diffusion Purification for Image\n  Restoration","summary":"  Diffusion models have recently gained traction as a powerful class of deep\ngenerative priors, excelling in a wide range of image restoration tasks due to\ntheir exceptional ability to model data distributions. To solve image\nrestoration problems, many existing techniques achieve data consistency by\nincorporating additional likelihood gradient steps into the reverse sampling\nprocess of diffusion models. However, the additional gradient steps pose a\nchallenge for real-world practical applications as they incur a large\ncomputational overhead, thereby increasing inference time. They also present\nadditional difficulties when using accelerated diffusion model samplers, as the\nnumber of data consistency steps is limited by the number of reverse sampling\nsteps. In this work, we propose a novel diffusion-based image restoration\nsolver that addresses these issues by decoupling the reverse process from the\ndata consistency steps. Our method involves alternating between a\nreconstruction phase to maintain data consistency and a refinement phase that\nenforces the prior via diffusion purification. Our approach demonstrates\nversatility, making it highly adaptable for efficient problem-solving in latent\nspace. Additionally, it reduces the necessity for numerous sampling steps\nthrough the integration of consistency models. The efficacy of our approach is\nvalidated through comprehensive experiments across various image restoration\ntasks, including image denoising, deblurring, inpainting, and super-resolution.\n","authors":["Xiang Li","Soo Min Kwon","Ismail R. Alkhouri","Saiprasad Ravishankar","Qing Qu"],"pdf_url":"https://arxiv.org/pdf/2403.06054v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18766v1","updated":"2024-03-27T17:05:03Z","published":"2024-03-27T17:05:03Z","title":"Superior Parallel Big Data Clustering through Competitive Stochastic\n  Sample Size Optimization in Big-means","summary":"  This paper introduces a novel K-means clustering algorithm, an advancement on\nthe conventional Big-means methodology. The proposed method efficiently\nintegrates parallel processing, stochastic sampling, and competitive\noptimization to create a scalable variant designed for big data applications.\nIt addresses scalability and computation time challenges typically faced with\ntraditional techniques. The algorithm adjusts sample sizes dynamically for each\nworker during execution, optimizing performance. Data from these sample sizes\nare continually analyzed, facilitating the identification of the most efficient\nconfiguration. By incorporating a competitive element among workers using\ndifferent sample sizes, efficiency within the Big-means algorithm is further\nstimulated. In essence, the algorithm balances computational time and\nclustering quality by employing a stochastic, competitive sampling strategy in\na parallel computing setting.\n","authors":["Rustam Mussabayev","Ravil Mussabayev"],"pdf_url":"https://arxiv.org/pdf/2403.18766v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18762v1","updated":"2024-03-27T17:01:10Z","published":"2024-03-27T17:01:10Z","title":"ModaLink: Unifying Modalities for Efficient Image-to-PointCloud Place\n  Recognition","summary":"  Place recognition is an important task for robots and autonomous cars to\nlocalize themselves and close loops in pre-built maps. While single-modal\nsensor-based methods have shown satisfactory performance, cross-modal place\nrecognition that retrieving images from a point-cloud database remains a\nchallenging problem. Current cross-modal methods transform images into 3D\npoints using depth estimation for modality conversion, which are usually\ncomputationally intensive and need expensive labeled data for depth\nsupervision. In this work, we introduce a fast and lightweight framework to\nencode images and point clouds into place-distinctive descriptors. We propose\nan effective Field of View (FoV) transformation module to convert point clouds\ninto an analogous modality as images. This module eliminates the necessity for\ndepth estimation and helps subsequent modules achieve real-time performance. We\nfurther design a non-negative factorization-based encoder to extract mutually\nconsistent semantic features between point clouds and images. This encoder\nyields more distinctive global descriptors for retrieval. Experimental results\non the KITTI dataset show that our proposed methods achieve state-of-the-art\nperformance while running in real time. Additional evaluation on the HAOMO\ndataset covering a 17 km trajectory further shows the practical generalization\ncapabilities. We have released the implementation of our methods as open source\nat: https://github.com/haomo-ai/ModaLink.git.\n","authors":["Weidong Xie","Lun Luo","Nanfei Ye","Yi Ren","Shaoyi Du","Minhang Wang","Jintao Xu","Rui Ai","Weihao Gu","Xieyuanli Chen"],"pdf_url":"https://arxiv.org/pdf/2403.18762v1.pdf","comment":"8 pages, 11 figures, conference"},{"id":"http://arxiv.org/abs/2311.01483v3","updated":"2024-03-27T16:56:23Z","published":"2023-11-02T14:47:06Z","title":"FedSN: A Novel Federated Learning Framework over LEO Satellite Networks","summary":"  Recently, a large number of Low Earth Orbit (LEO) satellites have been\nlaunched and deployed successfully in space by commercial companies, such as\nSpaceX. Due to multimodal sensors equipped by the LEO satellites, they serve\nnot only for communication but also for various machine learning applications,\nsuch as space modulation recognition, remote sensing image classification, etc.\nHowever, the ground station (GS) may be incapable of downloading such a large\nvolume of raw sensing data for centralized model training due to the limited\ncontact time with LEO satellites (e.g. 5 minutes). Therefore, federated\nlearning (FL) has emerged as the promising solution to address this problem via\non-device training. Unfortunately, to enable FL on LEO satellites, we still\nface three critical challenges that are i) heterogeneous computing and memory\ncapabilities, ii) limited uplink rate, and iii) model staleness. To this end,\nwe propose FedSN as a general FL framework to tackle the above challenges, and\nfully explore data diversity on LEO satellites. Specifically, we first present\na novel sub-structure scheme to enable heterogeneous local model training\nconsidering different computing, memory, and communication constraints on LEO\nsatellites. Additionally, we propose a pseudo-synchronous model aggregation\nstrategy to dynamically schedule model aggregation for compensating model\nstaleness. To further demonstrate the effectiveness of the FedSN, we evaluate\nit using space modulation recognition and remote sensing image classification\ntasks by leveraging the data from real-world satellite networks. Extensive\nexperimental results demonstrate that FedSN framework achieves higher accuracy,\nlower computing, and communication overhead than the state-of-the-art\nbenchmarks and the effectiveness of each components in FedSN.\n","authors":["Zheng Lin","Zhe Chen","Zihan Fang","Xianhao Chen","Xiong Wang","Yue Gao"],"pdf_url":"https://arxiv.org/pdf/2311.01483v3.pdf","comment":"14 pages, 17 figures"},{"id":"http://arxiv.org/abs/2403.18756v1","updated":"2024-03-27T16:56:14Z","published":"2024-03-27T16:56:14Z","title":"Detection of subclinical atherosclerosis by image-based deep learning on\n  chest x-ray","summary":"  Aims. To develop a deep-learning based system for recognition of subclinical\natherosclerosis on a plain frontal chest x-ray. Methods and Results. A\ndeep-learning algorithm to predict coronary artery calcium (CAC) score (the\nAI-CAC model) was developed on 460 chest x-ray (80% training cohort, 20%\ninternal validation cohort) of primary prevention patients (58.4% male, median\nage 63 [51-74] years) with available paired chest x-ray and chest computed\ntomography (CT) indicated for any clinical reason and performed within 3\nmonths. The CAC score calculated on chest CT was used as ground truth. The\nmodel was validated on an temporally-independent cohort of 90 patients from the\nsame institution (external validation). The diagnostic accuracy of the AI-CAC\nmodel assessed by the area under the curve (AUC) was the primary outcome.\nOverall, median AI-CAC score was 35 (0-388) and 28.9% patients had no AI-CAC.\nAUC of the AI-CAC model to identify a CAC>0 was 0.90 in the internal validation\ncohort and 0.77 in the external validation cohort. Sensitivity was consistently\nabove 92% in both cohorts. In the overall cohort (n=540), among patients with\nAI-CAC=0, a single ASCVD event occurred, after 4.3 years. Patients with\nAI-CAC>0 had significantly higher Kaplan Meier estimates for ASCVD events\n(13.5% vs. 3.4%, log-rank=0.013). Conclusion. The AI-CAC model seems to\naccurately detect subclinical atherosclerosis on chest x-ray with elevated\nsensitivity, and to predict ASCVD events with elevated negative predictive\nvalue. Adoption of the AI-CAC model to refine CV risk stratification or as an\nopportunistic screening tool requires prospective evaluation.\n","authors":["Guglielmo Gallone","Francesco Iodice","Alberto Presta","Davide Tore","Ovidio de Filippo","Michele Visciano","Carlo Alberto Barbano","Alessandro Serafini","Paola Gorrini","Alessandro Bruno","Walter Grosso Marra","James Hughes","Mario Iannaccone","Paolo Fonio","Attilio Fiandrotti","Alessandro Depaoli","Marco Grangetto","Gaetano Maria de Ferrari","Fabrizio D'Ascenzo"],"pdf_url":"https://arxiv.org/pdf/2403.18756v1.pdf","comment":"Submitted to European Heart Journal - Cardiovascular Imaging Added\n  also the additional material 44 pages (30 main paper, 14 additional\n  material), 14 figures (5 main manuscript, 9 additional material)"},{"id":"http://arxiv.org/abs/2403.18755v1","updated":"2024-03-27T16:54:45Z","published":"2024-03-27T16:54:45Z","title":"Many-Objective Evolutionary Influence Maximization: Balancing Spread,\n  Budget, Fairness, and Time","summary":"  The Influence Maximization (IM) problem seeks to discover the set of nodes in\na graph that can spread the information propagation at most. This problem is\nknown to be NP-hard, and it is usually studied by maximizing the influence\n(spread) and, optionally, optimizing a second objective, such as minimizing the\nseed set size or maximizing the influence fairness. However, in many practical\nscenarios multiple aspects of the IM problem must be optimized at the same\ntime. In this work, we propose a first case study where several IM-specific\nobjective functions, namely budget, fairness, communities, and time, are\noptimized on top of the maximization of influence and minimization of the seed\nset size. To this aim, we introduce MOEIM (Many-Objective Evolutionary\nAlgorithm for Influence Maximization) a Multi-Objective Evolutionary Algorithm\n(MOEA) based on NSGA-II incorporating graph-aware operators and a smart\ninitialization. We compare MOEIM in two experimental settings, including a\ntotal of nine graph datasets, two heuristic methods, a related MOEA, and a\nstate-of-the-art Deep Learning approach. The experiments show that MOEIM\noverall outperforms the competitors in most of the tested many-objective\nsettings. To conclude, we also investigate the correlation between the\nobjectives, leading to novel insights into the topic. The codebase is available\nat https://github.com/eliacunegatti/MOEIM.\n","authors":["Elia Cunegatti","Leonardo Lucio Custode","Giovanni Iacca"],"pdf_url":"https://arxiv.org/pdf/2403.18755v1.pdf","comment":"To appear in Genetic and Evolutionary Computation Conference (GECCO\n  24 Companion), July 14 18, 2024, Melbourne, VIC, Australia. ACM, New York,\n  NY, USA"},{"id":"http://arxiv.org/abs/2201.06180v2","updated":"2024-03-27T16:45:26Z","published":"2022-01-17T02:30:25Z","title":"Nonlinear Control Allocation: A Learning Based Approach","summary":"  Modern aircraft are designed with redundant control effectors to cater for\nfault tolerance and maneuverability requirements. This leads to aircraft being\nover-actuated and requires control allocation schemes to distribute the control\ncommands among control effectors. Traditionally, optimization-based control\nallocation schemes are used; however, for nonlinear allocation problems, these\nmethods require large computational resources. In this work, an artificial\nneural network (ANN) based nonlinear control allocation scheme is proposed. The\nproposed scheme is composed of learning the inverse of the control\neffectiveness map through ANN, and then implementing it as an allocator instead\nof solving an online optimization problem. Stability conditions are presented\nfor closed-loop systems incorporating the allocator, and computational\nchallenges are explored with piece-wise linear effectiveness functions and\nANN-based allocators. To demonstrate the efficacy of the proposed scheme, it is\ncompared with a standard quadratic programming-based method for control\nallocation.\n","authors":["Hafiz Zeeshan Iqbal Khan","Surrayya Mobeen","Jahanzeb Rajput","Jamshed Riaz"],"pdf_url":"https://arxiv.org/pdf/2201.06180v2.pdf","comment":"submitted to IEEE Conference on Decision and Control (CDC), 2024"},{"id":"http://arxiv.org/abs/2403.18742v1","updated":"2024-03-27T16:39:28Z","published":"2024-03-27T16:39:28Z","title":"Understanding the Learning Dynamics of Alignment with Human Feedback","summary":"  Aligning large language models (LLMs) with human intentions has become a\ncritical task for safely deploying models in real-world systems. While existing\nalignment approaches have seen empirical success, theoretically understanding\nhow these methods affect model behavior remains an open question. Our work\nprovides an initial attempt to theoretically analyze the learning dynamics of\nhuman preference alignment. We formally show how the distribution of preference\ndatasets influences the rate of model updates and provide rigorous guarantees\non the training accuracy. Our theory also reveals an intricate phenomenon where\nthe optimization is prone to prioritizing certain behaviors with higher\npreference distinguishability. We empirically validate our findings on\ncontemporary LLMs and alignment tasks, reinforcing our theoretical insights and\nshedding light on considerations for future alignment approaches. Disclaimer:\nThis paper contains potentially offensive text; reader discretion is advised.\n","authors":["Shawn Im","Yixuan Li"],"pdf_url":"https://arxiv.org/pdf/2403.18742v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18731v1","updated":"2024-03-27T16:21:24Z","published":"2024-03-27T16:21:24Z","title":"Enhancing Manufacturing Quality Prediction Models through the\n  Integration of Explainability Methods","summary":"  This research presents a method that utilizes explainability techniques to\namplify the performance of machine learning (ML) models in forecasting the\nquality of milling processes, as demonstrated in this paper through a\nmanufacturing use case. The methodology entails the initial training of ML\nmodels, followed by a fine-tuning phase where irrelevant features identified\nthrough explainability methods are eliminated. This procedural refinement\nresults in performance enhancements, paving the way for potential reductions in\nmanufacturing costs and a better understanding of the trained ML models. This\nstudy highlights the usefulness of explainability techniques in both explaining\nand optimizing predictive models in the manufacturing realm.\n","authors":["Dennis Gross","Helge Spieker","Arnaud Gotlieb","Ricardo Knoblauch"],"pdf_url":"https://arxiv.org/pdf/2403.18731v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18725v1","updated":"2024-03-27T16:15:21Z","published":"2024-03-27T16:15:21Z","title":"Probabilistic Model Checking of Stochastic Reinforcement Learning\n  Policies","summary":"  We introduce a method to verify stochastic reinforcement learning (RL)\npolicies. This approach is compatible with any RL algorithm as long as the\nalgorithm and its corresponding environment collectively adhere to the Markov\nproperty. In this setting, the future state of the environment should depend\nsolely on its current state and the action executed, independent of any\nprevious states or actions. Our method integrates a verification technique,\nreferred to as model checking, with RL, leveraging a Markov decision process, a\ntrained RL policy, and a probabilistic computation tree logic (PCTL) formula to\nbuild a formal model that can be subsequently verified via the model checker\nStorm. We demonstrate our method's applicability across multiple benchmarks,\ncomparing it to baseline methods called deterministic safety estimates and\nnaive monolithic model checking. Our results show that our method is suited to\nverify stochastic RL policies.\n","authors":["Dennis Gross","Helge Spieker"],"pdf_url":"https://arxiv.org/pdf/2403.18725v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.03100v2","updated":"2024-03-27T16:14:34Z","published":"2024-03-05T16:35:25Z","title":"NaturalSpeech 3: Zero-Shot Speech Synthesis with Factorized Codec and\n  Diffusion Models","summary":"  While recent large-scale text-to-speech (TTS) models have achieved\nsignificant progress, they still fall short in speech quality, similarity, and\nprosody. Considering speech intricately encompasses various attributes (e.g.,\ncontent, prosody, timbre, and acoustic details) that pose significant\nchallenges for generation, a natural idea is to factorize speech into\nindividual subspaces representing different attributes and generate them\nindividually. Motivated by it, we propose NaturalSpeech 3, a TTS system with\nnovel factorized diffusion models to generate natural speech in a zero-shot\nway. Specifically, 1) we design a neural codec with factorized vector\nquantization (FVQ) to disentangle speech waveform into subspaces of content,\nprosody, timbre, and acoustic details; 2) we propose a factorized diffusion\nmodel to generate attributes in each subspace following its corresponding\nprompt. With this factorization design, NaturalSpeech 3 can effectively and\nefficiently model intricate speech with disentangled subspaces in a\ndivide-and-conquer way. Experiments show that NaturalSpeech 3 outperforms the\nstate-of-the-art TTS systems on quality, similarity, prosody, and\nintelligibility, and achieves on-par quality with human recordings.\nFurthermore, we achieve better performance by scaling to 1B parameters and 200K\nhours of training data.\n","authors":["Zeqian Ju","Yuancheng Wang","Kai Shen","Xu Tan","Detai Xin","Dongchao Yang","Yanqing Liu","Yichong Leng","Kaitao Song","Siliang Tang","Zhizheng Wu","Tao Qin","Xiang-Yang Li","Wei Ye","Shikun Zhang","Jiang Bian","Lei He","Jinyu Li","Sheng Zhao"],"pdf_url":"https://arxiv.org/pdf/2403.03100v2.pdf","comment":"Achieving human-level quality and naturalness on multi-speaker\n  datasets (e.g., LibriSpeech) in a zero-shot way"},{"id":"http://arxiv.org/abs/2403.18717v1","updated":"2024-03-27T16:06:37Z","published":"2024-03-27T16:06:37Z","title":"Semi-Supervised Learning for Deep Causal Generative Models","summary":"  Developing models that can answer questions of the form \"How would $x$ change\nif $y$ had been $z$?\" is fundamental for advancing medical image analysis.\nTraining causal generative models that address such counterfactual questions,\nthough, currently requires that all relevant variables have been observed and\nthat corresponding labels are available in training data. However, clinical\ndata may not have complete records for all patients and state of the art causal\ngenerative models are unable to take full advantage of this. We thus develop,\nfor the first time, a semi-supervised deep causal generative model that\nexploits the causal relationships between variables to maximise the use of all\navailable data. We explore this in the setting where each sample is either\nfully labelled or fully unlabelled, as well as the more clinically realistic\ncase of having different labels missing for each sample. We leverage techniques\nfrom causal inference to infer missing values and subsequently generate\nrealistic counterfactuals, even for samples with incomplete labels.\n","authors":["Yasin Ibrahim","Hermione Warr","Konstantinos Kamnitsas"],"pdf_url":"https://arxiv.org/pdf/2403.18717v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18715v1","updated":"2024-03-27T16:04:47Z","published":"2024-03-27T16:04:47Z","title":"Mitigating Hallucinations in Large Vision-Language Models with\n  Instruction Contrastive Decoding","summary":"  Large Vision-Language Models (LVLMs) are increasingly adept at generating\ncontextually detailed and coherent responses from visual inputs. However, their\napplication in multimodal decision-making and open-ended generation is hindered\nby a notable rate of hallucinations, where generated text inaccurately\nrepresents the visual contents. To address this issue, this paper introduces\nthe Instruction Contrastive Decoding (ICD) method, a novel approach designed to\nreduce hallucinations during LVLM inference. Our method is inspired by our\nobservation that what we call disturbance instructions significantly exacerbate\nhallucinations in multimodal fusion modules. ICD contrasts distributions from\nstandard and instruction disturbance, thereby increasing alignment uncertainty\nand effectively subtracting hallucinated concepts from the original\ndistribution. Through comprehensive experiments on discriminative benchmarks\n(POPE and MME) and a generative benchmark (LLaVa-Bench), we demonstrate that\nICD significantly mitigates both object-level and attribute-level\nhallucinations. Moreover, our method not only addresses hallucinations but also\nsignificantly enhances the general perception and recognition capabilities of\nLVLMs.\n","authors":["Xintong Wang","Jingheng Pan","Liang Ding","Chris Biemann"],"pdf_url":"https://arxiv.org/pdf/2403.18715v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.03123v3","updated":"2024-03-27T16:03:32Z","published":"2023-04-13T16:01:28Z","title":"ChatGPT Needs SPADE (Sustainability, PrivAcy, Digital divide, and\n  Ethics) Evaluation: A Review","summary":"  ChatGPT is another large language model (LLM) vastly available for the\nconsumers on their devices but due to its performance and ability to converse\neffectively, it has gained a huge popularity amongst research as well as\nindustrial community. Recently, many studies have been published to show the\neffectiveness, efficiency, integration, and sentiments of chatGPT and other\nLLMs. In contrast, this study focuses on the important aspects that are mostly\noverlooked, i.e. sustainability, privacy, digital divide, and ethics and\nsuggests that not only chatGPT but every subsequent entry in the category of\nconversational bots should undergo Sustainability, PrivAcy, Digital divide, and\nEthics (SPADE) evaluation. This paper discusses in detail the issues and\nconcerns raised over chatGPT in line with aforementioned characteristics. We\nalso discuss the recent EU AI Act briefly in accordance with the SPADE\nevaluation. We support our hypothesis by some preliminary data collection and\nvisualizations along with hypothesized facts. We also suggest mitigations and\nrecommendations for each of the concerns. Furthermore, we also suggest some\npolicies and recommendations for EU AI policy act concerning ethics, digital\ndivide, and sustainability.\n","authors":["Sunder Ali Khowaja","Parus Khuwaja","Kapal Dev","Weizheng Wang","Lewis Nkenyereye"],"pdf_url":"https://arxiv.org/pdf/2305.03123v3.pdf","comment":"29 pages, 8 figures, 4 tables"},{"id":"http://arxiv.org/abs/2403.18711v1","updated":"2024-03-27T15:58:25Z","published":"2024-03-27T15:58:25Z","title":"SAT-NGP : Unleashing Neural Graphics Primitives for Fast Relightable\n  Transient-Free 3D reconstruction from Satellite Imagery","summary":"  Current stereo-vision pipelines produce high accuracy 3D reconstruction when\nusing multiple pairs or triplets of satellite images. However, these pipelines\nare sensitive to the changes between images that can occur as a result of\nmulti-date acquisitions. Such variations are mainly due to variable shadows,\nreflexions and transient objects (cars, vegetation). To take such changes into\naccount, Neural Radiance Fields (NeRF) have recently been applied to multi-date\nsatellite imagery. However, Neural methods are very compute-intensive, taking\ndozens of hours to learn, compared with minutes for standard stereo-vision\npipelines. Following the ideas of Instant Neural Graphics Primitives we propose\nto use an efficient sampling strategy and multi-resolution hash encoding to\naccelerate the learning. Our model, Satellite Neural Graphics Primitives\n(SAT-NGP) decreases the learning time to 15 minutes while maintaining the\nquality of the 3D reconstruction.\n","authors":["Camille Billouard","Dawa Derksen","Emmanuelle Sarrazin","Bruno Vallet"],"pdf_url":"https://arxiv.org/pdf/2403.18711v1.pdf","comment":"5 pages, 3 figures, 1 table; Accepted to International Geoscience and\n  Remote Sensing Symposium (IGARSS) 2024; Code available at\n  https://github.com/Ellimac0/SAT-NGP"},{"id":"http://arxiv.org/abs/2401.15120v2","updated":"2024-03-27T15:49:52Z","published":"2024-01-26T03:44:58Z","title":"Incorporating simulated spatial context information improves the\n  effectiveness of contrastive learning models","summary":"  Visual learning often occurs in a specific context, where an agent acquires\nskills through exploration and tracking of its location in a consistent\nenvironment. The historical spatial context of the agent provides a similarity\nsignal for self-supervised contrastive learning. We present a unique approach,\ntermed Environmental Spatial Similarity (ESS), that complements existing\ncontrastive learning methods. Using images from simulated, photorealistic\nenvironments as an experimental setting, we demonstrate that ESS outperforms\ntraditional instance discrimination approaches. Moreover, sampling additional\ndata from the same environment substantially improves accuracy and provides new\naugmentations. ESS allows remarkable proficiency in room classification and\nspatial prediction tasks, especially in unfamiliar environments. This learning\nparadigm has the potential to enable rapid visual learning in agents operating\nin new environments with unique visual characteristics. Potentially\ntransformative applications span from robotics to space exploration. Our proof\nof concept demonstrates improved efficiency over methods that rely on\nextensive, disconnected datasets.\n","authors":["Lizhen Zhu","James Z. Wang","Wonseuk Lee","Brad Wyble"],"pdf_url":"https://arxiv.org/pdf/2401.15120v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.11800v3","updated":"2024-03-27T15:48:29Z","published":"2024-02-19T03:08:02Z","title":"Stochastic Approximation with Delayed Updates: Finite-Time Rates under\n  Markovian Sampling","summary":"  Motivated by applications in large-scale and multi-agent reinforcement\nlearning, we study the non-asymptotic performance of stochastic approximation\n(SA) schemes with delayed updates under Markovian sampling. While the effect of\ndelays has been extensively studied for optimization, the manner in which they\ninteract with the underlying Markov process to shape the finite-time\nperformance of SA remains poorly understood. In this context, our first main\ncontribution is to show that under time-varying bounded delays, the delayed SA\nupdate rule guarantees exponentially fast convergence of the \\emph{last\niterate} to a ball around the SA operator's fixed point. Notably, our bound is\n\\emph{tight} in its dependence on both the maximum delay $\\tau_{max}$, and the\nmixing time $\\tau_{mix}$. To achieve this tight bound, we develop a novel\ninductive proof technique that, unlike various existing delayed-optimization\nanalyses, relies on establishing uniform boundedness of the iterates. As such,\nour proof may be of independent interest. Next, to mitigate the impact of the\nmaximum delay on the convergence rate, we provide the first finite-time\nanalysis of a delay-adaptive SA scheme under Markovian sampling. In particular,\nwe show that the exponent of convergence of this scheme gets scaled down by\n$\\tau_{avg}$, as opposed to $\\tau_{max}$ for the vanilla delayed SA rule; here,\n$\\tau_{avg}$ denotes the average delay across all iterations. Moreover, the\nadaptive scheme requires no prior knowledge of the delay sequence for step-size\ntuning. Our theoretical findings shed light on the finite-time effects of\ndelays for a broad class of algorithms, including TD learning, Q-learning, and\nstochastic gradient descent under Markovian sampling.\n","authors":["Arman Adibi","Nicolo Dal Fabbro","Luca Schenato","Sanjeev Kulkarni","H. Vincent Poor","George J. Pappas","Hamed Hassani","Aritra Mitra"],"pdf_url":"https://arxiv.org/pdf/2402.11800v3.pdf","comment":"Accepted to the 27th International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2024!"},{"id":"http://arxiv.org/abs/2403.18699v1","updated":"2024-03-27T15:48:16Z","published":"2024-03-27T15:48:16Z","title":"Contrastive Learning with Orthonormal Anchors (CLOA)","summary":"  This study focuses on addressing the instability issues prevalent in\ncontrastive learning, specifically examining the InfoNCE loss function and its\nderivatives. We reveal a critical observation that these loss functions exhibit\na restrictive behavior, leading to a convergence phenomenon where embeddings\ntend to merge into a singular point. This \"over-fusion\" effect detrimentally\naffects classification accuracy in subsequent supervised-learning tasks.\nThrough theoretical analysis, we demonstrate that embeddings, when equalized or\nconfined to a rank-1 linear subspace, represent a local minimum for InfoNCE. In\nresponse to this challenge, our research introduces an innovative strategy that\nleverages the same or fewer labeled data than typically used in the fine-tuning\nphase. The loss we proposed, Orthonormal Anchor Regression Loss, is designed to\ndisentangle embedding clusters, significantly enhancing the distinctiveness of\neach embedding while simultaneously ensuring their aggregation into dense,\nwell-defined clusters. Our method demonstrates remarkable improvements with\njust a fraction of the conventional label requirements, as evidenced by our\nresults on CIFAR10 and CIFAR100 datasets.\n","authors":["Huanran Li","Daniel Pimentel-Alarcón"],"pdf_url":"https://arxiv.org/pdf/2403.18699v1.pdf","comment":"11 pages, 4 figures"},{"id":"http://arxiv.org/abs/2303.12091v3","updated":"2024-03-27T15:44:25Z","published":"2023-03-21T09:07:15Z","title":"Adaptive Negative Evidential Deep Learning for Open-set Semi-supervised\n  Learning","summary":"  Semi-supervised learning (SSL) methods assume that labeled data, unlabeled\ndata and test data are from the same distribution. Open-set semi-supervised\nlearning (Open-set SSL) considers a more practical scenario, where unlabeled\ndata and test data contain new categories (outliers) not observed in labeled\ndata (inliers). Most previous works focused on outlier detection via binary\nclassifiers, which suffer from insufficient scalability and inability to\ndistinguish different types of uncertainty. In this paper, we propose a novel\nframework, Adaptive Negative Evidential Deep Learning (ANEDL) to tackle these\nlimitations. Concretely, we first introduce evidential deep learning (EDL) as\nan outlier detector to quantify different types of uncertainty, and design\ndifferent uncertainty metrics for self-training and inference. Furthermore, we\npropose a novel adaptive negative optimization strategy, making EDL more\ntailored to the unlabeled dataset containing both inliers and outliers. As\ndemonstrated empirically, our proposed method outperforms existing\nstate-of-the-art methods across four datasets.\n","authors":["Yang Yu","Danruo Deng","Furui Liu","Yueming Jin","Qi Dou","Guangyong Chen","Pheng-Ann Heng"],"pdf_url":"https://arxiv.org/pdf/2303.12091v3.pdf","comment":"Accepted by AAAI2024"},{"id":"http://arxiv.org/abs/2403.18690v1","updated":"2024-03-27T15:41:23Z","published":"2024-03-27T15:41:23Z","title":"Annolid: Annotate, Segment, and Track Anything You Need","summary":"  Annolid is a deep learning-based software package designed for the\nsegmentation, labeling, and tracking of research targets within video files,\nfocusing primarily on animal behavior analysis. Based on state-of-the-art\ninstance segmentation methods, Annolid now harnesses the Cutie video object\nsegmentation model to achieve resilient, markerless tracking of multiple\nanimals from single annotated frames, even in environments in which they may be\npartially or entirely concealed by environmental features or by one another.\nOur integration of Segment Anything and Grounding-DINO strategies additionally\nenables the automatic masking and segmentation of recognizable animals and\nobjects by text command, removing the need for manual annotation. Annolid's\ncomprehensive approach to object segmentation flexibly accommodates a broad\nspectrum of behavior analysis applications, enabling the classification of\ndiverse behavioral states such as freezing, digging, pup huddling, and social\ninteractions in addition to the tracking of animals and their body parts.\n","authors":["Chen Yang","Thomas A. Cleland"],"pdf_url":"https://arxiv.org/pdf/2403.18690v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18681v1","updated":"2024-03-27T15:24:54Z","published":"2024-03-27T15:24:54Z","title":"TransFusion: Contrastive Learning with Transformers","summary":"  This paper proposes a novel framework, TransFusion, designed to make the\nprocess of contrastive learning more analytical and explainable. TransFusion\nconsists of attention blocks whose softmax being replaced by ReLU, and its\nfinal block's weighted-sum operation is truncated to leave the adjacency matrix\nas the output. The model is trained by minimizing the Jensen-Shannon Divergence\nbetween its output and the target affinity matrix, which indicates whether each\npair of samples belongs to the same or different classes. The main contribution\nof TransFusion lies in defining a theoretical limit for answering two\nfundamental questions in the field: the maximum level of data augmentation and\nthe minimum batch size required for effective contrastive learning.\nFurthermore, experimental results indicate that TransFusion successfully\nextracts features that isolate clusters from complex real-world data, leading\nto improved classification accuracy in downstream tasks.\n","authors":["Huanran Li","Daniel Pimentel-Alarcón"],"pdf_url":"https://arxiv.org/pdf/2403.18681v1.pdf","comment":"17 pages, 4 figures,"},{"id":"http://arxiv.org/abs/2403.18668v1","updated":"2024-03-27T15:11:07Z","published":"2024-03-27T15:11:07Z","title":"Aiming for Relevance","summary":"  Vital signs are crucial in intensive care units (ICUs). They are used to\ntrack the patient's state and to identify clinically significant changes.\nPredicting vital sign trajectories is valuable for early detection of adverse\nevents. However, conventional machine learning metrics like RMSE often fail to\ncapture the true clinical relevance of such predictions. We introduce novel\nvital sign prediction performance metrics that align with clinical contexts,\nfocusing on deviations from clinical norms, overall trends, and trend\ndeviations. These metrics are derived from empirical utility curves obtained in\na previous study through interviews with ICU clinicians. We validate the\nmetrics' usefulness using simulated and real clinical datasets (MIMIC and\neICU). Furthermore, we employ these metrics as loss functions for neural\nnetworks, resulting in models that excel in predicting clinically significant\nevents. This research paves the way for clinically relevant machine learning\nmodel evaluation and optimization, promising to improve ICU patient care. 10\npages, 9 figures.\n","authors":["Bar Eini Porat","Danny Eytan","Uri Shalit"],"pdf_url":"https://arxiv.org/pdf/2403.18668v1.pdf","comment":"10 pages, 9 figures, AMIA Informatics 2024"},{"id":"http://arxiv.org/abs/2403.17219v2","updated":"2024-03-27T15:08:31Z","published":"2024-03-25T21:48:22Z","title":"SeSaMe: A Framework to Simulate Self-Reported Ground Truth for Mental\n  Health Sensing Studies","summary":"  Advances in mobile and wearable technologies have enabled the potential to\npassively monitor a person's mental, behavioral, and affective health. These\napproaches typically rely on longitudinal collection of self-reported outcomes,\ne.g., depression, stress, and anxiety, to train machine learning (ML) models.\nHowever, the need to continuously self-report adds a significant burden on the\nparticipants, often resulting in attrition, missing labels, or insincere\nresponses. In this work, we introduce the Scale Scores Simulation using Mental\nModels (SeSaMe) framework to alleviate participants' burden in digital mental\nhealth studies. By leveraging pre-trained large language models (LLMs), SeSaMe\nenables the simulation of participants' responses on psychological scales. In\nSeSaMe, researchers can prompt LLMs with information on participants' internal\nbehavioral dispositions, enabling LLMs to construct mental models of\nparticipants to simulate their responses on psychological scales. We\ndemonstrate an application of SeSaMe, where we use GPT-4 to simulate responses\non one scale using responses from another as behavioral information. We also\nevaluate the alignment between human and SeSaMe-simulated responses to\npsychological scales. Then, we present experiments to inspect the utility of\nSeSaMe-simulated responses as ground truth in training ML models by replicating\nestablished depression and anxiety screening tasks from a previous study. Our\nresults indicate SeSaMe to be a promising approach, but its alignment may vary\nacross scales and specific prediction objectives. We also observed that model\nperformance with simulated data was on par with using the real data for\ntraining in most evaluation scenarios. We conclude by discussing the potential\nimplications of SeSaMe in addressing some challenges researchers face with\nground-truth collection in passive sensing studies.\n","authors":["Akshat Choube","Vedant Das Swain","Varun Mishra"],"pdf_url":"https://arxiv.org/pdf/2403.17219v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18659v1","updated":"2024-03-27T15:03:33Z","published":"2024-03-27T15:03:33Z","title":"INEXA: Interactive and Explainable Process Model Abstraction Through\n  Object-Centric Process Mining","summary":"  Process events are recorded by multiple information systems at different\ngranularity levels. Based on the resulting event logs, process models are\ndiscovered at different granularity levels, as well. Events stored at a\nfine-grained granularity level, for example, may hinder the discovered process\nmodel to be displayed due the high number of resulting model elements. The\ndiscovered process model of a real-world manufacturing process, for example,\nconsists of 1,489 model elements and over 2,000 arcs. Existing process model\nabstraction techniques could help reducing the size of the model, but would\ndisconnect it from the underlying event log. Existing event abstraction\ntechniques do neither support the analysis of mixed granularity levels, nor\ninteractive exploration of a suitable granularity level. To enable the\nexploration of discovered process models at different granularity levels, we\npropose INEXA, an interactive, explainable process model abstraction method\nthat keeps the link to the event log. As a starting point, INEXA aggregates\nlarge process models to a \"displayable\" size, e.g., for the manufacturing use\ncase to a process model with 58 model elements. Then, the process analyst can\nexplore granularity levels interactively, while applied abstractions are\nautomatically traced in the event log for explainability.\n","authors":["Janik-Vasily Benzin","Gyunam Park","Juergen Mangler","Stefanie Rinderle-Ma"],"pdf_url":"https://arxiv.org/pdf/2403.18659v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13374v3","updated":"2024-03-27T14:57:54Z","published":"2024-03-20T08:15:08Z","title":"Byzantine-resilient Federated Learning With Adaptivity to Data\n  Heterogeneity","summary":"  This paper deals with federated learning (FL) in the presence of malicious\nByzantine attacks and data heterogeneity. A novel Robust Average Gradient\nAlgorithm (RAGA) is proposed, which leverages the geometric median for\naggregation and can freely select the round number for local updating.\nDifferent from most existing resilient approaches, which perform convergence\nanalysis based on strongly-convex loss function or homogeneously distributed\ndataset, we conduct convergence analysis for not only strongly-convex but also\nnon-convex loss function over heterogeneous dataset. According to our\ntheoretical analysis, as long as the fraction of dataset from malicious users\nis less than half, RAGA can achieve convergence at rate\n$\\mathcal{O}({1}/{T^{2/3- \\delta}})$ where $T$ is the iteration number and\n$\\delta \\in (0, 2/3)$ for non-convex loss function, and at linear rate for\nstrongly-convex loss function. Moreover, stationary point or global optimal\nsolution is proved to obtainable as data heterogeneity vanishes. Experimental\nresults corroborate the robustness of RAGA to Byzantine attacks and verifies\nthe advantage of RAGA over baselines on convergence performance under various\nintensity of Byzantine attacks, for heterogeneous dataset.\n","authors":["Shiyuan Zuo","Xingrun Yan","Rongfei Fan","Han Hu","Hangguan Shan","Tony Q. S. Quek"],"pdf_url":"https://arxiv.org/pdf/2403.13374v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.17251v2","updated":"2024-03-27T14:48:48Z","published":"2023-03-30T09:29:53Z","title":"Demystifying Misconceptions in Social Bots Research","summary":"  Research on social bots aims at advancing knowledge and providing solutions\nto one of the most debated forms of online manipulation. Yet, social bot\nresearch is plagued by widespread biases, hyped results, and misconceptions\nthat set the stage for ambiguities, unrealistic expectations, and seemingly\nirreconcilable findings. Overcoming such issues is instrumental towards\nensuring reliable solutions and reaffirming the validity of the scientific\nmethod. In this contribution, we review some recent results in social bots\nresearch, highlighting and revising factual errors as well as methodological\nand conceptual biases. More importantly, we demystify common misconceptions,\naddressing fundamental points on how social bots research is discussed. Our\nanalysis surfaces the need to discuss research about online disinformation and\nmanipulation in a rigorous, unbiased, and responsible way. This article\nbolsters such effort by identifying and refuting common fallacious arguments\nused by both proponents and opponents of social bots research, as well as\nproviding directions toward sound methodologies for future research in the\nfield.\n","authors":["Stefano Cresci","Kai-Cheng Yang","Angelo Spognardi","Roberto Di Pietro","Filippo Menczer","Marinella Petrocchi"],"pdf_url":"https://arxiv.org/pdf/2303.17251v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16451v3","updated":"2024-03-27T14:36:21Z","published":"2024-03-25T06:30:54Z","title":"DeepMachining: Online Prediction of Machining Errors of Lathe Machines","summary":"  We describe DeepMachining, a deep learning-based AI system for online\nprediction of machining errors of lathe machine operations. We have built and\nevaluated DeepMachining based on manufacturing data from factories.\nSpecifically, we first pretrain a deep learning model for a given lathe\nmachine's operations to learn the salient features of machining states. Then,\nwe fine-tune the pretrained model to adapt to specific machining tasks. We\ndemonstrate that DeepMachining achieves high prediction accuracy for multiple\ntasks that involve different workpieces and cutting tools. To the best of our\nknowledge, this work is one of the first factory experiments using pre-trained\ndeep-learning models to predict machining errors of lathe machines.\n","authors":["Xiang-Li Lu","Hwai-Jung Hsu","Che-Wei Chou","H. T. Kung","Chen-Hsin Lee"],"pdf_url":"https://arxiv.org/pdf/2403.16451v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.13284v2","updated":"2024-03-27T14:30:44Z","published":"2024-02-19T09:07:59Z","title":"Structure Guided Large Language Model for SQL Generation","summary":"  Generating accurate Structured Querying Language (SQL) is a long-standing\nproblem, especially in matching users' semantic queries with structured\ndatabases and then generating structured SQL. Existing models typically input\nqueries and database schemas into the LLM and rely on the LLM to perform\nsemantic-structure matching and generate structured SQL. However, such\nsolutions overlook the structural information within user queries and\ndatabases, which can be utilized to enhance the generation of structured SQL.\nThis oversight can lead to inaccurate or unexecutable SQL generation. To fully\nexploit the structure, we propose a structure-to-SQL framework, which leverages\nthe inherent structure information to improve the SQL generation of LLMs.\nSpecifically, we introduce our Structure Guided SQL~(SGU-SQL) generation model.\nSGU-SQL first links user queries and databases in a structure-enhanced manner.\nIt then decomposes complicated linked structures with grammar trees to guide\nthe LLM to generate the SQL step by step. Extensive experiments on two\nbenchmark datasets illustrate that SGU-SQL can outperform sixteen SQL\ngeneration baselines.\n","authors":["Qinggang Zhang","Junnan Dong","Hao Chen","Wentao Li","Feiran Huang","Xiao Huang"],"pdf_url":"https://arxiv.org/pdf/2402.13284v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18607v1","updated":"2024-03-27T14:25:02Z","published":"2024-03-27T14:25:02Z","title":"Spikewhisper: Temporal Spike Backdoor Attacks on Federated Neuromorphic\n  Learning over Low-power Devices","summary":"  Federated neuromorphic learning (FedNL) leverages event-driven spiking neural\nnetworks and federated learning frameworks to effectively execute intelligent\nanalysis tasks over amounts of distributed low-power devices but also perform\nvulnerability to poisoning attacks. The threat of backdoor attacks on\ntraditional deep neural networks typically comes from time-invariant data.\nHowever, in FedNL, unknown threats may be hidden in time-varying spike signals.\nIn this paper, we start to explore a novel vulnerability of FedNL-based systems\nwith the concept of time division multiplexing, termed Spikewhisper, which\nallows attackers to evade detection as much as possible, as multiple malicious\nclients can imperceptibly poison with different triggers at different\ntimeslices. In particular, the stealthiness of Spikewhisper is derived from the\ntime-domain divisibility of global triggers, in which each malicious client\npastes only one local trigger to a certain timeslice in the neuromorphic\nsample, and also the polarity and motion of each local trigger can be\nconfigured by attackers. Extensive experiments based on two different\nneuromorphic datasets demonstrate that the attack success rate of Spikewispher\nis higher than the temporally centralized attacks. Besides, it is validated\nthat the effect of Spikewispher is sensitive to the trigger duration.\n","authors":["Hanqing Fu","Gaolei Li","Jun Wu","Jianhua Li","Xi Lin","Kai Zhou","Yuchen Liu"],"pdf_url":"https://arxiv.org/pdf/2403.18607v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18600v1","updated":"2024-03-27T14:22:40Z","published":"2024-03-27T14:22:40Z","title":"RAP: Retrieval-Augmented Planner for Adaptive Procedure Planning in\n  Instructional Videos","summary":"  Procedure Planning in instructional videos entails generating a sequence of\naction steps based on visual observations of the initial and target states.\nDespite the rapid progress in this task, there remain several critical\nchallenges to be solved: (1) Adaptive procedures: Prior works hold an\nunrealistic assumption that the number of action steps is known and fixed,\nleading to non-generalizable models in real-world scenarios where the sequence\nlength varies. (2) Temporal relation: Understanding the step temporal relation\nknowledge is essential in producing reasonable and executable plans. (3)\nAnnotation cost: Annotating instructional videos with step-level labels (i.e.,\ntimestamp) or sequence-level labels (i.e., action category) is demanding and\nlabor-intensive, limiting its generalizability to large-scale datasets.In this\nwork, we propose a new and practical setting, called adaptive procedure\nplanning in instructional videos, where the procedure length is not fixed or\npre-determined. To address these challenges we introduce Retrieval-Augmented\nPlanner (RAP) model. Specifically, for adaptive procedures, RAP adaptively\ndetermines the conclusion of actions using an auto-regressive model\narchitecture. For temporal relation, RAP establishes an external memory module\nto explicitly retrieve the most relevant state-action pairs from the training\nvideos and revises the generated procedures. To tackle high annotation cost,\nRAP utilizes a weakly-supervised learning manner to expand the training dataset\nto other task-relevant, unannotated videos by generating pseudo labels for\naction steps. Experiments on CrossTask and COIN benchmarks show the superiority\nof RAP over traditional fixed-length models, establishing it as a strong\nbaseline solution for adaptive procedure planning.\n","authors":["Ali Zare","Yulei Niu","Hammad Ayyubi","Shih-fu Chang"],"pdf_url":"https://arxiv.org/pdf/2403.18600v1.pdf","comment":"23 pages, 6 figures, 12 tables"},{"id":"http://arxiv.org/abs/2403.18593v1","updated":"2024-03-27T14:18:09Z","published":"2024-03-27T14:18:09Z","title":"Homogeneous Tokenizer Matters: Homogeneous Visual Tokenizer for Remote\n  Sensing Image Understanding","summary":"  The tokenizer, as one of the fundamental components of large models, has long\nbeen overlooked or even misunderstood in visual tasks. One key factor of the\ngreat comprehension power of the large language model is that natural language\ntokenizers utilize meaningful words or subwords as the basic elements of\nlanguage. In contrast, mainstream visual tokenizers, represented by patch-based\nmethods such as Patch Embed, rely on meaningless rectangular patches as basic\nelements of vision, which cannot serve as effectively as words or subwords in\nlanguage. Starting from the essence of the tokenizer, we defined semantically\nindependent regions (SIRs) for vision. We designed a simple HOmogeneous visual\ntOKenizer: HOOK. HOOK mainly consists of two modules: the Object Perception\nModule (OPM) and the Object Vectorization Module (OVM). To achieve homogeneity,\nthe OPM splits the image into 4*4 pixel seeds and then utilizes the attention\nmechanism to perceive SIRs. The OVM employs cross-attention to merge seeds\nwithin the same SIR. To achieve adaptability, the OVM defines a variable number\nof learnable vectors as cross-attention queries, allowing for the adjustment of\ntoken quantity. We conducted experiments on the NWPU-RESISC45, WHU-RS19\nclassification dataset, and GID5 segmentation dataset for sparse and dense\ntasks. The results demonstrate that the visual tokens obtained by HOOK\ncorrespond to individual objects, which demonstrates homogeneity. HOOK\noutperformed Patch Embed by 6\\% and 10\\% in the two tasks and achieved\nstate-of-the-art performance compared to the baselines used for comparison.\nCompared to Patch Embed, which requires more than one hundred tokens for one\nimage, HOOK requires only 6 and 8 tokens for sparse and dense tasks,\nrespectively, resulting in efficiency improvements of 1.5 to 2.8 times. The\ncode is available at https://github.com/GeoX-Lab/Hook.\n","authors":["Run Shao","Zhaoyang Zhang","Chao Tao","Yunsheng Zhang","Chengli Peng","Haifeng Li"],"pdf_url":"https://arxiv.org/pdf/2403.18593v1.pdf","comment":"20 pages, 8 figures, 6 tables"},{"id":"http://arxiv.org/abs/2306.09459v3","updated":"2024-03-27T14:02:58Z","published":"2023-06-15T19:29:08Z","title":"Recurrent Action Transformer with Memory","summary":"  Recently, the use of transformers in offline reinforcement learning has\nbecome a rapidly developing area. This is due to their ability to treat the\nagent's trajectory in the environment as a sequence, thereby reducing the\npolicy learning problem to sequence modeling. In environments where the agent's\ndecisions depend on past events, it is essential to capture both the event\nitself and the decision point in the context of the model. However, the\nquadratic complexity of the attention mechanism limits the potential for\ncontext expansion. One solution to this problem is to enhance transformers with\nmemory mechanisms. In this paper, we propose the Recurrent Action Transformer\nwith Memory (RATE) - a model that incorporates recurrent memory. To evaluate\nour model, we conducted extensive experiments on both memory-intensive\nenvironments (VizDoom-Two-Color, T-Maze) and classic Atari games and MuJoCo\ncontrol environments. The results show that the use of memory can significantly\nimprove performance in memory-intensive environments while maintaining or\nimproving results in classic environments. We hope that our findings will\nstimulate research on memory mechanisms for transformers applicable to offline\nreinforcement learning.\n","authors":["Alexey Staroverov","Egor Cherepanov","Dmitry Yudin","Alexey K. Kovalev","Aleksandr I. Panov"],"pdf_url":"https://arxiv.org/pdf/2306.09459v3.pdf","comment":"15 pages, 11 figures"},{"id":"http://arxiv.org/abs/2309.11427v2","updated":"2024-03-27T14:02:57Z","published":"2023-09-20T16:01:45Z","title":"Generative Pre-Training of Time-Series Data for Unsupervised Fault\n  Detection in Semiconductor Manufacturing","summary":"  This paper introduces TRACE-GPT, which stands for Time-seRies\nAnomaly-detection with Convolutional Embedding and Generative Pre-trained\nTransformers. TRACE-GPT is designed to pre-train univariate time-series sensor\ndata and detect faults on unlabeled datasets in semiconductor manufacturing. In\nsemiconductor industry, classifying abnormal time-series sensor data from\nnormal data is important because it is directly related to wafer defect.\nHowever, small, unlabeled, and even mixed training data without enough\nanomalies make classification tasks difficult. In this research, we capture\nfeatures of time-series data with temporal convolutional embedding and\nGenerative Pre-trained Transformer (GPT) to classify abnormal sequences from\nnormal sequences using cross entropy loss. We prove that our model shows better\nperformance than previous unsupervised models with both an open dataset, the\nUniversity of California Riverside (UCR) time-series classification archive,\nand the process log of our Chemical Vapor Deposition (CVD) equipment. Our model\nhas the highest F1 score at Equal Error Rate (EER) across all datasets and is\nonly 0.026 below the supervised state-of-the-art baseline on the open dataset.\n","authors":["Sewoong Lee","JinKyou Choi","Min Su Kim"],"pdf_url":"https://arxiv.org/pdf/2309.11427v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.09283v3","updated":"2024-03-27T13:55:14Z","published":"2024-02-14T16:14:03Z","title":"Attacks, Defenses and Evaluations for LLM Conversation Safety: A Survey","summary":"  Large Language Models (LLMs) are now commonplace in conversation\napplications. However, their risks of misuse for generating harmful responses\nhave raised serious societal concerns and spurred recent research on LLM\nconversation safety. Therefore, in this survey, we provide a comprehensive\noverview of recent studies, covering three critical aspects of LLM conversation\nsafety: attacks, defenses, and evaluations. Our goal is to provide a structured\nsummary that enhances understanding of LLM conversation safety and encourages\nfurther investigation into this important subject. For easy reference, we have\ncategorized all the studies mentioned in this survey according to our taxonomy,\navailable at: https://github.com/niconi19/LLM-conversation-safety.\n","authors":["Zhichen Dong","Zhanhui Zhou","Chao Yang","Jing Shao","Yu Qiao"],"pdf_url":"https://arxiv.org/pdf/2402.09283v3.pdf","comment":"Accepted to NAACL 2024"},{"id":"http://arxiv.org/abs/2403.18570v1","updated":"2024-03-27T13:51:26Z","published":"2024-03-27T13:51:26Z","title":"Physics-Informed Graph Neural Networks for Water Distribution Systems","summary":"  Water distribution systems (WDS) are an integral part of critical\ninfrastructure which is pivotal to urban development. As 70% of the world's\npopulation will likely live in urban environments in 2050, efficient simulation\nand planning tools for WDS play a crucial role in reaching UN's sustainable\ndevelopmental goal (SDG) 6 - \"Clean water and sanitation for all\". In this\nrealm, we propose a novel and efficient machine learning emulator, more\nprecisely, a physics-informed deep learning (DL) model, for hydraulic state\nestimation in WDS. Using a recursive approach, our model only needs a few graph\nconvolutional neural network (GCN) layers and employs an innovative algorithm\nbased on message passing. Unlike conventional machine learning tasks, the model\nuses hydraulic principles to infer two additional hydraulic state features in\nthe process of reconstructing the available ground truth feature in an\nunsupervised manner. To the best of our knowledge, this is the first DL\napproach to emulate the popular hydraulic simulator EPANET, utilizing no\nadditional information. Like most DL models and unlike the hydraulic simulator,\nour model demonstrates vastly faster emulation times that do not increase\ndrastically with the size of the WDS. Moreover, we achieve high accuracy on the\nground truth and very similar results compared to the hydraulic simulator as\ndemonstrated through experiments on five real-world WDS datasets.\n","authors":["Inaam Ashraf","Janine Strotherm","Luca Hermes","Barbara Hammer"],"pdf_url":"https://arxiv.org/pdf/2403.18570v1.pdf","comment":"Extended version of the paper with the same title published at\n  Proceedings of the AAAI Conference on Artificial Intelligence 2024"},{"id":"http://arxiv.org/abs/2403.18569v1","updated":"2024-03-27T13:50:13Z","published":"2024-03-27T13:50:13Z","title":"PDNNet: PDN-Aware GNN-CNN Heterogeneous Network for Dynamic IR Drop\n  Prediction","summary":"  IR drop on the power delivery network (PDN) is closely related to PDN's\nconfiguration and cell current consumption. As the integrated circuit (IC)\ndesign is growing larger, dynamic IR drop simulation becomes computationally\nunaffordable and machine learning based IR drop prediction has been explored as\na promising solution. Although CNN-based methods have been adapted to IR drop\nprediction task in several works, the shortcomings of overlooking PDN\nconfiguration is non-negligible. In this paper, we consider not only how to\nproperly represent cell-PDN relation, but also how to model IR drop following\nits physical nature in the feature aggregation procedure. Thus, we propose a\nnovel graph structure, PDNGraph, to unify the representations of the PDN\nstructure and the fine-grained cell-PDN relation. We further propose a\ndual-branch heterogeneous network, PDNNet, incorporating two parallel GNN-CNN\nbranches to favorably capture the above features during the learning process.\nSeveral key designs are presented to make the dynamic IR drop prediction highly\neffective and interpretable. We are the first work to apply graph structure to\ndeep-learning based dynamic IR drop prediction method. Experiments show that\nPDNNet outperforms the state-of-the-art CNN-based methods by up to 39.3%\nreduction in prediction error and achieves 545x speedup compared to the\ncommercial tool, which demonstrates the superiority of our method.\n","authors":["Yuxiang Zhao","Zhuomin Chai","Xun Jiang","Yibo Lin","Runsheng Wang","Ru Huang"],"pdf_url":"https://arxiv.org/pdf/2403.18569v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.09700v2","updated":"2024-03-27T13:42:25Z","published":"2024-03-05T22:19:21Z","title":"Shapley Values-Powered Framework for Fair Reward Split in Content\n  Produced by GenAI","summary":"  It is evident that, currently, generative models are surpassed in quality by\nhuman professionals. However, with the advancements in Artificial Intelligence,\nthis gap will narrow, leading to scenarios where individuals who have dedicated\nyears of their lives to mastering a skill become obsolete due to their high\ncosts, which are inherently linked to the time they require to complete a task\n-- a task that AI could accomplish in minutes or seconds. To avoid future\nsocial upheavals, we must, even now, contemplate how to fairly assess the\ncontributions of such individuals in training generative models and how to\ncompensate them for the reduction or complete loss of their incomes. In this\nwork, we propose a method to structure collaboration between model developers\nand data providers. To achieve this, we employ Shapley Values to quantify the\ncontribution of artist(s) in an image generated by the Stable Diffusion-v1.5\nmodel and to equitably allocate the reward among them.\n","authors":["Alex Glinsky","Alexey Sokolsky"],"pdf_url":"https://arxiv.org/pdf/2403.09700v2.pdf","comment":"36 pages, 32 figures"},{"id":"http://arxiv.org/abs/2310.00117v4","updated":"2024-03-27T13:38:00Z","published":"2023-09-29T20:11:15Z","title":"ABScribe: Rapid Exploration & Organization of Multiple Writing\n  Variations in Human-AI Co-Writing Tasks using Large Language Models","summary":"  Exploring alternative ideas by rewriting text is integral to the writing\nprocess. State-of-the-art Large Language Models (LLMs) can simplify writing\nvariation generation. However, current interfaces pose challenges for\nsimultaneous consideration of multiple variations: creating new variations\nwithout overwriting text can be difficult, and pasting them sequentially can\nclutter documents, increasing workload and disrupting writers' flow. To tackle\nthis, we present ABScribe, an interface that supports rapid, yet visually\nstructured, exploration and organization of writing variations in human-AI\nco-writing tasks. With ABScribe, users can swiftly modify variations using LLM\nprompts, which are auto-converted into reusable buttons. Variations are stored\nadjacently within text fields for rapid in-place comparisons using mouse-over\ninteractions on a popup toolbar. Our user study with 12 writers shows that\nABScribe significantly reduces task workload (d = 1.20, p < 0.001), enhances\nuser perceptions of the revision process (d = 2.41, p < 0.001) compared to a\npopular baseline workflow, and provides insights into how writers explore\nvariations using LLMs.\n","authors":["Mohi Reza","Nathan Laundry","Ilya Musabirov","Peter Dushniku","Zhi Yuan \"Michael\" Yu","Kashish Mittal","Tovi Grossman","Michael Liut","Anastasia Kuzminykh","Joseph Jay Williams"],"pdf_url":"https://arxiv.org/pdf/2310.00117v4.pdf","comment":"CHI 2024"},{"id":"http://arxiv.org/abs/2403.18547v1","updated":"2024-03-27T13:25:43Z","published":"2024-03-27T13:25:43Z","title":"Neural Architecture Search for Sentence Classification with BERT","summary":"  Pre training of language models on large text corpora is common practice in\nNatural Language Processing. Following, fine tuning of these models is\nperformed to achieve the best results on a variety of tasks. In this paper we\nquestion the common practice of only adding a single output layer as a\nclassification head on top of the network. We perform an AutoML search to find\narchitectures that outperform the current single layer at only a small compute\ncost. We validate our classification architecture on a variety of NLP\nbenchmarks from the GLUE dataset.\n","authors":["Philip Kenneweg","Sarah Schröder","Barbara Hammer"],"pdf_url":"https://arxiv.org/pdf/2403.18547v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18546v1","updated":"2024-03-27T13:24:58Z","published":"2024-03-27T13:24:58Z","title":"Efficient Heatmap-Guided 6-Dof Grasp Detection in Cluttered Scenes","summary":"  Fast and robust object grasping in clutter is a crucial component of\nrobotics. Most current works resort to the whole observed point cloud for 6-Dof\ngrasp generation, ignoring the guidance information excavated from global\nsemantics, thus limiting high-quality grasp generation and real-time\nperformance. In this work, we show that the widely used heatmaps are\nunderestimated in the efficiency of 6-Dof grasp generation. Therefore, we\npropose an effective local grasp generator combined with grasp heatmaps as\nguidance, which infers in a global-to-local semantic-to-point way.\nSpecifically, Gaussian encoding and the grid-based strategy are applied to\npredict grasp heatmaps as guidance to aggregate local points into graspable\nregions and provide global semantic information. Further, a novel non-uniform\nanchor sampling mechanism is designed to improve grasp accuracy and diversity.\nBenefiting from the high-efficiency encoding in the image space and focusing on\npoints in local graspable regions, our framework can perform high-quality grasp\ndetection in real-time and achieve state-of-the-art results. In addition, real\nrobot experiments demonstrate the effectiveness of our method with a success\nrate of 94% and a clutter completion rate of 100%. Our code is available at\nhttps://github.com/THU-VCLab/HGGD.\n","authors":["Siang Chen","Wei Tang","Pengwei Xie","Wenming Yang","Guijin Wang"],"pdf_url":"https://arxiv.org/pdf/2403.18546v1.pdf","comment":"Extensive results on GraspNet-1B dataset"},{"id":"http://arxiv.org/abs/2403.18537v1","updated":"2024-03-27T13:12:57Z","published":"2024-03-27T13:12:57Z","title":"A Path Towards Legal Autonomy: An interoperable and explainable approach\n  to extracting, transforming, loading and computing legal information using\n  large language models, expert systems and Bayesian networks","summary":"  Legal autonomy - the lawful activity of artificial intelligence agents - can\nbe achieved in one of two ways. It can be achieved either by imposing\nconstraints on AI actors such as developers, deployers and users, and on AI\nresources such as data, or by imposing constraints on the range and scope of\nthe impact that AI agents can have on the environment. The latter approach\ninvolves encoding extant rules concerning AI driven devices into the software\nof AI agents controlling those devices (e.g., encoding rules about limitations\non zones of operations into the agent software of an autonomous drone device).\nThis is a challenge since the effectivity of such an approach requires a method\nof extracting, loading, transforming and computing legal information that would\nbe both explainable and legally interoperable, and that would enable AI agents\nto reason about the law. In this paper, we sketch a proof of principle for such\na method using large language models (LLMs), expert legal systems known as\nlegal decision paths, and Bayesian networks. We then show how the proposed\nmethod could be applied to extant regulation in matters of autonomous cars,\nsuch as the California Vehicle Code.\n","authors":["Axel Constant","Hannes Westermann","Bryan Wilson","Alex Kiefer","Ines Hipolito","Sylvain Pronovost","Steven Swanson","Mahault Albarracin","Maxwell J. D. Ramstead"],"pdf_url":"https://arxiv.org/pdf/2403.18537v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18536v1","updated":"2024-03-27T13:12:41Z","published":"2024-03-27T13:12:41Z","title":"A Novel Behavior-Based Recommendation System for E-commerce","summary":"  The majority of existing recommender systems rely on user ratings, which are\nlimited by the lack of user collaboration and the sparsity problem. To address\nthese issues, this study proposes a behavior-based recommender system that\nleverages customers' natural behaviors, such as browsing and clicking, on\ne-commerce platforms. The proposed recommendation system involves clustering\nactive customers, determining neighborhoods, collecting similar users,\ncalculating product reputation based on similar users, and recommending\nhigh-reputation products. To overcome the complexity of customer behaviors and\ntraditional clustering methods, an unsupervised clustering approach based on\nproduct categories is developed to enhance the recommendation methodology. This\nstudy makes notable contributions in several aspects. Firstly, a groundbreaking\nbehavior-based recommendation methodology is developed, incorporating customer\nbehavior to generate accurate and tailored recommendations leading to improved\ncustomer satisfaction and engagement. Secondly, an original unsupervised\nclustering method, focusing on product categories, enables more precise\nclustering and facilitates accurate recommendations. Finally, an approach to\ndetermine neighborhoods for active customers within clusters is established,\nensuring grouping of customers with similar behavioral patterns to enhance\nrecommendation accuracy and relevance. The proposed recommendation methodology\nand clustering method contribute to improved recommendation performance,\noffering valuable insights for researchers and practitioners in the field of\ne-commerce recommendation systems. Additionally, the proposed method\noutperforms benchmark methods in experiments conducted using a behavior dataset\nfrom the well-known e-commerce site Alibaba.\n","authors":["Reza Barzegar Nozari","Mahdi Divsalar","Sepehr Akbarzadeh Abkenar","Mohammadreza Fadavi Amiri","Ali Divsalar"],"pdf_url":"https://arxiv.org/pdf/2403.18536v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.10365v3","updated":"2024-03-27T12:53:12Z","published":"2023-03-18T08:48:16Z","title":"CroSel: Cross Selection of Confident Pseudo Labels for Partial-Label\n  Learning","summary":"  Partial-label learning (PLL) is an important weakly supervised learning\nproblem, which allows each training example to have a candidate label set\ninstead of a single ground-truth label. Identification-based methods have been\nwidely explored to tackle label ambiguity issues in PLL, which regard the true\nlabel as a latent variable to be identified. However, identifying the true\nlabels accurately and completely remains challenging, causing noise in pseudo\nlabels during model training. In this paper, we propose a new method called\nCroSel, which leverages historical predictions from the model to identify true\nlabels for most training examples. First, we introduce a cross selection\nstrategy, which enables two deep models to select true labels of partially\nlabeled data for each other. Besides, we propose a novel consistency\nregularization term called co-mix to avoid sample waste and tiny noise caused\nby false selection. In this way, CroSel can pick out the true labels of most\nexamples with high precision. Extensive experiments demonstrate the superiority\nof CroSel, which consistently outperforms previous state-of-the-art methods on\nbenchmark datasets. Additionally, our method achieves over 90\\% accuracy and\nquantity for selecting true labels on CIFAR-type datasets under various\nsettings.\n","authors":["Shiyu Tian","Hongxin Wei","Yiqun Wang","Lei Feng"],"pdf_url":"https://arxiv.org/pdf/2303.10365v3.pdf","comment":"Accepted by CVPR 2024"},{"id":"http://arxiv.org/abs/2403.18519v1","updated":"2024-03-27T12:50:27Z","published":"2024-03-27T12:50:27Z","title":"Improving Line Search Methods for Large Scale Neural Network Training","summary":"  In recent studies, line search methods have shown significant improvements in\nthe performance of traditional stochastic gradient descent techniques,\neliminating the need for a specific learning rate schedule. In this paper, we\nidentify existing issues in state-of-the-art line search methods, propose\nenhancements, and rigorously evaluate their effectiveness. We test these\nmethods on larger datasets and more complex data domains than before.\nSpecifically, we improve the Armijo line search by integrating the momentum\nterm from ADAM in its search direction, enabling efficient large-scale\ntraining, a task that was previously prone to failure using Armijo line search\nmethods. Our optimization approach outperforms both the previous Armijo\nimplementation and tuned learning rate schedules for Adam. Our evaluation\nfocuses on Transformers and CNNs in the domains of NLP and image data. Our work\nis publicly available as a Python package, which provides a hyperparameter free\nPytorch optimizer.\n","authors":["Philip Kenneweg","Tristan Kenneweg","Barbara Hammer"],"pdf_url":"https://arxiv.org/pdf/2403.18519v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18506v1","updated":"2024-03-27T12:35:23Z","published":"2024-03-27T12:35:23Z","title":"Faster Convergence for Transformer Fine-tuning with Line Search Methods","summary":"  Recent works have shown that line search methods greatly increase performance\nof traditional stochastic gradient descent methods on a variety of datasets and\narchitectures [1], [2]. In this work we succeed in extending line search\nmethods to the novel and highly popular Transformer architecture and dataset\ndomains in natural language processing. More specifically, we combine the\nArmijo line search with the Adam optimizer and extend it by subdividing the\nnetworks architecture into sensible units and perform the line search\nseparately on these local units. Our optimization method outperforms the\ntraditional Adam optimizer and achieves significant performance improvements\nfor small data sets or small training budgets, while performing equal or better\nfor other tested cases. Our work is publicly available as a python package,\nwhich provides a hyperparameter-free pytorch optimizer that is compatible with\narbitrary network architectures.\n","authors":["Philip Kenneweg","Leonardo Galli","Tristan Kenneweg","Barbara Hammer"],"pdf_url":"https://arxiv.org/pdf/2403.18506v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.04698v3","updated":"2024-03-27T12:24:17Z","published":"2023-11-08T14:10:19Z","title":"Challenging Common Paradigms in Multi-Task Learning","summary":"  While multi-task learning (MTL) has gained significant attention in recent\nyears, its underlying mechanisms remain poorly understood. Recent methods did\nnot yield consistent performance improvements over single task learning (STL)\nbaselines, underscoring the importance of gaining more profound insights about\nchallenges specific to MTL. In our study, we challenge paradigms in MTL in the\ncontext of STL: First, the impact of the choice of optimizer has only been\nmildly investigated in MTL. We show the pivotal role of common STL tools such\nas the Adam optimizer in MTL empirically in various experiments. To further\ninvestigate Adam's effectiveness, we theoretical derive a partial loss-scale\ninvariance under mild assumptions. Second, the notion of gradient conflicts has\noften been phrased as a specific problem in MTL. We delve into the role of\ngradient conflicts in MTL and compare it to STL. For angular gradient alignment\nwe find no evidence that this is a unique problem in MTL. We emphasize\ndifferences in gradient magnitude as the main distinguishing factor. Lastly, we\ncompare the transferability of features learned through MTL and STL on common\nimage corruptions, and find light evidence that MTL can lead to superior\ntransferability. Overall, we find surprising similarities between STL and MTL\nsuggesting to consider methods from both fields in a broader context.\n","authors":["Cathrin Elich","Lukas Kirchdorfer","Jan M. Köhler","Lukas Schott"],"pdf_url":"https://arxiv.org/pdf/2311.04698v3.pdf","comment":"-"},{"id":"http://arxiv.org/abs/2403.15114v2","updated":"2024-03-27T12:13:42Z","published":"2024-03-22T11:16:11Z","title":"Solving a Real-World Package Delivery Routing Problem Using Quantum\n  Annealers","summary":"  Research focused on the conjunction between quantum computing and routing\nproblems has been very prolific in recent years. Most of the works revolve\naround classical problems such as the Traveling Salesman Problem or the Vehicle\nRouting Problem. Even though working on these problems is valuable, it is also\nundeniable that their academic-oriented nature falls short of real-world\nrequirements. The main objective of this research is to present a solving\nmethod for realistic instances, avoiding problem relaxations or technical\nshortcuts. Instead, a quantum-classical hybrid solver has been developed,\ncoined Q4RPD, that considers a set of real constraints such as a heterogeneous\nfleet of vehicles, priority deliveries, and capacities characterized by two\nvalues: weight and dimensions of the packages. Q4RPD resorts to the Leap\nConstrained Quadratic Model Hybrid Solver of D-Wave. To demonstrate the\napplication of Q4RPD, an experimentation composed of six different instances\nhas been conducted, aiming to serve as illustrative examples.\n","authors":["Eneko Osaba","Esther Villar-Rodriguez","Antón Asla"],"pdf_url":"https://arxiv.org/pdf/2403.15114v2.pdf","comment":"15 pages, 11 figures and 4 tables. Paper submitted for review in\n  Scientific Reports"},{"id":"http://arxiv.org/abs/2403.18489v1","updated":"2024-03-27T12:01:51Z","published":"2024-03-27T12:01:51Z","title":"Impact of Employing Weather Forecast Data as Input to the Estimation of\n  Evapotranspiration by Deep Neural Network Models","summary":"  Reference Evapotranspiration (ET0) is a key parameter for designing smart\nirrigation scheduling, since it is related by a coefficient to the water needs\nof a crop. The United Nations Food and Agriculture Organization, proposed a\nstandard method for ET0 computation (FAO56PM), based on the parameterization of\nthe Penman-Monteith equation, that is widely adopted in the literature. To\ncompute ET0 using the FAO56-PM method, four main weather parameters are needed:\ntemperature, humidity, wind, and solar radiation (SR). One way to make daily\nET0 estimations for future days is to use freely available weather forecast\nservices (WFSs), where many meteorological parameters are estimated up to the\nnext 15 days. A problem with this method is that currently, SR is not provided\nas a free forecast parameter on most of those online services or, normally,\nsuch forecasts present a financial cost penalty. For this reason, several ET0\nestimation models using machine and deep learning were developed and presented\nin the literature, that use as input features a reduced set of carefully\nselected weather parameters, that are compatible with common freely available\nWFSs. However, most studies on this topic have only evaluated model performance\nusing data from weather stations (WSs), without considering the effect of using\nweather forecast data. In this study, the performance of authors' previous\nmodels is evaluated when using weather forecast data from two online WFSs, in\nthe following scenarios: (i) direct ET0 estimation by an ANN model, and (ii)\nestimate SR by ANN model, and then use that estimation for ET0 computation,\nusing the FAO56-PM method. Employing data collected from two WFSs and a WS\nlocated in Vale do Lobo, Portugal, the latter approach achieved the best\nresult, with a coefficient of determination (R2) ranging between 0.893 and\n0.667, when considering forecasts up to 15 days.\n","authors":["Pedro J. Vaz","Gabriela Schütz","Carlos Guerrero","Pedro J. S. Cardoso"],"pdf_url":"https://arxiv.org/pdf/2403.18489v1.pdf","comment":"A partial version of the work submitted to ESRE/INTERNATIONAL\n  CONFERENCE ON ENVIRONMENTAL SCIENCES AND RENEWABLE ENERGY"},{"id":"http://arxiv.org/abs/2403.18486v1","updated":"2024-03-27T11:58:45Z","published":"2024-03-27T11:58:45Z","title":"Synthesizing EEG Signals from Event-Related Potential Paradigms with\n  Conditional Diffusion Models","summary":"  Data scarcity in the brain-computer interface field can be alleviated through\nthe use of generative models, specifically diffusion models. While diffusion\nmodels have previously been successfully applied to electroencephalogram (EEG)\ndata, existing models lack flexibility w.r.t.~sampling or require alternative\nrepresentations of the EEG data. To overcome these limitations, we introduce a\nnovel approach to conditional diffusion models that utilizes classifier-free\nguidance to directly generate subject-, session-, and class-specific EEG data.\nIn addition to commonly used metrics, domain-specific metrics are employed to\nevaluate the specificity of the generated samples. The results indicate that\nthe proposed model can generate EEG data that resembles real data for each\nsubject, session, and class.\n","authors":["Guido Klein","Pierre Guetschel","Gianluigi Silvestri","Michael Tangermann"],"pdf_url":"https://arxiv.org/pdf/2403.18486v1.pdf","comment":"submitted to 9th Graz BCI conference, 6 pages, 3 figures, first\n  figure is split into two subfigures, 1 table"},{"id":"http://arxiv.org/abs/2311.12028v2","updated":"2024-03-27T11:43:28Z","published":"2023-11-20T18:59:51Z","title":"Hourglass Tokenizer for Efficient Transformer-Based 3D Human Pose\n  Estimation","summary":"  Transformers have been successfully applied in the field of video-based 3D\nhuman pose estimation. However, the high computational costs of these video\npose transformers (VPTs) make them impractical on resource-constrained devices.\nIn this paper, we present a plug-and-play pruning-and-recovering framework,\ncalled Hourglass Tokenizer (HoT), for efficient transformer-based 3D human pose\nestimation from videos. Our HoT begins with pruning pose tokens of redundant\nframes and ends with recovering full-length tokens, resulting in a few pose\ntokens in the intermediate transformer blocks and thus improving the model\nefficiency. To effectively achieve this, we propose a token pruning cluster\n(TPC) that dynamically selects a few representative tokens with high semantic\ndiversity while eliminating the redundancy of video frames. In addition, we\ndevelop a token recovering attention (TRA) to restore the detailed\nspatio-temporal information based on the selected tokens, thereby expanding the\nnetwork output to the original full-length temporal resolution for fast\ninference. Extensive experiments on two benchmark datasets (i.e., Human3.6M and\nMPI-INF-3DHP) demonstrate that our method can achieve both high efficiency and\nestimation accuracy compared to the original VPT models. For instance, applying\nto MotionBERT and MixSTE on Human3.6M, our HoT can save nearly 50% FLOPs\nwithout sacrificing accuracy and nearly 40% FLOPs with only 0.2% accuracy drop,\nrespectively. Code and models are available at\nhttps://github.com/NationalGAILab/HoT.\n","authors":["Wenhao Li","Mengyuan Liu","Hong Liu","Pichao Wang","Jialun Cai","Nicu Sebe"],"pdf_url":"https://arxiv.org/pdf/2311.12028v2.pdf","comment":"Accepted by CVPR 2024, Open Sourced"},{"id":"http://arxiv.org/abs/2403.16432v2","updated":"2024-03-27T11:37:58Z","published":"2024-03-25T05:27:35Z","title":"$\\textit{LinkPrompt}$: Natural and Universal Adversarial Attacks on\n  Prompt-based Language Models","summary":"  Prompt-based learning is a new language model training paradigm that adapts\nthe Pre-trained Language Models (PLMs) to downstream tasks, which revitalizes\nthe performance benchmarks across various natural language processing (NLP)\ntasks. Instead of using a fixed prompt template to fine-tune the model, some\nresearch demonstrates the effectiveness of searching for the prompt via\noptimization. Such prompt optimization process of prompt-based learning on PLMs\nalso gives insight into generating adversarial prompts to mislead the model,\nraising concerns about the adversarial vulnerability of this paradigm. Recent\nstudies have shown that universal adversarial triggers (UATs) can be generated\nto alter not only the predictions of the target PLMs but also the prediction of\ncorresponding Prompt-based Fine-tuning Models (PFMs) under the prompt-based\nlearning paradigm. However, UATs found in previous works are often unreadable\ntokens or characters and can be easily distinguished from natural texts with\nadaptive defenses. In this work, we consider the naturalness of the UATs and\ndevelop $\\textit{LinkPrompt}$, an adversarial attack algorithm to generate UATs\nby a gradient-based beam search algorithm that not only effectively attacks the\ntarget PLMs and PFMs but also maintains the naturalness among the trigger\ntokens. Extensive results demonstrate the effectiveness of\n$\\textit{LinkPrompt}$, as well as the transferability of UATs generated by\n$\\textit{LinkPrompt}$ to open-sourced Large Language Model (LLM) Llama2 and\nAPI-accessed LLM GPT-3.5-turbo.\n","authors":["Yue Xu","Wenjie Wang"],"pdf_url":"https://arxiv.org/pdf/2403.16432v2.pdf","comment":"Accepted to the main conference of NAACL2024"},{"id":"http://arxiv.org/abs/2311.07838v3","updated":"2024-03-27T11:36:46Z","published":"2023-11-14T01:38:02Z","title":"LLatrieval: LLM-Verified Retrieval for Verifiable Generation","summary":"  Verifiable generation aims to let the large language model (LLM) generate\ntext with supporting documents, which enables the user to flexibly verify the\nanswer and makes the LLM's output more reliable. Retrieval plays a crucial role\nin verifiable generation. Specifically, the retrieved documents not only\nsupplement knowledge to help the LLM generate correct answers, but also serve\nas supporting evidence for the user to verify the LLM's output. However, the\nwidely used retrievers become the bottleneck of the entire pipeline and limit\nthe overall performance. Their capabilities are usually inferior to LLMs since\nthey often have much fewer parameters than the large language model and have\nnot been demonstrated to scale well to the size of LLMs. If the retriever does\nnot correctly find the supporting documents, the LLM can not generate the\ncorrect and verifiable answer, which overshadows the LLM's remarkable\nabilities. To address these limitations, we propose \\LLatrieval (Large Language\nModel Verified Retrieval), where the LLM updates the retrieval result until it\nverifies that the retrieved documents can sufficiently support answering the\nquestion. Thus, the LLM can iteratively provide feedback to retrieval and\nfacilitate the retrieval result to fully support verifiable generation.\nExperiments show that LLatrieval significantly outperforms extensive baselines\nand achieves state-of-the-art results.\n","authors":["Xiaonan Li","Changtai Zhu","Linyang Li","Zhangyue Yin","Tianxiang Sun","Xipeng Qiu"],"pdf_url":"https://arxiv.org/pdf/2311.07838v3.pdf","comment":"Accepted by NAACL 2024 (Main Conference)"},{"id":"http://arxiv.org/abs/2403.18469v1","updated":"2024-03-27T11:28:57Z","published":"2024-03-27T11:28:57Z","title":"Density-guided Translator Boosts Synthetic-to-Real Unsupervised Domain\n  Adaptive Segmentation of 3D Point Clouds","summary":"  3D synthetic-to-real unsupervised domain adaptive segmentation is crucial to\nannotating new domains. Self-training is a competitive approach for this task,\nbut its performance is limited by different sensor sampling patterns (i.e.,\nvariations in point density) and incomplete training strategies. In this work,\nwe propose a density-guided translator (DGT), which translates point density\nbetween domains, and integrates it into a two-stage self-training pipeline\nnamed DGT-ST. First, in contrast to existing works that simultaneously conduct\ndata generation and feature/output alignment within unstable adversarial\ntraining, we employ the non-learnable DGT to bridge the domain gap at the input\nlevel. Second, to provide a well-initialized model for self-training, we\npropose a category-level adversarial network in stage one that utilizes the\nprototype to prevent negative transfer. Finally, by leveraging the designs\nabove, a domain-mixed self-training method with source-aware consistency loss\nis proposed in stage two to narrow the domain gap further. Experiments on two\nsynthetic-to-real segmentation tasks (SynLiDAR $\\rightarrow$ semanticKITTI and\nSynLiDAR $\\rightarrow$ semanticPOSS) demonstrate that DGT-ST outperforms\nstate-of-the-art methods, achieving 9.4$\\%$ and 4.3$\\%$ mIoU improvements,\nrespectively. Code is available at \\url{https://github.com/yuan-zm/DGT-ST}.\n","authors":["Zhimin Yuan","Wankang Zeng","Yanfei Su","Weiquan Liu","Ming Cheng","Yulan Guo","Cheng Wang"],"pdf_url":"https://arxiv.org/pdf/2403.18469v1.pdf","comment":"CVPR2024"},{"id":"http://arxiv.org/abs/2311.10522v4","updated":"2024-03-27T11:18:51Z","published":"2023-11-17T13:43:43Z","title":"Enhancing Object Coherence in Layout-to-Image Synthesis","summary":"  Layout-to-image synthesis is an emerging technique in conditional image\ngeneration. It aims to generate complex scenes, where users require fine\ncontrol over the layout of the objects in a scene. However, it remains\nchallenging to control the object coherence, including semantic coherence\n(e.g., the cat looks at the flowers or not) and physical coherence (e.g., the\nhand and the racket should not be misaligned). In this paper, we propose a\nnovel diffusion model with effective global semantic fusion (GSF) and\nself-similarity feature enhancement modules to guide the object coherence for\nthis task. For semantic coherence, we argue that the image caption contains\nrich information for defining the semantic relationship within the objects in\nthe images. Instead of simply employing cross-attention between captions and\ngenerated images, which addresses the highly relevant layout restriction and\nsemantic coherence separately and thus leads to unsatisfying results shown in\nour experiments, we develop GSF to fuse the supervision from the layout\nrestriction and semantic coherence requirement and exploit it to guide the\nimage synthesis process. Moreover, to improve the physical coherence, we\ndevelop a Self-similarity Coherence Attention (SCA) module to explicitly\nintegrate local contextual physical coherence into each pixel's generation\nprocess. Specifically, we adopt a self-similarity map to encode the coherence\nrestrictions and employ it to extract coherent features from text embedding.\nThrough visualization of our self-similarity map, we explore the essence of\nSCA, revealing that its effectiveness is not only in capturing reliable\nphysical coherence patterns but also in enhancing complex texture generation.\nExtensive experiments demonstrate the superiority of our proposed method in\nboth image generation quality and controllability.\n","authors":["Yibin Wang","Weizhong Zhang","Jianwei Zheng","Cheng Jin"],"pdf_url":"https://arxiv.org/pdf/2311.10522v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18459v1","updated":"2024-03-27T11:18:01Z","published":"2024-03-27T11:18:01Z","title":"CoBOS: Constraint-Based Online Scheduler for Human-Robot Collaboration","summary":"  Assembly processes involving humans and robots are challenging scenarios\nbecause the individual activities and access to shared workspace have to be\ncoordinated. Fixed robot programs leave no room to diverge from a fixed\nprotocol. Working on such a process can be stressful for the user and lead to\nineffective behavior or failure. We propose a novel approach of online\nconstraint-based scheduling in a reactive execution control framework\nfacilitating behavior trees called CoBOS. This allows the robot to adapt to\nuncertain events such as delayed activity completions and activity selection\n(by the human). The user will experience less stress as the robotic coworkers\nadapt their behavior to best complement the human-selected activities to\ncomplete the common task. In addition to the improved working conditions, our\nalgorithm leads to increased efficiency, even in highly uncertain scenarios. We\nevaluate our algorithm using a probabilistic simulation study with 56000\nexperiments. We outperform all baselines by a margin of 4-10%. Initial real\nrobot experiments using a Franka Emika Panda robot and human tracking based on\nHTC Vive VR gloves look promising.\n","authors":["Marina Ionova","Jan Kristof Behrens"],"pdf_url":"https://arxiv.org/pdf/2403.18459v1.pdf","comment":"7 pages, 8 figures"},{"id":"http://arxiv.org/abs/2403.18451v1","updated":"2024-03-27T11:11:06Z","published":"2024-03-27T11:11:06Z","title":"CoRAST: Towards Foundation Model-Powered Correlated Data Analysis in\n  Resource-Constrained CPS and IoT","summary":"  Foundation models (FMs) emerge as a promising solution to harness distributed\nand diverse environmental data by leveraging prior knowledge to understand the\ncomplicated temporal and spatial correlations within heterogeneous datasets.\nUnlike distributed learning frameworks such as federated learning, which often\nstruggle with multimodal data, FMs can transform diverse inputs into\nembeddings. This process facilitates the integration of information from\nvarious modalities and the application of prior learning to new domains.\nHowever, deploying FMs in resource-constrained edge systems poses significant\nchallenges. To this end, we introduce CoRAST, a novel learning framework that\nutilizes FMs for enhanced analysis of distributed, correlated heterogeneous\ndata. Utilizing a server-based FM, CoRAST can exploit existing environment\ninformation to extract temporal, spatial, and cross-modal correlations among\nsensor data. This enables CoRAST to offer context-aware insights for localized\nclient tasks through FM-powered global representation learning. Our evaluation\non real-world weather dataset demonstrates CoRAST's ability to exploit\ncorrelated heterogeneous data through environmental representation learning to\nreduce the forecast errors by up to 50.3% compared to the baselines.\n","authors":["Yi Hu","Jinhang Zuo","Alanis Zhao","Bob Iannucci","Carlee Joe-Wong"],"pdf_url":"https://arxiv.org/pdf/2403.18451v1.pdf","comment":"accepted and to be published in 2024 IEEE International Workshop on\n  Foundation Models for Cyber-Physical Systems & Internet of Things (FMSys)"},{"id":"http://arxiv.org/abs/2403.18425v1","updated":"2024-03-27T10:26:42Z","published":"2024-03-27T10:26:42Z","title":"U-Sketch: An Efficient Approach for Sketch to Image Diffusion Models","summary":"  Diffusion models have demonstrated remarkable performance in text-to-image\nsynthesis, producing realistic and high resolution images that faithfully\nadhere to the corresponding text-prompts. Despite their great success, they\nstill fall behind in sketch-to-image synthesis tasks, where in addition to\ntext-prompts, the spatial layout of the generated images has to closely follow\nthe outlines of certain reference sketches. Employing an MLP latent edge\npredictor to guide the spatial layout of the synthesized image by predicting\nedge maps at each denoising step has been recently proposed. Despite yielding\npromising results, the pixel-wise operation of the MLP does not take into\naccount the spatial layout as a whole, and demands numerous denoising\niterations to produce satisfactory images, leading to time inefficiency. To\nthis end, we introduce U-Sketch, a framework featuring a U-Net type latent edge\npredictor, which is capable of efficiently capturing both local and global\nfeatures, as well as spatial correlations between pixels. Moreover, we propose\nthe addition of a sketch simplification network that offers the user the choice\nof preprocessing and simplifying input sketches for enhanced outputs. The\nexperimental results, corroborated by user feedback, demonstrate that our\nproposed U-Net latent edge predictor leads to more realistic results, that are\nbetter aligned with the spatial outlines of the reference sketches, while\ndrastically reducing the number of required denoising steps and, consequently,\nthe overall execution time.\n","authors":["Ilias Mitsouras","Eleftherios Tsonis","Paraskevi Tzouveli","Athanasios Voulodimos"],"pdf_url":"https://arxiv.org/pdf/2403.18425v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.01739v2","updated":"2024-03-27T10:21:24Z","published":"2024-01-29T12:05:02Z","title":"OpenMoE: An Early Effort on Open Mixture-of-Experts Language Models","summary":"  To help the open-source community have a better understanding of\nMixture-of-Experts (MoE) based large language models (LLMs), we train and\nrelease OpenMoE, a series of fully open-sourced and reproducible decoder-only\nMoE LLMs, ranging from 650M to 34B parameters and trained on up to over 1T\ntokens. Our investigation confirms that MoE-based LLMs can offer a more\nfavorable cost-effectiveness trade-off than dense LLMs, highlighting the\npotential effectiveness for future LLM development.\n  One more important contribution of this study is an in-depth analysis of the\nrouting mechanisms within our OpenMoE models, leading to three significant\nfindings: Context-Independent Specialization, Early Routing Learning, and\nDrop-towards-the-End. We discovered that routing decisions in MoE models are\npredominantly based on token IDs, with minimal context relevance. The\ntoken-to-expert assignments are determined early in the pre-training phase and\nremain largely unchanged. This imperfect routing can result in performance\ndegradation, particularly in sequential tasks like multi-turn conversations,\nwhere tokens appearing later in a sequence are more likely to be dropped.\nFinally, we rethink our design based on the above-mentioned observations and\nanalysis. To facilitate future MoE LLM development, we propose potential\nstrategies for mitigating the issues we found and further improving\noff-the-shelf MoE LLM designs.\n","authors":["Fuzhao Xue","Zian Zheng","Yao Fu","Jinjie Ni","Zangwei Zheng","Wangchunshu Zhou","Yang You"],"pdf_url":"https://arxiv.org/pdf/2402.01739v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18421v1","updated":"2024-03-27T10:18:21Z","published":"2024-03-27T10:18:21Z","title":"BioMedLM: A 2.7B Parameter Language Model Trained On Biomedical Text","summary":"  Models such as GPT-4 and Med-PaLM 2 have demonstrated impressive performance\non a wide variety of biomedical NLP tasks. However, these models have hundreds\nof billions of parameters, are computationally expensive to run, require users\nto send their input data over the internet, and are trained on unknown data\nsources. Can smaller, more targeted models compete? To address this question,\nwe build and release BioMedLM, a 2.7 billion parameter GPT-style autoregressive\nmodel trained exclusively on PubMed abstracts and full articles. When\nfine-tuned, BioMedLM can produce strong multiple-choice biomedical\nquestion-answering results competitive with much larger models, such as\nachieving a score of 57.3% on MedMCQA (dev) and 69.0% on the MMLU Medical\nGenetics exam. BioMedLM can also be fine-tuned to produce useful answers to\npatient questions on medical topics. This demonstrates that smaller models can\npotentially serve as transparent, privacy-preserving, economical and\nenvironmentally friendly foundations for particular NLP applications, such as\nin biomedicine. The model is available on the Hugging Face Hub:\nhttps://huggingface.co/stanford-crfm/BioMedLM.\n","authors":["Elliot Bolton","Abhinav Venigalla","Michihiro Yasunaga","David Hall","Betty Xiong","Tony Lee","Roxana Daneshjou","Jonathan Frankle","Percy Liang","Michael Carbin","Christopher D. Manning"],"pdf_url":"https://arxiv.org/pdf/2403.18421v1.pdf","comment":"23 pages"},{"id":"http://arxiv.org/abs/2311.01191v2","updated":"2024-03-27T10:12:31Z","published":"2023-11-02T12:36:19Z","title":"VIGraph: Generative Self-supervised Learning for Class-Imbalanced Node\n  Classification","summary":"  Class imbalance in graph data presents significant challenges for node\nclassification. While existing methods, such as SMOTE-based approaches,\npartially mitigate this issue, they still exhibit limitations in constructing\nimbalanced graphs. Generative self-supervised learning (SSL) methods,\nexemplified by graph autoencoders (GAEs), offer a promising solution by\ndirectly generating minority nodes from the data itself, yet their potential\nremains underexplored. In this paper, we delve into the shortcomings of\nSMOTE-based approaches in the construction of imbalanced graphs. Furthermore,\nwe introduce VIGraph, a simple yet effective generative SSL approach that\nrelies on the Variational GAE as the fundamental model. VIGraph strictly\nadheres to the concept of imbalance when constructing imbalanced graphs and\ninnovatively leverages the variational inference (VI) ability of Variational\nGAE to generate nodes for minority classes. VIGraph introduces comprehensive\ntraining strategies, including cross-view contrastive learning at the decoding\nphase to capture semantic knowledge, adjacency matrix reconstruction to\npreserve graph structure, and alignment strategy to ensure stable training.\nVIGraph can generate high-quality nodes directly usable for classification,\neliminating the need to integrate the generated nodes back to the graph as well\nas additional retraining found in SMOTE-based methods. We conduct extensive\nexperiments, results from which demonstrate the superiority and generality of\nour approach.\n","authors":["Yulan Hu","Sheng Ouyang","Zhirui Yang","Yong Liu"],"pdf_url":"https://arxiv.org/pdf/2311.01191v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18407v1","updated":"2024-03-27T09:49:37Z","published":"2024-03-27T09:49:37Z","title":"A Channel-ensemble Approach: Unbiased and Low-variance Pseudo-labels is\n  Critical for Semi-supervised Classification","summary":"  Semi-supervised learning (SSL) is a practical challenge in computer vision.\nPseudo-label (PL) methods, e.g., FixMatch and FreeMatch, obtain the State Of\nThe Art (SOTA) performances in SSL. These approaches employ a\nthreshold-to-pseudo-label (T2L) process to generate PLs by truncating the\nconfidence scores of unlabeled data predicted by the self-training method.\nHowever, self-trained models typically yield biased and high-variance\npredictions, especially in the scenarios when a little labeled data are\nsupplied. To address this issue, we propose a lightweight channel-based\nensemble method to effectively consolidate multiple inferior PLs into the\ntheoretically guaranteed unbiased and low-variance one. Importantly, our\napproach can be readily extended to any SSL framework, such as FixMatch or\nFreeMatch. Experimental results demonstrate that our method significantly\noutperforms state-of-the-art techniques on CIFAR10/100 in terms of\neffectiveness and efficiency.\n","authors":["Jiaqi Wu","Junbiao Pang","Baochang Zhang","Qingming Huang"],"pdf_url":"https://arxiv.org/pdf/2403.18407v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18406v1","updated":"2024-03-27T09:48:23Z","published":"2024-03-27T09:48:23Z","title":"An Image Grid Can Be Worth a Video: Zero-shot Video Question Answering\n  Using a VLM","summary":"  Stimulated by the sophisticated reasoning capabilities of recent Large\nLanguage Models (LLMs), a variety of strategies for bridging video modality\nhave been devised. A prominent strategy involves Video Language Models\n(VideoLMs), which train a learnable interface with video data to connect\nadvanced vision encoders with LLMs. Recently, an alternative strategy has\nsurfaced, employing readily available foundation models, such as VideoLMs and\nLLMs, across multiple stages for modality bridging. In this study, we introduce\na simple yet novel strategy where only a single Vision Language Model (VLM) is\nutilized. Our starting point is the plain insight that a video comprises a\nseries of images, or frames, interwoven with temporal information. The essence\nof video comprehension lies in adeptly managing the temporal aspects along with\nthe spatial details of each frame. Initially, we transform a video into a\nsingle composite image by arranging multiple frames in a grid layout. The\nresulting single image is termed as an image grid. This format, while\nmaintaining the appearance of a solitary image, effectively retains temporal\ninformation within the grid structure. Therefore, the image grid approach\nenables direct application of a single high-performance VLM without\nnecessitating any video-data training. Our extensive experimental analysis\nacross ten zero-shot video question answering benchmarks, including five\nopen-ended and five multiple-choice benchmarks, reveals that the proposed Image\nGrid Vision Language Model (IG-VLM) surpasses the existing methods in nine out\nof ten benchmarks.\n","authors":["Wonkyun Kim","Changin Choi","Wonseok Lee","Wonjong Rhee"],"pdf_url":"https://arxiv.org/pdf/2403.18406v1.pdf","comment":"Our code is available at https://github.com/imagegridworth/IG-VLM"},{"id":"http://arxiv.org/abs/2403.18405v1","updated":"2024-03-27T09:46:56Z","published":"2024-03-27T09:46:56Z","title":"Leveraging Large Language Models for Relevance Judgments in Legal Case\n  Retrieval","summary":"  Collecting relevant judgments for legal case retrieval is a challenging and\ntime-consuming task. Accurately judging the relevance between two legal cases\nrequires a considerable effort to read the lengthy text and a high level of\ndomain expertise to extract Legal Facts and make juridical judgments. With the\nadvent of advanced large language models, some recent studies have suggested\nthat it is promising to use LLMs for relevance judgment. Nonetheless, the\nmethod of employing a general large language model for reliable relevance\njudgments in legal case retrieval is yet to be thoroughly explored. To fill\nthis research gap, we devise a novel few-shot workflow tailored to the relevant\njudgment of legal cases. The proposed workflow breaks down the annotation\nprocess into a series of stages, imitating the process employed by human\nannotators and enabling a flexible integration of expert reasoning to enhance\nthe accuracy of relevance judgments. By comparing the relevance judgments of\nLLMs and human experts, we empirically show that we can obtain reliable\nrelevance judgments with the proposed workflow. Furthermore, we demonstrate the\ncapacity to augment existing legal case retrieval models through the synthesis\nof data generated by the large language model.\n","authors":["Shengjie Ma","Chong Chen","Qi Chu","Jiaxin Mao"],"pdf_url":"https://arxiv.org/pdf/2403.18405v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18397v1","updated":"2024-03-27T09:35:56Z","published":"2024-03-27T09:35:56Z","title":"Colour and Brush Stroke Pattern Recognition in Abstract Art using\n  Modified Deep Convolutional Generative Adversarial Networks","summary":"  Abstract Art is an immensely popular, discussed form of art that often has\nthe ability to depict the emotions of an artist. Many researchers have made\nattempts to study abstract art in the form of edge detection, brush stroke and\nemotion recognition algorithms using machine and deep learning. This papers\ndescribes the study of a wide distribution of abstract paintings using\nGenerative Adversarial Neural Networks(GAN). GANs have the ability to learn and\nreproduce a distribution enabling researchers and scientists to effectively\nexplore and study the generated image space. However, the challenge lies in\ndeveloping an efficient GAN architecture that overcomes common training\npitfalls. This paper addresses this challenge by introducing a modified-DCGAN\n(mDCGAN) specifically designed for high-quality artwork generation. The\napproach involves a thorough exploration of the modifications made, delving\ninto the intricate workings of DCGANs, optimisation techniques, and\nregularisation methods aimed at improving stability and realism in art\ngeneration enabling effective study of generated patterns. The proposed mDCGAN\nincorporates meticulous adjustments in layer configurations and architectural\nchoices, offering tailored solutions to the unique demands of art generation\nwhile effectively combating issues like mode collapse and gradient vanishing.\nFurther this paper explores the generated latent space by performing random\nwalks to understand vector relationships between brush strokes and colours in\nthe abstract art space and a statistical analysis of unstable outputs after a\ncertain period of GAN training and compare its significant difference. These\nfindings validate the effectiveness of the proposed approach, emphasising its\npotential to revolutionise the field of digital art generation and digital art\necosystem.\n","authors":["Srinitish Srinivasan","Varenya Pathak"],"pdf_url":"https://arxiv.org/pdf/2403.18397v1.pdf","comment":"28 pages, 5 tables, 7 figures"},{"id":"http://arxiv.org/abs/2403.18388v1","updated":"2024-03-27T09:25:20Z","published":"2024-03-27T09:25:20Z","title":"FTBC: Forward Temporal Bias Correction for Optimizing ANN-SNN Conversion","summary":"  Spiking Neural Networks (SNNs) offer a promising avenue for energy-efficient\ncomputing compared with Artificial Neural Networks (ANNs), closely mirroring\nbiological neural processes. However, this potential comes with inherent\nchallenges in directly training SNNs through spatio-temporal backpropagation --\nstemming from the temporal dynamics of spiking neurons and their discrete\nsignal processing -- which necessitates alternative ways of training, most\nnotably through ANN-SNN conversion. In this work, we introduce a lightweight\nForward Temporal Bias Correction (FTBC) technique, aimed at enhancing\nconversion accuracy without the computational overhead. We ground our method on\nprovided theoretical findings that through proper temporal bias calibration the\nexpected error of ANN-SNN conversion can be reduced to be zero after each time\nstep. We further propose a heuristic algorithm for finding the temporal bias\nonly in the forward pass, thus eliminating the computational burden of\nbackpropagation and we evaluate our method on CIFAR-10/100 and ImageNet\ndatasets, achieving a notable increase in accuracy on all datasets. Codes are\nreleased at a GitHub repository.\n","authors":["Xiaofeng Wu","Velibor Bojkovic","Bin Gu","Kun Suo","Kai Zou"],"pdf_url":"https://arxiv.org/pdf/2403.18388v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14864v2","updated":"2024-03-27T09:24:55Z","published":"2024-03-21T22:18:59Z","title":"Learning Quadruped Locomotion Using Differentiable Simulation","summary":"  While most recent advancements in legged robot control have been driven by\nmodel-free reinforcement learning, we explore the potential of differentiable\nsimulation. Differentiable simulation promises faster convergence and more\nstable training by computing low-variant first-order gradients using the robot\nmodel, but so far, its use for legged robot control has remained limited to\nsimulation. The main challenge with differentiable simulation lies in the\ncomplex optimization landscape of robotic tasks due to discontinuities in\ncontact-rich environments, e.g., quadruped locomotion. This work proposes a\nnew, differentiable simulation framework to overcome these challenges. The key\nidea involves decoupling the complex whole-body simulation, which may exhibit\ndiscontinuities due to contact, into two separate continuous domains.\nSubsequently, we align the robot state resulting from the simplified model with\na more precise, non-differentiable simulator to maintain sufficient simulation\naccuracy. Our framework enables learning quadruped walking in minutes using a\nsingle simulated robot without any parallelization. When augmented with GPU\nparallelization, our approach allows the quadruped robot to master diverse\nlocomotion skills, including trot, pace, bound, and gallop, on challenging\nterrains in minutes. Additionally, our policy achieves robust locomotion\nperformance in the real world zero-shot. To the best of our knowledge, this\nwork represents the first demonstration of using differentiable simulation for\ncontrolling a real quadruped robot. This work provides several important\ninsights into using differentiable simulations for legged locomotion in the\nreal world.\n","authors":["Yunlong Song","Sangbae Kim","Davide Scaramuzza"],"pdf_url":"https://arxiv.org/pdf/2403.14864v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18383v1","updated":"2024-03-27T09:21:07Z","published":"2024-03-27T09:21:07Z","title":"Generative Multi-modal Models are Good Class-Incremental Learners","summary":"  In class-incremental learning (CIL) scenarios, the phenomenon of catastrophic\nforgetting caused by the classifier's bias towards the current task has long\nposed a significant challenge. It is mainly caused by the characteristic of\ndiscriminative models. With the growing popularity of the generative\nmulti-modal models, we would explore replacing discriminative models with\ngenerative ones for CIL. However, transitioning from discriminative to\ngenerative models requires addressing two key challenges. The primary challenge\nlies in transferring the generated textual information into the classification\nof distinct categories. Additionally, it requires formulating the task of CIL\nwithin a generative framework. To this end, we propose a novel generative\nmulti-modal model (GMM) framework for class-incremental learning. Our approach\ndirectly generates labels for images using an adapted generative model. After\nobtaining the detailed text, we use a text encoder to extract text features and\nemploy feature matching to determine the most similar label as the\nclassification prediction. In the conventional CIL settings, we achieve\nsignificantly better results in long-sequence task scenarios. Under the\nFew-shot CIL setting, we have improved by at least 14\\% accuracy over all the\ncurrent state-of-the-art methods with significantly less forgetting. Our code\nis available at \\url{https://github.com/DoubleClass/GMM}.\n","authors":["Xusheng Cao","Haori Lu","Linlan Huang","Xialei Liu","Ming-Ming Cheng"],"pdf_url":"https://arxiv.org/pdf/2403.18383v1.pdf","comment":"Accepted at CVPR 2024"},{"id":"http://arxiv.org/abs/2403.18381v1","updated":"2024-03-27T09:19:13Z","published":"2024-03-27T09:19:13Z","title":"Improving Attributed Text Generation of Large Language Models via\n  Preference Learning","summary":"  Large language models have been widely adopted in natural language\nprocessing, yet they face the challenge of generating unreliable content.\nRecent works aim to reduce misinformation and hallucinations by resorting to\nattribution as a means to provide evidence (i.e., citations). However, current\nattribution methods usually focus on the retrieval stage and automatic\nevaluation that neglect mirroring the citation mechanisms in human scholarly\nwriting to bolster credibility. In this paper, we address these challenges by\nmodelling the attribution task as preference learning and introducing an\nAutomatic Preference Optimization (APO) framework. First, we create a curated\ncollection for post-training with 6,330 examples by collecting and filtering\nfrom existing datasets. Second, considering the high cost of labelling\npreference data, we further propose an automatic method to synthesize\nattribution preference data resulting in 95,263 pairs. Moreover, inspired by\nthe human citation process, we further propose a progressive preference\noptimization method by leveraging fine-grained information. Extensive\nexperiments on three datasets (i.e., ASQA, StrategyQA, and ELI5) demonstrate\nthat APO achieves state-of-the-art citation F1 with higher answer quality.\n","authors":["Dongfang Li","Zetian Sun","Baotian Hu","Zhenyu Liu","Xinshuo Hu","Xuebo Liu","Min Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.18381v1.pdf","comment":"23 pages, 15 tables, 2 figures"},{"id":"http://arxiv.org/abs/2403.18379v1","updated":"2024-03-27T09:17:50Z","published":"2024-03-27T09:17:50Z","title":"IIP-Mixer:Intra-Inter Patch Mixing Architecture for Battery Remaining\n  Useful Life Prediction","summary":"  Accurately estimating the Remaining Useful Life (RUL) of lithium-ion\nbatteries is crucial for maintaining the safe and stable operation of\nrechargeable battery management systems. However, this task is often\nchallenging due to the complex temporal dynamics involved. Recently,\nattention-based networks, such as Transformers and Informer, have been the\npopular architecture in time series forecasting. Despite their effectiveness,\nthese models with abundant parameters necessitate substantial training time to\nunravel temporal patterns. To tackle these challenges, we propose a simple\nMLP-Mixer-based architecture named 'Intra-Inter Patch Mixer' (IIP-Mixer), which\nis an architecture based exclusively on multi-layer perceptrons (MLPs),\nextracting information by mixing operations along both intra-patch and\ninter-patch dimensions for battery RUL prediction. The proposed IIP-Mixer\ncomprises parallel dual-head mixer layers: the intra-patch mixing MLP,\ncapturing local temporal patterns in the short-term period, and the inter-patch\nmixing MLP, capturing global temporal patterns in the long-term period.\nNotably, to address the varying importance of features in RUL prediction, we\nintroduce a weighted loss function in the MLP-Mixer-based architecture, marking\nthe first time such an approach has been employed. Our experiments demonstrate\nthat IIP-Mixer achieves competitive performance in battery RUL prediction,\noutperforming other popular time-series frameworks\n","authors":["Guangzai Ye","Li Feng","Jianlan Guo","Yuqiang Chen"],"pdf_url":"https://arxiv.org/pdf/2403.18379v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.10997v5","updated":"2024-03-27T09:16:57Z","published":"2023-12-18T07:47:33Z","title":"Retrieval-Augmented Generation for Large Language Models: A Survey","summary":"  Large Language Models (LLMs) showcase impressive capabilities but encounter\nchallenges like hallucination, outdated knowledge, and non-transparent,\nuntraceable reasoning processes. Retrieval-Augmented Generation (RAG) has\nemerged as a promising solution by incorporating knowledge from external\ndatabases. This enhances the accuracy and credibility of the generation,\nparticularly for knowledge-intensive tasks, and allows for continuous knowledge\nupdates and integration of domain-specific information. RAG synergistically\nmerges LLMs' intrinsic knowledge with the vast, dynamic repositories of\nexternal databases. This comprehensive review paper offers a detailed\nexamination of the progression of RAG paradigms, encompassing the Naive RAG,\nthe Advanced RAG, and the Modular RAG. It meticulously scrutinizes the\ntripartite foundation of RAG frameworks, which includes the retrieval, the\ngeneration and the augmentation techniques. The paper highlights the\nstate-of-the-art technologies embedded in each of these critical components,\nproviding a profound understanding of the advancements in RAG systems.\nFurthermore, this paper introduces up-to-date evaluation framework and\nbenchmark. At the end, this article delineates the challenges currently faced\nand points out prospective avenues for research and development.\n","authors":["Yunfan Gao","Yun Xiong","Xinyu Gao","Kangxiang Jia","Jinliu Pan","Yuxi Bi","Yi Dai","Jiawei Sun","Meng Wang","Haofen Wang"],"pdf_url":"https://arxiv.org/pdf/2312.10997v5.pdf","comment":"Ongoing Work"},{"id":"http://arxiv.org/abs/2312.08533v4","updated":"2024-03-27T09:11:48Z","published":"2023-12-13T21:46:09Z","title":"World Models via Policy-Guided Trajectory Diffusion","summary":"  World models are a powerful tool for developing intelligent agents. By\npredicting the outcome of a sequence of actions, world models enable policies\nto be optimised via on-policy reinforcement learning (RL) using synthetic data,\ni.e. in \"in imagination\". Existing world models are autoregressive in that they\ninterleave predicting the next state with sampling the next action from the\npolicy. Prediction error inevitably compounds as the trajectory length grows.\nIn this work, we propose a novel world modelling approach that is not\nautoregressive and generates entire on-policy trajectories in a single pass\nthrough a diffusion model. Our approach, Policy-Guided Trajectory Diffusion\n(PolyGRAD), leverages a denoising model in addition to the gradient of the\naction distribution of the policy to diffuse a trajectory of initially random\nstates and actions into an on-policy synthetic trajectory. We analyse the\nconnections between PolyGRAD, score-based generative models, and\nclassifier-guided diffusion models. Our results demonstrate that PolyGRAD\noutperforms state-of-the-art baselines in terms of trajectory prediction error\nfor short trajectories, with the exception of autoregressive diffusion. For\nshort trajectories, PolyGRAD obtains similar errors to autoregressive\ndiffusion, but with lower computational requirements. For long trajectories,\nPolyGRAD obtains comparable performance to baselines. Our experiments\ndemonstrate that PolyGRAD enables performant policies to be trained via\non-policy RL in imagination for MuJoCo continuous control domains. Thus,\nPolyGRAD introduces a new paradigm for accurate on-policy world modelling\nwithout autoregressive sampling.\n","authors":["Marc Rigter","Jun Yamada","Ingmar Posner"],"pdf_url":"https://arxiv.org/pdf/2312.08533v4.pdf","comment":"Published in TMLR, March 2024"},{"id":"http://arxiv.org/abs/2403.10158v2","updated":"2024-03-27T08:57:20Z","published":"2024-03-15T10:01:19Z","title":"Functional Graph Convolutional Networks: A unified multi-task and\n  multi-modal learning framework to facilitate health and social-care insights","summary":"  This paper introduces a novel Functional Graph Convolutional Network (funGCN)\nframework that combines Functional Data Analysis and Graph Convolutional\nNetworks to address the complexities of multi-task and multi-modal learning in\ndigital health and longitudinal studies. With the growing importance of health\nsolutions to improve health care and social support, ensure healthy lives, and\npromote well-being at all ages, funGCN offers a unified approach to handle\nmultivariate longitudinal data for multiple entities and ensures\ninterpretability even with small sample sizes. Key innovations include\ntask-specific embedding components that manage different data types, the\nability to perform classification, regression, and forecasting, and the\ncreation of a knowledge graph for insightful data interpretation. The efficacy\nof funGCN is validated through simulation experiments and a real-data\napplication.\n","authors":["Tobia Boschi","Francesca Bonin","Rodrigo Ordonez-Hurtado","Cécile Rousseau","Alessandra Pascale","John Dinsmore"],"pdf_url":"https://arxiv.org/pdf/2403.10158v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18364v1","updated":"2024-03-27T08:57:15Z","published":"2024-03-27T08:57:15Z","title":"Intent-Aware DRL-Based Uplink Dynamic Scheduler for 5G-NR","summary":"  We investigate the problem of supporting Industrial Internet of Things user\nequipment (IIoT UEs) with intent (i.e., requested quality of service (QoS)) and\nrandom traffic arrival. A deep reinforcement learning (DRL) based centralized\ndynamic scheduler for time-frequency resources is proposed to learn how to\nschedule the available communication resources among the IIoT UEs. The proposed\nscheduler leverages an RL framework to adapt to the dynamic changes in the\nwireless communication system and traffic arrivals. Moreover, a graph-based\nreduction scheme is proposed to reduce the state and action space of the RL\nframework to allow fast convergence and a better learning strategy. Simulation\nresults demonstrate the effectiveness of the proposed intelligent scheduler in\nguaranteeing the expressed intent of IIoT UEs compared to several traditional\nscheduling schemes, such as round-robin, semi-static, and heuristic approaches.\nThe proposed scheduler also outperforms the contention-free and\ncontention-based schemes in maximizing the number of successfully computed\ntasks.\n","authors":["Salwa Mostafa","Mateus P. Mota","Alvaro Valcarce","Mehdi Bennis"],"pdf_url":"https://arxiv.org/pdf/2403.18364v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.03325v2","updated":"2024-03-27T08:54:35Z","published":"2023-10-05T05:41:21Z","title":"Learning Concept-Based Causal Transition and Symbolic Reasoning for\n  Visual Planning","summary":"  Visual planning simulates how humans make decisions to achieve desired goals\nin the form of searching for visual causal transitions between an initial\nvisual state and a final visual goal state. It has become increasingly\nimportant in egocentric vision with its advantages in guiding agents to perform\ndaily tasks in complex environments. In this paper, we propose an interpretable\nand generalizable visual planning framework consisting of i) a novel\nSubstitution-based Concept Learner (SCL) that abstracts visual inputs into\ndisentangled concept representations, ii) symbol abstraction and reasoning that\nperforms task planning via the self-learned symbols, and iii) a Visual Causal\nTransition model (ViCT) that grounds visual causal transitions to semantically\nsimilar real-world actions. Given an initial state, we perform goal-conditioned\nvisual planning with a symbolic reasoning method fueled by the learned\nrepresentations and causal transitions to reach the goal state. To verify the\neffectiveness of the proposed model, we collect a large-scale visual planning\ndataset based on AI2-THOR, dubbed as CCTP. Extensive experiments on this\nchallenging dataset demonstrate the superior performance of our method in\nvisual task planning. Empirically, we show that our framework can generalize to\nunseen task trajectories, unseen object categories, and real-world data.\nFurther details of this work are provided at\nhttps://fqyqc.github.io/ConTranPlan/.\n","authors":["Yilue Qian","Peiyu Yu","Ying Nian Wu","Yao Su","Wei Wang","Lifeng Fan"],"pdf_url":"https://arxiv.org/pdf/2310.03325v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.02151v2","updated":"2024-03-27T08:43:28Z","published":"2023-05-03T14:33:23Z","title":"Identifying the Correlation Between Language Distance and Cross-Lingual\n  Transfer in a Multilingual Representation Space","summary":"  Prior research has investigated the impact of various linguistic features on\ncross-lingual transfer performance. In this study, we investigate the manner in\nwhich this effect can be mapped onto the representation space. While past\nstudies have focused on the impact on cross-lingual alignment in multilingual\nlanguage models during fine-tuning, this study examines the absolute evolution\nof the respective language representation spaces produced by MLLMs. We place a\nspecific emphasis on the role of linguistic characteristics and investigate\ntheir inter-correlation with the impact on representation spaces and\ncross-lingual transfer performance. Additionally, this paper provides\npreliminary evidence of how these findings can be leveraged to enhance transfer\nto linguistically distant languages.\n","authors":["Fred Philippy","Siwen Guo","Shohreh Haddadan"],"pdf_url":"https://arxiv.org/pdf/2305.02151v2.pdf","comment":"SIGTYP Workshop 2023 (co-located with EACL 2023)"},{"id":"http://arxiv.org/abs/2403.18351v1","updated":"2024-03-27T08:42:47Z","published":"2024-03-27T08:42:47Z","title":"Generating Diverse Agricultural Data for Vision-Based Farming\n  Applications","summary":"  We present a specialized procedural model for generating synthetic\nagricultural scenes, focusing on soybean crops, along with various weeds. This\nmodel is capable of simulating distinct growth stages of these plants, diverse\nsoil conditions, and randomized field arrangements under varying lighting\nconditions. The integration of real-world textures and environmental factors\ninto the procedural generation process enhances the photorealism and\napplicability of the synthetic data. Our dataset includes 12,000 images with\nsemantic labels, offering a comprehensive resource for computer vision tasks in\nprecision agriculture, such as semantic segmentation for autonomous weed\ncontrol. We validate our model's effectiveness by comparing the synthetic data\nagainst real agricultural images, demonstrating its potential to significantly\naugment training data for machine learning models in agriculture. This approach\nnot only provides a cost-effective solution for generating high-quality,\ndiverse data but also addresses specific needs in agricultural vision tasks\nthat are not fully covered by general-purpose models.\n","authors":["Mikolaj Cieslak","Umabharathi Govindarajan","Alejandro Garcia","Anuradha Chandrashekar","Torsten Hädrich","Aleksander Mendoza-Drosik","Dominik L. Michels","Sören Pirk","Chia-Chun Fu","Wojciech Pałubicki"],"pdf_url":"https://arxiv.org/pdf/2403.18351v1.pdf","comment":"10 pages, 8 figures, 3 tables"},{"id":"http://arxiv.org/abs/2403.18347v1","updated":"2024-03-27T08:38:56Z","published":"2024-03-27T08:38:56Z","title":"A Quantum Fuzzy-based Approach for Real-Time Detection of Solar Coronal\n  Holes","summary":"  The detection and analysis of the solar coronal holes (CHs) is an important\nfield of study in the domain of solar physics. Mainly, it is required for the\nproper prediction of the geomagnetic storms which directly or indirectly affect\nvarious space and ground-based systems. For the detection of CHs till date, the\nsolar scientist depends on manual hand-drawn approaches. However, with the\nadvancement of image processing technologies, some automated image segmentation\nmethods have been used for the detection of CHs. In-spite of this, fast and\naccurate detection of CHs are till a major issues. Here in this work, a novel\nquantum computing-based fast fuzzy c-mean technique has been developed for fast\ndetection of the CHs region. The task has been carried out in two stages, in\nfirst stage the solar image has been segmented using a quantum computing based\nfast fuzzy c-mean (QCFFCM) and in the later stage the CHs has been extracted\nout from the segmented image based on image morphological operation. In the\nwork, quantum computing has been used to optimize the cost function of the fast\nfuzzy c-mean (FFCM) algorithm, where quantum approximate optimization algorithm\n(QAOA) has been used to optimize the quadratic part of the cost function. The\nproposed method has been tested for 193 \\AA{} SDO/AIA full-disk solar image\ndatasets and has been compared with the existing techniques. The outcome shows\nthe comparable performance of the proposed method with the existing one within\na very lesser time.\n","authors":["Sanmoy Bandyopadhyay","Suman Kundu"],"pdf_url":"https://arxiv.org/pdf/2403.18347v1.pdf","comment":"14 pages, 5 figures, 3 tables"},{"id":"http://arxiv.org/abs/2403.18344v1","updated":"2024-03-27T08:34:55Z","published":"2024-03-27T08:34:55Z","title":"LC-LLM: Explainable Lane-Change Intention and Trajectory Predictions\n  with Large Language Models","summary":"  To ensure safe driving in dynamic environments, autonomous vehicles should\npossess the capability to accurately predict the lane change intentions of\nsurrounding vehicles in advance and forecast their future trajectories.\nExisting motion prediction approaches have ample room for improvement,\nparticularly in terms of long-term prediction accuracy and interpretability. In\nthis paper, we address these challenges by proposing LC-LLM, an explainable\nlane change prediction model that leverages the strong reasoning capabilities\nand self-explanation abilities of Large Language Models (LLMs). Essentially, we\nreformulate the lane change prediction task as a language modeling problem,\nprocessing heterogeneous driving scenario information in natural language as\nprompts for input into the LLM and employing a supervised fine-tuning technique\nto tailor the LLM specifically for our lane change prediction task. This allows\nus to utilize the LLM's powerful common sense reasoning abilities to understand\ncomplex interactive information, thereby improving the accuracy of long-term\npredictions. Furthermore, we incorporate explanatory requirements into the\nprompts in the inference stage. Therefore, our LC-LLM model not only can\npredict lane change intentions and trajectories but also provides explanations\nfor its predictions, enhancing the interpretability. Extensive experiments on\nthe large-scale highD dataset demonstrate the superior performance and\ninterpretability of our LC-LLM in lane change prediction task. To the best of\nour knowledge, this is the first attempt to utilize LLMs for predicting lane\nchange behavior. Our study shows that LLMs can encode comprehensive interaction\ninformation for driving behavior understanding.\n","authors":["Mingxing Peng","Xusen Guo","Xianda Chen","Meixin Zhu","Kehua Chen"," Hao"," Yang","Xuesong Wang","Yinhai Wang"],"pdf_url":"https://arxiv.org/pdf/2403.18344v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18338v1","updated":"2024-03-27T08:25:28Z","published":"2024-03-27T08:25:28Z","title":"mALBERT: Is a Compact Multilingual BERT Model Still Worth It?","summary":"  Within the current trend of Pretained Language Models (PLM), emerge more and\nmore criticisms about the ethical andecological impact of such models. In this\narticle, considering these critical remarks, we propose to focus on\nsmallermodels, such as compact models like ALBERT, which are more ecologically\nvirtuous than these PLM. However,PLMs enable huge breakthroughs in Natural\nLanguage Processing tasks, such as Spoken and Natural LanguageUnderstanding,\nclassification, Question--Answering tasks. PLMs also have the advantage of\nbeing multilingual, and,as far as we know, a multilingual version of compact\nALBERT models does not exist. Considering these facts, wepropose the free\nrelease of the first version of a multilingual compact ALBERT model,\npre-trained using Wikipediadata, which complies with the ethical aspect of such\na language model. We also evaluate the model against classicalmultilingual PLMs\nin classical NLP tasks. Finally, this paper proposes a rare study on the\nsubword tokenizationimpact on language performances.\n","authors":["Christophe Servan","Sahar Ghannay","Sophie Rosset"],"pdf_url":"https://arxiv.org/pdf/2403.18338v1.pdf","comment":"The 2024 Joint International Conference on Computational Linguistics,\n  Language Resources and Evaluation, May 2024, Torino, Italy"},{"id":"http://arxiv.org/abs/2403.18327v1","updated":"2024-03-27T08:08:00Z","published":"2024-03-27T08:08:00Z","title":"Can LLMs Converse Formally? Automatically Assessing LLMs in Translating\n  and Interpreting Formal Specifications","summary":"  Stakeholders often describe system requirements using natural language which\nare then converted to formal syntax by a domain-expert leading to increased\ndesign costs. This paper assesses the capabilities of Large Language Models\n(LLMs) in converting between natural language descriptions and formal\nspecifications. Existing work has evaluated the capabilities of LLMs in\ngenerating formal syntax such as source code but such experiments are typically\nhand-crafted and use problems that are likely to be in the training set of\nLLMs, and often require human-annotated datasets. We propose an approach that\ncan use two copies of an LLM in conjunction with an off-the-shelf verifier to\nautomatically evaluate its translation abilities without any additional human\ninput. Our approach generates formal syntax using language grammars to\nautomatically generate a dataset. We conduct an empirical evaluation to measure\nthe accuracy of this translation task and show that SOTA LLMs cannot adequately\nsolve this task, limiting their current utility in the design of complex\nsystems.\n","authors":["Rushang Karia","Daksh Dobhal","Daniel Bramblett","Pulkit Verma","Siddharth Srivastava"],"pdf_url":"https://arxiv.org/pdf/2403.18327v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18314v1","updated":"2024-03-27T07:34:44Z","published":"2024-03-27T07:34:44Z","title":"Chinese Offensive Language Detection:Current Status and Future\n  Directions","summary":"  Despite the considerable efforts being made to monitor and regulate\nuser-generated content on social media platforms, the pervasiveness of\noffensive language, such as hate speech or cyberbullying, in the digital space\nremains a significant challenge. Given the importance of maintaining a\ncivilized and respectful online environment, there is an urgent and growing\nneed for automatic systems capable of detecting offensive speech in real time.\nHowever, developing effective systems for processing languages such as Chinese\npresents a significant challenge, owing to the language's complex and nuanced\nnature, which makes it difficult to process automatically. This paper provides\na comprehensive overview of offensive language detection in Chinese, examining\ncurrent benchmarks and approaches and highlighting specific models and tools\nfor addressing the unique challenges of detecting offensive language in this\ncomplex language. The primary objective of this survey is to explore the\nexisting techniques and identify potential avenues for further research that\ncan address the cultural and linguistic complexities of Chinese.\n","authors":["Yunze Xiao","Houda Bouamor","Wajdi Zaghouani"],"pdf_url":"https://arxiv.org/pdf/2403.18314v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18310v1","updated":"2024-03-27T07:22:32Z","published":"2024-03-27T07:22:32Z","title":"A thermodynamically consistent physics-informed deep learning material\n  model for short fiber/polymer nanocomposites","summary":"  This work proposes a physics-informed deep learning (PIDL)-based constitutive\nmodel for investigating the viscoelastic-viscoplastic behavior of short\nfiber-reinforced nanoparticle-filled epoxies under various ambient conditions.\nThe deep-learning model is trained to enforce thermodynamic principles, leading\nto a thermodynamically consistent constitutive model. To accomplish this, a\nlong short-term memory network is combined with a feed-forward neural network\nto predict internal variables required for characterizing the internal\ndissipation of the nanocomposite materials. In addition, another feed-forward\nneural network is used to indicate the free-energy function, which enables\ndefining the thermodynamic state of the entire system. The PIDL model is\ninitially developed for the three-dimensional case by generating synthetic data\nfrom a classical constitutive model. The model is then trained by extracting\nthe data directly from cyclic loading-unloading experimental tests. Numerical\nexamples show that the PIDL model can accurately predict the mechanical\nbehavior of epoxy-based nanocomposites for different volume fractions of fibers\nand nanoparticles under various hygrothermal conditions.\n","authors":["Betim Bahtiri","Behrouz Arash","Sven Scheffler","Maximilian Jux","Raimund Rolfes"],"pdf_url":"https://arxiv.org/pdf/2403.18310v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2305.08102"},{"id":"http://arxiv.org/abs/2307.09136v2","updated":"2024-03-27T07:16:28Z","published":"2023-07-18T10:34:21Z","title":"The Effects of Mixed Sample Data Augmentation are Class Dependent","summary":"  Mixed Sample Data Augmentation (MSDA) techniques, such as Mixup, CutMix, and\nPuzzleMix, have been widely acknowledged for enhancing performance in a variety\nof tasks. A previous study reported the class dependency of traditional data\naugmentation (DA), where certain classes benefit disproportionately compared to\nothers. This paper reveals a class dependent effect of MSDA, where some classes\nexperience improved performance while others experience degraded performance.\nThis research addresses the issue of class dependency in MSDA and proposes an\nalgorithm to mitigate it. The approach involves training on a mixture of MSDA\nand non-MSDA data, which not only mitigates the negative impact on the affected\nclasses, but also improves overall accuracy. Furthermore, we provide in-depth\nanalysis and discussion of why MSDA introduced class dependencies and which\nclasses are most likely to have them.\n","authors":["Haeil Lee","Hansang Lee","Junmo Kim"],"pdf_url":"https://arxiv.org/pdf/2307.09136v2.pdf","comment":"21 pages, 18 figures, Overall Revision"},{"id":"http://arxiv.org/abs/2402.18920v5","updated":"2024-03-27T07:16:21Z","published":"2024-02-29T07:26:23Z","title":"Spectral Meets Spatial: Harmonising 3D Shape Matching and Interpolation","summary":"  Although 3D shape matching and interpolation are highly interrelated, they\nare often studied separately and applied sequentially to relate different 3D\nshapes, thus resulting in sub-optimal performance. In this work we present a\nunified framework to predict both point-wise correspondences and shape\ninterpolation between 3D shapes. To this end, we combine the deep functional\nmap framework with classical surface deformation models to map shapes in both\nspectral and spatial domains. On the one hand, by incorporating spatial maps,\nour method obtains more accurate and smooth point-wise correspondences compared\nto previous functional map methods for shape matching. On the other hand, by\nintroducing spectral maps, our method gets rid of commonly used but\ncomputationally expensive geodesic distance constraints that are only valid for\nnear-isometric shape deformations. Furthermore, we propose a novel test-time\nadaptation scheme to capture both pose-dominant and shape-dominant\ndeformations. Using different challenging datasets, we demonstrate that our\nmethod outperforms previous state-of-the-art methods for both shape matching\nand interpolation, even compared to supervised approaches.\n","authors":["Dongliang Cao","Marvin Eisenberger","Nafie El Amrani","Daniel Cremers","Florian Bernard"],"pdf_url":"https://arxiv.org/pdf/2402.18920v5.pdf","comment":"accepted by CVPR2024"},{"id":"http://arxiv.org/abs/2306.12609v2","updated":"2024-03-27T07:11:30Z","published":"2023-06-22T00:12:30Z","title":"Towards Regulatable AI Systems: Technical Gaps and Policy Opportunities","summary":"  There is increasing attention being given to how to regulate AI systems. As\ngoverning bodies grapple with what values to encapsulate into regulation, we\nconsider the technical half of the question: To what extent can AI experts vet\nan AI system for adherence to regulatory requirements? We investigate this\nquestion through the lens of two public sector procurement checklists,\nidentifying what we can do now, what should be possible with technical\ninnovation, and what requirements need a more interdisciplinary approach.\n","authors":["Xudong Shen","Hannah Brown","Jiashu Tao","Martin Strobel","Yao Tong","Akshay Narayan","Harold Soh","Finale Doshi-Velez"],"pdf_url":"https://arxiv.org/pdf/2306.12609v2.pdf","comment":"scheduled for publication in the Communications of the ACM, titled\n  \"Directions of Technical Innovation for Regulatable AI Systems\""},{"id":"http://arxiv.org/abs/2310.17072v3","updated":"2024-03-27T07:04:58Z","published":"2023-10-26T00:28:37Z","title":"MMP++: Motion Manifold Primitives with Parametric Curve Models","summary":"  Motion Manifold Primitives (MMP), a manifold-based approach for encoding\nbasic motion skills, can produce diverse trajectories, enabling the system to\nadapt to unseen constraints. Nonetheless, we argue that current MMP models lack\ncrucial functionalities of movement primitives, such as temporal and via-points\nmodulation, found in traditional approaches. This shortfall primarily stems\nfrom MMP's reliance on discrete-time trajectories. To overcome these\nlimitations, we introduce Motion Manifold Primitives++ (MMP++), a new model\nthat integrates the strengths of both MMP and traditional methods by\nincorporating parametric curve representations into the MMP framework.\nFurthermore, we identify a significant challenge with MMP++: performance\ndegradation due to geometric distortions in the latent space, meaning that\nsimilar motions are not closely positioned. To address this, Isometric Motion\nManifold Primitives++ (IMMP++) is proposed to ensure the latent space\naccurately preserves the manifold's geometry. Our experimental results across\nvarious applications, including 2-DoF planar motions, 7-DoF robot arm motions,\nand SE(3) trajectory planning, show that MMP++ and IMMP++ outperform existing\nmethods in trajectory generation tasks, achieving substantial improvements in\nsome cases. Moreover, they enable the modulation of latent coordinates and\nvia-points, thereby allowing efficient online adaptation to dynamic\nenvironments.\n","authors":["Yonghyeon Lee"],"pdf_url":"https://arxiv.org/pdf/2310.17072v3.pdf","comment":"12 pages. This work has been submitted to the IEEE for possible\n  publication"},{"id":"http://arxiv.org/abs/2403.18305v1","updated":"2024-03-27T06:59:39Z","published":"2024-03-27T06:59:39Z","title":"A Recommender System for NFT Collectibles with Item Feature","summary":"  Recommender systems have been actively studied and applied in various domains\nto deal with information overload. Although there are numerous studies on\nrecommender systems for movies, music, and e-commerce, comparatively less\nattention has been paid to the recommender system for NFTs despite the\ncontinuous growth of the NFT market. This paper presents a recommender system\nfor NFTs that utilizes a variety of data sources, from NFT transaction records\nto external item features, to generate precise recommendations that cater to\nindividual preferences. We develop a data-efficient graph-based recommender\nsystem to efficiently capture the complex relationship between each item and\nusers and generate node(item) embeddings which incorporate both node feature\ninformation and graph structure. Furthermore, we exploit inputs beyond\nuser-item interactions, such as image feature, text feature, and price feature.\nNumerical experiments verify the performance of the graph-based recommender\nsystem improves significantly after utilizing all types of item features as\nside information, thereby outperforming all other baselines.\n","authors":["Minjoo Choi","Seonmi Kim","Yejin Kim","Youngbin Lee","Joohwan Hong","Yongjae Lee"],"pdf_url":"https://arxiv.org/pdf/2403.18305v1.pdf","comment":"Presented at the AAAI 2023 Bridge on AI for Financial Services\n  (https://sites.google.com/view/aaai-ai-fin/home)"},{"id":"http://arxiv.org/abs/2302.06912v4","updated":"2024-03-27T06:57:30Z","published":"2023-02-14T08:56:50Z","title":"Regret-Based Defense in Adversarial Reinforcement Learning","summary":"  Deep Reinforcement Learning (DRL) policies have been shown to be vulnerable\nto small adversarial noise in observations. Such adversarial noise can have\ndisastrous consequences in safety-critical environments. For instance, a\nself-driving car receiving adversarially perturbed sensory observations about\nnearby signs (e.g., a stop sign physically altered to be perceived as a speed\nlimit sign) or objects (e.g., cars altered to be recognized as trees) can be\nfatal. Existing approaches for making RL algorithms robust to an\nobservation-perturbing adversary have focused on reactive approaches that\niteratively improve against adversarial examples generated at each iteration.\nWhile such approaches have been shown to provide improvements over regular RL\nmethods, they are reactive and can fare significantly worse if certain\ncategories of adversarial examples are not generated during training. To that\nend, we pursue a more proactive approach that relies on directly optimizing a\nwell-studied robustness measure, regret instead of expected value. We provide a\nprincipled approach that minimizes maximum regret over a \"neighborhood\" of\nobservations to the received \"observation\". Our regret criterion can be used to\nmodify existing value- and policy-based Deep RL methods. We demonstrate that\nour approaches provide a significant improvement in performance across a wide\nvariety of benchmarks against leading approaches for robust Deep RL.\n","authors":["Roman Belaire","Pradeep Varakantham","Thanh Nguyen","David Lo"],"pdf_url":"https://arxiv.org/pdf/2302.06912v4.pdf","comment":"Accepted at AAMAS 2024"},{"id":"http://arxiv.org/abs/2403.18301v1","updated":"2024-03-27T06:55:23Z","published":"2024-03-27T06:55:23Z","title":"Selective Mixup Fine-Tuning for Optimizing Non-Decomposable Objectives","summary":"  The rise in internet usage has led to the generation of massive amounts of\ndata, resulting in the adoption of various supervised and semi-supervised\nmachine learning algorithms, which can effectively utilize the colossal amount\nof data to train models. However, before deploying these models in the real\nworld, these must be strictly evaluated on performance measures like worst-case\nrecall and satisfy constraints such as fairness. We find that current\nstate-of-the-art empirical techniques offer sub-optimal performance on these\npractical, non-decomposable performance objectives. On the other hand, the\ntheoretical techniques necessitate training a new model from scratch for each\nperformance objective. To bridge the gap, we propose SelMix, a selective\nmixup-based inexpensive fine-tuning technique for pre-trained models, to\noptimize for the desired objective. The core idea of our framework is to\ndetermine a sampling distribution to perform a mixup of features between\nsamples from particular classes such that it optimizes the given objective. We\ncomprehensively evaluate our technique against the existing empirical and\ntheoretically principled methods on standard benchmark datasets for imbalanced\nclassification. We find that proposed SelMix fine-tuning significantly improves\nthe performance for various practical non-decomposable objectives across\nbenchmarks.\n","authors":["Shrinivas Ramasubramanian","Harsh Rangwani","Sho Takemori","Kunal Samanta","Yuhei Umeda","Venkatesh Babu Radhakrishnan"],"pdf_url":"https://arxiv.org/pdf/2403.18301v1.pdf","comment":"ICLR 2024 SpotLight"},{"id":"http://arxiv.org/abs/2403.18296v1","updated":"2024-03-27T06:46:59Z","published":"2024-03-27T06:46:59Z","title":"GeNet: A Graph Neural Network-based Anti-noise Task-Oriented Semantic\n  Communication Paradigm","summary":"  Traditional approaches to semantic communication tasks rely on the knowledge\nof the signal-to-noise ratio (SNR) to mitigate channel noise. However, these\nmethods necessitate training under specific SNR conditions, entailing\nconsiderable time and computational resources. In this paper, we propose GeNet,\na Graph Neural Network (GNN)-based paradigm for semantic communication aimed at\ncombating noise, thereby facilitating Task-Oriented Communication (TOC). We\npropose a novel approach where we first transform the input data image into\ngraph structures. Then we leverage a GNN-based encoder to extract semantic\ninformation from the source data. This extracted semantic information is then\ntransmitted through the channel. At the receiver's end, a GNN-based decoder is\nutilized to reconstruct the relevant semantic information from the source data\nfor TOC. Through experimental evaluation, we show GeNet's effectiveness in\nanti-noise TOC while decoupling the SNR dependency. We further evaluate GeNet's\nperformance by varying the number of nodes, revealing its versatility as a new\nparadigm for semantic communication. Additionally, we show GeNet's robustness\nto geometric transformations by testing it with different rotation angles,\nwithout resorting to data augmentation.\n","authors":["Chunhang Zheng","Kechao Cai"],"pdf_url":"https://arxiv.org/pdf/2403.18296v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17421v2","updated":"2024-03-27T06:28:53Z","published":"2024-03-26T06:34:23Z","title":"MA4DIV: Multi-Agent Reinforcement Learning for Search Result\n  Diversification","summary":"  The objective of search result diversification (SRD) is to ensure that\nselected documents cover as many different subtopics as possible. Existing\nmethods primarily utilize a paradigm of \"greedy selection\", i.e., selecting one\ndocument with the highest diversity score at a time. These approaches tend to\nbe inefficient and are easily trapped in a suboptimal state. In addition, some\nother methods aim to approximately optimize the diversity metric, such as\n$\\alpha$-NDCG, but the results still remain suboptimal. To address these\nchallenges, we introduce Multi-Agent reinforcement learning (MARL) for search\nresult DIVersity, which called MA4DIV. In this approach, each document is an\nagent and the search result diversification is modeled as a cooperative task\namong multiple agents. This approach allows for directly optimizing the\ndiversity metrics, such as $\\alpha$-NDCG, while achieving high training\nefficiency. We conducted preliminary experiments on public TREC datasets to\ndemonstrate the effectiveness and potential of MA4DIV. Considering the limited\nnumber of queries in public TREC datasets, we construct a large-scale dataset\nfrom industry sources and show that MA4DIV achieves substantial improvements in\nboth effectiveness and efficiency than existing baselines on a industrial scale\ndataset.\n","authors":["Yiqun Chen","Jiaxin Mao","Yi Zhang","Dehong Ma","Long Xia","Jun Fan","Daiting Shi","Zhicong Cheng","Simiu Gu","Dawei Yin"],"pdf_url":"https://arxiv.org/pdf/2403.17421v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18286v1","updated":"2024-03-27T06:25:40Z","published":"2024-03-27T06:25:40Z","title":"Few-Shot Recalibration of Language Models","summary":"  Recent work has uncovered promising ways to extract well-calibrated\nconfidence estimates from language models (LMs), where the model's confidence\nscore reflects how likely it is to be correct. However, while LMs may appear\nwell-calibrated over broad distributions, this often hides significant\nmiscalibration within narrower slices (e.g., systemic over-confidence in math\ncan balance out systemic under-confidence in history, yielding perfect\ncalibration in aggregate). To attain well-calibrated confidence estimates for\nany slice of a distribution, we propose a new framework for few-shot\nslice-specific recalibration. Specifically, we train a recalibration model that\ntakes in a few unlabeled examples from any given slice and predicts a curve\nthat remaps confidence scores to be more accurate for that slice. Our trained\nmodel can recalibrate for arbitrary new slices, without using any labeled data\nfrom that slice. This enables us to identify domain-specific confidence\nthresholds above which the LM's predictions can be trusted, and below which it\nshould abstain. Experiments show that our few-shot recalibrator consistently\noutperforms existing calibration methods, for instance improving calibration\nerror for PaLM2-Large on MMLU by 16%, as compared to temperature scaling.\n","authors":["Xiang Lisa Li","Urvashi Khandelwal","Kelvin Guu"],"pdf_url":"https://arxiv.org/pdf/2403.18286v1.pdf","comment":"preprint"},{"id":"http://arxiv.org/abs/2403.16512v2","updated":"2024-03-27T06:25:10Z","published":"2024-03-25T07:55:29Z","title":"LLMs Are Few-Shot In-Context Low-Resource Language Learners","summary":"  In-context learning (ICL) empowers large language models (LLMs) to perform\ndiverse tasks in underrepresented languages using only short in-context\ninformation, offering a crucial avenue for narrowing the gap between\nhigh-resource and low-resource languages. Nonetheless, there is only a handful\nof works explored ICL for low-resource languages with most of them focusing on\nrelatively high-resource languages, such as French and Spanish. In this work,\nwe extensively study ICL and its cross-lingual variation (X-ICL) on 25\nlow-resource and 7 relatively higher-resource languages. Our study not only\nassesses the effectiveness of ICL with LLMs in low-resource languages but also\nidentifies the shortcomings of in-context label alignment, and introduces a\nmore effective alternative: query alignment. Moreover, we provide valuable\ninsights into various facets of ICL for low-resource languages. Our study\nconcludes the significance of few-shot in-context information on enhancing the\nlow-resource understanding quality of LLMs through semantically relevant\ninformation by closing the language gap in the target language and aligning the\nsemantics between the targeted low-resource and the high-resource language that\nthe model is proficient in. Our work highlights the importance of advancing ICL\nresearch, particularly for low-resource languages.\n","authors":["Samuel Cahyawijaya","Holy Lovenia","Pascale Fung"],"pdf_url":"https://arxiv.org/pdf/2403.16512v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15472v2","updated":"2024-03-27T06:22:41Z","published":"2024-03-20T15:47:28Z","title":"Enhancing Programming Education with ChatGPT: A Case Study on Student\n  Perceptions and Interactions in a Python Course","summary":"  The integration of ChatGPT as a supportive tool in education, notably in\nprogramming courses, addresses the unique challenges of programming education\nby providing assistance with debugging, code generation, and explanations.\nDespite existing research validating ChatGPT's effectiveness, its application\nin university-level programming education and a detailed understanding of\nstudent interactions and perspectives remain limited. This paper explores\nChatGPT's impact on learning in a Python programming course tailored for\nfirst-year students over eight weeks. By analyzing responses from surveys,\nopen-ended questions, and student-ChatGPT dialog data, we aim to provide a\ncomprehensive view of ChatGPT's utility and identify both its advantages and\nlimitations as perceived by students. Our study uncovers a generally positive\nreception toward ChatGPT and offers insights into its role in enhancing the\nprogramming education experience. These findings contribute to the broader\ndiscourse on AI's potential in education, suggesting paths for future research\nand application.\n","authors":["Boxaun Ma","Li Chen","Shin'ichi Konomi"],"pdf_url":"https://arxiv.org/pdf/2403.15472v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18278v1","updated":"2024-03-27T06:13:39Z","published":"2024-03-27T06:13:39Z","title":"Identification and Uses of Deep Learning Backbones via Pattern Mining","summary":"  Deep learning is extensively used in many areas of data mining as a black-box\nmethod with impressive results. However, understanding the core mechanism of\nhow deep learning makes predictions is a relatively understudied problem. Here\nwe explore the notion of identifying a backbone of deep learning for a given\ngroup of instances. A group here can be instances of the same class or even\nmisclassified instances of the same class. We view each instance for a given\ngroup as activating a subset of neurons and attempt to find a subgraph of\nneurons associated with a given concept/group. We formulate this problem as a\nset cover style problem and show it is intractable and presents a highly\nconstrained integer linear programming (ILP) formulation. As an alternative, we\nexplore a coverage-based heuristic approach related to pattern mining, and show\nit converges to a Pareto equilibrium point of the ILP formulation.\nExperimentally we explore these backbones to identify mistakes and improve\nperformance, explanation, and visualization. We demonstrate application-based\nresults using several challenging data sets, including Bird Audio Detection\n(BAD) Challenge and Labeled Faces in the Wild (LFW), as well as the classic\nMNIST data.\n","authors":["Michael Livanos","Ian Davidson"],"pdf_url":"https://arxiv.org/pdf/2403.18278v1.pdf","comment":"9 pages, 6 figures, published SIAM SDM24"},{"id":"http://arxiv.org/abs/2403.07711v2","updated":"2024-03-27T06:02:38Z","published":"2024-03-12T14:53:56Z","title":"SSM Meets Video Diffusion Models: Efficient Video Generation with\n  Structured State Spaces","summary":"  Given the remarkable achievements in image generation through diffusion\nmodels, the research community has shown increasing interest in extending these\nmodels to video generation. Recent diffusion models for video generation have\npredominantly utilized attention layers to extract temporal features. However,\nattention layers are limited by their memory consumption, which increases\nquadratically with the length of the sequence. This limitation presents\nsignificant challenges when attempting to generate longer video sequences using\ndiffusion models. To overcome this challenge, we propose leveraging state-space\nmodels (SSMs). SSMs have recently gained attention as viable alternatives due\nto their linear memory consumption relative to sequence length. In the\nexperiments, we first evaluate our SSM-based model with UCF101, a standard\nbenchmark of video generation. In addition, to investigate the potential of\nSSMs for longer video generation, we perform an experiment using the MineRL\nNavigate dataset, varying the number of frames to 64, 200, and 400. In these\nsettings, our SSM-based model can considerably save memory consumption for\nlonger sequences, while maintaining competitive FVD scores to the\nattention-based models. Our codes are available at\nhttps://github.com/shim0114/SSM-Meets-Video-Diffusion-Models.\n","authors":["Yuta Oshima","Shohei Taniguchi","Masahiro Suzuki","Yutaka Matsuo"],"pdf_url":"https://arxiv.org/pdf/2403.07711v2.pdf","comment":"Accepted as workshop paper at ICLR 2024"},{"id":"http://arxiv.org/abs/2305.14258v2","updated":"2024-03-27T05:45:37Z","published":"2023-05-23T17:11:33Z","title":"Weakly Supervised AUC Optimization: A Unified Partial AUC Approach","summary":"  Since acquiring perfect supervision is usually difficult, real-world machine\nlearning tasks often confront inaccurate, incomplete, or inexact supervision,\ncollectively referred to as weak supervision. In this work, we present WSAUC, a\nunified framework for weakly supervised AUC optimization problems, which covers\nnoisy label learning, positive-unlabeled learning, multi-instance learning, and\nsemi-supervised learning scenarios. Within the WSAUC framework, we first frame\nthe AUC optimization problems in various weakly supervised scenarios as a\ncommon formulation of minimizing the AUC risk on contaminated sets, and\ndemonstrate that the empirical risk minimization problems are consistent with\nthe true AUC. Then, we introduce a new type of partial AUC, specifically, the\nreversed partial AUC (rpAUC), which serves as a robust training objective for\nAUC maximization in the presence of contaminated labels. WSAUC offers a\nuniversal solution for AUC optimization in various weakly supervised scenarios\nby maximizing the empirical rpAUC. Theoretical and experimental results under\nmultiple settings support the effectiveness of WSAUC on a range of weakly\nsupervised AUC optimization tasks.\n","authors":["Zheng Xie","Yu Liu","Hao-Yuan He","Ming Li","Zhi-Hua Zhou"],"pdf_url":"https://arxiv.org/pdf/2305.14258v2.pdf","comment":"Accepted by IEEE TPAMI"},{"id":"http://arxiv.org/abs/2403.18267v1","updated":"2024-03-27T05:41:50Z","published":"2024-03-27T05:41:50Z","title":"DSF-GAN: DownStream Feedback Generative Adversarial Network","summary":"  Utility and privacy are two crucial measurements of the quality of synthetic\ntabular data. While significant advancements have been made in privacy\nmeasures, generating synthetic samples with high utility remains challenging.\nTo enhance the utility of synthetic samples, we propose a novel architecture\ncalled the DownStream Feedback Generative Adversarial Network (DSF-GAN). This\napproach incorporates feedback from a downstream prediction model during\ntraining to augment the generator's loss function with valuable information.\nThus, DSF-GAN utilizes a downstream prediction task to enhance the utility of\nsynthetic samples. To evaluate our method, we tested it using two popular\ndatasets. Our experiments demonstrate improved model performance when training\non synthetic samples generated by DSF-GAN, compared to those generated by the\nsame GAN architecture without feedback. The evaluation was conducted on the\nsame validation set comprising real samples. All code and datasets used in this\nresearch will be made openly available for ease of reproduction.\n","authors":["Oriel Perets","Nadav Rappoport"],"pdf_url":"https://arxiv.org/pdf/2403.18267v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18258v1","updated":"2024-03-27T05:10:38Z","published":"2024-03-27T05:10:38Z","title":"Enhancing Generative Class Incremental Learning Performance with Model\n  Forgetting Approach","summary":"  This study presents a novel approach to Generative Class Incremental Learning\n(GCIL) by introducing the forgetting mechanism, aimed at dynamically managing\nclass information for better adaptation to streaming data. GCIL is one of the\nhot topics in the field of computer vision, and this is considered one of the\ncrucial tasks in society, specifically the continual learning of generative\nmodels. The ability to forget is a crucial brain function that facilitates\ncontinual learning by selectively discarding less relevant information for\nhumans. However, in the field of machine learning models, the concept of\nintentionally forgetting has not been extensively investigated. In this study\nwe aim to bridge this gap by incorporating the forgetting mechanisms into GCIL,\nthereby examining their impact on the models' ability to learn in continual\nlearning. Through our experiments, we have found that integrating the\nforgetting mechanisms significantly enhances the models' performance in\nacquiring new knowledge, underscoring the positive role that strategic\nforgetting plays in the process of continual learning.\n","authors":["Taro Togo","Ren Togo","Keisuke Maeda","Takahiro Ogawa","Miki Haseyama"],"pdf_url":"https://arxiv.org/pdf/2403.18258v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.09131v2","updated":"2024-03-27T05:02:55Z","published":"2024-03-14T06:49:16Z","title":"ProSwitch: Knowledge-Guided Language Model Fine-Tuning to Generate\n  Professional and Non-Professional Styled Text","summary":"  Large Language Models (LLMs) have demonstrated efficacy in various linguistic\napplications, including text summarization and controlled text generation.\nHowever, studies into their capacity of switching between styles via\nfine-tuning remain underexplored. This study concentrates on textual\nprofessionalism and introduces a novel methodology, named ProSwitch, which\nequips a language model with the ability to produce both professional and\nnon-professional responses through knowledge-guided instruction tuning.\nProSwitch unfolds across three phases: data preparation for gathering domain\nknowledge and training corpus; instruction tuning for optimizing language\nmodels with multiple levels of instruction formats; and comprehensive\nevaluation for assessing the professionalism discrimination and reference-based\nquality of generated text. Comparative analysis of ProSwitch against both\ngeneral and specialized language models reveals that our approach outperforms\nbaselines in switching between professional and non-professional text\ngeneration.\n","authors":["Chang Zong","Yuyan Chen","Weiming Lu","Jian Shao","Yueting Zhuang"],"pdf_url":"https://arxiv.org/pdf/2403.09131v2.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2403.18256v1","updated":"2024-03-27T04:56:48Z","published":"2024-03-27T04:56:48Z","title":"Manipulating Neural Path Planners via Slight Perturbations","summary":"  Data-driven neural path planners are attracting increasing interest in the\nrobotics community. However, their neural network components typically come as\nblack boxes, obscuring their underlying decision-making processes. Their\nblack-box nature exposes them to the risk of being compromised via the\ninsertion of hidden malicious behaviors. For example, an attacker may hide\nbehaviors that, when triggered, hijack a delivery robot by guiding it to a\nspecific (albeit wrong) destination, trapping it in a predefined region, or\ninducing unnecessary energy expenditure by causing the robot to repeatedly\ncircle a region. In this paper, we propose a novel approach to specify and\ninject a range of hidden malicious behaviors, known as backdoors, into neural\npath planners. Our approach provides a concise but flexible way to define these\nbehaviors, and we show that hidden behaviors can be triggered by slight\nperturbations (e.g., inserting a tiny unnoticeable object), that can\nnonetheless significantly compromise their integrity. We also discuss potential\ntechniques to identify these backdoors aimed at alleviating such risks. We\ndemonstrate our approach on both sampling-based and search-based neural path\nplanners.\n","authors":["Zikang Xiong","Suresh Jagannathan"],"pdf_url":"https://arxiv.org/pdf/2403.18256v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18252v1","updated":"2024-03-27T04:49:23Z","published":"2024-03-27T04:49:23Z","title":"Beyond Embeddings: The Promise of Visual Table in Multi-Modal Models","summary":"  Visual representation learning has been a cornerstone in computer vision,\nevolving from supervised learning with human-annotated labels to aligning\nimage-text pairs from the Internet. Despite recent advancements in multi-modal\nlarge language models (MLLMs), the visual representations they rely on, such as\nCLIP embeddings, often lack access to external world knowledge critical for\nreal-world visual reasoning. In this work, we propose Visual Table, a novel\nvisual representation tailored for MLLMs. It provides hierarchical text\ndescriptions of holistic visual scenes, consisting of a scene description and\nmultiple object-centric descriptions that encompass categories, attributes, and\nknowledge at instance level. We further develop a scalable generator for visual\ntable generation and train it on small-scale annotations from GPT4V. Extensive\nevaluations demonstrate that, with generated visual tables as additional visual\nrepresentations, our model can consistently outperform the state-of-the-art\n(SOTA) MLLMs across diverse benchmarks. When visual tables serve as standalone\nvisual representations, our model can closely match or even beat the SOTA MLLMs\nthat are built on CLIP visual embeddings. Our code is available at\nhttps://github.com/LaVi-Lab/Visual-Table.\n","authors":["Yiwu Zhong","Zi-Yuan Hu","Michael R. Lyu","Liwei Wang"],"pdf_url":"https://arxiv.org/pdf/2403.18252v1.pdf","comment":"Project page: https://github.com/LaVi-Lab/Visual-Table"},{"id":"http://arxiv.org/abs/2403.18243v1","updated":"2024-03-27T04:20:18Z","published":"2024-03-27T04:20:18Z","title":"Boosting Conversational Question Answering with Fine-Grained\n  Retrieval-Augmentation and Self-Check","summary":"  Retrieval-Augmented Generation (RAG) aims to generate more reliable and\naccurate responses, by augmenting large language models (LLMs) with the\nexternal vast and dynamic knowledge. Most previous work focuses on using RAG\nfor single-round question answering, while how to adapt RAG to the complex\nconversational setting wherein the question is interdependent on the preceding\ncontext is not well studied. In this paper, we propose a conversation-level RAG\napproach, which incorporates fine-grained retrieval augmentation and self-check\nfor conversational question answering (CQA). In particular, our approach\nconsists of three components, namely conversational question refiner,\nfine-grained retriever and self-check based response generator, which work\ncollaboratively for question understanding and relevant information acquisition\nin conversational settings. Extensive experiments demonstrate the great\nadvantages of our approach over the state-of-the-art baselines. Moreover, we\nalso release a Chinese CQA dataset with new features including reformulated\nquestion, extracted keyword, retrieved paragraphs and their helpfulness, which\nfacilitates further researches in RAG enhanced CQA.\n","authors":["Linhao Ye","Zhikai Lei","Jianghao Yin","Qin Chen","Jie Zhou","Liang He"],"pdf_url":"https://arxiv.org/pdf/2403.18243v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18241v1","updated":"2024-03-27T04:09:34Z","published":"2024-03-27T04:09:34Z","title":"NeuSDFusion: A Spatial-Aware Generative Model for 3D Shape Completion,\n  Reconstruction, and Generation","summary":"  3D shape generation aims to produce innovative 3D content adhering to\nspecific conditions and constraints. Existing methods often decompose 3D shapes\ninto a sequence of localized components, treating each element in isolation\nwithout considering spatial consistency. As a result, these approaches exhibit\nlimited versatility in 3D data representation and shape generation, hindering\ntheir ability to generate highly diverse 3D shapes that comply with the\nspecified constraints. In this paper, we introduce a novel spatial-aware 3D\nshape generation framework that leverages 2D plane representations for enhanced\n3D shape modeling. To ensure spatial coherence and reduce memory usage, we\nincorporate a hybrid shape representation technique that directly learns a\ncontinuous signed distance field representation of the 3D shape using\northogonal 2D planes. Additionally, we meticulously enforce spatial\ncorrespondences across distinct planes using a transformer-based autoencoder\nstructure, promoting the preservation of spatial relationships in the generated\n3D shapes. This yields an algorithm that consistently outperforms\nstate-of-the-art 3D shape generation methods on various tasks, including\nunconditional shape generation, multi-modal shape completion, single-view\nreconstruction, and text-to-shape synthesis.\n","authors":["Ruikai Cui","Weizhe Liu","Weixuan Sun","Senbo Wang","Taizhang Shang","Yang Li","Xibin Song","Han Yan","Zhennan Wu","Shenzhou Chen","Hongdong Li","Pan Ji"],"pdf_url":"https://arxiv.org/pdf/2403.18241v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18230v1","updated":"2024-03-27T03:33:32Z","published":"2024-03-27T03:33:32Z","title":"Large Language Models Need Consultants for Reasoning: Becoming an Expert\n  in a Complex Human System Through Behavior Simulation","summary":"  Large language models (LLMs), in conjunction with various reasoning\nreinforcement methodologies, have demonstrated remarkable capabilities\ncomparable to humans in fields such as mathematics, law, coding, common sense,\nand world knowledge. In this paper, we delve into the reasoning abilities of\nLLMs within complex human systems. We propose a novel reasoning framework,\ntermed ``Mosaic Expert Observation Wall'' (MEOW) exploiting\ngenerative-agents-based simulation technique. In the MEOW framework, simulated\ndata are utilized to train an expert model concentrating ``experience'' about a\nspecific task in each independent time of simulation. It is the accumulated\n``experience'' through the simulation that makes for an expert on a task in a\ncomplex human system. We conduct the experiments within a communication game\nthat mirrors real-world security scenarios. The results indicate that our\nproposed methodology can cooperate with existing methodologies to enhance the\nreasoning abilities of LLMs in complex human systems.\n","authors":["Chuwen Wang","Shirong Zeng","Cheng Wang"],"pdf_url":"https://arxiv.org/pdf/2403.18230v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16427v3","updated":"2024-03-27T03:27:24Z","published":"2024-03-25T05:12:18Z","title":"Re2LLM: Reflective Reinforcement Large Language Model for Session-based\n  Recommendation","summary":"  Large Language Models (LLMs) are emerging as promising approaches to enhance\nsession-based recommendation (SBR), where both prompt-based and\nfine-tuning-based methods have been widely investigated to align LLMs with SBR.\nHowever, the former methods struggle with optimal prompts to elicit the correct\nreasoning of LLMs due to the lack of task-specific feedback, leading to\nunsatisfactory recommendations. Although the latter methods attempt to\nfine-tune LLMs with domain-specific knowledge, they face limitations such as\nhigh computational costs and reliance on open-source backbones. To address such\nissues, we propose a Reflective Reinforcement Large Language Model (Re2LLM) for\nSBR, guiding LLMs to focus on specialized knowledge essential for more accurate\nrecommendations effectively and efficiently. In particular, we first design the\nReflective Exploration Module to effectively extract knowledge that is readily\nunderstandable and digestible by LLMs. To be specific, we direct LLMs to\nexamine recommendation errors through self-reflection and construct a knowledge\nbase (KB) comprising hints capable of rectifying these errors. To efficiently\nelicit the correct reasoning of LLMs, we further devise the Reinforcement\nUtilization Module to train a lightweight retrieval agent. It learns to select\nhints from the constructed KB based on the task-specific feedback, where the\nhints can serve as guidance to help correct LLMs reasoning for better\nrecommendations. Extensive experiments on multiple real-world datasets\ndemonstrate that our method consistently outperforms state-of-the-art methods.\n","authors":["Ziyan Wang","Yingpeng Du","Zhu Sun","Haoyan Chua","Kaidong Feng","Wenya Wang","Jie Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.16427v3.pdf","comment":"11 pages, 4 figures"},{"id":"http://arxiv.org/abs/2403.18223v1","updated":"2024-03-27T03:25:45Z","published":"2024-03-27T03:25:45Z","title":"A Transformer-Based Framework for Payload Malware Detection and\n  Classification","summary":"  As malicious cyber threats become more sophisticated in breaching computer\nnetworks, the need for effective intrusion detection systems (IDSs) becomes\ncrucial. Techniques such as Deep Packet Inspection (DPI) have been introduced\nto allow IDSs analyze the content of network packets, providing more context\nfor identifying potential threats. IDSs traditionally rely on using\nanomaly-based and signature-based detection techniques to detect unrecognized\nand suspicious activity. Deep learning techniques have shown great potential in\nDPI for IDSs due to their efficiency in learning intricate patterns from the\npacket content being transmitted through the network. In this paper, we propose\na revolutionary DPI algorithm based on transformers adapted for the purpose of\ndetecting malicious traffic with a classifier head. Transformers learn the\ncomplex content of sequence data and generalize them well to similar scenarios\nthanks to their self-attention mechanism. Our proposed method uses the raw\npayload bytes that represent the packet contents and is deployed as\nman-in-the-middle. The payload bytes are used to detect malicious packets and\nclassify their types. Experimental results on the UNSW-NB15 and CIC-IOT23\ndatasets demonstrate that our transformer-based model is effective in\ndistinguishing malicious from benign traffic in the test dataset, attaining an\naverage accuracy of 79\\% using binary classification and 72\\% on the\nmulti-classification experiment, both using solely payload bytes.\n","authors":["Kyle Stein","Arash Mahyari","Guillermo Francia III","Eman El-Sheikh"],"pdf_url":"https://arxiv.org/pdf/2403.18223v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18219v1","updated":"2024-03-27T03:07:18Z","published":"2024-03-27T03:07:18Z","title":"From Two-Dimensional to Three-Dimensional Environment with Q-Learning:\n  Modeling Autonomous Navigation with Reinforcement Learning and no Libraries","summary":"  Reinforcement learning (RL) algorithms have become indispensable tools in\nartificial intelligence, empowering agents to acquire optimal decision-making\npolicies through interactions with their environment and feedback mechanisms.\nThis study explores the performance of RL agents in both two-dimensional (2D)\nand three-dimensional (3D) environments, aiming to research the dynamics of\nlearning across different spatial dimensions. A key aspect of this\ninvestigation is the absence of pre-made libraries for learning, with the\nalgorithm developed exclusively through computational mathematics. The\nmethodological framework centers on RL principles, employing a Q-learning agent\nclass and distinct environment classes tailored to each spatial dimension. The\nresearch aims to address the question: How do reinforcement learning agents\nadapt and perform in environments of varying spatial dimensions, particularly\nin 2D and 3D settings? Through empirical analysis, the study evaluates agents'\nlearning trajectories and adaptation processes, revealing insights into the\nefficacy of RL algorithms in navigating complex, multi-dimensional spaces.\nReflections on the findings prompt considerations for future research,\nparticularly in understanding the dynamics of learning in higher-dimensional\nenvironments.\n","authors":["Ergon Cugler de Moraes Silva"],"pdf_url":"https://arxiv.org/pdf/2403.18219v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.04357v5","updated":"2024-03-27T03:06:13Z","published":"2023-06-07T11:40:07Z","title":"Dial-MAE: ConTextual Masked Auto-Encoder for Retrieval-based Dialogue\n  Systems","summary":"  Dialogue response selection aims to select an appropriate response from\nseveral candidates based on a given user and system utterance history. Most\nexisting works primarily focus on post-training and fine-tuning tailored for\ncross-encoders. However, there are no post-training methods tailored for dense\nencoders in dialogue response selection. We argue that when the current\nlanguage model, based on dense dialogue systems (such as BERT), is employed as\na dense encoder, it separately encodes dialogue context and response, leading\nto a struggle to achieve the alignment of both representations. Thus, we\npropose Dial-MAE (Dialogue Contextual Masking Auto-Encoder), a straightforward\nyet effective post-training technique tailored for dense encoders in dialogue\nresponse selection. Dial-MAE uses an asymmetric encoder-decoder architecture to\ncompress the dialogue semantics into dense vectors, which achieves better\nalignment between the features of the dialogue context and response. Our\nexperiments have demonstrated that Dial-MAE is highly effective, achieving\nstate-of-the-art performance on two commonly evaluated benchmarks.\n","authors":["Zhenpeng Su","Xing Wu","Wei Zhou","Guangyuan Ma","Songlin Hu"],"pdf_url":"https://arxiv.org/pdf/2306.04357v5.pdf","comment":"This paper has been accepted by NAACL 2024"},{"id":"http://arxiv.org/abs/2403.18218v1","updated":"2024-03-27T03:04:21Z","published":"2024-03-27T03:04:21Z","title":"Leveraging Large Language Models for Fuzzy String Matching in Political\n  Science","summary":"  Fuzzy string matching remains a key issue when political scientists combine\ndata from different sources. Existing matching methods invariably rely on\nstring distances, such as Levenshtein distance and cosine similarity. As such,\nthey are inherently incapable of matching strings that refer to the same entity\nwith different names such as ''JP Morgan'' and ''Chase Bank'', ''DPRK'' and\n''North Korea'', ''Chuck Fleischmann (R)'' and ''Charles Fleischmann (R)''. In\nthis letter, we propose to use large language models to entirely sidestep this\nproblem in an easy and intuitive manner. Extensive experiments show that our\nproposed methods can improve the state of the art by as much as 39% in terms of\naverage precision while being substantially easier and more intuitive to use by\npolitical scientists. Moreover, our results are robust against various\ntemperatures. We further note that enhanced prompting can lead to additional\nperformance improvements.\n","authors":["Yu Wang"],"pdf_url":"https://arxiv.org/pdf/2403.18218v1.pdf","comment":"7 pages, 2 figures, 1 table;"},{"id":"http://arxiv.org/abs/2403.00868v2","updated":"2024-03-27T03:03:00Z","published":"2024-03-01T04:39:16Z","title":"SoftTiger: A Clinical Foundation Model for Healthcare Workflows","summary":"  We introduce SoftTiger, a clinical large language model (CLaM) designed as a\nfoundation model for healthcare workflows. The narrative and unstructured\nnature of clinical notes is a major obstacle for healthcare intelligentization.\nWe address a critical problem of structuring clinical notes into clinical data,\naccording to international interoperability standards. We collect and annotate\ndata for three subtasks, namely, international patient summary, clinical\nimpression and medical encounter. We then supervised fine-tuned a\nstate-of-the-art LLM using public and credentialed clinical data. The training\nis orchestrated in a way that the target model can first support basic clinical\ntasks such as abbreviation expansion and temporal information extraction, and\nthen learn to perform more complex downstream clinical tasks. Moreover, we\naddress several modeling challenges in the healthcare context, e.g., extra long\ncontext window. Our blind pairwise evaluation shows that SoftTiger outperforms\nother popular open-source models and GPT-3.5, comparable to Gemini-pro, with a\nmild gap from GPT-4. We believe that LLMs may become a step-stone towards\nhealthcare digitalization and democratization. Therefore, we publicly release\nSoftTiger models at scales of 13 billion and 70 billion parameters, as well as\ndatasets and code for our innovative scalable evaluation, hopefully, making a\nsignificant contribution to the healthcare industry.\n","authors":["Ye Chen","Igor Couto","Wei Cai","Cong Fu","Bruno Dorneles"],"pdf_url":"https://arxiv.org/pdf/2403.00868v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.17304v2","updated":"2024-03-27T02:59:57Z","published":"2024-02-27T08:27:15Z","title":"Probing Multimodal Large Language Models for Global and Local Semantic\n  Representations","summary":"  The advancement of Multimodal Large Language Models (MLLMs) has greatly\naccelerated the development of applications in understanding integrated texts\nand images. Recent works leverage image-caption datasets to train MLLMs,\nachieving state-of-the-art performance on image-to-text tasks. However, there\nare few studies exploring which layers of MLLMs make the most effort to the\nglobal image information, which plays vital roles in multimodal comprehension\nand generation. In this study, we find that the intermediate layers of models\ncan encode more global semantic information, whose representation vectors\nperform better on visual-language entailment tasks, rather than the topmost\nlayers. We further probe models regarding local semantic representations\nthrough object recognition tasks. We find that the topmost layers may\nexcessively focus on local information, leading to a diminished ability to\nencode global information. Our code and data are released via\nhttps://github.com/kobayashikanna01/probing_MLLM_rep.\n","authors":["Mingxu Tao","Quzhe Huang","Kun Xu","Liwei Chen","Yansong Feng","Dongyan Zhao"],"pdf_url":"https://arxiv.org/pdf/2402.17304v2.pdf","comment":"Accepted by LREC-COLING 2024 as a short paper (Camera Ready)"},{"id":"http://arxiv.org/abs/2304.06427v2","updated":"2024-03-27T02:58:26Z","published":"2023-04-13T11:46:32Z","title":"In-Distribution and Out-of-Distribution Self-supervised ECG\n  Representation Learning for Arrhythmia Detection","summary":"  This paper presents a systematic investigation into the effectiveness of\nSelf-Supervised Learning (SSL) methods for Electrocardiogram (ECG) arrhythmia\ndetection. We begin by conducting a novel analysis of the data distributions on\nthree popular ECG-based arrhythmia datasets: PTB-XL, Chapman, and Ribeiro. To\nthe best of our knowledge, our study is the first to quantitatively explore and\ncharacterize these distributions in the area. We then perform a comprehensive\nset of experiments using different augmentations and parameters to evaluate the\neffectiveness of various SSL methods, namely SimCRL, BYOL, and SwAV, for ECG\nrepresentation learning, where we observe the best performance achieved by\nSwAV. Furthermore, our analysis shows that SSL methods achieve highly\ncompetitive results to those achieved by supervised state-of-the-art methods.\nTo further assess the performance of these methods on both In-Distribution (ID)\nand Out-of-Distribution (OOD) ECG data, we conduct cross-dataset training and\ntesting experiments. Our comprehensive experiments show almost identical\nresults when comparing ID and OOD schemes, indicating that SSL techniques can\nlearn highly effective representations that generalize well across different\nOOD datasets. This finding can have major implications for ECG-based arrhythmia\ndetection. Lastly, to further analyze our results, we perform detailed\nper-disease studies on the performance of the SSL methods on the three\ndatasets.\n","authors":["Sahar Soltanieh","Javad Hashemi","Ali Etemad"],"pdf_url":"https://arxiv.org/pdf/2304.06427v2.pdf","comment":"This paper has been published in the IEEE Journal of Biomedical and\n  Health Informatics (JBHI). Copyright IEEE. Please cite as: S. Soltanieh, J.\n  Hashemi and A. Etemad, \"In-Distribution and Out-of-Distribution\n  Self-Supervised ECG Representation Learning for Arrhythmia Detection,\" in\n  IEEE Journal of Biomedical and Health Informatics, vol. 28, no. 2, pp.\n  789-800, Feb. 2024"},{"id":"http://arxiv.org/abs/2403.18212v1","updated":"2024-03-27T02:46:09Z","published":"2024-03-27T02:46:09Z","title":"Preference-Based Planning in Stochastic Environments: From\n  Partially-Ordered Temporal Goals to Most Preferred Policies","summary":"  Human preferences are not always represented via complete linear orders: It\nis natural to employ partially-ordered preferences for expressing incomparable\noutcomes. In this work, we consider decision-making and probabilistic planning\nin stochastic systems modeled as Markov decision processes (MDPs), given a\npartially ordered preference over a set of temporally extended goals.\nSpecifically, each temporally extended goal is expressed using a formula in\nLinear Temporal Logic on Finite Traces (LTL$_f$). To plan with the partially\nordered preference, we introduce order theory to map a preference over temporal\ngoals to a preference over policies for the MDP. Accordingly, a most preferred\npolicy under a stochastic ordering induces a stochastic nondominated\nprobability distribution over the finite paths in the MDP. To synthesize a most\npreferred policy, our technical approach includes two key steps. In the first\nstep, we develop a procedure to transform a partially ordered preference over\ntemporal goals into a computational model, called preference automaton, which\nis a semi-automaton with a partial order over acceptance conditions. In the\nsecond step, we prove that finding a most preferred policy is equivalent to\ncomputing a Pareto-optimal policy in a multi-objective MDP that is constructed\nfrom the original MDP, the preference automaton, and the chosen stochastic\nordering relation. Throughout the paper, we employ running examples to\nillustrate the proposed preference specification and solution approaches. We\ndemonstrate the efficacy of our algorithm using these examples, providing\ndetailed analysis, and then discuss several potential future directions.\n","authors":["Hazhar Rahmani","Abhishek N. Kulkarni","Jie Fu"],"pdf_url":"https://arxiv.org/pdf/2403.18212v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2209.12267"},{"id":"http://arxiv.org/abs/2403.18209v1","updated":"2024-03-27T02:41:52Z","published":"2024-03-27T02:41:52Z","title":"Long and Short-Term Constraints Driven Safe Reinforcement Learning for\n  Autonomous Driving","summary":"  Reinforcement learning (RL) has been widely used in decision-making tasks,\nbut it cannot guarantee the agent's safety in the training process due to the\nrequirements of interaction with the environment, which seriously limits its\nindustrial applications such as autonomous driving. Safe RL methods are\ndeveloped to handle this issue by constraining the expected safety violation\ncosts as a training objective, but they still permit unsafe state occurrence,\nwhich is unacceptable in autonomous driving tasks. Moreover, these methods are\ndifficult to achieve a balance between the cost and return expectations, which\nleads to learning performance degradation for the algorithms. In this paper, we\npropose a novel algorithm based on the long and short-term constraints (LSTC)\nfor safe RL. The short-term constraint aims to guarantee the short-term state\nsafety that the vehicle explores, while the long-term constraint ensures the\noverall safety of the vehicle throughout the decision-making process. In\naddition, we develop a safe RL method with dual-constraint optimization based\non the Lagrange multiplier to optimize the training process for end-to-end\nautonomous driving. Comprehensive experiments were conducted on the MetaDrive\nsimulator. Experimental results demonstrate that the proposed method achieves\nhigher safety in continuous state and action tasks, and exhibits higher\nexploration performance in long-distance decision-making tasks compared with\nstate-of-the-art methods.\n","authors":["Xuemin Hu","Pan Chen","Yijun Wen","Bo Tang","Long Chen"],"pdf_url":"https://arxiv.org/pdf/2403.18209v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17456v2","updated":"2024-03-27T02:39:26Z","published":"2024-03-26T07:41:54Z","title":"Imitating Cost-Constrained Behaviors in Reinforcement Learning","summary":"  Complex planning and scheduling problems have long been solved using various\noptimization or heuristic approaches. In recent years, imitation learning that\naims to learn from expert demonstrations has been proposed as a viable\nalternative to solving these problems. Generally speaking, imitation learning\nis designed to learn either the reward (or preference) model or directly the\nbehavioral policy by observing the behavior of an expert. Existing work in\nimitation learning and inverse reinforcement learning has focused on imitation\nprimarily in unconstrained settings (e.g., no limit on fuel consumed by the\nvehicle). However, in many real-world domains, the behavior of an expert is\ngoverned not only by reward (or preference) but also by constraints. For\ninstance, decisions on self-driving delivery vehicles are dependent not only on\nthe route preferences/rewards (depending on past demand data) but also on the\nfuel in the vehicle and the time available. In such problems, imitation\nlearning is challenging as decisions are not only dictated by the reward model\nbut are also dependent on a cost-constrained model. In this paper, we provide\nmultiple methods that match expert distributions in the presence of trajectory\ncost constraints through (a) Lagrangian-based method; (b) Meta-gradients to\nfind a good trade-off between expected return and minimizing constraint\nviolation; and (c) Cost-violation-based alternating gradient. We empirically\nshow that leading imitation learning approaches imitate cost-constrained\nbehaviors poorly and our meta-gradient-based approach achieves the best\nperformance.\n","authors":["Qian Shao","Pradeep Varakantham","Shih-Fen Cheng"],"pdf_url":"https://arxiv.org/pdf/2403.17456v2.pdf","comment":"Accepted to the 34th International Conference on Automated Planning\n  and Scheduling (ICAPS-24)"},{"id":"http://arxiv.org/abs/2403.18208v1","updated":"2024-03-27T02:39:23Z","published":"2024-03-27T02:39:23Z","title":"An Evolutionary Network Architecture Search Framework with Adaptive\n  Multimodal Fusion for Hand Gesture Recognition","summary":"  Hand gesture recognition (HGR) based on multimodal data has attracted\nconsiderable attention owing to its great potential in applications. Various\nmanually designed multimodal deep networks have performed well in multimodal\nHGR (MHGR), but most of existing algorithms require a lot of expert experience\nand time-consuming manual trials. To address these issues, we propose an\nevolutionary network architecture search framework with the adaptive multimodel\nfusion (AMF-ENAS). Specifically, we design an encoding space that\nsimultaneously considers fusion positions and ratios of the multimodal data,\nallowing for the automatic construction of multimodal networks with different\narchitectures through decoding. Additionally, we consider three input streams\ncorresponding to intra-modal surface electromyography (sEMG), intra-modal\naccelerometer (ACC), and inter-modal sEMG-ACC. To automatically adapt to\nvarious datasets, the ENAS framework is designed to automatically search a MHGR\nnetwork with appropriate fusion positions and ratios. To the best of our\nknowledge, this is the first time that ENAS has been utilized in MHGR to tackle\nissues related to the fusion position and ratio of multimodal data.\nExperimental results demonstrate that AMF-ENAS achieves state-of-the-art\nperformance on the Ninapro DB2, DB3, and DB7 datasets.\n","authors":["Yizhang Xia","Shihao Song","Zhanglu Hou","Junwen Xu","Juan Zou","Yuan Liu","Shengxiang Yang"],"pdf_url":"https://arxiv.org/pdf/2403.18208v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18205v1","updated":"2024-03-27T02:31:54Z","published":"2024-03-27T02:31:54Z","title":"Exploring the Privacy Protection Capabilities of Chinese Large Language\n  Models","summary":"  Large language models (LLMs), renowned for their impressive capabilities in\nvarious tasks, have significantly advanced artificial intelligence. Yet, these\nadvancements have raised growing concerns about privacy and security\nimplications. To address these issues and explain the risks inherent in these\nmodels, we have devised a three-tiered progressive framework tailored for\nevaluating privacy in language systems. This framework consists of\nprogressively complex and in-depth privacy test tasks at each tier. Our primary\nobjective is to comprehensively evaluate the sensitivity of large language\nmodels to private information, examining how effectively they discern, manage,\nand safeguard sensitive data in diverse scenarios. This systematic evaluation\nhelps us understand the degree to which these models comply with privacy\nprotection guidelines and the effectiveness of their inherent safeguards\nagainst privacy breaches. Our observations indicate that existing Chinese large\nlanguage models universally show privacy protection shortcomings. It seems that\nat the moment this widespread issue is unavoidable and may pose corresponding\nprivacy risks in applications based on these models.\n","authors":["Yuqi Yang","Xiaowen Huang","Jitao Sang"],"pdf_url":"https://arxiv.org/pdf/2403.18205v1.pdf","comment":"11 pages"},{"id":"http://arxiv.org/abs/2403.18203v1","updated":"2024-03-27T02:24:38Z","published":"2024-03-27T02:24:38Z","title":"EndToEndML: An Open-Source End-to-End Pipeline for Machine Learning\n  Applications","summary":"  Artificial intelligence (AI) techniques are widely applied in the life\nsciences. However, applying innovative AI techniques to understand and\ndeconvolute biological complexity is hindered by the learning curve for life\nscience scientists to understand and use computing languages. An open-source,\nuser-friendly interface for AI models, that does not require programming skills\nto analyze complex biological data will be extremely valuable to the\nbioinformatics community. With easy access to different sequencing technologies\nand increased interest in different 'omics' studies, the number of biological\ndatasets being generated has increased and analyzing these high-throughput\ndatasets is computationally demanding. The majority of AI libraries today\nrequire advanced programming skills as well as machine learning, data\npreprocessing, and visualization skills. In this research, we propose a\nweb-based end-to-end pipeline that is capable of preprocessing, training,\nevaluating, and visualizing machine learning (ML) models without manual\nintervention or coding expertise. By integrating traditional machine learning\nand deep neural network models with visualizations, our library assists in\nrecognizing, classifying, clustering, and predicting a wide range of\nmulti-modal, multi-sensor datasets, including images, languages, and\none-dimensional numerical data, for drug discovery, pathogen classification,\nand medical diagnostics.\n","authors":["Nisha Pillai","Athish Ram Das","Moses Ayoola","Ganga Gireesan","Bindu Nanduri","Mahalingam Ramkumar"],"pdf_url":"https://arxiv.org/pdf/2403.18203v1.pdf","comment":"2024 7th International Conference on Information and Computer\n  Technologies (ICICT)"},{"id":"http://arxiv.org/abs/2303.13300v3","updated":"2024-03-27T02:23:29Z","published":"2023-03-23T14:37:35Z","title":"The Innovation Paradox: Concept Space Expansion with Diminishing\n  Originality and the Promise of Creative AI","summary":"  Innovation, typically spurred by reusing, recombining, and synthesizing\nexisting concepts, is expected to result in an exponential growth of the\nconcept space over time. However, our statistical analysis of TechNet, which is\na comprehensive technology semantic network encompassing over four million\nconcepts derived from patent texts, reveals a linear rather than exponential\nexpansion of the overall technological concept space. Moreover, there is a\nnotable decline in the originality of newly created concepts. These trends can\nbe attributed to the constraints of human cognitive abilities to innovate\nbeyond an ever-growing space of prior art, among other factors. Integrating\ncreative artificial intelligence (CAI) into the innovation process holds the\npotential to overcome these limitations and alter the observed trends in the\nfuture.\n","authors":["Serhad Sarica","Jianxi Luo"],"pdf_url":"https://arxiv.org/pdf/2303.13300v3.pdf","comment":"Forthcoming on the Design Science"},{"id":"http://arxiv.org/abs/2403.00154v2","updated":"2024-03-27T02:21:03Z","published":"2024-02-29T22:11:20Z","title":"LLMs in Political Science: Heralding a New Era of Visual Analysis","summary":"  Interest is increasing among political scientists in leveraging the extensive\ninformation available in images. However, the challenge of interpreting these\nimages lies in the need for specialized knowledge in computer vision and access\nto specialized hardware. As a result, image analysis has been limited to a\nrelatively small group within the political science community. This landscape\ncould potentially change thanks to the rise of large language models (LLMs).\nThis paper aims to raise awareness of the feasibility of using Gemini for image\ncontent analysis. A retrospective analysis was conducted on a corpus of 688\nimages. Content reports were elicited from Gemini for each image and then\nmanually evaluated by the authors. We find that Gemini is highly accurate in\nperforming object detection, which is arguably the most common and fundamental\ntask in image analysis for political scientists. Equally important, we show\nthat it is easy to implement as the entire command consists of a single prompt\nin natural language; it is fast to run and should meet the time budget of most\nresearchers; and it is free to use and does not require any specialized\nhardware. In addition, we illustrate how political scientists can leverage\nGemini for other image understanding tasks, including face identification,\nsentiment analysis, and caption generation. Our findings suggest that Gemini\nand other similar LLMs have the potential to drastically stimulate and\naccelerate image research in political science and social sciences more\nbroadly.\n","authors":["Yu Wang"],"pdf_url":"https://arxiv.org/pdf/2403.00154v2.pdf","comment":"7 pages, 3 tables"},{"id":"http://arxiv.org/abs/2403.18196v1","updated":"2024-03-27T02:13:20Z","published":"2024-03-27T02:13:20Z","title":"Looking Beyond What You See: An Empirical Analysis on Subgroup\n  Intersectional Fairness for Multi-label Chest X-ray Classification Using\n  Social Determinants of Racial Health Inequities","summary":"  There has been significant progress in implementing deep learning models in\ndisease diagnosis using chest X- rays. Despite these advancements, inherent\nbiases in these models can lead to disparities in prediction accuracy across\nprotected groups. In this study, we propose a framework to achieve accurate\ndiagnostic outcomes and ensure fairness across intersectional groups in\nhigh-dimensional chest X- ray multi-label classification. Transcending\ntraditional protected attributes, we consider complex interactions within\nsocial determinants, enabling a more granular benchmark and evaluation of\nfairness. We present a simple and robust method that involves retraining the\nlast classification layer of pre-trained models using a balanced dataset across\ngroups. Additionally, we account for fairness constraints and integrate\nclass-balanced fine-tuning for multi-label settings. The evaluation of our\nmethod on the MIMIC-CXR dataset demonstrates that our framework achieves an\noptimal tradeoff between accuracy and fairness compared to baseline methods.\n","authors":["Dana Moukheiber","Saurabh Mahindre","Lama Moukheiber","Mira Moukheiber","Mingchen Gao"],"pdf_url":"https://arxiv.org/pdf/2403.18196v1.pdf","comment":"ICCV CVAMD 2023"},{"id":"http://arxiv.org/abs/2403.18195v1","updated":"2024-03-27T02:08:12Z","published":"2024-03-27T02:08:12Z","title":"SCANet: Correcting LEGO Assembly Errors with Self-Correct Assembly\n  Network","summary":"  Autonomous assembly in robotics and 3D vision presents significant\nchallenges, particularly in ensuring assembly correctness. Presently,\npredominant methods such as MEPNet focus on assembling components based on\nmanually provided images. However, these approaches often fall short in\nachieving satisfactory results for tasks requiring long-term planning.\nConcurrently, we observe that integrating a self-correction module can\npartially alleviate such issues. Motivated by this concern, we introduce the\nsingle-step assembly error correction task, which involves identifying and\nrectifying misassembled components. To support research in this area, we\npresent the LEGO Error Correction Assembly Dataset (LEGO-ECA), comprising\nmanual images for assembly steps and instances of assembly failures.\nAdditionally, we propose the Self-Correct Assembly Network (SCANet), a novel\nmethod to address this task. SCANet treats assembled components as queries,\ndetermining their correctness in manual images and providing corrections when\nnecessary. Finally, we utilize SCANet to correct the assembly results of\nMEPNet. Experimental results demonstrate that SCANet can identify and correct\nMEPNet's misassembled results, significantly improving the correctness of\nassembly. Our code and dataset are available at\nhttps://github.com/Yaser-wyx/SCANet.\n","authors":["Yuxuan Wan","Kaichen Zhou","jinhong Chen","Hao Dong"],"pdf_url":"https://arxiv.org/pdf/2403.18195v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16915v3","updated":"2024-03-27T01:53:36Z","published":"2024-03-25T16:32:50Z","title":"Coarse-Tuning for Ad-hoc Document Retrieval Using Pre-trained Language\n  Models","summary":"  Fine-tuning in information retrieval systems using pre-trained language\nmodels (PLM-based IR) requires learning query representations and\nquery-document relations, in addition to downstream task-specific learning.\nThis study introduces coarse-tuning as an intermediate learning stage that\nbridges pre-training and fine-tuning. By learning query representations and\nquery-document relations in coarse-tuning, we aim to reduce the load of\nfine-tuning and improve the learning effect of downstream IR tasks. We propose\nQuery-Document Pair Prediction (QDPP) for coarse-tuning, which predicts the\nappropriateness of query-document pairs. Evaluation experiments show that the\nproposed method significantly improves MRR and/or nDCG@5 in four ad-hoc\ndocument retrieval datasets. Furthermore, the results of the query prediction\ntask suggested that coarse-tuning facilitated learning of query representation\nand query-document relations.\n","authors":["Atsushi Keyaki","Ribeka Keyaki"],"pdf_url":"https://arxiv.org/pdf/2403.16915v3.pdf","comment":"Accepted at LREC-COLING 2024"},{"id":"http://arxiv.org/abs/2402.15764v2","updated":"2024-03-27T01:23:58Z","published":"2024-02-24T08:40:30Z","title":"Look Before You Leap: Problem Elaboration Prompting Improves\n  Mathematical Reasoning in Large Language Models","summary":"  Large language models (LLMs) still grapple with complex tasks like\nmathematical reasoning. Despite significant efforts invested in improving\nprefix prompts or reasoning process, the crucial role of problem context might\nhave been neglected. Accurate recognition of inputs is fundamental for solving\nmathematical tasks, as ill-formed problems could potentially mislead LLM's\nreasoning. In this study, we propose a new approach named Problem Elaboration\nPrompting (PEP) to enhance the mathematical capacities of LLMs. Specifically,\nPEP decomposes and elucidates the problem context before reasoning, therefore\nenhancing the context modeling and parsing efficiency. Experiments across\ndatasets and models demonstrate promising performances: (1) PEP demonstrates an\noverall enhancement in various mathematical tasks. For instance, with the\nGPT-3.5 model, PEP exhibits improvements of 9.93% and 8.80% on GSM8k through\ngreedy decoding and self-consistency, respectively. (2) PEP can be easily\nimplemented and integrated with other prompting methods. (3) PEP shows\nparticular strength in handling distraction problems.\n","authors":["Haoran Liao","Jidong Tian","Shaohua Hu","Hao He","Yaohui Jin"],"pdf_url":"https://arxiv.org/pdf/2402.15764v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18183v1","updated":"2024-03-27T01:21:48Z","published":"2024-03-27T01:21:48Z","title":"Can AI Models Appreciate Document Aesthetics? An Exploration of\n  Legibility and Layout Quality in Relation to Prediction Confidence","summary":"  A well-designed document communicates not only through its words but also\nthrough its visual eloquence. Authors utilize aesthetic elements such as\ncolors, fonts, graphics, and layouts to shape the perception of information.\nThoughtful document design, informed by psychological insights, enhances both\nthe visual appeal and the comprehension of the content. While state-of-the-art\ndocument AI models demonstrate the benefits of incorporating layout and image\ndata, it remains unclear whether the nuances of document aesthetics are\neffectively captured. To bridge the gap between human cognition and AI\ninterpretation of aesthetic elements, we formulated hypotheses concerning AI\nbehavior in document understanding tasks, specifically anchored in document\ndesign principles. With a focus on legibility and layout quality, we tested\nfour aspects of aesthetic effects: noise, font-size contrast, alignment, and\ncomplexity, on model confidence using correlational analysis. The results and\nobservations highlight the value of model analysis rooted in document design\ntheories. Our work serves as a trailhead for further studies and we advocate\nfor continued research in this topic to deepen our understanding of how AI\ninterprets document aesthetics.\n","authors":["Hsiu-Wei Yang","Abhinav Agrawal","Pavlos Fragkogiannis","Shubham Nitin Mulay"],"pdf_url":"https://arxiv.org/pdf/2403.18183v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01421v3","updated":"2024-03-27T00:38:33Z","published":"2023-02-02T21:21:14Z","title":"Follower Agnostic Methods for Stackelberg Games","summary":"  In this paper, we present an efficient algorithm to solve online Stackelberg\ngames, featuring multiple followers, in a follower-agnostic manner. Unlike\nprevious works, our approach works even when leader has no knowledge about the\nfollowers' utility functions or strategy space. Our algorithm introduces a\nunique gradient estimator, leveraging specially designed strategies to probe\nfollowers. In a departure from traditional assumptions of optimal play, we\nmodel followers' responses using a convergent adaptation rule, allowing for\nrealistic and dynamic interactions. The leader constructs the gradient\nestimator solely based on observations of followers' actions. We provide both\nnon-asymptotic convergence rates to stationary points of the leader's objective\nand demonstrate asymptotic convergence to a \\emph{local Stackelberg\nequilibrium}. To validate the effectiveness of our algorithm, we use this\nalgorithm to solve the problem of incentive design on a large-scale\ntransportation network, showcasing its robustness even when the leader lacks\naccess to followers' demand.\n","authors":["Chinmay Maheshwari","James Cheng","S. Shankar Sasty","Lillian Ratliff","Eric Mazumdar"],"pdf_url":"https://arxiv.org/pdf/2302.01421v3.pdf","comment":"31 pages"},{"id":"http://arxiv.org/abs/2403.18167v1","updated":"2024-03-27T00:23:03Z","published":"2024-03-27T00:23:03Z","title":"Mechanisms of non-factual hallucinations in language models","summary":"  State-of-the-art language models (LMs) sometimes generate non-factual\nhallucinations that misalign with world knowledge. Despite extensive efforts to\ndetect and mitigate hallucinations, understanding their internal mechanisms\nremains elusive. Our study investigates the mechanistic causes of\nhallucination, specifically non-factual ones where the LM incorrectly predicts\nobject attributes in response to subject-relation queries. With causal\nmediation analysis and embedding space projection, we identify two general\nmechanistic causes of hallucinations shared across LMs of various scales and\ndesigns: 1) insufficient subject attribute knowledge in lower layer MLPs, and\n2) failing to select the correct object attribute in upper layer attention\nheads and MLPs. These two mechanisms exhibit varying degrees of subject-object\nassociation, predictive uncertainty and perturbation robustness. Additionally,\nwe scrutinize LM pre-training checkpoints, revealing distinct learning dynamics\nfor the two mechanistic causes of hallucinations. We also highlight how\nattribution features from our causal analysis can effectively construct\nhallucination detectors. Our work proposes a mechanistic understanding of LM\nfactual errors.\n","authors":["Lei Yu","Meng Cao","Jackie Chi Kit Cheung","Yue Dong"],"pdf_url":"https://arxiv.org/pdf/2403.18167v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.10812v2","updated":"2024-03-27T00:15:16Z","published":"2023-12-17T20:39:54Z","title":"Learning to Act without Actions","summary":"  Pre-training large models on vast amounts of web data has proven to be an\neffective approach for obtaining powerful, general models in domains such as\nlanguage and vision. However, this paradigm has not yet taken hold in\nreinforcement learning. This is because videos, the most abundant form of\nembodied behavioral data on the web, lack the action labels required by\nexisting methods for imitating behavior from demonstrations. We introduce\nLatent Action Policies (LAPO), a method for recovering latent action\ninformation, and thereby latent-action policies, world models, and inverse\ndynamics models, purely from videos. LAPO is the first method able to recover\nthe structure of the true action space just from observed dynamics, even in\nchallenging procedurally-generated environments. LAPO enables training\nlatent-action policies that can be rapidly fine-tuned into expert-level\npolicies, either offline using a small action-labeled dataset, or online with\nrewards. LAPO takes a first step towards pre-training powerful, generalist\npolicies and world models on the vast amounts of videos readily available on\nthe web.\n","authors":["Dominik Schmidt","Minqi Jiang"],"pdf_url":"https://arxiv.org/pdf/2312.10812v2.pdf","comment":"Accepted at ICLR 2024 (spotlight). The code can be found at\n  http://github.com/schmidtdominik/LAPO"},{"id":"http://arxiv.org/abs/2403.18804v1","updated":"2024-03-27T17:50:00Z","published":"2024-03-27T17:50:00Z","title":"Is Modularity Transferable? A Case Study through the Lens of Knowledge\n  Distillation","summary":"  The rise of Modular Deep Learning showcases its potential in various Natural\nLanguage Processing applications. Parameter-efficient fine-tuning (PEFT)\nmodularity has been shown to work for various use cases, from domain adaptation\nto multilingual setups. However, all this work covers the case where the\nmodular components are trained and deployed within one single Pre-trained\nLanguage Model (PLM). This model-specific setup is a substantial limitation on\nthe very modularity that modular architectures are trying to achieve. We ask\nwhether current modular approaches are transferable between models and whether\nwe can transfer the modules from more robust and larger PLMs to smaller ones.\nIn this work, we aim to fill this gap via a lens of Knowledge Distillation,\ncommonly used for model compression, and present an extremely straightforward\napproach to transferring pre-trained, task-specific PEFT modules between\nsame-family PLMs. Moreover, we propose a method that allows the transfer of\nmodules between incompatible PLMs without any change in the inference\ncomplexity. The experiments on Named Entity Recognition, Natural Language\nInference, and Paraphrase Identification tasks over multiple languages and PEFT\nmethods showcase the initial potential of transferable modularity.\n","authors":["Mateusz Klimaszewski","Piotr Andruszkiewicz","Alexandra Birch"],"pdf_url":"https://arxiv.org/pdf/2403.18804v1.pdf","comment":"Accepted at LREC-COLING 2024"},{"id":"http://arxiv.org/abs/2403.18803v1","updated":"2024-03-27T17:49:31Z","published":"2024-03-27T17:49:31Z","title":"Projective Methods for Mitigating Gender Bias in Pre-trained Language\n  Models","summary":"  Mitigation of gender bias in NLP has a long history tied to debiasing static\nword embeddings. More recently, attention has shifted to debiasing pre-trained\nlanguage models. We study to what extent the simplest projective debiasing\nmethods, developed for word embeddings, can help when applied to BERT's\ninternal representations. Projective methods are fast to implement, use a small\nnumber of saved parameters, and make no updates to the existing model\nparameters. We evaluate the efficacy of the methods in reducing both intrinsic\nbias, as measured by BERT's next sentence prediction task, and in mitigating\nobserved bias in a downstream setting when fine-tuned. To this end, we also\nprovide a critical analysis of a popular gender-bias assessment test for\nquantifying intrinsic bias, resulting in an enhanced test set and new bias\nmeasures. We find that projective methods can be effective at both intrinsic\nbias and downstream bias mitigation, but that the two outcomes are not\nnecessarily correlated. This finding serves as a warning that intrinsic bias\ntest sets, based either on language modeling tasks or next sentence prediction,\nshould not be the only benchmark in developing a debiased language model.\n","authors":["Hillary Dawkins","Isar Nejadgholi","Daniel Gillis","Judi McCuaig"],"pdf_url":"https://arxiv.org/pdf/2403.18803v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18783v1","updated":"2024-03-27T17:31:39Z","published":"2024-03-27T17:31:39Z","title":"Towards a World-English Language Model for On-Device Virtual Assistants","summary":"  Neural Network Language Models (NNLMs) for Virtual Assistants (VAs) are\ngenerally language-, region-, and in some cases, device-dependent, which\nincreases the effort to scale and maintain them. Combining NNLMs for one or\nmore of the categories is one way to improve scalability. In this work, we\ncombine regional variants of English to build a ``World English'' NNLM for\non-device VAs. In particular, we investigate the application of adapter\nbottlenecks to model dialect-specific characteristics in our existing\nproduction NNLMs {and enhance the multi-dialect baselines}. We find that\nadapter modules are more effective in modeling dialects than specializing\nentire sub-networks. Based on this insight and leveraging the design of our\nproduction models, we introduce a new architecture for World English NNLM that\nmeets the accuracy, latency, and memory constraints of our single-dialect\nmodels.\n","authors":["Rricha Jalota","Lyan Verwimp","Markus Nussbaum-Thom","Amr Mousa","Arturo Argueta","Youssef Oualil"],"pdf_url":"https://arxiv.org/pdf/2403.18783v1.pdf","comment":"Accepted in ICASSP 2024"},{"id":"http://arxiv.org/abs/2403.18771v1","updated":"2024-03-27T17:20:39Z","published":"2024-03-27T17:20:39Z","title":"CheckEval: Robust Evaluation Framework using Large Language Model via\n  Checklist","summary":"  We introduce CheckEval, a novel evaluation framework using Large Language\nModels, addressing the challenges of ambiguity and inconsistency in current\nevaluation methods. CheckEval addresses these challenges by dividing evaluation\ncriteria into detailed sub-aspects and constructing a checklist of Boolean\nquestions for each, simplifying the evaluation. This approach not only renders\nthe process more interpretable but also significantly enhances the robustness\nand reliability of results by focusing on specific evaluation dimensions.\nValidated through a focused case study using the SummEval benchmark, CheckEval\nindicates a strong correlation with human judgments. Furthermore, it\ndemonstrates a highly consistent Inter-Annotator Agreement. These findings\nhighlight the effectiveness of CheckEval for objective, flexible, and precise\nevaluations. By offering a customizable and interactive framework, CheckEval\nsets a new standard for the use of LLMs in evaluation, responding to the\nevolving needs of the field and establishing a clear method for future\nLLM-based evaluation.\n","authors":["Yukyung Lee","Joonghoon Kim","Jaehee Kim","Hyowon Cho","Pilsung Kang"],"pdf_url":"https://arxiv.org/pdf/2403.18771v1.pdf","comment":"HEAL at CHI 2024"},{"id":"http://arxiv.org/abs/2403.18769v1","updated":"2024-03-27T17:13:38Z","published":"2024-03-27T17:13:38Z","title":"Improved Neural Protoform Reconstruction via Reflex Prediction","summary":"  Protolanguage reconstruction is central to historical linguistics. The\ncomparative method, one of the most influential theoretical and methodological\nframeworks in the history of the language sciences, allows linguists to infer\nprotoforms (reconstructed ancestral words) from their reflexes (related modern\nwords) based on the assumption of regular sound change. Not surprisingly,\nnumerous computational linguists have attempted to operationalize comparative\nreconstruction through various computational models, the most successful of\nwhich have been supervised encoder-decoder models, which treat the problem of\npredicting protoforms given sets of reflexes as a sequence-to-sequence problem.\nWe argue that this framework ignores one of the most important aspects of the\ncomparative method: not only should protoforms be inferable from cognate sets\n(sets of related reflexes) but the reflexes should also be inferable from the\nprotoforms. Leveraging another line of research -- reflex prediction -- we\npropose a system in which candidate protoforms from a reconstruction model are\nreranked by a reflex prediction model. We show that this more complete\nimplementation of the comparative method allows us to surpass state-of-the-art\nprotoform reconstruction methods on three of four Chinese and Romance datasets.\n","authors":["Liang Lu","Jingzhi Wang","David R. Mortensen"],"pdf_url":"https://arxiv.org/pdf/2403.18769v1.pdf","comment":"Accepted to LREC-COLING 2024"},{"id":"http://arxiv.org/abs/2403.18746v1","updated":"2024-03-27T16:45:02Z","published":"2024-03-27T16:45:02Z","title":"CYCLE: Learning to Self-Refine the Code Generation","summary":"  Pre-trained code language models have achieved promising performance in code\ngeneration and improved the programming efficiency of human developers.\nHowever, their self-refinement capability is typically overlooked by the\nexisting evaluations of code LMs, which focus only on the accuracy of the\none-time prediction. For the cases when code LMs fail to implement the correct\nprogram, developers actually find it hard to debug and fix the faulty\nprediction since it is not written by the developers themselves. Unfortunately,\nour study reveals that code LMs cannot efficiently self-refine their faulty\ngenerations as well.\n  In this paper, we propose CYCLE framework, learning to self-refine the faulty\ngeneration according to the available feedback, such as the execution results\nreported by the test suites. We evaluate CYCLE on three popular code generation\nbenchmarks, HumanEval, MBPP, and APPS. The results reveal that CYCLE\nsuccessfully maintains, sometimes improves, the quality of one-time code\ngeneration, while significantly improving the self-refinement capability of\ncode LMs. We implement four variants of CYCLE with varied numbers of parameters\nacross 350M, 1B, 2B, and 3B, and the experiments show that CYCLE consistently\nboosts the code generation performance, by up to 63.5%, across benchmarks and\nvaried model sizes. We also notice that CYCLE outperforms code LMs that have\n3$\\times$ more parameters in self-refinement.\n","authors":["Yangruibo Ding","Marcus J. Min","Gail Kaiser","Baishakhi Ray"],"pdf_url":"https://arxiv.org/pdf/2403.18746v1.pdf","comment":"Camera-ready for OOPSLA'24"},{"id":"http://arxiv.org/abs/2403.18697v1","updated":"2024-03-27T15:46:25Z","published":"2024-03-27T15:46:25Z","title":"The Invalsi Benchmark: measuring Language Models Mathematical and\n  Language understanding in Italian","summary":"  While Italian is by all metrics a high resource language, currently, there\nare isn't a Language Model pre-trained exclusively in this language. This\nresults in a lower number of available benchmarks to evaluate the performance\nof language models in Italian.\n  This work presents two new benchmarks to evaluate the models performance on\nmathematical understanding and language understanding in Italian. These\nbenchmarks are based on real tests that are undertaken by students of age\nbetween 11 and 18 within the Italian school system and have therefore been\nvalidated by several experts in didactics and pedagogy.\n  To validate this dataset we evaluate the performance of 9 language models\nthat are the best performing when writing in Italian, including our own\nfine-tuned models. We show that this is a challenging benchmark where current\nlanguage models are bound by 60\\% accuracy.\n  We believe that the release of this dataset paves the way for improving\nfuture models mathematical and language understanding in Italian.\n","authors":["Andrea Esuli","Giovanni Puccetti"],"pdf_url":"https://arxiv.org/pdf/2403.18697v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18684v1","updated":"2024-03-27T15:27:36Z","published":"2024-03-27T15:27:36Z","title":"Scaling Laws For Dense Retrieval","summary":"  Scaling up neural models has yielded significant advancements in a wide array\nof tasks, particularly in language generation. Previous studies have found that\nthe performance of neural models frequently adheres to predictable scaling\nlaws, correlated with factors such as training set size and model size. This\ninsight is invaluable, especially as large-scale experiments grow increasingly\nresource-intensive. Yet, such scaling law has not been fully explored in dense\nretrieval due to the discrete nature of retrieval metrics and complex\nrelationships between training data and model sizes in retrieval tasks. In this\nstudy, we investigate whether the performance of dense retrieval models follows\nthe scaling law as other neural models. We propose to use contrastive\nlog-likelihood as the evaluation metric and conduct extensive experiments with\ndense retrieval models implemented with different numbers of parameters and\ntrained with different amounts of annotated data. Results indicate that, under\nour settings, the performance of dense retrieval models follows a precise\npower-law scaling related to the model size and the number of annotations.\nAdditionally, we examine scaling with prevalent data augmentation methods to\nassess the impact of annotation quality, and apply the scaling law to find the\nbest resource allocation strategy under a budget constraint. We believe that\nthese insights will significantly contribute to understanding the scaling\neffect of dense retrieval models and offer meaningful guidance for future\nresearch endeavors.\n","authors":["Yan Fang","Jingtao Zhan","Qingyao Ai","Jiaxin Mao","Weihang Su","Jia Chen","Yiqun Liu"],"pdf_url":"https://arxiv.org/pdf/2403.18684v1.pdf","comment":"Accepted at SIGIR 2024"},{"id":"http://arxiv.org/abs/2403.11128v2","updated":"2024-03-27T15:22:53Z","published":"2024-03-17T07:34:12Z","title":"Beyond Static Evaluation: A Dynamic Approach to Assessing AI Assistants'\n  API Invocation Capabilities","summary":"  With the rise of Large Language Models (LLMs), AI assistants' ability to\nutilize tools, especially through API calls, has advanced notably. This\nprogress has necessitated more accurate evaluation methods. Many existing\nstudies adopt static evaluation, where they assess AI assistants' API call\nbased on pre-defined dialogue histories. However, such evaluation method can be\nmisleading, as an AI assistant might fail in generating API calls from\npreceding human interaction in real cases. Instead of the resource-intensive\nmethod of direct human-machine interactions, we propose Automated Dynamic\nEvaluation (AutoDE) to assess an assistant's API call capability without human\ninvolvement. In our framework, we endeavor to closely mirror genuine human\nconversation patterns in human-machine interactions, using a LLM-based user\nagent, equipped with a user script to ensure human alignment. Experimental\nresults highlight that AutoDE uncovers errors overlooked by static evaluations,\naligning more closely with human assessment. Testing four AI assistants using\nour crafted benchmark, our method further mirrored human evaluation compared to\nconventional static evaluations.\n","authors":["Honglin Mu","Yang Xu","Yunlong Feng","Xiaofeng Han","Yitong Li","Yutai Hou","Wanxiang Che"],"pdf_url":"https://arxiv.org/pdf/2403.11128v2.pdf","comment":"Accepted at LREC-COLING 2024"},{"id":"http://arxiv.org/abs/2403.18680v1","updated":"2024-03-27T15:22:16Z","published":"2024-03-27T15:22:16Z","title":"NL-ITI: Optimizing Probing and Intervention for Improvement of ITI\n  Method","summary":"  Large Language Models (LLM) are prone to returning false information. It\nconstitutes one of major challenges in the AI field. In our work, we explore\nparadigm introduced by Inference-Time-Intervention (ITI). In first stage, it\nidentifies attention heads, which contain the highest amount of desired type of\nknowledge (e.g., truthful). Afterwards, during inference, LLM activations are\nshifted for chosen subset of attention heads. We further improved the ITI\nframework by introducing a nonlinear probing and multi-token intervention -\nNon-Linear ITI (NL-ITI). NL-ITI is tested on diverse multiple-choice\nbenchmarks, including TruthfulQA, on which we report around 14% MC1 metric\nimprovement with respect to the baseline ITI results. NL-ITI achieves also\nencouraging results on other testsets - on Business Ethics subdomain of MMLU,\naround 18% MC1 improvement over baseline LLaMA2-7B. Additionally, NL-ITI\nperforms better while being less invasive in the behavior of LLM at the same\ntime (as measured by Kullback-Leibler divergence).\n","authors":["Jakub Hoscilowicz","Adam Wiacek","Jan Chojnacki","Adam Cieslak","Leszek Michon","Vitalii Urbanevych","Artur Janicki"],"pdf_url":"https://arxiv.org/pdf/2403.18680v1.pdf","comment":"Code is available at https://github.com/Samsung/NL-ITI"},{"id":"http://arxiv.org/abs/2403.17143v2","updated":"2024-03-27T15:15:16Z","published":"2024-03-25T19:40:26Z","title":"Guided Distant Supervision for Multilingual Relation Extraction Data:\n  Adapting to a New Language","summary":"  Relation extraction is essential for extracting and understanding\nbiographical information in the context of digital humanities and related\nsubjects. There is a growing interest in the community to build datasets\ncapable of training machine learning models to extract relationships. However,\nannotating such datasets can be expensive and time-consuming, in addition to\nbeing limited to English. This paper applies guided distant supervision to\ncreate a large biographical relationship extraction dataset for German. Our\ndataset, composed of more than 80,000 instances for nine relationship types, is\nthe largest biographical German relationship extraction dataset. We also create\na manually annotated dataset with 2000 instances to evaluate the models and\nrelease it together with the dataset compiled using guided distant supervision.\nWe train several state-of-the-art machine learning models on the automatically\ncreated dataset and release them as well. Furthermore, we experiment with\nmultilingual and cross-lingual experiments that could benefit many low-resource\nlanguages.\n","authors":["Alistair Plum","Tharindu Ranasinghe","Christoph Purschke"],"pdf_url":"https://arxiv.org/pdf/2403.17143v2.pdf","comment":"Accepted to LREC-COLING 2024 (The 2024 Joint International Conference\n  on Computational Linguistics, Language Resources and Evaluation)"},{"id":"http://arxiv.org/abs/2403.18671v1","updated":"2024-03-27T15:15:14Z","published":"2024-03-27T15:15:14Z","title":"Fact Checking Beyond Training Set","summary":"  Evaluating the veracity of everyday claims is time consuming and in some\ncases requires domain expertise. We empirically demonstrate that the commonly\nused fact checking pipeline, known as the retriever-reader, suffers from\nperformance deterioration when it is trained on the labeled data from one\ndomain and used in another domain. Afterwards, we delve into each component of\nthe pipeline and propose novel algorithms to address this problem. We propose\nan adversarial algorithm to make the retriever component robust against\ndistribution shift. Our core idea is to initially train a bi-encoder on the\nlabeled source data, and then, to adversarially train two separate document and\nclaim encoders using unlabeled target data. We then focus on the reader\ncomponent and propose to train it such that it is insensitive towards the order\nof claims and evidence documents. Our empirical evaluations support the\nhypothesis that such a reader shows a higher robustness against distribution\nshift. To our knowledge, there is no publicly available multi-topic fact\nchecking dataset. Thus, we propose a simple automatic method to re-purpose two\nwell-known fact checking datasets. We then construct eight fact checking\nscenarios from these datasets, and compare our model to a set of strong\nbaseline models, including recent domain adaptation models that use GPT4 for\ngenerating synthetic data.\n","authors":["Payam Karisani","Heng Ji"],"pdf_url":"https://arxiv.org/pdf/2403.18671v1.pdf","comment":"NAACL 2024"},{"id":"http://arxiv.org/abs/2403.18667v1","updated":"2024-03-27T15:11:00Z","published":"2024-03-27T15:11:00Z","title":"Improving Content Recommendation: Knowledge Graph-Based Semantic\n  Contrastive Learning for Diversity and Cold-Start Users","summary":"  Addressing the challenges related to data sparsity, cold-start problems, and\ndiversity in recommendation systems is both crucial and demanding. Many current\nsolutions leverage knowledge graphs to tackle these issues by combining both\nitem-based and user-item collaborative signals. A common trend in these\napproaches focuses on improving ranking performance at the cost of escalating\nmodel complexity, reducing diversity, and complicating the task. It is\nessential to provide recommendations that are both personalized and diverse,\nrather than solely relying on achieving high rank-based performance, such as\nClick-through Rate, Recall, etc. In this paper, we propose a hybrid multi-task\nlearning approach, training on user-item and item-item interactions. We apply\nitem-based contrastive learning on descriptive text, sampling positive and\nnegative pairs based on item metadata. Our approach allows the model to better\nunderstand the relationships between entities within the knowledge graph by\nutilizing semantic information from text. It leads to more accurate, relevant,\nand diverse user recommendations and a benefit that extends even to cold-start\nusers who have few interactions with items. We perform extensive experiments on\ntwo widely used datasets to validate the effectiveness of our approach. Our\nfindings demonstrate that jointly training user-item interactions and\nitem-based signals using synopsis text is highly effective. Furthermore, our\nresults provide evidence that item-based contrastive learning enhances the\nquality of entity embeddings, as indicated by metrics such as uniformity and\nalignment.\n","authors":["Yejin Kim","Scott Rome","Kevin Foley","Mayur Nankani","Rimon Melamed","Javier Morales","Abhay Yadav","Maria Peifer","Sardar Hamidian","H. Howie Huang"],"pdf_url":"https://arxiv.org/pdf/2403.18667v1.pdf","comment":"Accepted at LREC-COLING 2024"},{"id":"http://arxiv.org/abs/2309.13320v2","updated":"2024-03-27T14:57:29Z","published":"2023-09-23T09:35:55Z","title":"GlotScript: A Resource and Tool for Low Resource Writing System\n  Identification","summary":"  We present GlotScript, an open resource and tool for low resource writing\nsystem identification. GlotScript-R is a resource that provides the attested\nwriting systems for more than 7,000 languages. It is compiled by aggregating\ninformation from existing writing system resources. GlotScript-T is a writing\nsystem identification tool that covers all 161 Unicode 15.0 scripts. For an\ninput text, it returns its script distribution where scripts are identified by\nISO 15924 codes. We also present two use cases for GlotScript. First, we\ndemonstrate that GlotScript can help cleaning multilingual corpora such as mC4\nand OSCAR. Second, we analyze the tokenization of a number of language models\nsuch as GPT-4 using GlotScript and provide insights on the coverage of low\nresource scripts and languages by each language model. We hope that GlotScript\nwill become a useful resource for work on low resource languages in the NLP\ncommunity. GlotScript-R and GlotScript-T are available at\nhttps://github.com/cisnlp/GlotScript.\n","authors":["Amir Hossein Kargaran","François Yvon","Hinrich Schütze"],"pdf_url":"https://arxiv.org/pdf/2309.13320v2.pdf","comment":"LREC-COLING 2024"},{"id":"http://arxiv.org/abs/2403.18647v1","updated":"2024-03-27T14:54:27Z","published":"2024-03-27T14:54:27Z","title":"SDSAT: Accelerating LLM Inference through Speculative Decoding with\n  Semantic Adaptive Tokens","summary":"  We propose an acceleration scheme for large language models (LLMs) through\nSpeculative Decoding with Semantic Adaptive Tokens (SDSAT). The primary\nobjective of this design is to enhance the LLM model's ability to generate\ndraft tokens more accurately without compromising the model's accuracy. The\ncore strategies involve: 1) Fine-tune the model by incorporating semantic\nadaptive tokens that possess flexible decoding capabilities without changing\nits structure, allowing them to generate high-quality draft tokens. 2) By\nemploying a training method that does not affect the standard tokens, the model\ncan acquire parallel decoding abilities atop its original framework with\nminimal training overhead. 3) We have designed the \"two-step-draft-then-verify\"\ngeneration strategies using both greedy search and nucleus sampling.\nExperiments conducted on the CodeLlama-13B and 7B models have yielded speed\nincreases of over 3.5X and 3.0X, respectively. Please refer to\nhttps://github.com/hasuoshenyun/SDSAT.\n","authors":["Chengbo Liu","Yong Zhu"],"pdf_url":"https://arxiv.org/pdf/2403.18647v1.pdf","comment":"12 pages, 7 figures"},{"id":"http://arxiv.org/abs/2403.04507v2","updated":"2024-03-27T14:50:56Z","published":"2024-03-07T14:07:00Z","title":"NLPre: a revised approach towards language-centric benchmarking of\n  Natural Language Preprocessing systems","summary":"  With the advancements of transformer-based architectures, we observe the rise\nof natural language preprocessing (NLPre) tools capable of solving preliminary\nNLP tasks (e.g. tokenisation, part-of-speech tagging, dependency parsing, or\nmorphological analysis) without any external linguistic guidance. It is arduous\nto compare novel solutions to well-entrenched preprocessing toolkits, relying\non rule-based morphological analysers or dictionaries. Aware of the\nshortcomings of existing NLPre evaluation approaches, we investigate a novel\nmethod of reliable and fair evaluation and performance reporting. Inspired by\nthe GLUE benchmark, the proposed language-centric benchmarking system enables\ncomprehensive ongoing evaluation of multiple NLPre tools, while credibly\ntracking their performance. The prototype application is configured for Polish\nand integrated with the thoroughly assembled NLPre-PL benchmark. Based on this\nbenchmark, we conduct an extensive evaluation of a variety of Polish NLPre\nsystems. To facilitate the construction of benchmarking environments for other\nlanguages, e.g. NLPre-GA for Irish or NLPre-ZH for Chinese, we ensure full\ncustomization of the publicly released source code of the benchmarking system.\nThe links to all the resources (deployed platforms, source code, trained\nmodels, datasets etc.) can be found on the project website:\nhttps://sites.google.com/view/nlpre-benchmark.\n","authors":["Martyna Wiącek","Piotr Rybak","Łukasz Pszenny","Alina Wróblewska"],"pdf_url":"https://arxiv.org/pdf/2403.04507v2.pdf","comment":"Accepted at LREC-COLING 2024"},{"id":"http://arxiv.org/abs/2403.18624v1","updated":"2024-03-27T14:34:29Z","published":"2024-03-27T14:34:29Z","title":"Vulnerability Detection with Code Language Models: How Far Are We?","summary":"  In the context of the rising interest in code language models (code LMs) and\nvulnerability detection, we study the effectiveness of code LMs for detecting\nvulnerabilities. Our analysis reveals significant shortcomings in existing\nvulnerability datasets, including poor data quality, low label accuracy, and\nhigh duplication rates, leading to unreliable model performance in realistic\nvulnerability detection scenarios. Additionally, the evaluation methods used\nwith these datasets are not representative of real-world vulnerability\ndetection.\n  To address these challenges, we introduce PrimeVul, a new dataset for\ntraining and evaluating code LMs for vulnerability detection. PrimeVul\nincorporates a novel set of data labeling techniques that achieve comparable\nlabel accuracy to human-verified benchmarks while significantly expanding the\ndataset. It also implements a rigorous data de-duplication and chronological\ndata splitting strategy to mitigate data leakage issues, alongside introducing\nmore realistic evaluation metrics and settings. This comprehensive approach\naims to provide a more accurate assessment of code LMs' performance in\nreal-world conditions.\n  Evaluating code LMs on PrimeVul reveals that existing benchmarks\nsignificantly overestimate the performance of these models. For instance, a\nstate-of-the-art 7B model scored 68.26% F1 on BigVul but only 3.09% F1 on\nPrimeVul. Attempts to improve performance through advanced training techniques\nand larger models like GPT-3.5 and GPT-4 were unsuccessful, with results akin\nto random guessing in the most stringent settings. These findings underscore\nthe considerable gap between current capabilities and the practical\nrequirements for deploying code LMs in security roles, highlighting the need\nfor more innovative research in this domain.\n","authors":["Yangruibo Ding","Yanjun Fu","Omniyyah Ibrahim","Chawin Sitawarin","Xinyun Chen","Basel Alomair","David Wagner","Baishakhi Ray","Yizheng Chen"],"pdf_url":"https://arxiv.org/pdf/2403.18624v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18609v1","updated":"2024-03-27T14:26:41Z","published":"2024-03-27T14:26:41Z","title":"A survey on learning models of spiking neural membrane systems and\n  spiking neural networks","summary":"  Spiking neural networks (SNN) are a biologically inspired model of neural\nnetworks with certain brain-like properties. In the past few decades, this\nmodel has received increasing attention in computer science community, owing\nalso to the successful phenomenon of deep learning. In SNN, communication\nbetween neurons takes place through the spikes and spike trains. This\ndifferentiates these models from the ``standard'' artificial neural networks\n(ANN) where the frequency of spikes is replaced by real-valued signals. Spiking\nneural P systems (SNPS) can be considered a branch of SNN based more on the\nprinciples of formal automata, with many variants developed within the\nframework of the membrane computing theory. In this paper, we first briefly\ncompare structure and function, advantages and drawbacks of SNN and SNPS. A key\npart of the article is a survey of recent results and applications of machine\nlearning and deep learning models of both SNN and SNPS formalisms.\n","authors":["Prithwineel Paul","Petr Sosik","Lucie Ciencialova"],"pdf_url":"https://arxiv.org/pdf/2403.18609v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.12997v3","updated":"2024-03-27T13:59:57Z","published":"2024-02-20T13:25:16Z","title":"Towards Trustworthy Reranking: A Simple yet Effective Abstention\n  Mechanism","summary":"  Neural Information Retrieval (NIR) has significantly improved upon\nheuristic-based IR systems. Yet, failures remain frequent, the models used\noften being unable to retrieve documents relevant to the user's query. We\naddress this challenge by proposing a lightweight abstention mechanism tailored\nfor real-world constraints, with particular emphasis placed on the reranking\nphase. We introduce a protocol for evaluating abstention strategies in a\nblack-box scenario, demonstrating their efficacy, and propose a simple yet\neffective data-driven mechanism. We provide open-source code for experiment\nreplication and abstention implementation, fostering wider adoption and\napplication in diverse contexts.\n","authors":["Hippolyte Gisserot-Boukhlef","Manuel Faysse","Emmanuel Malherbe","Céline Hudelot","Pierre Colombo"],"pdf_url":"https://arxiv.org/pdf/2402.12997v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.12531v2","updated":"2024-03-27T13:46:37Z","published":"2023-08-24T03:40:54Z","title":"CARE: Co-Attention Network for Joint Entity and Relation Extraction","summary":"  Joint entity and relation extraction is the fundamental task of information\nextraction, consisting of two subtasks: named entity recognition and relation\nextraction. However, most existing joint extraction methods suffer from issues\nof feature confusion or inadequate interaction between the two subtasks.\nAddressing these challenges, in this work, we propose a Co-Attention network\nfor joint entity and Relation Extraction (CARE). Our approach includes adopting\na parallel encoding strategy to learn separate representations for each\nsubtask, aiming to avoid feature overlap or confusion. At the core of our\napproach is the co-attention module that captures two-way interaction between\nthe two subtasks, allowing the model to leverage entity information for\nrelation prediction and vice versa, thus promoting mutual enhancement. Through\nextensive experiments on three benchmark datasets for joint entity and relation\nextraction (NYT, WebNLG, and SciERC), we demonstrate that our proposed model\noutperforms existing baseline models. Our code will be available at\nhttps://github.com/kwj0x7f/CARE.\n","authors":["Wenjun Kong","Yamei Xia"],"pdf_url":"https://arxiv.org/pdf/2308.12531v2.pdf","comment":"Accepted by LREC-COLING 2024"},{"id":"http://arxiv.org/abs/2401.06712v2","updated":"2024-03-27T13:38:35Z","published":"2024-01-12T17:26:51Z","title":"Few-Shot Detection of Machine-Generated Text using Style Representations","summary":"  The advent of instruction-tuned language models that convincingly mimic human\nwriting poses a significant risk of abuse. However, such abuse may be\ncounteracted with the ability to detect whether a piece of text was composed by\na language model rather than a human author. Some previous approaches to this\nproblem have relied on supervised methods by training on corpora of confirmed\nhuman- and machine- written documents. Unfortunately, model under-specification\nposes an unavoidable challenge for neural network-based detectors, making them\nbrittle in the face of data shifts, such as the release of newer language\nmodels producing still more fluent text than the models used to train the\ndetectors. Other approaches require access to the models that may have\ngenerated a document in question, which is often impractical. In light of these\nchallenges, we pursue a fundamentally different approach not relying on samples\nfrom language models of concern at training time. Instead, we propose to\nleverage representations of writing style estimated from human-authored text.\nIndeed, we find that features effective at distinguishing among human authors\nare also effective at distinguishing human from machine authors, including\nstate-of-the-art large language models like Llama-2, ChatGPT, and GPT-4.\nFurthermore, given a handful of examples composed by each of several specific\nlanguage models of interest, our approach affords the ability to predict which\nmodel generated a given document. The code and data to reproduce our\nexperiments are available at\nhttps://github.com/LLNL/LUAR/tree/main/fewshot_iclr2024.\n","authors":["Rafael Rivera Soto","Kailin Koch","Aleem Khan","Barry Chen","Marcus Bishop","Nicholas Andrews"],"pdf_url":"https://arxiv.org/pdf/2401.06712v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18555v1","updated":"2024-03-27T13:34:59Z","published":"2024-03-27T13:34:59Z","title":"Debiasing Sentence Embedders through Contrastive Word Pairs","summary":"  Over the last years, various sentence embedders have been an integral part in\nthe success of current machine learning approaches to Natural Language\nProcessing (NLP). Unfortunately, multiple sources have shown that the bias,\ninherent in the datasets upon which these embedding methods are trained, is\nlearned by them. A variety of different approaches to remove biases in\nembeddings exists in the literature. Most of these approaches are applicable to\nword embeddings and in fewer cases to sentence embeddings. It is problematic\nthat most debiasing approaches are directly transferred from word embeddings,\ntherefore these approaches fail to take into account the nonlinear nature of\nsentence embedders and the embeddings they produce. It has been shown in\nliterature that bias information is still present if sentence embeddings are\ndebiased using such methods. In this contribution, we explore an approach to\nremove linear and nonlinear bias information for NLP solutions, without\nimpacting downstream performance. We compare our approach to common debiasing\nmethods on classical bias metrics and on bias metrics which take nonlinear\ninformation into account.\n","authors":["Philip Kenneweg","Sarah Schröder","Alexander Schulz","Barbara Hammer"],"pdf_url":"https://arxiv.org/pdf/2403.18555v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.08268v3","updated":"2024-03-27T13:29:31Z","published":"2023-11-14T16:02:16Z","title":"A Wolf in Sheep's Clothing: Generalized Nested Jailbreak Prompts can\n  Fool Large Language Models Easily","summary":"  Large Language Models (LLMs), such as ChatGPT and GPT-4, are designed to\nprovide useful and safe responses. However, adversarial prompts known as\n'jailbreaks' can circumvent safeguards, leading LLMs to generate potentially\nharmful content. Exploring jailbreak prompts can help to better reveal the\nweaknesses of LLMs and further steer us to secure them. Unfortunately, existing\njailbreak methods either suffer from intricate manual design or require\noptimization on other white-box models, which compromises either generalization\nor efficiency. In this paper, we generalize jailbreak prompt attacks into two\naspects: (1) Prompt Rewriting and (2) Scenario Nesting. Based on this, we\npropose ReNeLLM, an automatic framework that leverages LLMs themselves to\ngenerate effective jailbreak prompts. Extensive experiments demonstrate that\nReNeLLM significantly improves the attack success rate while greatly reducing\nthe time cost compared to existing baselines. Our study also reveals the\ninadequacy of current defense methods in safeguarding LLMs. Finally, we analyze\nthe failure of LLMs defense from the perspective of prompt execution priority,\nand propose corresponding defense strategies. We hope that our research can\ncatalyze both the academic community and LLMs developers towards the provision\nof safer and more regulated LLMs. The code is available at\nhttps://github.com/NJUNLP/ReNeLLM.\n","authors":["Peng Ding","Jun Kuang","Dan Ma","Xuezhi Cao","Yunsen Xian","Jiajun Chen","Shujian Huang"],"pdf_url":"https://arxiv.org/pdf/2311.08268v3.pdf","comment":"Acccepted by NAACL 2024, 18 pages, 7 figures, 13 tables"},{"id":"http://arxiv.org/abs/2403.18542v1","updated":"2024-03-27T13:22:38Z","published":"2024-03-27T13:22:38Z","title":"Attention-aware semantic relevance predicting Chinese sentence reading","summary":"  In recent years, several influential computational models and metrics have\nbeen proposed to predict how humans comprehend and process sentence. One\nparticularly promising approach is contextual semantic similarity. Inspired by\nthe attention algorithm in Transformer and human memory mechanisms, this study\nproposes an ``attention-aware'' approach for computing contextual semantic\nrelevance. This new approach takes into account the different contributions of\ncontextual parts and the expectation effect, allowing it to incorporate\ncontextual information fully. The attention-aware approach also facilitates the\nsimulation of existing reading models and evaluate them. The resulting\n``attention-aware'' metrics of semantic relevance can more accurately predict\nfixation durations in Chinese reading tasks recorded in an eye-tracking corpus\nthan those calculated by existing approaches. The study's findings further\nprovide strong support for the presence of semantic preview benefits in Chinese\nnaturalistic reading. Furthermore, the attention-aware metrics of semantic\nrelevance, being memory-based, possess high interpretability from both\nlinguistic and cognitive standpoints, making them a valuable computational tool\nfor modeling eye-movements in reading and further gaining insight into the\nprocess of language comprehension. Our approach underscores the potential of\nthese metrics to advance our comprehension of how humans understand and process\nlanguage, ultimately leading to a better understanding of language\ncomprehension and processing.\n","authors":["Kun Sun"],"pdf_url":"https://arxiv.org/pdf/2403.18542v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18525v1","updated":"2024-03-27T12:59:44Z","published":"2024-03-27T12:59:44Z","title":"Language Plays a Pivotal Role in the Object-Attribute Compositional\n  Generalization of CLIP","summary":"  Vision-language models, such as CLIP, have shown promising\nOut-of-Distribution (OoD) generalization under various types of distribution\nshifts. Recent studies attempted to investigate the leading cause of this\ncapability. In this work, we follow the same path, but focus on a specific type\nof OoD data - images with novel compositions of attribute-object pairs - and\nstudy whether such models can successfully classify those images into\ncomposition classes. We carefully designed an authentic image test dataset\ncalled ImageNet-AO, consisting of attributes for objects that are unlikely\nencountered in the CLIP training sets. We found that CLIPs trained with large\ndatasets such as OpenAI CLIP, LAION-400M, and LAION-2B show orders-of-magnitude\nimprovement in effective compositional OoD generalization compared to both\nsupervised models and CLIPs trained with smaller datasets, such as CC-12M and\nYFCC-15M. Our results provide evidence that the scale and diversity of training\ndata and language supervision play a key role in unlocking the compositional\ngeneralization abilities of vision-language models.\n","authors":["Reza Abbasi","Mohammad Samiei","Mohammad Hossein Rohban","Mahdieh Soleymani Baghshah"],"pdf_url":"https://arxiv.org/pdf/2403.18525v1.pdf","comment":"Oral accepted at OODCV 2023(http://www.ood-cv.org)"},{"id":"http://arxiv.org/abs/2403.18504v1","updated":"2024-03-27T12:33:42Z","published":"2024-03-27T12:33:42Z","title":"AcTED: Automatic Acquisition of Typical Event Duration for\n  Semi-supervised Temporal Commonsense QA","summary":"  We propose a voting-driven semi-supervised approach to automatically acquire\nthe typical duration of an event and use it as pseudo-labeled data. The human\nevaluation demonstrates that our pseudo labels exhibit surprisingly high\naccuracy and balanced coverage. In the temporal commonsense QA task,\nexperimental results show that using only pseudo examples of 400 events, we\nachieve performance comparable to the existing BERT-based weakly supervised\napproaches that require a significant amount of training examples. When\ncompared to the RoBERTa baselines, our best approach establishes\nstate-of-the-art performance with a 7% improvement in Exact Match.\n","authors":["Felix Virgo","Fei Cheng","Lis Kanashiro Pereira","Masayuki Asahara","Ichiro Kobayashi","Sadao Kurohashi"],"pdf_url":"https://arxiv.org/pdf/2403.18504v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16516v2","updated":"2024-03-27T12:32:31Z","published":"2024-03-25T08:00:43Z","title":"Visually Guided Generative Text-Layout Pre-training for Document\n  Intelligence","summary":"  Prior study shows that pre-training techniques can boost the performance of\nvisual document understanding (VDU), which typically requires models to gain\nabilities to perceive and reason both document texts and layouts (e.g.,\nlocations of texts and table-cells). To this end, we propose visually guided\ngenerative text-layout pre-training, named ViTLP. Given a document image, the\nmodel optimizes hierarchical language and layout modeling objectives to\ngenerate the interleaved text and layout sequence. In addition, to address the\nlimitation of processing long documents by Transformers, we introduce a\nstraightforward yet effective multi-segment generative pre-training scheme,\nfacilitating ViTLP to process word-intensive documents of any length. ViTLP can\nfunction as a native OCR model to localize and recognize texts of document\nimages. Besides, ViTLP can be effectively applied to various downstream VDU\ntasks. Extensive experiments show that ViTLP achieves competitive performance\nover existing baselines on benchmark VDU tasks, including information\nextraction, document classification, and document question answering.\n","authors":["Zhiming Mao","Haoli Bai","Lu Hou","Jiansheng Wei","Xin Jiang","Qun Liu","Kam-Fai Wong"],"pdf_url":"https://arxiv.org/pdf/2403.16516v2.pdf","comment":"Accepted to NAACL 2024 main conference. The first version of this\n  paper was submitted to OpenReview\n  (https://openreview.net/forum?id=ARtBIBAmNR) in June 2023"},{"id":"http://arxiv.org/abs/2403.18447v1","updated":"2024-03-27T11:06:44Z","published":"2024-03-27T11:06:44Z","title":"Can Language Beat Numerical Regression? Language-Based Multimodal\n  Trajectory Prediction","summary":"  Language models have demonstrated impressive ability in context understanding\nand generative performance. Inspired by the recent success of language\nfoundation models, in this paper, we propose LMTraj (Language-based Multimodal\nTrajectory predictor), which recasts the trajectory prediction task into a sort\nof question-answering problem. Departing from traditional numerical regression\nmodels, which treat the trajectory coordinate sequence as continuous signals,\nwe consider them as discrete signals like text prompts. Specially, we first\ntransform an input space for the trajectory coordinate into the natural\nlanguage space. Here, the entire time-series trajectories of pedestrians are\nconverted into a text prompt, and scene images are described as text\ninformation through image captioning. The transformed numerical and image data\nare then wrapped into the question-answering template for use in a language\nmodel. Next, to guide the language model in understanding and reasoning\nhigh-level knowledge, such as scene context and social relationships between\npedestrians, we introduce an auxiliary multi-task question and answering. We\nthen train a numerical tokenizer with the prompt data. We encourage the\ntokenizer to separate the integer and decimal parts well, and leverage it to\ncapture correlations between the consecutive numbers in the language model.\nLastly, we train the language model using the numerical tokenizer and all of\nthe question-answer prompts. Here, we propose a beam-search-based most-likely\nprediction and a temperature-based multimodal prediction to implement both\ndeterministic and stochastic inferences. Applying our LMTraj, we show that the\nlanguage-based model can be a powerful pedestrian trajectory predictor, and\noutperforms existing numerical-based predictor methods. Code is publicly\navailable at https://github.com/inhwanbae/LMTrajectory .\n","authors":["Inhwan Bae","Junoh Lee","Hae-Gon Jeon"],"pdf_url":"https://arxiv.org/pdf/2403.18447v1.pdf","comment":"Accepted at CVPR 2024"},{"id":"http://arxiv.org/abs/2304.03544v2","updated":"2024-03-27T10:53:42Z","published":"2023-04-07T08:49:43Z","title":"InfoCTM: A Mutual Information Maximization Perspective of Cross-Lingual\n  Topic Modeling","summary":"  Cross-lingual topic models have been prevalent for cross-lingual text\nanalysis by revealing aligned latent topics. However, most existing methods\nsuffer from producing repetitive topics that hinder further analysis and\nperformance decline caused by low-coverage dictionaries. In this paper, we\npropose the Cross-lingual Topic Modeling with Mutual Information (InfoCTM).\nInstead of the direct alignment in previous work, we propose a topic alignment\nwith mutual information method. This works as a regularization to properly\nalign topics and prevent degenerate topic representations of words, which\nmitigates the repetitive topic issue. To address the low-coverage dictionary\nissue, we further propose a cross-lingual vocabulary linking method that finds\nmore linked cross-lingual words for topic alignment beyond the translations of\na given dictionary. Extensive experiments on English, Chinese, and Japanese\ndatasets demonstrate that our method outperforms state-of-the-art baselines,\nproducing more coherent, diverse, and well-aligned topics and showing better\ntransferability for cross-lingual classification tasks.\n","authors":["Xiaobao Wu","Xinshuai Dong","Thong Nguyen","Chaoqun Liu","Liangming Pan","Anh Tuan Luu"],"pdf_url":"https://arxiv.org/pdf/2304.03544v2.pdf","comment":"Accepted to AAAI2023 conference. Code is available at\n  https://github.com/BobXWu/InfoCTM"},{"id":"http://arxiv.org/abs/2309.13322v2","updated":"2024-03-27T10:50:24Z","published":"2023-09-23T09:51:37Z","title":"From Text to Source: Results in Detecting Large Language Model-Generated\n  Content","summary":"  The widespread use of Large Language Models (LLMs), celebrated for their\nability to generate human-like text, has raised concerns about misinformation\nand ethical implications. Addressing these concerns necessitates the\ndevelopment of robust methods to detect and attribute text generated by LLMs.\nThis paper investigates \"Cross-Model Detection,\" by evaluating whether a\nclassifier trained to distinguish between source LLM-generated and\nhuman-written text can also detect text from a target LLM without further\ntraining. The study comprehensively explores various LLM sizes and families,\nand assesses the impact of conversational fine-tuning techniques, quantization,\nand watermarking on classifier generalization. The research also explores Model\nAttribution, encompassing source model identification, model family, and model\nsize classification, in addition to quantization and watermarking detection.\nOur results reveal several key findings: a clear inverse relationship between\nclassifier effectiveness and model size, with larger LLMs being more\nchallenging to detect, especially when the classifier is trained on data from\nsmaller models. Training on data from similarly sized LLMs can improve\ndetection performance from larger models but may lead to decreased performance\nwhen dealing with smaller models. Additionally, model attribution experiments\nshow promising results in identifying source models and model families,\nhighlighting detectable signatures in LLM-generated text, with particularly\nremarkable outcomes in watermarking detection, while no detectable signatures\nof quantization were observed. Overall, our study contributes valuable insights\ninto the interplay of model size, family, and training data in LLM detection\nand attribution.\n","authors":["Wissam Antoun","Benoît Sagot","Djamé Seddah"],"pdf_url":"https://arxiv.org/pdf/2309.13322v2.pdf","comment":"Accepted to COLING-LREC 2024"},{"id":"http://arxiv.org/abs/2403.18435v1","updated":"2024-03-27T10:40:14Z","published":"2024-03-27T10:40:14Z","title":"DELTA: Pre-train a Discriminative Encoder for Legal Case Retrieval via\n  Structural Word Alignment","summary":"  Recent research demonstrates the effectiveness of using pre-trained language\nmodels for legal case retrieval. Most of the existing works focus on improving\nthe representation ability for the contextualized embedding of the [CLS] token\nand calculate relevance using textual semantic similarity. However, in the\nlegal domain, textual semantic similarity does not always imply that the cases\nare relevant enough. Instead, relevance in legal cases primarily depends on the\nsimilarity of key facts that impact the final judgment. Without proper\ntreatments, the discriminative ability of learned representations could be\nlimited since legal cases are lengthy and contain numerous non-key facts. To\nthis end, we introduce DELTA, a discriminative model designed for legal case\nretrieval. The basic idea involves pinpointing key facts in legal cases and\npulling the contextualized embedding of the [CLS] token closer to the key facts\nwhile pushing away from the non-key facts, which can warm up the case embedding\nspace in an unsupervised manner. To be specific, this study brings the word\nalignment mechanism to the contextual masked auto-encoder. First, we leverage\nshallow decoders to create information bottlenecks, aiming to enhance the\nrepresentation ability. Second, we employ the deep decoder to enable\ntranslation between different structures, with the goal of pinpointing key\nfacts to enhance discriminative ability. Comprehensive experiments conducted on\npublicly available legal benchmarks show that our approach can outperform\nexisting state-of-the-art methods in legal case retrieval. It provides a new\nperspective on the in-depth understanding and processing of legal case\ndocuments.\n","authors":["Haitao Li","Qingyao Ai","Xinyan Han","Jia Chen","Qian Dong","Yiqun Liu","Chong Chen","Qi Tian"],"pdf_url":"https://arxiv.org/pdf/2403.18435v1.pdf","comment":"11 pages"},{"id":"http://arxiv.org/abs/2403.18430v1","updated":"2024-03-27T10:36:17Z","published":"2024-03-27T10:36:17Z","title":"Exploring language relations through syntactic distances and geographic\n  proximity","summary":"  Languages are grouped into families that share common linguistic traits.\nWhile this approach has been successful in understanding genetic relations\nbetween diverse languages, more analyses are needed to accurately quantify\ntheir relatedness, especially in less studied linguistic levels such as syntax.\nHere, we explore linguistic distances using series of parts of speech (POS)\nextracted from the Universal Dependencies dataset. Within an\ninformation-theoretic framework, we show that employing POS trigrams maximizes\nthe possibility of capturing syntactic variations while being at the same time\ncompatible with the amount of available data. Linguistic connections are then\nestablished by assessing pairwise distances based on the POS distributions.\nIntriguingly, our analysis reveals definite clusters that correspond to well\nknown language families and groups, with exceptions explained by distinct\nmorphological typologies. Furthermore, we obtain a significant correlation\nbetween language similarity and geographic distance, which underscores the\ninfluence of spatial proximity on language kinships.\n","authors":["Juan De Gregorio","Raúl Toral","David Sánchez"],"pdf_url":"https://arxiv.org/pdf/2403.18430v1.pdf","comment":"36 pages"},{"id":"http://arxiv.org/abs/2403.18426v1","updated":"2024-03-27T10:27:28Z","published":"2024-03-27T10:27:28Z","title":"TriviaHG: A Dataset for Automatic Hint Generation from Factoid Questions","summary":"  Nowadays, individuals tend to engage in dialogues with Large Language Models,\nseeking answers to their questions. In times when such answers are readily\naccessible to anyone, the stimulation and preservation of human's cognitive\nabilities, as well as the assurance of maintaining good reasoning skills by\nhumans becomes crucial. This study addresses such needs by proposing hints\n(instead of final answers or before giving answers) as a viable solution. We\nintroduce a framework for the automatic hint generation for factoid questions,\nemploying it to construct TriviaHG, a novel large-scale dataset featuring\n160,230 hints corresponding to 16,645 questions from the TriviaQA dataset.\nAdditionally, we present an automatic evaluation method that measures the\nConvergence and Familiarity quality attributes of hints. To evaluate the\nTriviaHG dataset and the proposed evaluation method, we enlisted 10 individuals\nto annotate 2,791 hints and tasked 6 humans with answering questions using the\nprovided hints. The effectiveness of hints varied, with success rates of 96%,\n78%, and 36% for questions with easy, medium, and hard answers, respectively.\nMoreover, the proposed automatic evaluation methods showed a robust correlation\nwith annotators' results. Conclusively, the findings highlight three key\ninsights: the facilitative role of hints in resolving unknown questions, the\ndependence of hint quality on answer difficulty, and the feasibility of\nemploying automatic evaluation methods for hint assessment.\n","authors":["Jamshid Mozafari","Anubhav Jangra","Adam Jatowt"],"pdf_url":"https://arxiv.org/pdf/2403.18426v1.pdf","comment":"Accepted at SIGIR 2024"},{"id":"http://arxiv.org/abs/2403.18423v1","updated":"2024-03-27T10:24:25Z","published":"2024-03-27T10:24:25Z","title":"SemRoDe: Macro Adversarial Training to Learn Representations That are\n  Robust to Word-Level Attacks","summary":"  Language models (LMs) are indispensable tools for natural language processing\ntasks, but their vulnerability to adversarial attacks remains a concern. While\ncurrent research has explored adversarial training techniques, their\nimprovements to defend against word-level attacks have been limited. In this\nwork, we propose a novel approach called Semantic Robust Defence (SemRoDe), a\nMacro Adversarial Training strategy to enhance the robustness of LMs. Drawing\ninspiration from recent studies in the image domain, we investigate and later\nconfirm that in a discrete data setting such as language, adversarial samples\ngenerated via word substitutions do indeed belong to an adversarial domain\nexhibiting a high Wasserstein distance from the base domain. Our method learns\na robust representation that bridges these two domains. We hypothesize that if\nsamples were not projected into an adversarial domain, but instead to a domain\nwith minimal shift, it would improve attack robustness. We align the domains by\nincorporating a new distance-based objective. With this, our model is able to\nlearn more generalized representations by aligning the model's high-level\noutput features and therefore better handling unseen adversarial samples. This\nmethod can be generalized across word embeddings, even when they share minimal\noverlap at both vocabulary and word-substitution levels. To evaluate the\neffectiveness of our approach, we conduct experiments on BERT and RoBERTa\nmodels on three datasets. The results demonstrate promising state-of-the-art\nrobustness.\n","authors":["Brian Formento","Wenjie Feng","Chuan Sheng Foo","Luu Anh Tuan","See-Kiong Ng"],"pdf_url":"https://arxiv.org/pdf/2403.18423v1.pdf","comment":"Published in NAACL 2024 (Main Track)"},{"id":"http://arxiv.org/abs/2403.17647v2","updated":"2024-03-27T10:07:59Z","published":"2024-03-26T12:29:18Z","title":"Intrinsic Subgraph Generation for Interpretable Graph based Visual\n  Question Answering","summary":"  The large success of deep learning based methods in Visual Question Answering\n(VQA) has concurrently increased the demand for explainable methods. Most\nmethods in Explainable Artificial Intelligence (XAI) focus on generating\npost-hoc explanations rather than taking an intrinsic approach, the latter\ncharacterizing an interpretable model. In this work, we introduce an\ninterpretable approach for graph-based VQA and demonstrate competitive\nperformance on the GQA dataset. This approach bridges the gap between\ninterpretability and performance. Our model is designed to intrinsically\nproduce a subgraph during the question-answering process as its explanation,\nproviding insight into the decision making. To evaluate the quality of these\ngenerated subgraphs, we compare them against established post-hoc\nexplainability methods for graph neural networks, and perform a human\nevaluation. Moreover, we present quantitative metrics that correlate with the\nevaluations of human assessors, acting as automatic metrics for the generated\nexplanatory subgraphs. Our implementation is available at\nhttps://github.com/DigitalPhonetics/Intrinsic-Subgraph-Generation-for-VQA.\n","authors":["Pascal Tilli","Ngoc Thang Vu"],"pdf_url":"https://arxiv.org/pdf/2403.17647v2.pdf","comment":"Accepted at LREC-COLING 2024"},{"id":"http://arxiv.org/abs/2403.18365v1","updated":"2024-03-27T08:57:21Z","published":"2024-03-27T08:57:21Z","title":"BLADE: Enhancing Black-box Large Language Models with Small\n  Domain-Specific Models","summary":"  Large Language Models (LLMs) like ChatGPT and GPT-4 are versatile and capable\nof addressing a diverse range of tasks. However, general LLMs, which are\ndeveloped on open-domain data, may lack the domain-specific knowledge essential\nfor tasks in vertical domains, such as legal, medical, etc. To address this\nissue, previous approaches either conduct continuous pre-training with\ndomain-specific data or employ retrieval augmentation to support general LLMs.\nUnfortunately, these strategies are either cost-intensive or unreliable in\npractical applications. To this end, we present a novel framework named BLADE,\nwhich enhances Black-box LArge language models with small Domain-spEcific\nmodels. BLADE consists of a black-box LLM and a small domain-specific LM. The\nsmall LM preserves domain-specific knowledge and offers specialized insights,\nwhile the general LLM contributes robust language comprehension and reasoning\ncapabilities. Specifically, our method involves three steps: 1) pre-training\nthe small LM with domain-specific data, 2) fine-tuning this model using\nknowledge instruction data, and 3) joint Bayesian optimization of the general\nLLM and the small LM. Extensive experiments conducted on public legal and\nmedical benchmarks reveal that BLADE significantly outperforms existing\napproaches. This shows the potential of BLADE as an effective and\ncost-efficient solution in adapting general LLMs for vertical domains.\n","authors":["Haitao Li","Qingyao Ai","Jia Chen","Qian Dong","Zhijing Wu","Yiqun Liu","Chong Chen","Qi Tian"],"pdf_url":"https://arxiv.org/pdf/2403.18365v1.pdf","comment":"11pages"},{"id":"http://arxiv.org/abs/2307.16071v2","updated":"2024-03-27T08:56:01Z","published":"2023-07-29T20:42:50Z","title":"ÌròyìnSpeech: A multi-purpose Yorùbá Speech Corpus","summary":"  We introduce \\`{I}r\\`{o}y\\`{i}nSpeech, a new corpus influenced by the desire\nto increase the amount of high quality, contemporary Yor\\`{u}b\\'{a} speech\ndata, which can be used for both Text-to-Speech (TTS) and Automatic Speech\nRecognition (ASR) tasks. We curated about 23000 text sentences from news and\ncreative writing domains with the open license CC-BY-4.0. To encourage a\nparticipatory approach to data creation, we provide 5000 curated sentences to\nthe Mozilla Common Voice platform to crowd-source the recording and validation\nof Yor\\`{u}b\\'{a} speech data. In total, we created about 42 hours of speech\ndata recorded by 80 volunteers in-house, and 6 hours of validated recordings on\nMozilla Common Voice platform. Our TTS evaluation suggests that a\nhigh-fidelity, general domain, single-speaker Yor\\`{u}b\\'{a} voice is possible\nwith as little as 5 hours of speech. Similarly, for ASR we obtained a baseline\nword error rate (WER) of 23.8.\n","authors":["Tolulope Ogunremi","Kola Tubosun","Anuoluwapo Aremu","Iroro Orife","David Ifeoluwa Adelani"],"pdf_url":"https://arxiv.org/pdf/2307.16071v2.pdf","comment":"Accepted to LREC-COLING 2024"},{"id":"http://arxiv.org/abs/2403.15837v2","updated":"2024-03-27T08:54:06Z","published":"2024-03-23T13:24:31Z","title":"Centered Masking for Language-Image Pre-Training","summary":"  We introduce Gaussian masking for Language-Image Pre-Training (GLIP) a novel,\nstraightforward, and effective technique for masking image patches during\npre-training of a vision-language model. GLIP builds on Fast Language-Image\nPre-Training (FLIP), which randomly masks image patches while training a CLIP\nmodel. GLIP replaces random masking with centered masking, that uses a Gaussian\ndistribution and is inspired by the importance of image patches at the center\nof the image. GLIP retains the same computational savings as FLIP, while\nimproving performance across a range of downstream datasets and tasks, as\ndemonstrated by our experimental results. We show the benefits of GLIP to be\neasy to obtain, requiring no delicate tuning of the Gaussian, and also\napplicable to data sets containing images without an obvious center focus.\n","authors":["Mingliang Liang","Martha Larson"],"pdf_url":"https://arxiv.org/pdf/2403.15837v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18350v1","updated":"2024-03-27T08:42:31Z","published":"2024-03-27T08:42:31Z","title":"Evaluation of Semantic Search and its Role in\n  Retrieved-Augmented-Generation (RAG) for Arabic Language","summary":"  The latest advancements in machine learning and deep learning have brought\nforth the concept of semantic similarity, which has proven immensely beneficial\nin multiple applications and has largely replaced keyword search. However,\nevaluating semantic similarity and conducting searches for a specific query\nacross various documents continue to be a complicated task. This complexity is\ndue to the multifaceted nature of the task, the lack of standard benchmarks,\nwhereas these challenges are further amplified for Arabic language. This paper\nendeavors to establish a straightforward yet potent benchmark for semantic\nsearch in Arabic. Moreover, to precisely evaluate the effectiveness of these\nmetrics and the dataset, we conduct our assessment of semantic search within\nthe framework of retrieval augmented generation (RAG).\n","authors":["Ali Mahboub","Muhy Eddin Za'ter","Bashar Alfrou","Yazan Estaitia","Adnan Jaljuli","Asma Hakouz"],"pdf_url":"https://arxiv.org/pdf/2403.18350v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18349v1","updated":"2024-03-27T08:39:56Z","published":"2024-03-27T08:39:56Z","title":"Rejection Improves Reliability: Training LLMs to Refuse Unknown\n  Questions Using RL from Knowledge Feedback","summary":"  Large Language Models (LLMs) often generate erroneous outputs, known as\nhallucinations, due to their limitations in discerning questions beyond their\nknowledge scope. While addressing hallucination has been a focal point in\nresearch, previous efforts primarily concentrate on enhancing correctness\nwithout giving due consideration to the significance of rejection mechanisms.\nIn this paper, we conduct a comprehensive examination of the role of rejection,\nintroducing the notion of model reliability along with corresponding metrics.\nThese metrics measure the model's ability to provide accurate responses while\nadeptly rejecting questions exceeding its knowledge boundaries, thereby\nminimizing hallucinations. To improve the inherent reliability of LLMs, we\npresent a novel alignment framework called Reinforcement Learning from\nKnowledge Feedback (RLKF). RLKF leverages knowledge feedback to dynamically\ndetermine the model's knowledge boundary and trains a reliable reward model to\nencourage the refusal of out-of-knowledge questions. Experimental results on\nmathematical questions affirm the substantial efficacy of RLKF in significantly\nenhancing LLM reliability.\n","authors":["Hongshen Xu","Zichen Zhu","Da Ma","Situo Zhang","Shuai Fan","Lu Chen","Kai Yu"],"pdf_url":"https://arxiv.org/pdf/2403.18349v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18346v1","updated":"2024-03-27T08:38:49Z","published":"2024-03-27T08:38:49Z","title":"Quantifying and Mitigating Unimodal Biases in Multimodal Large Language\n  Models: A Causal Perspective","summary":"  Recent advancements in Large Language Models (LLMs) have facilitated the\ndevelopment of Multimodal LLMs (MLLMs). Despite their impressive capabilities,\nMLLMs often suffer from an over-reliance on unimodal biases (e.g., language\nbias and vision bias), leading to incorrect answers in complex multimodal\ntasks. To investigate this issue, we propose a causal framework to interpret\nthe biases in Visual Question Answering (VQA) problems. Within our framework,\nwe devise a causal graph to elucidate the predictions of MLLMs on VQA problems,\nand assess the causal effect of biases through an in-depth causal analysis.\nMotivated by the causal graph, we introduce a novel MORE dataset, consisting of\n12,000 VQA instances. This dataset is designed to challenge MLLMs' abilities,\nnecessitating multi-hop reasoning and the surmounting of unimodal biases.\nFurthermore, we propose two strategies to mitigate unimodal biases and enhance\nMLLMs' reasoning capabilities, including a Decompose-Verify-Answer (DeVA)\nframework for limited-access MLLMs and the refinement of open-source MLLMs\nthrough fine-tuning. Extensive quantitative and qualitative experiments offer\nvaluable insights for future research.\n","authors":["Meiqi Chen","Yixin Cao","Yan Zhang","Chaochao Lu"],"pdf_url":"https://arxiv.org/pdf/2403.18346v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18341v1","updated":"2024-03-27T08:32:19Z","published":"2024-03-27T08:32:19Z","title":"IterAlign: Iterative Constitutional Alignment of Large Language Models","summary":"  With the rapid development of large language models (LLMs), aligning LLMs\nwith human values and societal norms to ensure their reliability and safety has\nbecome crucial. Reinforcement learning with human feedback (RLHF) and\nConstitutional AI (CAI) have been proposed for LLM alignment. However, these\nmethods require either heavy human annotations or explicitly pre-defined\nconstitutions, which are labor-intensive and resource-consuming. To overcome\nthese drawbacks, we study constitution-based LLM alignment and propose a\ndata-driven constitution discovery and self-alignment framework called\nIterAlign. IterAlign leverages red teaming to unveil the weaknesses of an LLM\nand automatically discovers new constitutions using a stronger LLM. These\nconstitutions are then used to guide self-correction of the base LLM. Such a\nconstitution discovery pipeline can be run iteratively and automatically to\ndiscover new constitutions that specifically target the alignment gaps in the\ncurrent LLM. Empirical results on several safety benchmark datasets and\nmultiple base LLMs show that IterAlign successfully improves truthfulness,\nhelpfulness, harmlessness and honesty, improving the LLM alignment by up to\n$13.5\\%$ in harmlessness.\n","authors":["Xiusi Chen","Hongzhi Wen","Sreyashi Nag","Chen Luo","Qingyu Yin","Ruirui Li","Zheng Li","Wei Wang"],"pdf_url":"https://arxiv.org/pdf/2403.18341v1.pdf","comment":"NAACL 2024"},{"id":"http://arxiv.org/abs/2403.18336v1","updated":"2024-03-27T08:21:01Z","published":"2024-03-27T08:21:01Z","title":"A Dataset for Pharmacovigilance in German, French, and Japanese:\n  Annotating Adverse Drug Reactions across Languages","summary":"  User-generated data sources have gained significance in uncovering Adverse\nDrug Reactions (ADRs), with an increasing number of discussions occurring in\nthe digital world. However, the existing clinical corpora predominantly revolve\naround scientific articles in English. This work presents a multilingual corpus\nof texts concerning ADRs gathered from diverse sources, including patient fora,\nsocial media, and clinical reports in German, French, and Japanese. Our corpus\ncontains annotations covering 12 entity types, four attribute types, and 13\nrelation types. It contributes to the development of real-world multilingual\nlanguage models for healthcare. We provide statistics to highlight certain\nchallenges associated with the corpus and conduct preliminary experiments\nresulting in strong baselines for extracting entities and relations between\nthese entities, both within and across languages.\n","authors":["Lisa Raithel","Hui-Syuan Yeh","Shuntaro Yada","Cyril Grouin","Thomas Lavergne","Aurélie Névéol","Patrick Paroubek","Philippe Thomas","Tomohiro Nishiyama","Sebastian Möller","Eiji Aramaki","Yuji Matsumoto","Roland Roller","Pierre Zweigenbaum"],"pdf_url":"https://arxiv.org/pdf/2403.18336v1.pdf","comment":"Accepted at LREC-COLING 2024"},{"id":"http://arxiv.org/abs/2403.11399v2","updated":"2024-03-27T07:05:22Z","published":"2024-03-18T01:14:47Z","title":"X-LLaVA: Optimizing Bilingual Large Vision-Language Alignment","summary":"  The impressive development of large language models (LLMs) is expanding into\nthe realm of large multimodal models (LMMs), which incorporate multiple types\nof data beyond text. However, the nature of multimodal models leads to\nsignificant expenses in the creation of training data. Furthermore,\nconstructing multilingual data for LMMs presents its own set of challenges due\nto language diversity and complexity. Therefore, in this study, we propose two\ncost-effective methods to solve this problem: (1) vocabulary expansion and\npretraining of multilingual LLM for specific languages, and (2) automatic and\nelaborate construction of multimodal datasets using GPT4-V. Based on015 these\nmethods, we constructed a 91K English-Korean-Chinese multilingual, multimodal\ntraining dataset. Additionally, we developed a bilingual multimodal model that\nexhibits excellent performance in both Korean and English, surpassing existing\napproaches.\n","authors":["Dongjae Shin","Hyunseok Lim","Inho Won","Changsu Choi","Minjun Kim","Seungwoo Song","Hangyeol Yoo","Sangmin Kim","Kyungtae Lim"],"pdf_url":"https://arxiv.org/pdf/2403.11399v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12468v3","updated":"2024-03-27T06:46:56Z","published":"2023-02-24T05:48:53Z","title":"Adapting Knowledge for Few-shot Table-to-Text Generation","summary":"  Pretrained language models (PLMs) have made remarkable progress in\ntable-to-text generation tasks. However, the lack of domain-specific knowledge\nmakes it challenging to bridge the topological gap between tabular data and\ntext, especially in real-world applications with limited resources. To mitigate\nthe limitation of insufficient labeled data, we propose a novel framework:\nAdapt-Knowledge-to-Generate (AKG). The core insight of AKG is to adapt\nunlabeled domain-specific knowledge into the model, which brings at least three\nbenefits: (1) it injects representation of normal table-related descriptions to\nbridge the topological gap between tabular data and texts; (2) it enables us to\nuse large amounts of unlabeled domain-specific knowledge fully, which can\nalleviate the PLMs' inherent shortcomings of lacking domain knowledge; (3) it\nallows us to design various tasks to employ the domain-specific knowledge.\nExtensive experiments and analyses are conducted on three open-domain, few-shot\nnatural language generation (NLG) data sets: Humans, Songs, and Books. Compared\nto previous state-of-the-art approaches, our model achieves superior\nperformance in terms of both fluency and accuracy as judged by human and\nautomatic evaluations.\n","authors":["Zhixin Guo","Minyxuan Yan","Jiexing Qi","Jianping Zhou","Ziwei He","Guanjie Zheng","Xinbing Wang"],"pdf_url":"https://arxiv.org/pdf/2302.12468v3.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2302.04415"},{"id":"http://arxiv.org/abs/2403.18295v1","updated":"2024-03-27T06:43:58Z","published":"2024-03-27T06:43:58Z","title":"Dual Instruction Tuning with Large Language Models for Mathematical\n  Reasoning","summary":"  Recent advancements highlight the success of instruction tuning with large\nlanguage models (LLMs) utilizing Chain-of-Thought (CoT) data for mathematical\nreasoning tasks. Despite the fine-tuned LLMs, challenges persist, such as\nincorrect, missing, and redundant steps in CoT generation leading to\ninaccuracies in answer predictions. To alleviate this problem, we propose a\ndual instruction tuning strategy to meticulously model mathematical reasoning\nfrom both forward and reverse directions. This involves introducing the\nIntermediate Reasoning State Prediction task (forward reasoning) and the\nInstruction Reconstruction task (reverse reasoning) to enhance the LLMs'\nunderstanding and execution of instructions. Training instances for these tasks\nare constructed based on existing mathematical instruction tuning datasets.\nSubsequently, LLMs undergo multi-task fine-tuning using both existing\nmathematical instructions and the newly created data. Comprehensive experiments\nvalidate the effectiveness and domain generalization of the dual instruction\ntuning strategy across various mathematical reasoning tasks.\n","authors":["Yongwei Zhou","Tiejun Zhao"],"pdf_url":"https://arxiv.org/pdf/2403.18295v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.06201v3","updated":"2024-03-27T06:31:42Z","published":"2024-01-11T15:45:11Z","title":"EASYTOOL: Enhancing LLM-based Agents with Concise Tool Instruction","summary":"  To address intricate real-world tasks, there has been a rising interest in\ntool utilization in applications of large language models (LLMs). To develop\nLLM-based agents, it usually requires LLMs to understand many tool functions\nfrom different tool documentation. But these documentations could be diverse,\nredundant or incomplete, which immensely affects the capability of LLMs in\nusing tools. To solve this, we introduce EASYTOOL, a framework transforming\ndiverse and lengthy tool documentation into a unified and concise tool\ninstruction for easier tool usage. EasyTool purifies essential information from\nextensive tool documentation of different sources, and elaborates a unified\ninterface (i.e., tool instruction) to offer standardized tool descriptions and\nfunctionalities for LLM-based agents. Extensive experiments on multiple\ndifferent tasks demonstrate that EasyTool can significantly reduce token\nconsumption and improve the performance of tool utilization in real-world\nscenarios. Our code will be available at\n\\url{https://github.com/microsoft/JARVIS/} in the future.\n","authors":["Siyu Yuan","Kaitao Song","Jiangjie Chen","Xu Tan","Yongliang Shen","Ren Kan","Dongsheng Li","Deqing Yang"],"pdf_url":"https://arxiv.org/pdf/2401.06201v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18277v1","updated":"2024-03-27T06:13:04Z","published":"2024-03-27T06:13:04Z","title":"BlendX: Complex Multi-Intent Detection with Blended Patterns","summary":"  Task-oriented dialogue (TOD) systems are commonly designed with the\npresumption that each utterance represents a single intent. However, this\nassumption may not accurately reflect real-world situations, where users\nfrequently express multiple intents within a single utterance. While there is\nan emerging interest in multi-intent detection (MID), existing in-domain\ndatasets such as MixATIS and MixSNIPS have limitations in their formulation. To\naddress these issues, we present BlendX, a suite of refined datasets featuring\nmore diverse patterns than their predecessors, elevating both its complexity\nand diversity. For dataset construction, we utilize both rule-based heuristics\nas well as a generative tool -- OpenAI's ChatGPT -- which is augmented with a\nsimilarity-driven strategy for utterance selection. To ensure the quality of\nthe proposed datasets, we also introduce three novel metrics that assess the\nstatistical properties of an utterance related to word count, conjunction use,\nand pronoun usage. Extensive experiments on BlendX reveal that state-of-the-art\nMID models struggle with the challenges posed by the new datasets, highlighting\nthe need to reexamine the current state of the MID field. The dataset is\navailable at https://github.com/HYU-NLP/BlendX.\n","authors":["Yejin Yoon","Jungyeon Lee","Kangsan Kim","Chanhee Park","Taeuk Kim"],"pdf_url":"https://arxiv.org/pdf/2403.18277v1.pdf","comment":"Accepted to LREC-COLING2024"},{"id":"http://arxiv.org/abs/2403.18276v1","updated":"2024-03-27T06:07:05Z","published":"2024-03-27T06:07:05Z","title":"RankMamba, Benchmarking Mamba's Document Ranking Performance in the Era\n  of Transformers","summary":"  Transformer structure has achieved great success in multiple applied machine\nlearning communities, such as natural language processing (NLP), computer\nvision (CV) and information retrieval (IR). Transformer architecture's core\nmechanism -- attention requires $O(n^2)$ time complexity in training and $O(n)$\ntime complexity in inference. Many works have been proposed to improve the\nattention mechanism's scalability, such as Flash Attention and Multi-query\nAttention. A different line of work aims to design new mechanisms to replace\nattention. Recently, a notable model structure -- Mamba, which is based on\nstate space models, has achieved transformer-equivalent performance in multiple\nsequence modeling tasks.\n  In this work, we examine \\mamba's efficacy through the lens of a classical IR\ntask -- document ranking. A reranker model takes a query and a document as\ninput, and predicts a scalar relevance score. This task demands the language\nmodel's ability to comprehend lengthy contextual inputs and to capture the\ninteraction between query and document tokens. We find that (1) Mamba models\nachieve competitive performance compared to transformer-based models with the\nsame training recipe; (2) but also have a lower training throughput in\ncomparison to efficient transformer implementations such as flash attention. We\nhope this study can serve as a starting point to explore Mamba models in other\nclassical IR tasks. Our code implementation and trained checkpoints are made\npublic to facilitate\nreproducibility.\\footnote{https://github.com/zhichaoxu-shufe/RankMamba}.\n","authors":["Zhichao Xu"],"pdf_url":"https://arxiv.org/pdf/2403.18276v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17636v2","updated":"2024-03-27T05:55:35Z","published":"2024-03-26T12:11:29Z","title":"Mix-Initiative Response Generation with Dynamic Prefix Tuning","summary":"  Mixed initiative serves as one of the key factors in controlling conversation\ndirections. For a speaker, responding passively or leading proactively would\nresult in rather different responses. However, most dialogue systems focus on\ntraining a holistic response generation model without any distinction among\ndifferent initiatives. It leads to the cross-contamination problem, where the\nmodel confuses different initiatives and generates inappropriate responses.\nMoreover, obtaining plenty of human annotations for initiative labels can be\nexpensive. To address this issue, we propose a general mix-Initiative Dynamic\nPrefix Tuning framework (IDPT) to decouple different initiatives from the\ngeneration model, which learns initiative-aware prefixes in both supervised and\nunsupervised settings. Specifically, IDPT decouples initiative factors into\ndifferent prefix parameters and uses the attention mechanism to adjust the\nselection of initiatives in guiding generation dynamically. The prefix\nparameters can be tuned towards accurate initiative prediction as well as\nmix-initiative response generation. Extensive experiments on two public\ndialogue datasets show that the proposed IDPT outperforms previous baselines on\nboth automatic metrics and human evaluations. It also manages to generate\nappropriate responses with manipulated initiatives.\n","authors":["Yuxiang Nie","Heyan Huang","Xian-Ling Mao","Lizi Liao"],"pdf_url":"https://arxiv.org/pdf/2403.17636v2.pdf","comment":"Accepted to the main conference of NAACL 2024"},{"id":"http://arxiv.org/abs/2311.08590v2","updated":"2024-03-27T05:53:58Z","published":"2023-11-14T23:20:51Z","title":"PEMA: An Offsite-Tunable Plug-in External Memory Adaptation for Language\n  Models","summary":"  Pre-trained language models (PLMs) show impressive performance in various\ndownstream NLP tasks. However, pre-training large language models demands\nsubstantial memory and training compute. Furthermore, due to the substantial\nresources required, many PLM weights are confidential. Consequently, users are\ncompelled to share their data with model owners for fine-tuning specific tasks.\nTo overcome the limitations, we introduce Plug-in External Memory Adaptation\n(PEMA), a Parameter-Efficient Fine-Tuning (PEFT) method, enabling PLM\nfine-tuning without requiring access to all the weights. PEMA integrates with\ncontext representations from test data during inference to perform downstream\ntasks. It uses external memory to store PLM-generated context representations\nmapped with target tokens. Our method utilizes weight matrices of LoRA-like\nbottlenecked adapter in the PLM's final layer to enhance efficiency. Our\napproach also includes Gradual Unrolling, a novel interpolation strategy to\nimprove generation quality. We validate PEMA's effectiveness through\nexperiments on syntactic and real datasets for machine translation and style\ntransfer. Our findings show that PEMA outperforms other PEFT approaches in\nmemory and latency efficiency for training, and also excels in maintaining\nsentence meaning and generating appropriate language and styles.\n","authors":["HyunJin Kim","Young Jin Kim","JinYeong Bak"],"pdf_url":"https://arxiv.org/pdf/2311.08590v2.pdf","comment":"Accepted to NAACL 2024"},{"id":"http://arxiv.org/abs/2403.18260v1","updated":"2024-03-27T05:22:06Z","published":"2024-03-27T05:22:06Z","title":"Toward Interactive Regional Understanding in Vision-Large Language\n  Models","summary":"  Recent Vision-Language Pre-training (VLP) models have demonstrated\nsignificant advancements. Nevertheless, these models heavily rely on image-text\npairs that capture only coarse and global information of an image, leading to a\nlimitation in their regional understanding ability. In this work, we introduce\n\\textbf{RegionVLM}, equipped with explicit regional modeling capabilities,\nallowing them to understand user-indicated image regions. To achieve this, we\ndesign a simple yet innovative architecture, requiring no modifications to the\nmodel architecture or objective function. Additionally, we leverage a dataset\nthat contains a novel source of information, namely Localized Narratives, which\nhas been overlooked in previous VLP research. Our experiments demonstrate that\nour single generalist model not only achieves an interactive dialogue system\nbut also exhibits superior performance on various zero-shot region\nunderstanding tasks, without compromising its ability for global image\nunderstanding.\n","authors":["Jungbeom Lee","Sanghyuk Chun","Sangdoo Yun"],"pdf_url":"https://arxiv.org/pdf/2403.18260v1.pdf","comment":"NAACL 2024 Main Conference"},{"id":"http://arxiv.org/abs/2312.07950v3","updated":"2024-03-27T04:51:51Z","published":"2023-12-13T07:56:27Z","title":"CBQ: Cross-Block Quantization for Large Language Models","summary":"  Post-training quantization (PTQ) has played a key role in compressing large\nlanguage models (LLMs) with ultra-low costs. However, existing PTQ methods only\nfocus on handling the outliers within one layer or one block, which ignores the\ndependency of blocks and leads to severe performance degradation in low-bit\nsettings. In this paper, we propose CBQ, a cross-block reconstruction-based PTQ\nmethod for LLMs. CBQ employs a cross-block dependency using a homologous\nreconstruction scheme, establishing long-range dependencies across multiple\nblocks to minimize error accumulation. Furthermore, CBQ incorporates a\ncoarse-to-fine preprocessing (CFP) strategy for suppressing weight and\nactivation outliers, coupled with an adaptive LoRA-Rounding technique for\nprecise weight quantization. These innovations enable CBQ to not only handle\nextreme outliers effectively but also improve overall quantization accuracy.\nExtensive experiments show that CBQ achieves superior low-bit quantization\n(W4A4, W4A8, W2A16) and outperforms existing state-of-the-art methods across\nvarious LLMs and datasets. Notably, CBQ quantizes the 4-bit LLAMA1-65B model\nwithin only 4.3 hours on a single GPU, achieving a commendable tradeoff between\nperformance and quantization efficiency.\n","authors":["Xin Ding","Xiaoyu Liu","Zhijun Tu","Yun Zhang","Wei Li","Jie Hu","Hanting Chen","Yehui Tang","Zhiwei Xiong","Baoqun Yin","Yunhe Wang"],"pdf_url":"https://arxiv.org/pdf/2312.07950v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18253v1","updated":"2024-03-27T04:51:42Z","published":"2024-03-27T04:51:42Z","title":"MD-PK: Metaphor Detection via Prompt Learning and Knowledge Distillation","summary":"  Metaphors are ubiquitous in daily life, yet detecting them poses a\nsignificant challenge. Previous approaches often struggled with improper\napplication of language rules and overlooked the issue of data sparsity. To\naddress these challenges, we introduce knowledge distillation and prompt\nlearning into metaphor detection. Specifically, we devise a prompt learning\ntemplate tailored for the metaphor detection task. By masking target words and\nproviding relevant prompt information, we guide the model to accurately infer\nthe contextual meaning of these words. This approach not only mitigates the\ninterference from the literal meaning of target words but also ensures the\nproper utilization of MIP language rules for metaphor detection. Moreover, we\nemploy a teacher model equipped with prior knowledge to generate meaningful\nsoft labels, guiding the optimization process of the student model. The\ninclusion of soft labels, akin to label smoothing, helps alleviate the model's\ntendency towards over-confidence and effectively addresses the challenge of\ndata sparsity. Experimental results demonstrate that our proposed model\nachieves state-of-the-art performance across multiple datasets.\n","authors":["Kaidi Jia","Rongsheng Li"],"pdf_url":"https://arxiv.org/pdf/2403.18253v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18251v1","updated":"2024-03-27T04:47:10Z","published":"2024-03-27T04:47:10Z","title":"Since the Scientific Literature Is Multilingual, Our Models Should Be\n  Too","summary":"  English has long been assumed the $\\textit{lingua franca}$ of scientific\nresearch, and this notion is reflected in the natural language processing (NLP)\nresearch involving scientific document representation. In this position piece,\nwe quantitatively show that the literature is largely multilingual and argue\nthat current models and benchmarks should reflect this linguistic diversity. We\nprovide evidence that text-based models fail to create meaningful\nrepresentations for non-English papers and highlight the negative user-facing\nimpacts of using English-only models non-discriminately across a multilingual\ndomain. We end with suggestions for the NLP community on how to improve\nperformance on non-English documents.\n","authors":["Abteen Ebrahimi","Kenneth Church"],"pdf_url":"https://arxiv.org/pdf/2403.18251v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18249v1","updated":"2024-03-27T04:39:18Z","published":"2024-03-27T04:39:18Z","title":"Exploring the Deceptive Power of LLM-Generated Fake News: A Study of\n  Real-World Detection Challenges","summary":"  Recent advancements in Large Language Models (LLMs) have enabled the creation\nof fake news, particularly in complex fields like healthcare. Studies highlight\nthe gap in the deceptive power of LLM-generated fake news with and without\nhuman assistance, yet the potential of prompting techniques has not been fully\nexplored. Thus, this work aims to determine whether prompting strategies can\neffectively narrow this gap. Current LLM-based fake news attacks require human\nintervention for information gathering and often miss details and fail to\nmaintain context consistency. Therefore, to better understand threat tactics,\nwe propose a strong fake news attack method called conditional\nVariational-autoencoder-Like Prompt (VLPrompt). Unlike current methods,\nVLPrompt eliminates the need for additional data collection while maintaining\ncontextual coherence and preserving the intricacies of the original text. To\npropel future research on detecting VLPrompt attacks, we created a new dataset\nnamed VLPrompt fake news (VLPFN) containing real and fake texts. Our\nexperiments, including various detection methods and novel human study metrics,\nwere conducted to assess their performance on our dataset, yielding numerous\nfindings.\n","authors":["Yanshen Sun","Jianfeng He","Limeng Cui","Shuo Lei","Chang-Tien Lu"],"pdf_url":"https://arxiv.org/pdf/2403.18249v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.14965v4","updated":"2024-03-27T04:38:44Z","published":"2023-05-24T09:57:37Z","title":"Tricking LLMs into Disobedience: Formalizing, Analyzing, and Detecting\n  Jailbreaks","summary":"  Recent explorations with commercial Large Language Models (LLMs) have shown\nthat non-expert users can jailbreak LLMs by simply manipulating their prompts;\nresulting in degenerate output behavior, privacy and security breaches,\noffensive outputs, and violations of content regulator policies. Limited\nstudies have been conducted to formalize and analyze these attacks and their\nmitigations. We bridge this gap by proposing a formalism and a taxonomy of\nknown (and possible) jailbreaks. We survey existing jailbreak methods and their\neffectiveness on open-source and commercial LLMs (such as GPT-based models,\nOPT, BLOOM, and FLAN-T5-XXL). We further discuss the challenges of jailbreak\ndetection in terms of their effectiveness against known attacks. For further\nanalysis, we release a dataset of model outputs across 3700 jailbreak prompts\nover 4 tasks.\n","authors":["Abhinav Rao","Sachin Vashistha","Atharva Naik","Somak Aditya","Monojit Choudhury"],"pdf_url":"https://arxiv.org/pdf/2305.14965v4.pdf","comment":"Accepted at LREC-COLING 2024 - The 2024 Joint International\n  Conference on Computational Linguistics, Language Resources and Evaluation"},{"id":"http://arxiv.org/abs/2206.08657v6","updated":"2024-03-27T03:53:23Z","published":"2022-06-17T09:42:35Z","title":"BridgeTower: Building Bridges Between Encoders in Vision-Language\n  Representation Learning","summary":"  Vision-Language (VL) models with the Two-Tower architecture have dominated\nvisual-language representation learning in recent years. Current VL models\neither use lightweight uni-modal encoders and learn to extract, align and fuse\nboth modalities simultaneously in a deep cross-modal encoder, or feed the\nlast-layer uni-modal representations from the deep pre-trained uni-modal\nencoders into the top cross-modal encoder. Both approaches potentially restrict\nvision-language representation learning and limit model performance. In this\npaper, we propose BridgeTower, which introduces multiple bridge layers that\nbuild a connection between the top layers of uni-modal encoders and each layer\nof the cross-modal encoder. This enables effective bottom-up cross-modal\nalignment and fusion between visual and textual representations of different\nsemantic levels of pre-trained uni-modal encoders in the cross-modal encoder.\nPre-trained with only 4M images, BridgeTower achieves state-of-the-art\nperformance on various downstream vision-language tasks. In particular, on the\nVQAv2 test-std set, BridgeTower achieves an accuracy of 78.73%, outperforming\nthe previous state-of-the-art model METER by 1.09% with the same pre-training\ndata and almost negligible additional parameters and computational costs.\nNotably, when further scaling the model, BridgeTower achieves an accuracy of\n81.15%, surpassing models that are pre-trained on orders-of-magnitude larger\ndatasets. Code and checkpoints are available at\nhttps://github.com/microsoft/BridgeTower.\n","authors":["Xiao Xu","Chenfei Wu","Shachar Rosenman","Vasudev Lal","Wanxiang Che","Nan Duan"],"pdf_url":"https://arxiv.org/pdf/2206.08657v6.pdf","comment":"Accepted by AAAI 2023, Oral"},{"id":"http://arxiv.org/abs/2403.17343v2","updated":"2024-03-27T02:49:16Z","published":"2024-03-26T03:05:20Z","title":"Language Models are Free Boosters for Biomedical Imaging Tasks","summary":"  In this study, we uncover the unexpected efficacy of residual-based large\nlanguage models (LLMs) as part of encoders for biomedical imaging tasks, a\ndomain traditionally devoid of language or textual data. The approach diverges\nfrom established methodologies by utilizing a frozen transformer block,\nextracted from pre-trained LLMs, as an innovative encoder layer for the direct\nprocessing of visual tokens. This strategy represents a significant departure\nfrom the standard multi-modal vision-language frameworks, which typically hinge\non language-driven prompts and inputs. We found that these LLMs could boost\nperformance across a spectrum of biomedical imaging applications, including\nboth 2D and 3D visual classification tasks, serving as plug-and-play boosters.\nMore interestingly, as a byproduct, we found that the proposed framework\nachieved superior performance, setting new state-of-the-art results on\nextensive, standardized datasets in MedMNIST-2D and 3D. Through this work, we\naim to open new avenues for employing LLMs in biomedical imaging and enriching\nthe understanding of their potential in this specialized domain.\n","authors":["Zhixin Lai","Jing Wu","Suiyao Chen","Yucheng Zhou","Naira Hovakimyan"],"pdf_url":"https://arxiv.org/pdf/2403.17343v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18182v1","updated":"2024-03-27T01:19:23Z","published":"2024-03-27T01:19:23Z","title":"ZAEBUC-Spoken: A Multilingual Multidialectal Arabic-English Speech\n  Corpus","summary":"  We present ZAEBUC-Spoken, a multilingual multidialectal Arabic-English speech\ncorpus. The corpus comprises twelve hours of Zoom meetings involving multiple\nspeakers role-playing a work situation where Students brainstorm ideas for a\ncertain topic and then discuss it with an Interlocutor. The meetings cover\ndifferent topics and are divided into phases with different language setups.\nThe corpus presents a challenging set for automatic speech recognition (ASR),\nincluding two languages (Arabic and English) with Arabic spoken in multiple\nvariants (Modern Standard Arabic, Gulf Arabic, and Egyptian Arabic) and English\nused with various accents. Adding to the complexity of the corpus, there is\nalso code-switching between these languages and dialects. As part of our work,\nwe take inspiration from established sets of transcription guidelines to\npresent a set of guidelines handling issues of conversational speech,\ncode-switching and orthography of both languages. We further enrich the corpus\nwith two layers of annotations; (1) dialectness level annotation for the\nportion of the corpus where mixing occurs between different variants of Arabic,\nand (2) automatic morphological annotations, including tokenization,\nlemmatization, and part-of-speech tagging.\n","authors":["Injy Hamed","Fadhl Eryani","David Palfreyman","Nizar Habash"],"pdf_url":"https://arxiv.org/pdf/2403.18182v1.pdf","comment":"Accepted to LREC-COLING 2024"},{"id":"http://arxiv.org/abs/2301.10856v3","updated":"2024-03-27T00:47:21Z","published":"2023-01-25T22:27:40Z","title":"Partial Mobilization: Tracking Multilingual Information Flows Amongst\n  Russian Media Outlets and Telegram","summary":"  In response to disinformation and propaganda from Russian online media\nfollowing the invasion of Ukraine, Russian media outlets such as Russia Today\nand Sputnik News were banned throughout Europe. To maintain viewership, many of\nthese Russian outlets began to heavily promote their content on messaging\nservices like Telegram. In this work, we study how 16 Russian media outlets\ninteracted with and utilized 732 Telegram channels throughout 2022. Leveraging\nthe foundational model MPNet, DP-means clustering, and Hawkes processes, we\ntrace how narratives spread between news sites and Telegram channels. We show\nthat news outlets not only propagate existing narratives through Telegram but\nthat they source material from the messaging platform. For example, across the\nwebsites in our study, between 2.3% (ura.news) and 26.7% (ukraina.ru) of\narticles discussed content that originated/resulted from activity on Telegram.\nFinally, tracking the spread of individual topics, we measure the rate at which\nnews outlets and Telegram channels disseminate content within the Russian media\necosystem, finding that websites like ura.news and Telegram channels such as\n@genshab are the most effective at disseminating their content.\n","authors":["Hans W. A. Hanley","Zakir Durumeric"],"pdf_url":"https://arxiv.org/pdf/2301.10856v3.pdf","comment":"Accepted to ICWSM 2024"},{"id":"http://arxiv.org/abs/2308.11138v3","updated":"2024-03-27T00:29:33Z","published":"2023-08-22T02:39:42Z","title":"NLP-based detection of systematic anomalies among the narratives of\n  consumer complaints","summary":"  We develop an NLP-based procedure for detecting systematic nonmeritorious\nconsumer complaints, simply called systematic anomalies, among complaint\nnarratives. While classification algorithms are used to detect pronounced\nanomalies, in the case of smaller and frequent systematic anomalies, the\nalgorithms may falter due to a variety of reasons, including technical ones as\nwell as natural limitations of human analysts. Therefore, as the next step\nafter classification, we convert the complaint narratives into quantitative\ndata, which are then analyzed using an algorithm for detecting systematic\nanomalies. We illustrate the entire procedure using complaint narratives from\nthe Consumer Complaint Database of the Consumer Financial Protection Bureau.\n","authors":["Peiheng Gao","Ning Sun","Xuefeng Wang","Chen Yang","Ričardas Zitikis"],"pdf_url":"https://arxiv.org/pdf/2308.11138v3.pdf","comment":null}],"Computer Science and Game Theory":[{"id":"http://arxiv.org/abs/2403.17139v2","updated":"2024-03-27T17:37:52Z","published":"2024-03-25T19:23:44Z","title":"An Equilibrium Analysis of the Arad-Rubinstein Game","summary":"  Colonel Blotto games with discrete strategy spaces effectively illustrate the\nintricate nature of multidimensional strategic reasoning. This paper studies\nthe equilibrium set of such games where, in line with prior experimental work,\nthe tie-breaking rule is allowed to be flexible. We begin by pointing out that\nequilibrium constructions known from the literature extend to our class of\ngames. However, we also note that irrespective of the tie-breaking rule, the\nequilibrium set is excessively large. Specifically, any pure strategy that\nallocates at most twice the fair share to each battlefield is used with\npositive probability in some equilibrium. Furthermore, refinements based on the\nelimination of weakly dominated strategies prove ineffective. To derive\nspecific predictions amid this multiplicity, we compute strategies resulting\nfrom long-run adaptive learning.\n","authors":["Christian Ewerhart","Stanisław Kaźmierowski"],"pdf_url":"https://arxiv.org/pdf/2403.17139v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18642v1","updated":"2024-03-27T14:45:43Z","published":"2024-03-27T14:45:43Z","title":"Collective schedules: axioms and algorithms","summary":"  The collective schedules problem consists in computing a schedule of tasks\nshared between individuals. Tasks may have different duration, and individuals\nhave preferences over the order of the shared tasks. This problem has numerous\napplications since tasks may model public infrastructure projects, events\ntaking place in a shared room, or work done by co-workers. Our aim is, given\nthe preferred schedules of individuals (voters), to return a consensus\nschedule. We propose an axiomatic study of the collective schedule problem, by\nusing classic axioms in computational social choice and new axioms that take\ninto account the duration of the tasks. We show that some axioms are\nincompatible, and we study the axioms fulfilled by three rules: one which has\nbeen studied in the seminal paper on collective schedules (Pascual et al.\n2018), one which generalizes the Kemeny rule, and one which generalizes\nSpearman's footrule. From an algorithmic point of view, we show that these\nrules solve NP-hard problems, but that it is possible to solve optimally these\nproblems for small but realistic size instances, and we give an efficient\nheuristic for large instances. We conclude this paper with experiments.\n","authors":["Martin Durand","Fanny Pascual"],"pdf_url":"https://arxiv.org/pdf/2403.18642v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.12370v2","updated":"2024-03-27T13:44:21Z","published":"2023-10-18T22:34:32Z","title":"No-Regret Learning in Bilateral Trade via Global Budget Balance","summary":"  Bilateral trade models the problem of intermediating between two rational\nagents -- a seller and a buyer -- both characterized by a private valuation for\nan item they want to trade. We study the online learning version of the\nproblem, in which at each time step a new seller and buyer arrive and the\nlearner has to set prices for them without any knowledge about their\n(adversarially generated) valuations.\n  In this setting, known impossibility results rule out the existence of\nno-regret algorithms when budget balanced has to be enforced at each time step.\nIn this paper, we introduce the notion of \\emph{global budget balance}, which\nonly requires the learner to fulfill budget balance over the entire time\nhorizon. Under this natural relaxation, we provide the first no-regret\nalgorithms for adversarial bilateral trade under various feedback models.\nFirst, we show that in the full-feedback model, the learner can guarantee\n$\\tilde O(\\sqrt{T})$ regret against the best fixed prices in hindsight, and\nthat this bound is optimal up to poly-logarithmic terms. Second, we provide a\nlearning algorithm guaranteeing a $\\tilde O(T^{3/4})$ regret upper bound with\none-bit feedback, which we complement with a $\\Omega(T^{5/7})$ lower bound that\nholds even in the two-bit feedback model. Finally, we introduce and analyze an\nalternative benchmark that is provably stronger than the best fixed prices in\nhindsight and is inspired by the literature on bandits with knapsacks.\n","authors":["Martino Bernasconi","Matteo Castiglioni","Andrea Celli","Federico Fusco"],"pdf_url":"https://arxiv.org/pdf/2310.12370v2.pdf","comment":"Accepted at STOC 2024"},{"id":"http://arxiv.org/abs/2306.11376v2","updated":"2024-03-27T10:51:35Z","published":"2023-06-20T08:33:07Z","title":"Coevolution of cognition and cooperation in structured populations under\n  reinforcement learning","summary":"  We study the evolution of behavior under reinforcement learning in a\nPrisoner's Dilemma where agents interact in a regular network and can learn\nabout whether they play one-shot or repeatedly by incurring a cost of\ndeliberation. With respect to other behavioral rules used in the literature,\n(i) we confirm the existence of a threshold value of the probability of\nrepeated interaction, switching the emergent behavior from intuitive defector\nto dual-process cooperator; (ii) we find a different role of the node degree,\nwith smaller degrees reducing the evolutionary success of dual-process\ncooperators; (iii) we observe a higher frequency of deliberation.\n","authors":["Rossana Mastrandrea","Leonardo Boncinelli","Ennio Bilancini"],"pdf_url":"https://arxiv.org/pdf/2306.11376v2.pdf","comment":"10 pages, 2 figures"},{"id":"http://arxiv.org/abs/2403.18340v1","updated":"2024-03-27T08:31:09Z","published":"2024-03-27T08:31:09Z","title":"The Metric Distortion of Randomized Social Choice Functions: C1 Maximal\n  Lottery Rules and Simulations","summary":"  The metric distortion of a randomized social choice function (RSCF)\nquantifies its worst-case approximation ratio of the optimal social cost when\nthe voters' costs for alternatives are given by distances in a metric space.\nThis notion has recently attracted significant attention as numerous RSCFs that\naim to minimize the metric distortion have been suggested. However, such\ntailored voting rules usually have little appeal other than their low metric\ndistortion. In this paper, we will thus study the metric distortion of\nwell-established RSCFs. In more detail, we first show that C1 maximal lottery\nrules, a well-known class of RSCFs, have a metric distortion of $4$ and\nfurthermore prove that this is optimal within the class of majoritarian RSCFs\n(which only depend on the majority relation). As our second contribution, we\nperform extensive computer experiments on the metric distortion of established\nRSCFs to obtain insights into their average-case performance. These computer\nexperiments are based on a new linear program for computing the metric\ndistortion of a lottery on a given profile and reveal that some classical RSCFs\nperform almost as well as the currently best known RSCF with respect to the\nmetric distortion on randomly sampled profiles.\n","authors":["Fabian Frank","Patrick Lederer"],"pdf_url":"https://arxiv.org/pdf/2403.18340v1.pdf","comment":"8 pages, 1 figure"},{"id":"http://arxiv.org/abs/2403.18176v1","updated":"2024-03-27T01:05:45Z","published":"2024-03-27T01:05:45Z","title":"Mistake, Manipulation and Margin Guarantees in Online Strategic\n  Classification","summary":"  We consider an online strategic classification problem where each arriving\nagent can manipulate their true feature vector to obtain a positive predicted\nlabel, while incurring a cost that depends on the amount of manipulation. The\nlearner seeks to predict the agent's true label given access to only the\nmanipulated features. After the learner releases their prediction, the agent's\ntrue label is revealed. Previous algorithms such as the strategic perceptron\nguarantee finitely many mistakes under a margin assumption on agents' true\nfeature vectors. However, these are not guaranteed to encourage agents to be\ntruthful. Promoting truthfulness is intimately linked to obtaining adequate\nmargin on the predictions, thus we provide two new algorithms aimed at\nrecovering the maximum margin classifier in the presence of strategic agent\nbehavior. We prove convergence, finite mistake and finite manipulation\nguarantees for a variety of agent cost structures. We also provide generalized\nversions of the strategic perceptron with mistake guarantees for different\ncosts. Our numerical study on real and synthetic data demonstrates that the new\nalgorithms outperform previous ones in terms of margin, number of manipulation\nand number of mistakes.\n","authors":["Lingqing Shen","Nam Ho-Nguyen","Khanh-Hung Giang-Tran","Fatma Kılınç-Karzan"],"pdf_url":"https://arxiv.org/pdf/2403.18176v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18174v1","updated":"2024-03-27T01:02:27Z","published":"2024-03-27T01:02:27Z","title":"Local (coarse) correlated equilibria in non-concave games","summary":"  We investigate local notions of correlated equilibria, distributions of\nactions for smooth games such that players do not incur any regret against\nmodifications of their strategies along a set of continuous vector fields. Our\nanalysis shows that such equilibria are intrinsically linked to the projected\ngradient dynamics of the game. We identify the equivalent of coarse equilibria\nin this setting when no regret is incurred against any gradient field of a\ndifferentiable function. As a result, such equilibria are approximable when all\nplayers employ online (projected) gradient ascent with equal step-sizes as\nlearning algorithms, and when their compact and convex action sets either (1)\npossess a smooth boundary, or (2) are polyhedra over which linear optimisation\nis ``trivial''. As a consequence, primal-dual proofs of performance guarantees\nfor local coarse equilibria take the form of a generalised Lyapunov function\nfor the gradient dynamics of the game. Adapting the regret matching framework\nto our setting, we also show that general local correlated equilibria are\napproximable when the set of vector fields is finite, given access to a\nfixed-point oracle for linear or conical combinations. For the class of\naffine-linear vector fields, which subsumes correlated equilibria of normal\nform games as a special case, such a fixed-point turns out to be the solution\nof a convex quadratic minimisation problem. Our results are independent of\nconcavity assumptions on players' utilities.\n","authors":["Mete Şeref Ahunbay"],"pdf_url":"https://arxiv.org/pdf/2403.18174v1.pdf","comment":"39 pages"},{"id":"http://arxiv.org/abs/2302.01421v3","updated":"2024-03-27T00:38:33Z","published":"2023-02-02T21:21:14Z","title":"Follower Agnostic Methods for Stackelberg Games","summary":"  In this paper, we present an efficient algorithm to solve online Stackelberg\ngames, featuring multiple followers, in a follower-agnostic manner. Unlike\nprevious works, our approach works even when leader has no knowledge about the\nfollowers' utility functions or strategy space. Our algorithm introduces a\nunique gradient estimator, leveraging specially designed strategies to probe\nfollowers. In a departure from traditional assumptions of optimal play, we\nmodel followers' responses using a convergent adaptation rule, allowing for\nrealistic and dynamic interactions. The leader constructs the gradient\nestimator solely based on observations of followers' actions. We provide both\nnon-asymptotic convergence rates to stationary points of the leader's objective\nand demonstrate asymptotic convergence to a \\emph{local Stackelberg\nequilibrium}. To validate the effectiveness of our algorithm, we use this\nalgorithm to solve the problem of incentive design on a large-scale\ntransportation network, showcasing its robustness even when the leader lacks\naccess to followers' demand.\n","authors":["Chinmay Maheshwari","James Cheng","S. Shankar Sasty","Lillian Ratliff","Eric Mazumdar"],"pdf_url":"https://arxiv.org/pdf/2302.01421v3.pdf","comment":"31 pages"},{"id":"http://arxiv.org/abs/2403.18162v1","updated":"2024-03-27T00:05:48Z","published":"2024-03-27T00:05:48Z","title":"Optimizing Cyber Response Time on Temporal Active Directory Networks\n  Using Decoys","summary":"  Microsoft Active Directory (AD) is the default security management system for\nWindow domain network. We study the problem of placing decoys in AD network to\ndetect potential attacks. We model the problem as a Stackelberg game between an\nattacker and a defender on AD attack graphs where the defender employs a set of\ndecoys to detect the attacker on their way to Domain Admin (DA). Contrary to\nprevious works, we consider time-varying (temporal) attack graphs. We proposed\na novel metric called response time, to measure the effectiveness of our decoy\nplacement in temporal attack graphs. Response time is defined as the duration\nfrom the moment attackers trigger the first decoy to when they compromise the\nDA. Our goal is to maximize the defender's response time to the worst-case\nattack paths. We establish the NP-hard nature of the defender's optimization\nproblem, leading us to develop Evolutionary Diversity Optimization (EDO)\nalgorithms. EDO algorithms identify diverse sets of high-quality solutions for\nthe optimization problem. Despite the polynomial nature of the fitness\nfunction, it proves experimentally slow for larger graphs. To enhance\nscalability, we proposed an algorithm that exploits the static nature of AD\ninfrastructure in the temporal setting. Then, we introduce tailored repair\noperations, ensuring the convergence to better results while maintaining\nscalability for larger graphs.\n","authors":["Huy Q. Ngo","Mingyu Guo","Hung Nguyen"],"pdf_url":"https://arxiv.org/pdf/2403.18162v1.pdf","comment":"To be appear in ACM GECCO 2024"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2403.18807v1","updated":"2024-03-27T17:53:30Z","published":"2024-03-27T17:53:30Z","title":"ECoDepth: Effective Conditioning of Diffusion Models for Monocular Depth\n  Estimation","summary":"  In the absence of parallax cues, a learning-based single image depth\nestimation (SIDE) model relies heavily on shading and contextual cues in the\nimage. While this simplicity is attractive, it is necessary to train such\nmodels on large and varied datasets, which are difficult to capture. It has\nbeen shown that using embeddings from pre-trained foundational models, such as\nCLIP, improves zero shot transfer in several applications. Taking inspiration\nfrom this, in our paper we explore the use of global image priors generated\nfrom a pre-trained ViT model to provide more detailed contextual information.\nWe argue that the embedding vector from a ViT model, pre-trained on a large\ndataset, captures greater relevant information for SIDE than the usual route of\ngenerating pseudo image captions, followed by CLIP based text embeddings. Based\non this idea, we propose a new SIDE model using a diffusion backbone which is\nconditioned on ViT embeddings. Our proposed design establishes a new\nstate-of-the-art (SOTA) for SIDE on NYUv2 dataset, achieving Abs Rel error of\n0.059(14% improvement) compared to 0.069 by the current SOTA (VPD). And on\nKITTI dataset, achieving Sq Rel error of 0.139 (2% improvement) compared to\n0.142 by the current SOTA (GEDepth). For zero-shot transfer with a model\ntrained on NYUv2, we report mean relative improvement of (20%, 23%, 81%, 25%)\nover NeWCRFs on (Sun-RGBD, iBims1, DIODE, HyperSim) datasets, compared to (16%,\n18%, 45%, 9%) by ZoeDepth. The code is available at\nhttps://github.com/Aradhye2002/EcoDepth.\n","authors":["Suraj Patni","Aradhye Agarwal","Chetan Arora"],"pdf_url":"https://arxiv.org/pdf/2403.18807v1.pdf","comment":"Accepted at IEEE/CVF Conference on Computer Vision and Pattern\n  Recognition (CVPR) 2024"},{"id":"http://arxiv.org/abs/2403.18802v1","updated":"2024-03-27T17:48:55Z","published":"2024-03-27T17:48:55Z","title":"Long-form factuality in large language models","summary":"  Large language models (LLMs) often generate content that contains factual\nerrors when responding to fact-seeking prompts on open-ended topics. To\nbenchmark a model's long-form factuality in open domains, we first use GPT-4 to\ngenerate LongFact, a prompt set comprising thousands of questions spanning 38\ntopics. We then propose that LLM agents can be used as automated evaluators for\nlong-form factuality through a method which we call Search-Augmented Factuality\nEvaluator (SAFE). SAFE utilizes an LLM to break down a long-form response into\na set of individual facts and to evaluate the accuracy of each fact using a\nmulti-step reasoning process comprising sending search queries to Google Search\nand determining whether a fact is supported by the search results. Furthermore,\nwe propose extending F1 score as an aggregated metric for long-form factuality.\nTo do so, we balance the percentage of supported facts in a response\n(precision) with the percentage of provided facts relative to a hyperparameter\nrepresenting a user's preferred response length (recall).\n  Empirically, we demonstrate that LLM agents can achieve superhuman rating\nperformance - on a set of ~16k individual facts, SAFE agrees with crowdsourced\nhuman annotators 72% of the time, and on a random subset of 100 disagreement\ncases, SAFE wins 76% of the time. At the same time, SAFE is more than 20 times\ncheaper than human annotators. We also benchmark thirteen language models on\nLongFact across four model families (Gemini, GPT, Claude, and PaLM-2), finding\nthat larger language models generally achieve better long-form factuality.\nLongFact, SAFE, and all experimental code are available at\nhttps://github.com/google-deepmind/long-form-factuality.\n","authors":["Jerry Wei","Chengrun Yang","Xinying Song","Yifeng Lu","Nathan Hu","Dustin Tran","Daiyi Peng","Ruibo Liu","Da Huang","Cosmo Du","Quoc V. Le"],"pdf_url":"https://arxiv.org/pdf/2403.18802v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.13525v2","updated":"2024-03-27T17:47:56Z","published":"2023-05-22T22:41:49Z","title":"A 4D Hybrid Algorithm to Scale Parallel Training to Thousands of GPUs","summary":"  Large communication costs are a critical bottleneck in training\nstate-of-the-art neural networks on distributed systems. This paper introduces\nAxoNN, a novel four-dimensional (4D) parallelization approach, inspired by\nAgarwal's algorithm for matrix multiplication, for parallelizing tensor\ncomputations in deep learning, AxoNN employs two key strategies to minimize\ncommunication overhead. First, we optimize communication by overlapping\nexpensive collective operations (reduce-scatter, all-gather, all-reduce) with\ncomputations. Our experiments with a 20-billion parameter transformer model\ndemonstrate that these optimizations deliver nearly 53\\% improvement. Second,\nwe present an analytical model to assist users in identifying\ncommunication-minimizing configurations within the vast search space defined by\nour 4D algorithm. This model empowers practitioners by simplifying the tuning\nprocess for their specific training workloads. When training an 80-billion\nparameter model on 1024 GPUs of Perlmutter, AxoNN surpasses Megatron-LM, a\nstate-of-the-art framework, by a significant 26%. Additionally, it achieves 57%\nof the theoretical peak FLOP/s.\n","authors":["Siddharth Singh","Prajwal Singhania","Aditya K. Ranjan","Zack Sating","Abhinav Bhatele"],"pdf_url":"https://arxiv.org/pdf/2305.13525v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13483v4","updated":"2024-03-27T17:38:27Z","published":"2023-02-27T02:42:27Z","title":"CrystalBox: Future-Based Explanations for Input-Driven Deep RL Systems","summary":"  We present CrystalBox, a novel, model-agnostic, posthoc explainability\nframework for Deep Reinforcement Learning (DRL) controllers in the large family\nof input-driven environments which includes computer systems. We combine the\nnatural decomposability of reward functions in input-driven environments with\nthe explanatory power of decomposed returns. We propose an efficient algorithm\nto generate future-based explanations across both discrete and continuous\ncontrol environments. Using applications such as adaptive bitrate streaming and\ncongestion control, we demonstrate CrystalBox's capability to generate\nhigh-fidelity explanations. We further illustrate its higher utility across\nthree practical use cases: contrastive explanations, network observability, and\nguided reward design, as opposed to prior explainability techniques that\nidentify salient features.\n","authors":["Sagar Patel","Sangeetha Abdu Jyothi","Nina Narodytska"],"pdf_url":"https://arxiv.org/pdf/2302.13483v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18775v1","updated":"2024-03-27T17:23:39Z","published":"2024-03-27T17:23:39Z","title":"ImageNet-D: Benchmarking Neural Network Robustness on Diffusion\n  Synthetic Object","summary":"  We establish rigorous benchmarks for visual perception robustness. Synthetic\nimages such as ImageNet-C, ImageNet-9, and Stylized ImageNet provide specific\ntype of evaluation over synthetic corruptions, backgrounds, and textures, yet\nthose robustness benchmarks are restricted in specified variations and have low\nsynthetic quality. In this work, we introduce generative model as a data source\nfor synthesizing hard images that benchmark deep models' robustness. Leveraging\ndiffusion models, we are able to generate images with more diversified\nbackgrounds, textures, and materials than any prior work, where we term this\nbenchmark as ImageNet-D. Experimental results show that ImageNet-D results in a\nsignificant accuracy drop to a range of vision models, from the standard ResNet\nvisual classifier to the latest foundation models like CLIP and MiniGPT-4,\nsignificantly reducing their accuracy by up to 60\\%. Our work suggests that\ndiffusion models can be an effective source to test vision models. The code and\ndataset are available at https://github.com/chenshuang-zhang/imagenet_d.\n","authors":["Chenshuang Zhang","Fei Pan","Junmo Kim","In So Kweon","Chengzhi Mao"],"pdf_url":"https://arxiv.org/pdf/2403.18775v1.pdf","comment":"Accepted at CVPR 2024"},{"id":"http://arxiv.org/abs/2309.04381v2","updated":"2024-03-27T17:07:47Z","published":"2023-09-08T15:23:40Z","title":"Generalization Bounds: Perspectives from Information Theory and\n  PAC-Bayes","summary":"  A fundamental question in theoretical machine learning is generalization.\nOver the past decades, the PAC-Bayesian approach has been established as a\nflexible framework to address the generalization capabilities of machine\nlearning algorithms, and design new ones. Recently, it has garnered increased\ninterest due to its potential applicability for a variety of learning\nalgorithms, including deep neural networks. In parallel, an\ninformation-theoretic view of generalization has developed, wherein the\nrelation between generalization and various information measures has been\nestablished. This framework is intimately connected to the PAC-Bayesian\napproach, and a number of results have been independently discovered in both\nstrands. In this monograph, we highlight this strong connection and present a\nunified treatment of PAC-Bayesian and information-theoretic generalization\nbounds. We present techniques and results that the two perspectives have in\ncommon, and discuss the approaches and interpretations that differ. In\nparticular, we demonstrate how many proofs in the area share a modular\nstructure, through which the underlying ideas can be intuited. We pay special\nattention to the conditional mutual information (CMI) framework; analytical\nstudies of the information complexity of learning algorithms; and the\napplication of the proposed methods to deep learning. This monograph is\nintended to provide a comprehensive introduction to information-theoretic\ngeneralization bounds and their connection to PAC-Bayes, serving as a\nfoundation from which the most recent developments are accessible. It is aimed\nbroadly towards researchers with an interest in generalization and theoretical\nmachine learning.\n","authors":["Fredrik Hellström","Giuseppe Durisi","Benjamin Guedj","Maxim Raginsky"],"pdf_url":"https://arxiv.org/pdf/2309.04381v2.pdf","comment":"228 pages"},{"id":"http://arxiv.org/abs/2403.06054v4","updated":"2024-03-27T17:06:10Z","published":"2024-03-10T00:47:05Z","title":"Decoupled Data Consistency with Diffusion Purification for Image\n  Restoration","summary":"  Diffusion models have recently gained traction as a powerful class of deep\ngenerative priors, excelling in a wide range of image restoration tasks due to\ntheir exceptional ability to model data distributions. To solve image\nrestoration problems, many existing techniques achieve data consistency by\nincorporating additional likelihood gradient steps into the reverse sampling\nprocess of diffusion models. However, the additional gradient steps pose a\nchallenge for real-world practical applications as they incur a large\ncomputational overhead, thereby increasing inference time. They also present\nadditional difficulties when using accelerated diffusion model samplers, as the\nnumber of data consistency steps is limited by the number of reverse sampling\nsteps. In this work, we propose a novel diffusion-based image restoration\nsolver that addresses these issues by decoupling the reverse process from the\ndata consistency steps. Our method involves alternating between a\nreconstruction phase to maintain data consistency and a refinement phase that\nenforces the prior via diffusion purification. Our approach demonstrates\nversatility, making it highly adaptable for efficient problem-solving in latent\nspace. Additionally, it reduces the necessity for numerous sampling steps\nthrough the integration of consistency models. The efficacy of our approach is\nvalidated through comprehensive experiments across various image restoration\ntasks, including image denoising, deblurring, inpainting, and super-resolution.\n","authors":["Xiang Li","Soo Min Kwon","Ismail R. Alkhouri","Saiprasad Ravishankar","Qing Qu"],"pdf_url":"https://arxiv.org/pdf/2403.06054v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18766v1","updated":"2024-03-27T17:05:03Z","published":"2024-03-27T17:05:03Z","title":"Superior Parallel Big Data Clustering through Competitive Stochastic\n  Sample Size Optimization in Big-means","summary":"  This paper introduces a novel K-means clustering algorithm, an advancement on\nthe conventional Big-means methodology. The proposed method efficiently\nintegrates parallel processing, stochastic sampling, and competitive\noptimization to create a scalable variant designed for big data applications.\nIt addresses scalability and computation time challenges typically faced with\ntraditional techniques. The algorithm adjusts sample sizes dynamically for each\nworker during execution, optimizing performance. Data from these sample sizes\nare continually analyzed, facilitating the identification of the most efficient\nconfiguration. By incorporating a competitive element among workers using\ndifferent sample sizes, efficiency within the Big-means algorithm is further\nstimulated. In essence, the algorithm balances computational time and\nclustering quality by employing a stochastic, competitive sampling strategy in\na parallel computing setting.\n","authors":["Rustam Mussabayev","Ravil Mussabayev"],"pdf_url":"https://arxiv.org/pdf/2403.18766v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18765v1","updated":"2024-03-27T17:03:31Z","published":"2024-03-27T17:03:31Z","title":"CaT: Constraints as Terminations for Legged Locomotion Reinforcement\n  Learning","summary":"  Deep Reinforcement Learning (RL) has demonstrated impressive results in\nsolving complex robotic tasks such as quadruped locomotion. Yet, current\nsolvers fail to produce efficient policies respecting hard constraints. In this\nwork, we advocate for integrating constraints into robot learning and present\nConstraints as Terminations (CaT), a novel constrained RL algorithm. Departing\nfrom classical constrained RL formulations, we reformulate constraints through\nstochastic terminations during policy learning: any violation of a constraint\ntriggers a probability of terminating potential future rewards the RL agent\ncould attain. We propose an algorithmic approach to this formulation, by\nminimally modifying widely used off-the-shelf RL algorithms in robot learning\n(such as Proximal Policy Optimization). Our approach leads to excellent\nconstraint adherence without introducing undue complexity and computational\noverhead, thus mitigating barriers to broader adoption. Through empirical\nevaluation on the real quadruped robot Solo crossing challenging obstacles, we\ndemonstrate that CaT provides a compelling solution for incorporating\nconstraints into RL frameworks. Videos and code are available at\nhttps://constraints-as-terminations.github.io.\n","authors":["Elliot Chane-Sane","Pierre-Alexandre Leziart","Thomas Flayols","Olivier Stasse","Philippe Souères","Nicolas Mansard"],"pdf_url":"https://arxiv.org/pdf/2403.18765v1.pdf","comment":"Project webpage: https://constraints-as-terminations.github.io"},{"id":"http://arxiv.org/abs/2311.01483v3","updated":"2024-03-27T16:56:23Z","published":"2023-11-02T14:47:06Z","title":"FedSN: A Novel Federated Learning Framework over LEO Satellite Networks","summary":"  Recently, a large number of Low Earth Orbit (LEO) satellites have been\nlaunched and deployed successfully in space by commercial companies, such as\nSpaceX. Due to multimodal sensors equipped by the LEO satellites, they serve\nnot only for communication but also for various machine learning applications,\nsuch as space modulation recognition, remote sensing image classification, etc.\nHowever, the ground station (GS) may be incapable of downloading such a large\nvolume of raw sensing data for centralized model training due to the limited\ncontact time with LEO satellites (e.g. 5 minutes). Therefore, federated\nlearning (FL) has emerged as the promising solution to address this problem via\non-device training. Unfortunately, to enable FL on LEO satellites, we still\nface three critical challenges that are i) heterogeneous computing and memory\ncapabilities, ii) limited uplink rate, and iii) model staleness. To this end,\nwe propose FedSN as a general FL framework to tackle the above challenges, and\nfully explore data diversity on LEO satellites. Specifically, we first present\na novel sub-structure scheme to enable heterogeneous local model training\nconsidering different computing, memory, and communication constraints on LEO\nsatellites. Additionally, we propose a pseudo-synchronous model aggregation\nstrategy to dynamically schedule model aggregation for compensating model\nstaleness. To further demonstrate the effectiveness of the FedSN, we evaluate\nit using space modulation recognition and remote sensing image classification\ntasks by leveraging the data from real-world satellite networks. Extensive\nexperimental results demonstrate that FedSN framework achieves higher accuracy,\nlower computing, and communication overhead than the state-of-the-art\nbenchmarks and the effectiveness of each components in FedSN.\n","authors":["Zheng Lin","Zhe Chen","Zihan Fang","Xianhao Chen","Xiong Wang","Yue Gao"],"pdf_url":"https://arxiv.org/pdf/2311.01483v3.pdf","comment":"14 pages, 17 figures"},{"id":"http://arxiv.org/abs/2403.18756v1","updated":"2024-03-27T16:56:14Z","published":"2024-03-27T16:56:14Z","title":"Detection of subclinical atherosclerosis by image-based deep learning on\n  chest x-ray","summary":"  Aims. To develop a deep-learning based system for recognition of subclinical\natherosclerosis on a plain frontal chest x-ray. Methods and Results. A\ndeep-learning algorithm to predict coronary artery calcium (CAC) score (the\nAI-CAC model) was developed on 460 chest x-ray (80% training cohort, 20%\ninternal validation cohort) of primary prevention patients (58.4% male, median\nage 63 [51-74] years) with available paired chest x-ray and chest computed\ntomography (CT) indicated for any clinical reason and performed within 3\nmonths. The CAC score calculated on chest CT was used as ground truth. The\nmodel was validated on an temporally-independent cohort of 90 patients from the\nsame institution (external validation). The diagnostic accuracy of the AI-CAC\nmodel assessed by the area under the curve (AUC) was the primary outcome.\nOverall, median AI-CAC score was 35 (0-388) and 28.9% patients had no AI-CAC.\nAUC of the AI-CAC model to identify a CAC>0 was 0.90 in the internal validation\ncohort and 0.77 in the external validation cohort. Sensitivity was consistently\nabove 92% in both cohorts. In the overall cohort (n=540), among patients with\nAI-CAC=0, a single ASCVD event occurred, after 4.3 years. Patients with\nAI-CAC>0 had significantly higher Kaplan Meier estimates for ASCVD events\n(13.5% vs. 3.4%, log-rank=0.013). Conclusion. The AI-CAC model seems to\naccurately detect subclinical atherosclerosis on chest x-ray with elevated\nsensitivity, and to predict ASCVD events with elevated negative predictive\nvalue. Adoption of the AI-CAC model to refine CV risk stratification or as an\nopportunistic screening tool requires prospective evaluation.\n","authors":["Guglielmo Gallone","Francesco Iodice","Alberto Presta","Davide Tore","Ovidio de Filippo","Michele Visciano","Carlo Alberto Barbano","Alessandro Serafini","Paola Gorrini","Alessandro Bruno","Walter Grosso Marra","James Hughes","Mario Iannaccone","Paolo Fonio","Attilio Fiandrotti","Alessandro Depaoli","Marco Grangetto","Gaetano Maria de Ferrari","Fabrizio D'Ascenzo"],"pdf_url":"https://arxiv.org/pdf/2403.18756v1.pdf","comment":"Submitted to European Heart Journal - Cardiovascular Imaging Added\n  also the additional material 44 pages (30 main paper, 14 additional\n  material), 14 figures (5 main manuscript, 9 additional material)"},{"id":"http://arxiv.org/abs/2403.14623v2","updated":"2024-03-27T16:49:35Z","published":"2024-03-21T17:59:41Z","title":"Simplified Diffusion Schrödinger Bridge","summary":"  This paper introduces a novel theoretical simplification of the Diffusion\nSchr\\\"odinger Bridge (DSB) that facilitates its unification with Score-based\nGenerative Models (SGMs), addressing the limitations of DSB in complex data\ngeneration and enabling faster convergence and enhanced performance. By\nemploying SGMs as an initial solution for DSB, our approach capitalizes on the\nstrengths of both frameworks, ensuring a more efficient training process and\nimproving the performance of SGM. We also propose a reparameterization\ntechnique that, despite theoretical approximations, practically improves the\nnetwork's fitting capabilities. Our extensive experimental evaluations confirm\nthe effectiveness of the simplified DSB, demonstrating its significant\nimprovements. We believe the contributions of this work pave the way for\nadvanced generative modeling. The code is available at\nhttps://github.com/checkcrab/SDSB.\n","authors":["Zhicong Tang","Tiankai Hang","Shuyang Gu","Dong Chen","Baining Guo"],"pdf_url":"https://arxiv.org/pdf/2403.14623v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.03683v2","updated":"2024-03-27T16:44:22Z","published":"2023-11-07T03:19:16Z","title":"Preventing Arbitrarily High Confidence on Far-Away Data in\n  Point-Estimated Discriminative Neural Networks","summary":"  Discriminatively trained, deterministic neural networks are the de facto\nchoice for classification problems. However, even though they achieve\nstate-of-the-art results on in-domain test sets, they tend to be overconfident\non out-of-distribution (OOD) data. For instance, ReLU networks - a popular\nclass of neural network architectures - have been shown to almost always yield\nhigh confidence predictions when the test data are far away from the training\nset, even when they are trained with OOD data. We overcome this problem by\nadding a term to the output of the neural network that corresponds to the logit\nof an extra class, that we design to dominate the logits of the original\nclasses as we move away from the training data.This technique provably prevents\narbitrarily high confidence on far-away test data while maintaining a simple\ndiscriminative point-estimate training. Evaluation on various benchmarks\ndemonstrates strong performance against competitive baselines on both far-away\nand realistic OOD data.\n","authors":["Ahmad Rashid","Serena Hacker","Guojun Zhang","Agustinus Kristiadi","Pascal Poupart"],"pdf_url":"https://arxiv.org/pdf/2311.03683v2.pdf","comment":"Accepted at AISTATS 2024"},{"id":"http://arxiv.org/abs/2403.18742v1","updated":"2024-03-27T16:39:28Z","published":"2024-03-27T16:39:28Z","title":"Understanding the Learning Dynamics of Alignment with Human Feedback","summary":"  Aligning large language models (LLMs) with human intentions has become a\ncritical task for safely deploying models in real-world systems. While existing\nalignment approaches have seen empirical success, theoretically understanding\nhow these methods affect model behavior remains an open question. Our work\nprovides an initial attempt to theoretically analyze the learning dynamics of\nhuman preference alignment. We formally show how the distribution of preference\ndatasets influences the rate of model updates and provide rigorous guarantees\non the training accuracy. Our theory also reveals an intricate phenomenon where\nthe optimization is prone to prioritizing certain behaviors with higher\npreference distinguishability. We empirically validate our findings on\ncontemporary LLMs and alignment tasks, reinforcing our theoretical insights and\nshedding light on considerations for future alignment approaches. Disclaimer:\nThis paper contains potentially offensive text; reader discretion is advised.\n","authors":["Shawn Im","Yixuan Li"],"pdf_url":"https://arxiv.org/pdf/2403.18742v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18739v1","updated":"2024-03-27T16:32:32Z","published":"2024-03-27T16:32:32Z","title":"Usage-Specific Survival Modeling Based on Operational Data and Neural\n  Networks","summary":"  Accurate predictions of when a component will fail are crucial when planning\nmaintenance, and by modeling the distribution of these failure times, survival\nmodels have shown to be particularly useful in this context. The presented\nmethodology is based on conventional neural network-based survival models that\nare trained using data that is continuously gathered and stored at specific\ntimes, called snapshots. An important property of this type of training data is\nthat it can contain more than one snapshot from a specific individual which\nresults in that standard maximum likelihood training can not be directly\napplied since the data is not independent. However, the papers show that if the\ndata is in a specific format where all snapshot times are the same for all\nindividuals, called homogeneously sampled, maximum likelihood training can be\napplied and produce desirable results. In many cases, the data is not\nhomogeneously sampled and in this case, it is proposed to resample the data to\nmake it homogeneously sampled. How densely the dataset is sampled turns out to\nbe an important parameter; it should be chosen large enough to produce good\nresults, but this also increases the size of the dataset which makes training\nslow. To reduce the number of samples needed during training, the paper also\nproposes a technique to, instead of resampling the dataset once before the\ntraining starts, randomly resample the dataset at the start of each epoch\nduring the training. The proposed methodology is evaluated on both a simulated\ndataset and an experimental dataset of starter battery failures. The results\nshow that if the data is homogeneously sampled the methodology works as\nintended and produces accurate survival models. The results also show that\nrandomly resampling the dataset on each epoch is an effective way to reduce the\nsize of the training data.\n","authors":["Olov Holmer","Mattias Krysander","Erik Frisk"],"pdf_url":"https://arxiv.org/pdf/2403.18739v1.pdf","comment":"7 pages"},{"id":"http://arxiv.org/abs/2403.18735v1","updated":"2024-03-27T16:24:26Z","published":"2024-03-27T16:24:26Z","title":"Nonlinear model reduction for operator learning","summary":"  Operator learning provides methods to approximate mappings between\ninfinite-dimensional function spaces. Deep operator networks (DeepONets) are a\nnotable architecture in this field. Recently, an extension of DeepONet based on\nmodel reduction and neural networks, proper orthogonal decomposition\n(POD)-DeepONet, has been able to outperform other architectures in terms of\naccuracy for several benchmark tests. We extend this idea towards nonlinear\nmodel order reduction by proposing an efficient framework that combines neural\nnetworks with kernel principal component analysis (KPCA) for operator learning.\nOur results demonstrate the superior performance of KPCA-DeepONet over\nPOD-DeepONet.\n","authors":["Hamidreza Eivazi","Stefan Wittek","Andreas Rausch"],"pdf_url":"https://arxiv.org/pdf/2403.18735v1.pdf","comment":"Published as a Tiny Paper at ICLR 2024 (Notable)"},{"id":"http://arxiv.org/abs/2403.18731v1","updated":"2024-03-27T16:21:24Z","published":"2024-03-27T16:21:24Z","title":"Enhancing Manufacturing Quality Prediction Models through the\n  Integration of Explainability Methods","summary":"  This research presents a method that utilizes explainability techniques to\namplify the performance of machine learning (ML) models in forecasting the\nquality of milling processes, as demonstrated in this paper through a\nmanufacturing use case. The methodology entails the initial training of ML\nmodels, followed by a fine-tuning phase where irrelevant features identified\nthrough explainability methods are eliminated. This procedural refinement\nresults in performance enhancements, paving the way for potential reductions in\nmanufacturing costs and a better understanding of the trained ML models. This\nstudy highlights the usefulness of explainability techniques in both explaining\nand optimizing predictive models in the manufacturing realm.\n","authors":["Dennis Gross","Helge Spieker","Arnaud Gotlieb","Ricardo Knoblauch"],"pdf_url":"https://arxiv.org/pdf/2403.18731v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.03100v2","updated":"2024-03-27T16:14:34Z","published":"2024-03-05T16:35:25Z","title":"NaturalSpeech 3: Zero-Shot Speech Synthesis with Factorized Codec and\n  Diffusion Models","summary":"  While recent large-scale text-to-speech (TTS) models have achieved\nsignificant progress, they still fall short in speech quality, similarity, and\nprosody. Considering speech intricately encompasses various attributes (e.g.,\ncontent, prosody, timbre, and acoustic details) that pose significant\nchallenges for generation, a natural idea is to factorize speech into\nindividual subspaces representing different attributes and generate them\nindividually. Motivated by it, we propose NaturalSpeech 3, a TTS system with\nnovel factorized diffusion models to generate natural speech in a zero-shot\nway. Specifically, 1) we design a neural codec with factorized vector\nquantization (FVQ) to disentangle speech waveform into subspaces of content,\nprosody, timbre, and acoustic details; 2) we propose a factorized diffusion\nmodel to generate attributes in each subspace following its corresponding\nprompt. With this factorization design, NaturalSpeech 3 can effectively and\nefficiently model intricate speech with disentangled subspaces in a\ndivide-and-conquer way. Experiments show that NaturalSpeech 3 outperforms the\nstate-of-the-art TTS systems on quality, similarity, prosody, and\nintelligibility, and achieves on-par quality with human recordings.\nFurthermore, we achieve better performance by scaling to 1B parameters and 200K\nhours of training data.\n","authors":["Zeqian Ju","Yuancheng Wang","Kai Shen","Xu Tan","Detai Xin","Dongchao Yang","Yanqing Liu","Yichong Leng","Kaitao Song","Siliang Tang","Zhizheng Wu","Tao Qin","Xiang-Yang Li","Wei Ye","Shikun Zhang","Jiang Bian","Lei He","Jinyu Li","Sheng Zhao"],"pdf_url":"https://arxiv.org/pdf/2403.03100v2.pdf","comment":"Achieving human-level quality and naturalness on multi-speaker\n  datasets (e.g., LibriSpeech) in a zero-shot way"},{"id":"http://arxiv.org/abs/2402.07868v2","updated":"2024-03-27T16:12:43Z","published":"2024-02-12T18:29:17Z","title":"Nesting Particle Filters for Experimental Design in Dynamical Systems","summary":"  In this paper, we propose a novel approach to Bayesian experimental design\nfor non-exchangeable data that formulates it as risk-sensitive policy\noptimization. We develop the Inside-Out SMC$^2$ algorithm, a nested sequential\nMonte Carlo technique to infer optimal designs, and embed it into a particle\nMarkov chain Monte Carlo framework to perform gradient-based policy\namortization. Our approach is distinct from other amortized experimental design\ntechniques, as it does not rely on contrastive estimators. Numerical validation\non a set of dynamical systems showcases the efficacy of our method in\ncomparison to other state-of-the-art strategies.\n","authors":["Sahel Iqbal","Adrien Corenflos","Simo Särkkä","Hany Abdulsamad"],"pdf_url":"https://arxiv.org/pdf/2402.07868v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.11798v3","updated":"2024-03-27T16:12:18Z","published":"2023-09-21T06:04:06Z","title":"A Comprehensive Review of Community Detection in Graphs","summary":"  The study of complex networks has significantly advanced our understanding of\ncommunity structures which serves as a crucial feature of real-world graphs.\nDetecting communities in graphs is a challenging problem with applications in\nsociology, biology, and computer science. Despite the efforts of an\ninterdisciplinary community of scientists, a satisfactory solution to this\nproblem has not yet been achieved. This review article delves into the topic of\ncommunity detection in graphs, which serves as a thorough exposition of various\ncommunity detection methods from perspectives of modularity-based method,\nspectral clustering, probabilistic modelling, and deep learning. Along with the\nmethods, a new community detection method designed by us is also presented.\nAdditionally, the performance of these methods on the datasets with and without\nground truth is compared. In conclusion, this comprehensive review provides a\ndeep understanding of community detection in graphs.\n","authors":["Jiakang Li","Songning Lai","Zhihao Shuai","Yuan Tan","Yifan Jia","Mianyang Yu","Zichen Song","Xiaokang Peng","Ziyang Xu","Yongxin Ni","Haifeng Qiu","Jiayu Yang","Yutong Liu","Yonggang Lu"],"pdf_url":"https://arxiv.org/pdf/2309.11798v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18717v1","updated":"2024-03-27T16:06:37Z","published":"2024-03-27T16:06:37Z","title":"Semi-Supervised Learning for Deep Causal Generative Models","summary":"  Developing models that can answer questions of the form \"How would $x$ change\nif $y$ had been $z$?\" is fundamental for advancing medical image analysis.\nTraining causal generative models that address such counterfactual questions,\nthough, currently requires that all relevant variables have been observed and\nthat corresponding labels are available in training data. However, clinical\ndata may not have complete records for all patients and state of the art causal\ngenerative models are unable to take full advantage of this. We thus develop,\nfor the first time, a semi-supervised deep causal generative model that\nexploits the causal relationships between variables to maximise the use of all\navailable data. We explore this in the setting where each sample is either\nfully labelled or fully unlabelled, as well as the more clinically realistic\ncase of having different labels missing for each sample. We leverage techniques\nfrom causal inference to infer missing values and subsequently generate\nrealistic counterfactuals, even for samples with incomplete labels.\n","authors":["Yasin Ibrahim","Hermione Warr","Konstantinos Kamnitsas"],"pdf_url":"https://arxiv.org/pdf/2403.18717v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.07494v3","updated":"2024-03-27T16:06:34Z","published":"2024-01-15T06:26:53Z","title":"Input Convex Lipschitz RNN: A Fast and Robust Approach for Engineering\n  Tasks","summary":"  Computational efficiency and non-adversarial robustness are critical factors\nin real-world engineering applications. Yet, conventional neural networks often\nfall short in addressing both simultaneously, or even separately. Drawing\ninsights from natural physical systems and existing literature, it is known\nthat an input convex architecture enhances computational efficiency, while a\nLipschitz-constrained architecture bolsters non-adversarial robustness. By\nleveraging the strengths of convexity and Lipschitz continuity, we develop a\nnovel network architecture, termed Input Convex Lipschitz Recurrent Neural\nNetworks. This model is explicitly designed for fast and robust\noptimization-based tasks and outperforms existing recurrent units across a\nspectrum of engineering tasks in terms of computational efficiency and\nnon-adversarial robustness, including real-world solar irradiance prediction\nfor Solar PV system planning at LHT Holdings in Singapore and real-time Model\nPredictive Control optimization for a nonlinear chemical reactor.\n","authors":["Zihao Wang","P S Pravin","Zhe Wu"],"pdf_url":"https://arxiv.org/pdf/2401.07494v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.03123v3","updated":"2024-03-27T16:03:32Z","published":"2023-04-13T16:01:28Z","title":"ChatGPT Needs SPADE (Sustainability, PrivAcy, Digital divide, and\n  Ethics) Evaluation: A Review","summary":"  ChatGPT is another large language model (LLM) vastly available for the\nconsumers on their devices but due to its performance and ability to converse\neffectively, it has gained a huge popularity amongst research as well as\nindustrial community. Recently, many studies have been published to show the\neffectiveness, efficiency, integration, and sentiments of chatGPT and other\nLLMs. In contrast, this study focuses on the important aspects that are mostly\noverlooked, i.e. sustainability, privacy, digital divide, and ethics and\nsuggests that not only chatGPT but every subsequent entry in the category of\nconversational bots should undergo Sustainability, PrivAcy, Digital divide, and\nEthics (SPADE) evaluation. This paper discusses in detail the issues and\nconcerns raised over chatGPT in line with aforementioned characteristics. We\nalso discuss the recent EU AI Act briefly in accordance with the SPADE\nevaluation. We support our hypothesis by some preliminary data collection and\nvisualizations along with hypothesized facts. We also suggest mitigations and\nrecommendations for each of the concerns. Furthermore, we also suggest some\npolicies and recommendations for EU AI policy act concerning ethics, digital\ndivide, and sustainability.\n","authors":["Sunder Ali Khowaja","Parus Khuwaja","Kapal Dev","Weizheng Wang","Lewis Nkenyereye"],"pdf_url":"https://arxiv.org/pdf/2305.03123v3.pdf","comment":"29 pages, 8 figures, 4 tables"},{"id":"http://arxiv.org/abs/2403.17878v2","updated":"2024-03-27T16:01:00Z","published":"2024-03-26T17:10:15Z","title":"Empowering Data Mesh with Federated Learning","summary":"  The evolution of data architecture has seen the rise of data lakes, aiming to\nsolve the bottlenecks of data management and promote intelligent\ndecision-making. However, this centralized architecture is limited by the\nproliferation of data sources and the growing demand for timely analysis and\nprocessing. A new data paradigm, Data Mesh, is proposed to overcome these\nchallenges. Data Mesh treats domains as a first-class concern by distributing\nthe data ownership from the central team to each data domain, while keeping the\nfederated governance to monitor domains and their data products. Many\nmulti-million dollar organizations like Paypal, Netflix, and Zalando have\nalready transformed their data analysis pipelines based on this new\narchitecture. In this decentralized architecture where data is locally\npreserved by each domain team, traditional centralized machine learning is\nincapable of conducting effective analysis across multiple domains, especially\nfor security-sensitive organizations. To this end, we introduce a pioneering\napproach that incorporates Federated Learning into Data Mesh. To the best of\nour knowledge, this is the first open-source applied work that represents a\ncritical advancement toward the integration of federated learning methods into\nthe Data Mesh paradigm, underscoring the promising prospects for\nprivacy-preserving and decentralized data analysis strategies within Data Mesh\narchitecture.\n","authors":["Haoyuan Li","Salman Toor"],"pdf_url":"https://arxiv.org/pdf/2403.17878v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18710v1","updated":"2024-03-27T15:57:42Z","published":"2024-03-27T15:57:42Z","title":"Deep Learning for Traffic Flow Prediction using Cellular Automata-based\n  Model and CNN-LSTM architecture","summary":"  Recent works have attempted to use deep learning to predict future states of\ntraffic flow, but have met with mixed results. These approaches face two key\nchallenges. First, training deep learning neural networks requires large\namounts of training data which are not yet easily available for traffic flow\nsystems. Second, even when data is available, the neural networks require\naccess to historical data that covers most possible traffic flow dynamics to\nsuccessfully predict future traffic states. Specifically, these deep learning\napproaches do not fully leverage domain-knowledge about traffic flow dynamics,\ndespite a significant existing knowledge-base. In this work, we propose to\nsolve both issues using a Convolutional Neural Network (CNNs) with Long Short\nTerm Memory (LSTM) deep learning architecture to successfully predict traffic\nflow, while leveraging a cellular automata-based statistical mechanics model of\ntraffic flow to generate training and test data. Another major contribution of\nthis paper is the insight that training data for a large traffic system can\nactually be sampled from the simulations of a much smaller traffic system. This\nis achieved through observing that the normalized energy distribution of the\nstatistical mechanics model is scale invariant, which significantly eases the\nburden of data generation for large scale traffic systems. The resulting\nsimulations indicate good agreement between the predicted and the true traffic\nflow dynamics.\n","authors":["Zhaohui Yang","Kshitij Jerath"],"pdf_url":"https://arxiv.org/pdf/2403.18710v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18705v1","updated":"2024-03-27T15:54:55Z","published":"2024-03-27T15:54:55Z","title":"Conditional Wasserstein Distances with Applications in Bayesian OT Flow\n  Matching","summary":"  In inverse problems, many conditional generative models approximate the\nposterior measure by minimizing a distance between the joint measure and its\nlearned approximation. While this approach also controls the distance between\nthe posterior measures in the case of the Kullback--Leibler divergence, this is\nin general not hold true for the Wasserstein distance. In this paper, we\nintroduce a conditional Wasserstein distance via a set of restricted couplings\nthat equals the expected Wasserstein distance of the posteriors. Interestingly,\nthe dual formulation of the conditional Wasserstein-1 flow resembles losses in\nthe conditional Wasserstein GAN literature in a quite natural way. We derive\ntheoretical properties of the conditional Wasserstein distance, characterize\nthe corresponding geodesics and velocity fields as well as the flow ODEs.\nSubsequently, we propose to approximate the velocity fields by relaxing the\nconditional Wasserstein distance. Based on this, we propose an extension of OT\nFlow Matching for solving Bayesian inverse problems and demonstrate its\nnumerical advantages on an inverse problem and class-conditional image\ngeneration.\n","authors":["Jannis Chemseddine","Paul Hagemann","Christian Wald","Gabriele Steidl"],"pdf_url":"https://arxiv.org/pdf/2403.18705v1.pdf","comment":"This paper supersedes arXiv:2310.13433"},{"id":"http://arxiv.org/abs/2403.18703v1","updated":"2024-03-27T15:52:54Z","published":"2024-03-27T15:52:54Z","title":"Fpga-Based Neural Thrust Controller for UAVs","summary":"  The advent of unmanned aerial vehicles (UAVs) has improved a variety of\nfields by providing a versatile, cost-effective and accessible platform for\nimplementing state-of-the-art algorithms. To accomplish a broader range of\ntasks, there is a growing need for enhanced on-board computing to cope with\nincreasing complexity and dynamic environmental conditions. Recent advances\nhave seen the application of Deep Neural Networks (DNNs), particularly in\ncombination with Reinforcement Learning (RL), to improve the adaptability and\nperformance of UAVs, especially in unknown environments. However, the\ncomputational requirements of DNNs pose a challenge to the limited computing\nresources available on many UAVs. This work explores the use of Field\nProgrammable Gate Arrays (FPGAs) as a viable solution to this challenge,\noffering flexibility, high performance, energy and time efficiency. We propose\na novel hardware board equipped with an Artix-7 FPGA for a popular open-source\nmicro-UAV platform. We successfully validate its functionality by implementing\nan RL-based low-level controller using real-world experiments.\n","authors":["Sharif Azem","David Scheunert","Mengguang Li","Jonas Gehrunger","Kai Cui","Christian Hochberger","Heinz Koepp"],"pdf_url":"https://arxiv.org/pdf/2403.18703v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.11800v3","updated":"2024-03-27T15:48:29Z","published":"2024-02-19T03:08:02Z","title":"Stochastic Approximation with Delayed Updates: Finite-Time Rates under\n  Markovian Sampling","summary":"  Motivated by applications in large-scale and multi-agent reinforcement\nlearning, we study the non-asymptotic performance of stochastic approximation\n(SA) schemes with delayed updates under Markovian sampling. While the effect of\ndelays has been extensively studied for optimization, the manner in which they\ninteract with the underlying Markov process to shape the finite-time\nperformance of SA remains poorly understood. In this context, our first main\ncontribution is to show that under time-varying bounded delays, the delayed SA\nupdate rule guarantees exponentially fast convergence of the \\emph{last\niterate} to a ball around the SA operator's fixed point. Notably, our bound is\n\\emph{tight} in its dependence on both the maximum delay $\\tau_{max}$, and the\nmixing time $\\tau_{mix}$. To achieve this tight bound, we develop a novel\ninductive proof technique that, unlike various existing delayed-optimization\nanalyses, relies on establishing uniform boundedness of the iterates. As such,\nour proof may be of independent interest. Next, to mitigate the impact of the\nmaximum delay on the convergence rate, we provide the first finite-time\nanalysis of a delay-adaptive SA scheme under Markovian sampling. In particular,\nwe show that the exponent of convergence of this scheme gets scaled down by\n$\\tau_{avg}$, as opposed to $\\tau_{max}$ for the vanilla delayed SA rule; here,\n$\\tau_{avg}$ denotes the average delay across all iterations. Moreover, the\nadaptive scheme requires no prior knowledge of the delay sequence for step-size\ntuning. Our theoretical findings shed light on the finite-time effects of\ndelays for a broad class of algorithms, including TD learning, Q-learning, and\nstochastic gradient descent under Markovian sampling.\n","authors":["Arman Adibi","Nicolo Dal Fabbro","Luca Schenato","Sanjeev Kulkarni","H. Vincent Poor","George J. Pappas","Hamed Hassani","Aritra Mitra"],"pdf_url":"https://arxiv.org/pdf/2402.11800v3.pdf","comment":"Accepted to the 27th International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2024!"},{"id":"http://arxiv.org/abs/2403.18699v1","updated":"2024-03-27T15:48:16Z","published":"2024-03-27T15:48:16Z","title":"Contrastive Learning with Orthonormal Anchors (CLOA)","summary":"  This study focuses on addressing the instability issues prevalent in\ncontrastive learning, specifically examining the InfoNCE loss function and its\nderivatives. We reveal a critical observation that these loss functions exhibit\na restrictive behavior, leading to a convergence phenomenon where embeddings\ntend to merge into a singular point. This \"over-fusion\" effect detrimentally\naffects classification accuracy in subsequent supervised-learning tasks.\nThrough theoretical analysis, we demonstrate that embeddings, when equalized or\nconfined to a rank-1 linear subspace, represent a local minimum for InfoNCE. In\nresponse to this challenge, our research introduces an innovative strategy that\nleverages the same or fewer labeled data than typically used in the fine-tuning\nphase. The loss we proposed, Orthonormal Anchor Regression Loss, is designed to\ndisentangle embedding clusters, significantly enhancing the distinctiveness of\neach embedding while simultaneously ensuring their aggregation into dense,\nwell-defined clusters. Our method demonstrates remarkable improvements with\njust a fraction of the conventional label requirements, as evidenced by our\nresults on CIFAR10 and CIFAR100 datasets.\n","authors":["Huanran Li","Daniel Pimentel-Alarcón"],"pdf_url":"https://arxiv.org/pdf/2403.18699v1.pdf","comment":"11 pages, 4 figures"},{"id":"http://arxiv.org/abs/2303.12091v3","updated":"2024-03-27T15:44:25Z","published":"2023-03-21T09:07:15Z","title":"Adaptive Negative Evidential Deep Learning for Open-set Semi-supervised\n  Learning","summary":"  Semi-supervised learning (SSL) methods assume that labeled data, unlabeled\ndata and test data are from the same distribution. Open-set semi-supervised\nlearning (Open-set SSL) considers a more practical scenario, where unlabeled\ndata and test data contain new categories (outliers) not observed in labeled\ndata (inliers). Most previous works focused on outlier detection via binary\nclassifiers, which suffer from insufficient scalability and inability to\ndistinguish different types of uncertainty. In this paper, we propose a novel\nframework, Adaptive Negative Evidential Deep Learning (ANEDL) to tackle these\nlimitations. Concretely, we first introduce evidential deep learning (EDL) as\nan outlier detector to quantify different types of uncertainty, and design\ndifferent uncertainty metrics for self-training and inference. Furthermore, we\npropose a novel adaptive negative optimization strategy, making EDL more\ntailored to the unlabeled dataset containing both inliers and outliers. As\ndemonstrated empirically, our proposed method outperforms existing\nstate-of-the-art methods across four datasets.\n","authors":["Yang Yu","Danruo Deng","Furui Liu","Yueming Jin","Qi Dou","Guangyong Chen","Pheng-Ann Heng"],"pdf_url":"https://arxiv.org/pdf/2303.12091v3.pdf","comment":"Accepted by AAAI2024"},{"id":"http://arxiv.org/abs/2403.18687v1","updated":"2024-03-27T15:34:27Z","published":"2024-03-27T15:34:27Z","title":"InceptionTime vs. Wavelet -- A comparison for time series classification","summary":"  Neural networks were used to classify infrasound data. Two different\napproaches were compared. One based on the direct classification of time series\ndata, using a custom implementation of the InceptionTime network. For the other\napproach, we generated 2D images of the wavelet transformation of the signals,\nwhich were subsequently classified using a ResNet implementation. Choosing\nappropriate hyperparameter settings, both achieve a classification accuracy of\nabove 90 %, with the direct approach reaching 95.2 %.\n","authors":["Daniel Klenkert","Daniel Schaeffer","Julian Stauch"],"pdf_url":"https://arxiv.org/pdf/2403.18687v1.pdf","comment":"4 pages, 1 figure"},{"id":"http://arxiv.org/abs/2403.18685v1","updated":"2024-03-27T15:29:08Z","published":"2024-03-27T15:29:08Z","title":"Representatividad Muestral en la Incertidumbre Simétrica Multivariada\n  para la Selección de Atributos","summary":"  In this work, we analyze the behavior of the multivariate symmetric\nuncertainty (MSU) measure through the use of statistical simulation techniques\nunder various mixes of informative and non-informative randomly generated\nfeatures. Experiments show how the number of attributes, their cardinalities,\nand the sample size affect the MSU. In this thesis, through observation of\nresults, it is proposed an heuristic condition that preserves good quality in\nthe MSU under different combinations of these three factors, providing a new\nuseful criterion to help drive the process of dimension reduction.\n  --\n  En el presente trabajo hemos analizado el comportamiento de una versi\\'on\nmultivariada de la incertidumbre sim\\'etrica a trav\\'es de t\\'ecnicas de\nsimulaci\\'on estad\\'isticas sobre varias combinaciones de atributos\ninformativos y no-informativos generados de forma aleatoria. Los experimentos\nmuestran como el n\\'umero de atributos, sus cardinalidades y el tama\\~no\nmuestral afectan al MSU como medida. En esta tesis, mediante la observaci\\'on\nde resultados hemos propuesto una condici\\'on que preserva una buena calidad en\nel MSU bajo diferentes combinaciones de los tres factores mencionados, lo cual\nprovee un nuevo y valioso criterio para llevar a cabo el proceso de reducci\\'on\nde dimensionalidad.\n","authors":["Gustavo Sosa-Cabrera"],"pdf_url":"https://arxiv.org/pdf/2403.18685v1.pdf","comment":"52 pages, in Spanish. Advisors: Miguel Garc\\'ia-Torres, Santiago\n  G\\'omez-Guerrero, Christian E. Schaerer Serra"},{"id":"http://arxiv.org/abs/2403.18681v1","updated":"2024-03-27T15:24:54Z","published":"2024-03-27T15:24:54Z","title":"TransFusion: Contrastive Learning with Transformers","summary":"  This paper proposes a novel framework, TransFusion, designed to make the\nprocess of contrastive learning more analytical and explainable. TransFusion\nconsists of attention blocks whose softmax being replaced by ReLU, and its\nfinal block's weighted-sum operation is truncated to leave the adjacency matrix\nas the output. The model is trained by minimizing the Jensen-Shannon Divergence\nbetween its output and the target affinity matrix, which indicates whether each\npair of samples belongs to the same or different classes. The main contribution\nof TransFusion lies in defining a theoretical limit for answering two\nfundamental questions in the field: the maximum level of data augmentation and\nthe minimum batch size required for effective contrastive learning.\nFurthermore, experimental results indicate that TransFusion successfully\nextracts features that isolate clusters from complex real-world data, leading\nto improved classification accuracy in downstream tasks.\n","authors":["Huanran Li","Daniel Pimentel-Alarcón"],"pdf_url":"https://arxiv.org/pdf/2403.18681v1.pdf","comment":"17 pages, 4 figures,"},{"id":"http://arxiv.org/abs/2403.18680v1","updated":"2024-03-27T15:22:16Z","published":"2024-03-27T15:22:16Z","title":"NL-ITI: Optimizing Probing and Intervention for Improvement of ITI\n  Method","summary":"  Large Language Models (LLM) are prone to returning false information. It\nconstitutes one of major challenges in the AI field. In our work, we explore\nparadigm introduced by Inference-Time-Intervention (ITI). In first stage, it\nidentifies attention heads, which contain the highest amount of desired type of\nknowledge (e.g., truthful). Afterwards, during inference, LLM activations are\nshifted for chosen subset of attention heads. We further improved the ITI\nframework by introducing a nonlinear probing and multi-token intervention -\nNon-Linear ITI (NL-ITI). NL-ITI is tested on diverse multiple-choice\nbenchmarks, including TruthfulQA, on which we report around 14% MC1 metric\nimprovement with respect to the baseline ITI results. NL-ITI achieves also\nencouraging results on other testsets - on Business Ethics subdomain of MMLU,\naround 18% MC1 improvement over baseline LLaMA2-7B. Additionally, NL-ITI\nperforms better while being less invasive in the behavior of LLM at the same\ntime (as measured by Kullback-Leibler divergence).\n","authors":["Jakub Hoscilowicz","Adam Wiacek","Jan Chojnacki","Adam Cieslak","Leszek Michon","Vitalii Urbanevych","Artur Janicki"],"pdf_url":"https://arxiv.org/pdf/2403.18680v1.pdf","comment":"Code is available at https://github.com/Samsung/NL-ITI"},{"id":"http://arxiv.org/abs/2403.17143v2","updated":"2024-03-27T15:15:16Z","published":"2024-03-25T19:40:26Z","title":"Guided Distant Supervision for Multilingual Relation Extraction Data:\n  Adapting to a New Language","summary":"  Relation extraction is essential for extracting and understanding\nbiographical information in the context of digital humanities and related\nsubjects. There is a growing interest in the community to build datasets\ncapable of training machine learning models to extract relationships. However,\nannotating such datasets can be expensive and time-consuming, in addition to\nbeing limited to English. This paper applies guided distant supervision to\ncreate a large biographical relationship extraction dataset for German. Our\ndataset, composed of more than 80,000 instances for nine relationship types, is\nthe largest biographical German relationship extraction dataset. We also create\na manually annotated dataset with 2000 instances to evaluate the models and\nrelease it together with the dataset compiled using guided distant supervision.\nWe train several state-of-the-art machine learning models on the automatically\ncreated dataset and release them as well. Furthermore, we experiment with\nmultilingual and cross-lingual experiments that could benefit many low-resource\nlanguages.\n","authors":["Alistair Plum","Tharindu Ranasinghe","Christoph Purschke"],"pdf_url":"https://arxiv.org/pdf/2403.17143v2.pdf","comment":"Accepted to LREC-COLING 2024 (The 2024 Joint International Conference\n  on Computational Linguistics, Language Resources and Evaluation)"},{"id":"http://arxiv.org/abs/2403.18671v1","updated":"2024-03-27T15:15:14Z","published":"2024-03-27T15:15:14Z","title":"Fact Checking Beyond Training Set","summary":"  Evaluating the veracity of everyday claims is time consuming and in some\ncases requires domain expertise. We empirically demonstrate that the commonly\nused fact checking pipeline, known as the retriever-reader, suffers from\nperformance deterioration when it is trained on the labeled data from one\ndomain and used in another domain. Afterwards, we delve into each component of\nthe pipeline and propose novel algorithms to address this problem. We propose\nan adversarial algorithm to make the retriever component robust against\ndistribution shift. Our core idea is to initially train a bi-encoder on the\nlabeled source data, and then, to adversarially train two separate document and\nclaim encoders using unlabeled target data. We then focus on the reader\ncomponent and propose to train it such that it is insensitive towards the order\nof claims and evidence documents. Our empirical evaluations support the\nhypothesis that such a reader shows a higher robustness against distribution\nshift. To our knowledge, there is no publicly available multi-topic fact\nchecking dataset. Thus, we propose a simple automatic method to re-purpose two\nwell-known fact checking datasets. We then construct eight fact checking\nscenarios from these datasets, and compare our model to a set of strong\nbaseline models, including recent domain adaptation models that use GPT4 for\ngenerating synthetic data.\n","authors":["Payam Karisani","Heng Ji"],"pdf_url":"https://arxiv.org/pdf/2403.18671v1.pdf","comment":"NAACL 2024"},{"id":"http://arxiv.org/abs/2403.18668v1","updated":"2024-03-27T15:11:07Z","published":"2024-03-27T15:11:07Z","title":"Aiming for Relevance","summary":"  Vital signs are crucial in intensive care units (ICUs). They are used to\ntrack the patient's state and to identify clinically significant changes.\nPredicting vital sign trajectories is valuable for early detection of adverse\nevents. However, conventional machine learning metrics like RMSE often fail to\ncapture the true clinical relevance of such predictions. We introduce novel\nvital sign prediction performance metrics that align with clinical contexts,\nfocusing on deviations from clinical norms, overall trends, and trend\ndeviations. These metrics are derived from empirical utility curves obtained in\na previous study through interviews with ICU clinicians. We validate the\nmetrics' usefulness using simulated and real clinical datasets (MIMIC and\neICU). Furthermore, we employ these metrics as loss functions for neural\nnetworks, resulting in models that excel in predicting clinically significant\nevents. This research paves the way for clinically relevant machine learning\nmodel evaluation and optimization, promising to improve ICU patient care. 10\npages, 9 figures.\n","authors":["Bar Eini Porat","Danny Eytan","Uri Shalit"],"pdf_url":"https://arxiv.org/pdf/2403.18668v1.pdf","comment":"10 pages, 9 figures, AMIA Informatics 2024"},{"id":"http://arxiv.org/abs/2403.18664v1","updated":"2024-03-27T15:08:00Z","published":"2024-03-27T15:08:00Z","title":"Neural Network-Based Piecewise Survival Models","summary":"  In this paper, a family of neural network-based survival models is presented.\nThe models are specified based on piecewise definitions of the hazard function\nand the density function on a partitioning of the time; both constant and\nlinear piecewise definitions are presented, resulting in a family of four\nmodels. The models can be seen as an extension of the commonly used\ndiscrete-time and piecewise exponential models and thereby add flexibility to\nthis set of standard models. Using a simulated dataset the models are shown to\nperform well compared to the highly expressive, state-of-the-art energy-based\nmodel, while only requiring a fraction of the computation time.\n","authors":["Olov Holmer","Erik Frisk","Mattias Krysander"],"pdf_url":"https://arxiv.org/pdf/2403.18664v1.pdf","comment":"7 pages"},{"id":"http://arxiv.org/abs/2403.13374v3","updated":"2024-03-27T14:57:54Z","published":"2024-03-20T08:15:08Z","title":"Byzantine-resilient Federated Learning With Adaptivity to Data\n  Heterogeneity","summary":"  This paper deals with federated learning (FL) in the presence of malicious\nByzantine attacks and data heterogeneity. A novel Robust Average Gradient\nAlgorithm (RAGA) is proposed, which leverages the geometric median for\naggregation and can freely select the round number for local updating.\nDifferent from most existing resilient approaches, which perform convergence\nanalysis based on strongly-convex loss function or homogeneously distributed\ndataset, we conduct convergence analysis for not only strongly-convex but also\nnon-convex loss function over heterogeneous dataset. According to our\ntheoretical analysis, as long as the fraction of dataset from malicious users\nis less than half, RAGA can achieve convergence at rate\n$\\mathcal{O}({1}/{T^{2/3- \\delta}})$ where $T$ is the iteration number and\n$\\delta \\in (0, 2/3)$ for non-convex loss function, and at linear rate for\nstrongly-convex loss function. Moreover, stationary point or global optimal\nsolution is proved to obtainable as data heterogeneity vanishes. Experimental\nresults corroborate the robustness of RAGA to Byzantine attacks and verifies\nthe advantage of RAGA over baselines on convergence performance under various\nintensity of Byzantine attacks, for heterogeneous dataset.\n","authors":["Shiyuan Zuo","Xingrun Yan","Rongfei Fan","Han Hu","Hangguan Shan","Tony Q. S. Quek"],"pdf_url":"https://arxiv.org/pdf/2403.13374v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.17251v2","updated":"2024-03-27T14:48:48Z","published":"2023-03-30T09:29:53Z","title":"Demystifying Misconceptions in Social Bots Research","summary":"  Research on social bots aims at advancing knowledge and providing solutions\nto one of the most debated forms of online manipulation. Yet, social bot\nresearch is plagued by widespread biases, hyped results, and misconceptions\nthat set the stage for ambiguities, unrealistic expectations, and seemingly\nirreconcilable findings. Overcoming such issues is instrumental towards\nensuring reliable solutions and reaffirming the validity of the scientific\nmethod. In this contribution, we review some recent results in social bots\nresearch, highlighting and revising factual errors as well as methodological\nand conceptual biases. More importantly, we demystify common misconceptions,\naddressing fundamental points on how social bots research is discussed. Our\nanalysis surfaces the need to discuss research about online disinformation and\nmanipulation in a rigorous, unbiased, and responsible way. This article\nbolsters such effort by identifying and refuting common fallacious arguments\nused by both proponents and opponents of social bots research, as well as\nproviding directions toward sound methodologies for future research in the\nfield.\n","authors":["Stefano Cresci","Kai-Cheng Yang","Angelo Spognardi","Roberto Di Pietro","Filippo Menczer","Marinella Petrocchi"],"pdf_url":"https://arxiv.org/pdf/2303.17251v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.12882v2","updated":"2024-03-27T14:47:41Z","published":"2023-08-23T17:42:00Z","title":"LCANets++: Robust Audio Classification using Multi-layer Neural Networks\n  with Lateral Competition","summary":"  Audio classification aims at recognizing audio signals, including speech\ncommands or sound events. However, current audio classifiers are susceptible to\nperturbations and adversarial attacks. In addition, real-world audio\nclassification tasks often suffer from limited labeled data. To help bridge\nthese gaps, previous work developed neuro-inspired convolutional neural\nnetworks (CNNs) with sparse coding via the Locally Competitive Algorithm (LCA)\nin the first layer (i.e., LCANets) for computer vision. LCANets learn in a\ncombination of supervised and unsupervised learning, reducing dependency on\nlabeled samples. Motivated by the fact that auditory cortex is also sparse, we\nextend LCANets to audio recognition tasks and introduce LCANets++, which are\nCNNs that perform sparse coding in multiple layers via LCA. We demonstrate that\nLCANets++ are more robust than standard CNNs and LCANets against perturbations,\ne.g., background noise, as well as black-box and white-box attacks, e.g.,\nevasion and fast gradient sign (FGSM) attacks.\n","authors":["Sayanton V. Dibbo","Juston S. Moore","Garrett T. Kenyon","Michael A. Teti"],"pdf_url":"https://arxiv.org/pdf/2308.12882v2.pdf","comment":"Accepted at 2024 IEEE International Conference on Acoustics, Speech\n  and Signal Processing Workshops (ICASSPW)"},{"id":"http://arxiv.org/abs/2403.18637v1","updated":"2024-03-27T14:42:08Z","published":"2024-03-27T14:42:08Z","title":"Transformers-based architectures for stroke segmentation: A review","summary":"  Stroke remains a significant global health concern, necessitating precise and\nefficient diagnostic tools for timely intervention and improved patient\noutcomes. The emergence of deep learning methodologies has transformed the\nlandscape of medical image analysis. Recently, Transformers, initially designed\nfor natural language processing, have exhibited remarkable capabilities in\nvarious computer vision applications, including medical image analysis. This\ncomprehensive review aims to provide an in-depth exploration of the\ncutting-edge Transformer-based architectures applied in the context of stroke\nsegmentation. It commences with an exploration of stroke pathology, imaging\nmodalities, and the challenges associated with accurate diagnosis and\nsegmentation. Subsequently, the review delves into the fundamental ideas of\nTransformers, offering detailed insights into their architectural intricacies\nand the underlying mechanisms that empower them to effectively capture complex\nspatial information within medical images. The existing literature is\nsystematically categorized and analyzed, discussing various approaches that\nleverage Transformers for stroke segmentation. A critical assessment is\nprovided, highlighting the strengths and limitations of these methods,\nincluding considerations of performance and computational efficiency.\nAdditionally, this review explores potential avenues for future research and\ndevelopment\n","authors":["Yalda Zafari-Ghadim","Essam A. Rashed","Mohamed Mabrok"],"pdf_url":"https://arxiv.org/pdf/2403.18637v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18635v1","updated":"2024-03-27T14:40:25Z","published":"2024-03-27T14:40:25Z","title":"Fusion approaches for emotion recognition from speech using acoustic and\n  text-based features","summary":"  In this paper, we study different approaches for classifying emotions from\nspeech using acoustic and text-based features. We propose to obtain\ncontextualized word embeddings with BERT to represent the information contained\nin speech transcriptions and show that this results in better performance than\nusing Glove embeddings. We also propose and compare different strategies to\ncombine the audio and text modalities, evaluating them on IEMOCAP and\nMSP-PODCAST datasets. We find that fusing acoustic and text-based systems is\nbeneficial on both datasets, though only subtle differences are observed across\nthe evaluated fusion approaches. Finally, for IEMOCAP, we show the large effect\nthat the criteria used to define the cross-validation folds have on results. In\nparticular, the standard way of creating folds for this dataset results in a\nhighly optimistic estimation of performance for the text-based system,\nsuggesting that some previous works may overestimate the advantage of\nincorporating transcriptions.\n","authors":["Leonardo Pepino","Pablo Riera","Luciana Ferrer","Agustin Gravano"],"pdf_url":"https://arxiv.org/pdf/2403.18635v1.pdf","comment":"5 pages. Accepted in ICASSP 2020"},{"id":"http://arxiv.org/abs/2403.18631v1","updated":"2024-03-27T14:38:02Z","published":"2024-03-27T14:38:02Z","title":"First Experiences with the Identification of People at Risk for Diabetes\n  in Argentina using Machine Learning Techniques","summary":"  Detecting Type 2 Diabetes (T2D) and Prediabetes (PD) is a real challenge for\nmedicine due to the absence of pathogenic symptoms and the lack of known\nassociated risk factors. Even though some proposals for machine learning models\nenable the identification of people at risk, the nature of the condition makes\nit so that a model suitable for one population may not necessarily be suitable\nfor another. In this article, the development and assessment of predictive\nmodels to identify people at risk for T2D and PD specifically in Argentina are\ndiscussed. First, the database was thoroughly preprocessed and three specific\ndatasets were generated considering a compromise between the number of records\nand the amount of available variables. After applying 5 different\nclassification models, the results obtained show that a very good performance\nwas observed for two datasets with some of these models. In particular, RF, DT,\nand ANN demonstrated great classification power, with good values for the\nmetrics under consideration. Given the lack of this type of tool in Argentina,\nthis work represents the first step towards the development of more\nsophisticated models.\n","authors":["Enzo Rucci","Gonzalo Tittarelli","Franco Ronchetti","Jorge F. Elgart","Laura Lanzarini","Juan José Gagliardino"],"pdf_url":"https://arxiv.org/pdf/2403.18631v1.pdf","comment":"Accepted for publication in Computer Science - CACIC 2023"},{"id":"http://arxiv.org/abs/2403.16451v3","updated":"2024-03-27T14:36:21Z","published":"2024-03-25T06:30:54Z","title":"DeepMachining: Online Prediction of Machining Errors of Lathe Machines","summary":"  We describe DeepMachining, a deep learning-based AI system for online\nprediction of machining errors of lathe machine operations. We have built and\nevaluated DeepMachining based on manufacturing data from factories.\nSpecifically, we first pretrain a deep learning model for a given lathe\nmachine's operations to learn the salient features of machining states. Then,\nwe fine-tune the pretrained model to adapt to specific machining tasks. We\ndemonstrate that DeepMachining achieves high prediction accuracy for multiple\ntasks that involve different workpieces and cutting tools. To the best of our\nknowledge, this work is one of the first factory experiments using pre-trained\ndeep-learning models to predict machining errors of lathe machines.\n","authors":["Xiang-Li Lu","Hwai-Jung Hsu","Che-Wei Chou","H. T. Kung","Chen-Hsin Lee"],"pdf_url":"https://arxiv.org/pdf/2403.16451v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18613v1","updated":"2024-03-27T14:28:44Z","published":"2024-03-27T14:28:44Z","title":"Scalable Lipschitz Estimation for CNNs","summary":"  Estimating the Lipschitz constant of deep neural networks is of growing\ninterest as it is useful for informing on generalisability and adversarial\nrobustness. Convolutional neural networks (CNNs) in particular, underpin much\nof the recent success in computer vision related applications. However,\nalthough existing methods for estimating the Lipschitz constant can be tight,\nthey have limited scalability when applied to CNNs. To tackle this, we propose\na novel method to accelerate Lipschitz constant estimation for CNNs. The core\nidea is to divide a large convolutional block via a joint layer and width-wise\npartition, into a collection of smaller blocks. We prove an upper-bound on the\nLipschitz constant of the larger block in terms of the Lipschitz constants of\nthe smaller blocks. Through varying the partition factor, the resulting method\ncan be adjusted to prioritise either accuracy or scalability and permits\nparallelisation. We demonstrate an enhanced scalability and comparable accuracy\nto existing baselines through a range of experiments.\n","authors":["Yusuf Sulehman","Tingting Mu"],"pdf_url":"https://arxiv.org/pdf/2403.18613v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18597v1","updated":"2024-03-27T14:20:11Z","published":"2024-03-27T14:20:11Z","title":"Heterogeneous Peridynamic Neural Operators: Discover Biotissue\n  Constitutive Law and Microstructure From Digital Image Correlation\n  Measurements","summary":"  Human tissues are highly organized structures with specific collagen fiber\narrangements varying from point to point. The effects of such heterogeneity\nplay an important role for tissue function, and hence it is of critical to\ndiscover and understand the distribution of such fiber orientations from\nexperimental measurements, such as the digital image correlation data. To this\nend, we introduce the heterogeneous peridynamic neural operator (HeteroPNO)\napproach, for data-driven constitutive modeling of heterogeneous anisotropic\nmaterials. The goal is to learn both a nonlocal constitutive law together with\nthe material microstructure, in the form of a heterogeneous fiber orientation\nfield, from loading field-displacement field measurements. To this end, we\npropose a two-phase learning approach. Firstly, we learn a homogeneous\nconstitutive law in the form of a neural network-based kernel function and a\nnonlocal bond force, to capture complex homogeneous material responses from\ndata. Then, in the second phase we reinitialize the learnt bond force and the\nkernel function, and training them together with a fiber orientation field for\neach material point. Owing to the state-based peridynamic skeleton, our\nHeteroPNO-learned material models are objective and have the balance of linear\nand angular momentum guaranteed. Moreover, the effects from heterogeneity and\nnonlinear constitutive relationship are captured by the kernel function and the\nbond force respectively, enabling physical interpretability. As a result, our\nHeteroPNO architecture can learn a constitutive model for a biological tissue\nwith anisotropic heterogeneous response undergoing large deformation regime.\nMoreover, the framework is capable to provide displacement and stress field\npredictions for new and unseen loading instances.\n","authors":["Siavash Jafarzadeh","Stewart Silling","Lu Zhang","Colton Ross","Chung-Hao Lee","S. M. Rakibur Rahman","Shuodao Wang","Yue Yu"],"pdf_url":"https://arxiv.org/pdf/2403.18597v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18587v1","updated":"2024-03-27T14:11:23Z","published":"2024-03-27T14:11:23Z","title":"The Impact of Uniform Inputs on Activation Sparsity and Energy-Latency\n  Attacks in Computer Vision","summary":"  Resource efficiency plays an important role for machine learning nowadays.\nThe energy and decision latency are two critical aspects to ensure a\nsustainable and practical application. Unfortunately, the energy consumption\nand decision latency are not robust against adversaries. Researchers have\nrecently demonstrated that attackers can compute and submit so-called sponge\nexamples at inference time to increase the energy consumption and decision\nlatency of neural networks. In computer vision, the proposed strategy crafts\ninputs with less activation sparsity which could otherwise be used to\naccelerate the computation. In this paper, we analyze the mechanism how these\nenergy-latency attacks reduce activation sparsity. In particular, we find that\ninput uniformity is a key enabler. A uniform image, that is, an image with\nmostly flat, uniformly colored surfaces, triggers more activations due to a\nspecific interplay of convolution, batch normalization, and ReLU activation.\nBased on these insights, we propose two new simple, yet effective strategies\nfor crafting sponge examples: sampling images from a probability distribution\nand identifying dense, yet inconspicuous inputs in natural datasets. We\nempirically examine our findings in a comprehensive evaluation with multiple\nimage classification models and show that our attack achieves the same sparsity\neffect as prior sponge-example methods, but at a fraction of computation\neffort. We also show that our sponge examples transfer between different neural\nnetworks. Finally, we discuss applications of our findings for the good by\nimproving efficiency by increasing sparsity.\n","authors":["Andreas Müller","Erwin Quiring"],"pdf_url":"https://arxiv.org/pdf/2403.18587v1.pdf","comment":"Accepted at the DLSP 2024"},{"id":"http://arxiv.org/abs/2403.18582v1","updated":"2024-03-27T14:03:41Z","published":"2024-03-27T14:03:41Z","title":"One flow to correct them all: improving simulations in high-energy\n  physics with a single normalising flow and a switch","summary":"  Simulated events are key ingredients in almost all high-energy physics\nanalyses. However, imperfections in the simulation can lead to sizeable\ndifferences between the observed data and simulated events. The effects of such\nmismodelling on relevant observables must be corrected either effectively via\nscale factors, with weights or by modifying the distributions of the\nobservables and their correlations. We introduce a correction method that\ntransforms one multidimensional distribution (simulation) into another one\n(data) using a simple architecture based on a single normalising flow with a\nboolean condition. We demonstrate the effectiveness of the method on a\nphysics-inspired toy dataset with non-trivial mismodelling of several\nobservables and their correlations.\n","authors":["Caio Cesar Daumann","Mauro Donega","Johannes Erdmann","Massimiliano Galli","Jan Lukas Späh","Davide Valsecchi"],"pdf_url":"https://arxiv.org/pdf/2403.18582v1.pdf","comment":"19 pages, 12 figures"},{"id":"http://arxiv.org/abs/2306.09459v3","updated":"2024-03-27T14:02:58Z","published":"2023-06-15T19:29:08Z","title":"Recurrent Action Transformer with Memory","summary":"  Recently, the use of transformers in offline reinforcement learning has\nbecome a rapidly developing area. This is due to their ability to treat the\nagent's trajectory in the environment as a sequence, thereby reducing the\npolicy learning problem to sequence modeling. In environments where the agent's\ndecisions depend on past events, it is essential to capture both the event\nitself and the decision point in the context of the model. However, the\nquadratic complexity of the attention mechanism limits the potential for\ncontext expansion. One solution to this problem is to enhance transformers with\nmemory mechanisms. In this paper, we propose the Recurrent Action Transformer\nwith Memory (RATE) - a model that incorporates recurrent memory. To evaluate\nour model, we conducted extensive experiments on both memory-intensive\nenvironments (VizDoom-Two-Color, T-Maze) and classic Atari games and MuJoCo\ncontrol environments. The results show that the use of memory can significantly\nimprove performance in memory-intensive environments while maintaining or\nimproving results in classic environments. We hope that our findings will\nstimulate research on memory mechanisms for transformers applicable to offline\nreinforcement learning.\n","authors":["Alexey Staroverov","Egor Cherepanov","Dmitry Yudin","Alexey K. Kovalev","Aleksandr I. Panov"],"pdf_url":"https://arxiv.org/pdf/2306.09459v3.pdf","comment":"15 pages, 11 figures"},{"id":"http://arxiv.org/abs/2309.11427v2","updated":"2024-03-27T14:02:57Z","published":"2023-09-20T16:01:45Z","title":"Generative Pre-Training of Time-Series Data for Unsupervised Fault\n  Detection in Semiconductor Manufacturing","summary":"  This paper introduces TRACE-GPT, which stands for Time-seRies\nAnomaly-detection with Convolutional Embedding and Generative Pre-trained\nTransformers. TRACE-GPT is designed to pre-train univariate time-series sensor\ndata and detect faults on unlabeled datasets in semiconductor manufacturing. In\nsemiconductor industry, classifying abnormal time-series sensor data from\nnormal data is important because it is directly related to wafer defect.\nHowever, small, unlabeled, and even mixed training data without enough\nanomalies make classification tasks difficult. In this research, we capture\nfeatures of time-series data with temporal convolutional embedding and\nGenerative Pre-trained Transformer (GPT) to classify abnormal sequences from\nnormal sequences using cross entropy loss. We prove that our model shows better\nperformance than previous unsupervised models with both an open dataset, the\nUniversity of California Riverside (UCR) time-series classification archive,\nand the process log of our Chemical Vapor Deposition (CVD) equipment. Our model\nhas the highest F1 score at Equal Error Rate (EER) across all datasets and is\nonly 0.026 below the supervised state-of-the-art baseline on the open dataset.\n","authors":["Sewoong Lee","JinKyou Choi","Min Su Kim"],"pdf_url":"https://arxiv.org/pdf/2309.11427v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18579v1","updated":"2024-03-27T13:59:09Z","published":"2024-03-27T13:59:09Z","title":"On Optimizing Hyperparameters for Quantum Neural Networks","summary":"  The increasing capabilities of Machine Learning (ML) models go hand in hand\nwith an immense amount of data and computational power required for training.\nTherefore, training is usually outsourced into HPC facilities, where we have\nstarted to experience limits in scaling conventional HPC hardware, as theorized\nby Moore's law. Despite heavy parallelization and optimization efforts, current\nstate-of-the-art ML models require weeks for training, which is associated with\nan enormous $CO_2$ footprint. Quantum Computing, and specifically Quantum\nMachine Learning (QML), can offer significant theoretical speed-ups and\nenhanced expressive power. However, training QML models requires tuning various\nhyperparameters, which is a nontrivial task and suboptimal choices can highly\naffect the trainability and performance of the models. In this study, we\nidentify the most impactful hyperparameters and collect data about the\nperformance of QML models. We compare different configurations and provide\nresearchers with performance data and concrete suggestions for hyperparameter\nselection.\n","authors":["Sabrina Herbst","Vincenzo De Maio","Ivona Brandic"],"pdf_url":"https://arxiv.org/pdf/2403.18579v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18578v1","updated":"2024-03-27T13:59:05Z","published":"2024-03-27T13:59:05Z","title":"SteinGen: Generating Fidelitous and Diverse Graph Samples","summary":"  Generating graphs that preserve characteristic structures while promoting\nsample diversity can be challenging, especially when the number of graph\nobservations is small. Here, we tackle the problem of graph generation from\nonly one observed graph. The classical approach of graph generation from\nparametric models relies on the estimation of parameters, which can be\ninconsistent or expensive to compute due to intractable normalisation\nconstants. Generative modelling based on machine learning techniques to\ngenerate high-quality graph samples avoids parameter estimation but usually\nrequires abundant training samples. Our proposed generating procedure,\nSteinGen, which is phrased in the setting of graphs as realisations of\nexponential random graph models, combines ideas from Stein's method and MCMC by\nemploying Markovian dynamics which are based on a Stein operator for the target\nmodel. SteinGen uses the Glauber dynamics associated with an estimated Stein\noperator to generate a sample, and re-estimates the Stein operator from the\nsample after every sampling step. We show that on a class of exponential random\ngraph models this novel \"estimation and re-estimation\" generation strategy\nyields high distributional similarity (high fidelity) to the original data,\ncombined with high sample diversity.\n","authors":["Gesine Reinert","Wenkai Xu"],"pdf_url":"https://arxiv.org/pdf/2403.18578v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.09283v3","updated":"2024-03-27T13:55:14Z","published":"2024-02-14T16:14:03Z","title":"Attacks, Defenses and Evaluations for LLM Conversation Safety: A Survey","summary":"  Large Language Models (LLMs) are now commonplace in conversation\napplications. However, their risks of misuse for generating harmful responses\nhave raised serious societal concerns and spurred recent research on LLM\nconversation safety. Therefore, in this survey, we provide a comprehensive\noverview of recent studies, covering three critical aspects of LLM conversation\nsafety: attacks, defenses, and evaluations. Our goal is to provide a structured\nsummary that enhances understanding of LLM conversation safety and encourages\nfurther investigation into this important subject. For easy reference, we have\ncategorized all the studies mentioned in this survey according to our taxonomy,\navailable at: https://github.com/niconi19/LLM-conversation-safety.\n","authors":["Zhichen Dong","Zhanhui Zhou","Chao Yang","Jing Shao","Yu Qiao"],"pdf_url":"https://arxiv.org/pdf/2402.09283v3.pdf","comment":"Accepted to NAACL 2024"},{"id":"http://arxiv.org/abs/2403.18570v1","updated":"2024-03-27T13:51:26Z","published":"2024-03-27T13:51:26Z","title":"Physics-Informed Graph Neural Networks for Water Distribution Systems","summary":"  Water distribution systems (WDS) are an integral part of critical\ninfrastructure which is pivotal to urban development. As 70% of the world's\npopulation will likely live in urban environments in 2050, efficient simulation\nand planning tools for WDS play a crucial role in reaching UN's sustainable\ndevelopmental goal (SDG) 6 - \"Clean water and sanitation for all\". In this\nrealm, we propose a novel and efficient machine learning emulator, more\nprecisely, a physics-informed deep learning (DL) model, for hydraulic state\nestimation in WDS. Using a recursive approach, our model only needs a few graph\nconvolutional neural network (GCN) layers and employs an innovative algorithm\nbased on message passing. Unlike conventional machine learning tasks, the model\nuses hydraulic principles to infer two additional hydraulic state features in\nthe process of reconstructing the available ground truth feature in an\nunsupervised manner. To the best of our knowledge, this is the first DL\napproach to emulate the popular hydraulic simulator EPANET, utilizing no\nadditional information. Like most DL models and unlike the hydraulic simulator,\nour model demonstrates vastly faster emulation times that do not increase\ndrastically with the size of the WDS. Moreover, we achieve high accuracy on the\nground truth and very similar results compared to the hydraulic simulator as\ndemonstrated through experiments on five real-world WDS datasets.\n","authors":["Inaam Ashraf","Janine Strotherm","Luca Hermes","Barbara Hammer"],"pdf_url":"https://arxiv.org/pdf/2403.18570v1.pdf","comment":"Extended version of the paper with the same title published at\n  Proceedings of the AAAI Conference on Artificial Intelligence 2024"},{"id":"http://arxiv.org/abs/2403.18569v1","updated":"2024-03-27T13:50:13Z","published":"2024-03-27T13:50:13Z","title":"PDNNet: PDN-Aware GNN-CNN Heterogeneous Network for Dynamic IR Drop\n  Prediction","summary":"  IR drop on the power delivery network (PDN) is closely related to PDN's\nconfiguration and cell current consumption. As the integrated circuit (IC)\ndesign is growing larger, dynamic IR drop simulation becomes computationally\nunaffordable and machine learning based IR drop prediction has been explored as\na promising solution. Although CNN-based methods have been adapted to IR drop\nprediction task in several works, the shortcomings of overlooking PDN\nconfiguration is non-negligible. In this paper, we consider not only how to\nproperly represent cell-PDN relation, but also how to model IR drop following\nits physical nature in the feature aggregation procedure. Thus, we propose a\nnovel graph structure, PDNGraph, to unify the representations of the PDN\nstructure and the fine-grained cell-PDN relation. We further propose a\ndual-branch heterogeneous network, PDNNet, incorporating two parallel GNN-CNN\nbranches to favorably capture the above features during the learning process.\nSeveral key designs are presented to make the dynamic IR drop prediction highly\neffective and interpretable. We are the first work to apply graph structure to\ndeep-learning based dynamic IR drop prediction method. Experiments show that\nPDNNet outperforms the state-of-the-art CNN-based methods by up to 39.3%\nreduction in prediction error and achieves 545x speedup compared to the\ncommercial tool, which demonstrates the superiority of our method.\n","authors":["Yuxiang Zhao","Zhuomin Chai","Xun Jiang","Yibo Lin","Runsheng Wang","Ru Huang"],"pdf_url":"https://arxiv.org/pdf/2403.18569v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.12370v2","updated":"2024-03-27T13:44:21Z","published":"2023-10-18T22:34:32Z","title":"No-Regret Learning in Bilateral Trade via Global Budget Balance","summary":"  Bilateral trade models the problem of intermediating between two rational\nagents -- a seller and a buyer -- both characterized by a private valuation for\nan item they want to trade. We study the online learning version of the\nproblem, in which at each time step a new seller and buyer arrive and the\nlearner has to set prices for them without any knowledge about their\n(adversarially generated) valuations.\n  In this setting, known impossibility results rule out the existence of\nno-regret algorithms when budget balanced has to be enforced at each time step.\nIn this paper, we introduce the notion of \\emph{global budget balance}, which\nonly requires the learner to fulfill budget balance over the entire time\nhorizon. Under this natural relaxation, we provide the first no-regret\nalgorithms for adversarial bilateral trade under various feedback models.\nFirst, we show that in the full-feedback model, the learner can guarantee\n$\\tilde O(\\sqrt{T})$ regret against the best fixed prices in hindsight, and\nthat this bound is optimal up to poly-logarithmic terms. Second, we provide a\nlearning algorithm guaranteeing a $\\tilde O(T^{3/4})$ regret upper bound with\none-bit feedback, which we complement with a $\\Omega(T^{5/7})$ lower bound that\nholds even in the two-bit feedback model. Finally, we introduce and analyze an\nalternative benchmark that is provably stronger than the best fixed prices in\nhindsight and is inspired by the literature on bandits with knapsacks.\n","authors":["Martino Bernasconi","Matteo Castiglioni","Andrea Celli","Federico Fusco"],"pdf_url":"https://arxiv.org/pdf/2310.12370v2.pdf","comment":"Accepted at STOC 2024"},{"id":"http://arxiv.org/abs/2403.18560v1","updated":"2024-03-27T13:42:14Z","published":"2024-03-27T13:42:14Z","title":"Noise-Robust Keyword Spotting through Self-supervised Pretraining","summary":"  Voice assistants are now widely available, and to activate them a keyword\nspotting (KWS) algorithm is used. Modern KWS systems are mainly trained using\nsupervised learning methods and require a large amount of labelled data to\nachieve a good performance. Leveraging unlabelled data through self-supervised\nlearning (SSL) has been shown to increase the accuracy in clean conditions.\nThis paper explores how SSL pretraining such as Data2Vec can be used to enhance\nthe robustness of KWS models in noisy conditions, which is under-explored.\n  Models of three different sizes are pretrained using different pretraining\napproaches and then fine-tuned for KWS. These models are then tested and\ncompared to models trained using two baseline supervised learning methods, one\nbeing standard training using clean data and the other one being multi-style\ntraining (MTR). The results show that pretraining and fine-tuning on clean data\nis superior to supervised learning on clean data across all testing conditions,\nand superior to supervised MTR for testing conditions of SNR above 5 dB. This\nindicates that pretraining alone can increase the model's robustness. Finally,\nit is found that using noisy data for pretraining models, especially with the\nData2Vec-denoising approach, significantly enhances the robustness of KWS\nmodels in noisy conditions.\n","authors":["Jacob Mørk","Holger Severin Bovbjerg","Gergely Kiss","Zheng-Hua Tan"],"pdf_url":"https://arxiv.org/pdf/2403.18560v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.06712v2","updated":"2024-03-27T13:38:35Z","published":"2024-01-12T17:26:51Z","title":"Few-Shot Detection of Machine-Generated Text using Style Representations","summary":"  The advent of instruction-tuned language models that convincingly mimic human\nwriting poses a significant risk of abuse. However, such abuse may be\ncounteracted with the ability to detect whether a piece of text was composed by\na language model rather than a human author. Some previous approaches to this\nproblem have relied on supervised methods by training on corpora of confirmed\nhuman- and machine- written documents. Unfortunately, model under-specification\nposes an unavoidable challenge for neural network-based detectors, making them\nbrittle in the face of data shifts, such as the release of newer language\nmodels producing still more fluent text than the models used to train the\ndetectors. Other approaches require access to the models that may have\ngenerated a document in question, which is often impractical. In light of these\nchallenges, we pursue a fundamentally different approach not relying on samples\nfrom language models of concern at training time. Instead, we propose to\nleverage representations of writing style estimated from human-authored text.\nIndeed, we find that features effective at distinguishing among human authors\nare also effective at distinguishing human from machine authors, including\nstate-of-the-art large language models like Llama-2, ChatGPT, and GPT-4.\nFurthermore, given a handful of examples composed by each of several specific\nlanguage models of interest, our approach affords the ability to predict which\nmodel generated a given document. The code and data to reproduce our\nexperiments are available at\nhttps://github.com/LLNL/LUAR/tree/main/fewshot_iclr2024.\n","authors":["Rafael Rivera Soto","Kailin Koch","Aleem Khan","Barry Chen","Marcus Bishop","Nicholas Andrews"],"pdf_url":"https://arxiv.org/pdf/2401.06712v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.00117v4","updated":"2024-03-27T13:38:00Z","published":"2023-09-29T20:11:15Z","title":"ABScribe: Rapid Exploration & Organization of Multiple Writing\n  Variations in Human-AI Co-Writing Tasks using Large Language Models","summary":"  Exploring alternative ideas by rewriting text is integral to the writing\nprocess. State-of-the-art Large Language Models (LLMs) can simplify writing\nvariation generation. However, current interfaces pose challenges for\nsimultaneous consideration of multiple variations: creating new variations\nwithout overwriting text can be difficult, and pasting them sequentially can\nclutter documents, increasing workload and disrupting writers' flow. To tackle\nthis, we present ABScribe, an interface that supports rapid, yet visually\nstructured, exploration and organization of writing variations in human-AI\nco-writing tasks. With ABScribe, users can swiftly modify variations using LLM\nprompts, which are auto-converted into reusable buttons. Variations are stored\nadjacently within text fields for rapid in-place comparisons using mouse-over\ninteractions on a popup toolbar. Our user study with 12 writers shows that\nABScribe significantly reduces task workload (d = 1.20, p < 0.001), enhances\nuser perceptions of the revision process (d = 2.41, p < 0.001) compared to a\npopular baseline workflow, and provides insights into how writers explore\nvariations using LLMs.\n","authors":["Mohi Reza","Nathan Laundry","Ilya Musabirov","Peter Dushniku","Zhi Yuan \"Michael\" Yu","Kashish Mittal","Tovi Grossman","Michael Liut","Anastasia Kuzminykh","Joseph Jay Williams"],"pdf_url":"https://arxiv.org/pdf/2310.00117v4.pdf","comment":"CHI 2024"},{"id":"http://arxiv.org/abs/2403.18542v1","updated":"2024-03-27T13:22:38Z","published":"2024-03-27T13:22:38Z","title":"Attention-aware semantic relevance predicting Chinese sentence reading","summary":"  In recent years, several influential computational models and metrics have\nbeen proposed to predict how humans comprehend and process sentence. One\nparticularly promising approach is contextual semantic similarity. Inspired by\nthe attention algorithm in Transformer and human memory mechanisms, this study\nproposes an ``attention-aware'' approach for computing contextual semantic\nrelevance. This new approach takes into account the different contributions of\ncontextual parts and the expectation effect, allowing it to incorporate\ncontextual information fully. The attention-aware approach also facilitates the\nsimulation of existing reading models and evaluate them. The resulting\n``attention-aware'' metrics of semantic relevance can more accurately predict\nfixation durations in Chinese reading tasks recorded in an eye-tracking corpus\nthan those calculated by existing approaches. The study's findings further\nprovide strong support for the presence of semantic preview benefits in Chinese\nnaturalistic reading. Furthermore, the attention-aware metrics of semantic\nrelevance, being memory-based, possess high interpretability from both\nlinguistic and cognitive standpoints, making them a valuable computational tool\nfor modeling eye-movements in reading and further gaining insight into the\nprocess of language comprehension. Our approach underscores the potential of\nthese metrics to advance our comprehension of how humans understand and process\nlanguage, ultimately leading to a better understanding of language\ncomprehension and processing.\n","authors":["Kun Sun"],"pdf_url":"https://arxiv.org/pdf/2403.18542v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18540v1","updated":"2024-03-27T13:17:15Z","published":"2024-03-27T13:17:15Z","title":"skscope: Fast Sparsity-Constrained Optimization in Python","summary":"  Applying iterative solvers on sparsity-constrained optimization (SCO)\nrequires tedious mathematical deduction and careful programming/debugging that\nhinders these solvers' broad impact. In the paper, the library skscope is\nintroduced to overcome such an obstacle. With skscope, users can solve the SCO\nby just programming the objective function. The convenience of skscope is\ndemonstrated through two examples in the paper, where sparse linear regression\nand trend filtering are addressed with just four lines of code. More\nimportantly, skscope's efficient implementation allows state-of-the-art solvers\nto quickly attain the sparse solution regardless of the high dimensionality of\nparameter space. Numerical experiments reveal the available solvers in skscope\ncan achieve up to 80x speedup on the competing relaxation solutions obtained\nvia the benchmarked convex solver. skscope is published on the Python Package\nIndex (PyPI) and Conda, and its source code is available at:\nhttps://github.com/abess-team/skscope.\n","authors":["Zezhi Wang","Jin Zhu","Peng Chen","Huiyang Peng","Xiaoke Zhang","Anran Wang","Yu Zheng","Junxian Zhu","Xueqin Wang"],"pdf_url":"https://arxiv.org/pdf/2403.18540v1.pdf","comment":"4 pages"},{"id":"http://arxiv.org/abs/2403.18539v1","updated":"2024-03-27T13:14:29Z","published":"2024-03-27T13:14:29Z","title":"Safe and Robust Reinforcement-Learning: Principles and Practice","summary":"  Reinforcement Learning (RL) has shown remarkable success in solving\nrelatively complex tasks, yet the deployment of RL systems in real-world\nscenarios poses significant challenges related to safety and robustness. This\npaper aims to identify and further understand those challenges thorough the\nexploration of the main dimensions of the safe and robust RL landscape,\nencompassing algorithmic, ethical, and practical considerations. We conduct a\ncomprehensive review of methodologies and open problems that summarizes the\nefforts in recent years to address the inherent risks associated with RL\napplications.\n  After discussing and proposing definitions for both safe and robust RL, the\npaper categorizes existing research works into different algorithmic approaches\nthat enhance the safety and robustness of RL agents. We examine techniques such\nas uncertainty estimation, optimisation methodologies, exploration-exploitation\ntrade-offs, and adversarial training. Environmental factors, including\nsim-to-real transfer and domain adaptation, are also scrutinized to understand\nhow RL systems can adapt to diverse and dynamic surroundings. Moreover, human\ninvolvement is an integral ingredient of the analysis, acknowledging the broad\nset of roles that humans can take in this context.\n  Importantly, to aid practitioners in navigating the complexities of safe and\nrobust RL implementation, this paper introduces a practical checklist derived\nfrom the synthesized literature. The checklist encompasses critical aspects of\nalgorithm design, training environment considerations, and ethical guidelines.\nIt will serve as a resource for developers and policymakers alike to ensure the\nresponsible deployment of RL systems in many application domains.\n","authors":["Taku Yamagata","Raul Santos-Rodriguez"],"pdf_url":"https://arxiv.org/pdf/2403.18539v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18535v1","updated":"2024-03-27T13:11:34Z","published":"2024-03-27T13:11:34Z","title":"Theoretical Bound-Guided Hierarchical VAE for Neural Image Codecs","summary":"  Recent studies reveal a significant theoretical link between variational\nautoencoders (VAEs) and rate-distortion theory, notably in utilizing VAEs to\nestimate the theoretical upper bound of the information rate-distortion\nfunction of images. Such estimated theoretical bounds substantially exceed the\nperformance of existing neural image codecs (NICs). To narrow this gap, we\npropose a theoretical bound-guided hierarchical VAE (BG-VAE) for NIC. The\nproposed BG-VAE leverages the theoretical bound to guide the NIC model towards\nenhanced performance. We implement the BG-VAE using Hierarchical VAEs and\ndemonstrate its effectiveness through extensive experiments. Along with\nadvanced neural network blocks, we provide a versatile, variable-rate NIC that\noutperforms existing methods when considering both rate-distortion performance\nand computational complexity. The code is available at BG-VAE.\n","authors":["Yichi Zhang","Zhihao Duan","Yuning Huang","Fengqing Zhu"],"pdf_url":"https://arxiv.org/pdf/2403.18535v1.pdf","comment":"2024 IEEE International Conference on Multimedia and Expo (ICME2024)"},{"id":"http://arxiv.org/abs/2403.18525v1","updated":"2024-03-27T12:59:44Z","published":"2024-03-27T12:59:44Z","title":"Language Plays a Pivotal Role in the Object-Attribute Compositional\n  Generalization of CLIP","summary":"  Vision-language models, such as CLIP, have shown promising\nOut-of-Distribution (OoD) generalization under various types of distribution\nshifts. Recent studies attempted to investigate the leading cause of this\ncapability. In this work, we follow the same path, but focus on a specific type\nof OoD data - images with novel compositions of attribute-object pairs - and\nstudy whether such models can successfully classify those images into\ncomposition classes. We carefully designed an authentic image test dataset\ncalled ImageNet-AO, consisting of attributes for objects that are unlikely\nencountered in the CLIP training sets. We found that CLIPs trained with large\ndatasets such as OpenAI CLIP, LAION-400M, and LAION-2B show orders-of-magnitude\nimprovement in effective compositional OoD generalization compared to both\nsupervised models and CLIPs trained with smaller datasets, such as CC-12M and\nYFCC-15M. Our results provide evidence that the scale and diversity of training\ndata and language supervision play a key role in unlocking the compositional\ngeneralization abilities of vision-language models.\n","authors":["Reza Abbasi","Mohammad Samiei","Mohammad Hossein Rohban","Mahdieh Soleymani Baghshah"],"pdf_url":"https://arxiv.org/pdf/2403.18525v1.pdf","comment":"Oral accepted at OODCV 2023(http://www.ood-cv.org)"},{"id":"http://arxiv.org/abs/2303.10365v3","updated":"2024-03-27T12:53:12Z","published":"2023-03-18T08:48:16Z","title":"CroSel: Cross Selection of Confident Pseudo Labels for Partial-Label\n  Learning","summary":"  Partial-label learning (PLL) is an important weakly supervised learning\nproblem, which allows each training example to have a candidate label set\ninstead of a single ground-truth label. Identification-based methods have been\nwidely explored to tackle label ambiguity issues in PLL, which regard the true\nlabel as a latent variable to be identified. However, identifying the true\nlabels accurately and completely remains challenging, causing noise in pseudo\nlabels during model training. In this paper, we propose a new method called\nCroSel, which leverages historical predictions from the model to identify true\nlabels for most training examples. First, we introduce a cross selection\nstrategy, which enables two deep models to select true labels of partially\nlabeled data for each other. Besides, we propose a novel consistency\nregularization term called co-mix to avoid sample waste and tiny noise caused\nby false selection. In this way, CroSel can pick out the true labels of most\nexamples with high precision. Extensive experiments demonstrate the superiority\nof CroSel, which consistently outperforms previous state-of-the-art methods on\nbenchmark datasets. Additionally, our method achieves over 90\\% accuracy and\nquantity for selecting true labels on CIFAR-type datasets under various\nsettings.\n","authors":["Shiyu Tian","Hongxin Wei","Yiqun Wang","Lei Feng"],"pdf_url":"https://arxiv.org/pdf/2303.10365v3.pdf","comment":"Accepted by CVPR 2024"},{"id":"http://arxiv.org/abs/2403.18519v1","updated":"2024-03-27T12:50:27Z","published":"2024-03-27T12:50:27Z","title":"Improving Line Search Methods for Large Scale Neural Network Training","summary":"  In recent studies, line search methods have shown significant improvements in\nthe performance of traditional stochastic gradient descent techniques,\neliminating the need for a specific learning rate schedule. In this paper, we\nidentify existing issues in state-of-the-art line search methods, propose\nenhancements, and rigorously evaluate their effectiveness. We test these\nmethods on larger datasets and more complex data domains than before.\nSpecifically, we improve the Armijo line search by integrating the momentum\nterm from ADAM in its search direction, enabling efficient large-scale\ntraining, a task that was previously prone to failure using Armijo line search\nmethods. Our optimization approach outperforms both the previous Armijo\nimplementation and tuned learning rate schedules for Adam. Our evaluation\nfocuses on Transformers and CNNs in the domains of NLP and image data. Our work\nis publicly available as a Python package, which provides a hyperparameter free\nPytorch optimizer.\n","authors":["Philip Kenneweg","Tristan Kenneweg","Barbara Hammer"],"pdf_url":"https://arxiv.org/pdf/2403.18519v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18517v1","updated":"2024-03-27T12:49:14Z","published":"2024-03-27T12:49:14Z","title":"Efficient Algorithms for Regularized Nonnegative Scale-invariant\n  Low-rank Approximation Models","summary":"  Regularized nonnegative low-rank approximations such as sparse Nonnegative\nMatrix Factorization or sparse Nonnegative Tucker Decomposition are an\nimportant branch of dimensionality reduction models with enhanced\ninterpretability. However, from a practical perspective, the choice of\nregularizers and regularization coefficients, as well as the design of\nefficient algorithms, is challenging because of the multifactor nature of these\nmodels and the lack of theory to back these choices. This paper aims at\nimproving upon these issues. By studying a more general model called the\nHomogeneous Regularized Scale-Invariant, we prove that the scale-invariance\ninherent to low-rank approximation models causes an implicit regularization\nwith both unexpected beneficial and detrimental effects. This observation\nallows to better understand the effect of regularization functions in low-rank\napproximation models, to guide the choice of the regularization\nhyperparameters, and to design balancing strategies to enhance the convergence\nspeed of dedicated optimization algorithms. Some of these results were already\nknown but restricted to specific instances of regularized low-rank\napproximations. We also derive a generic Majorization Minimization algorithm\nthat handles many regularized nonnegative low-rank approximations, with\nconvergence guarantees. We showcase our contributions on sparse Nonnegative\nMatrix Factorization, ridge-regularized Canonical Polyadic decomposition and\nsparse Nonnegative Tucker Decomposition.\n","authors":["Jeremy E. Cohen","Valentin Leplat"],"pdf_url":"https://arxiv.org/pdf/2403.18517v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18514v1","updated":"2024-03-27T12:44:57Z","published":"2024-03-27T12:44:57Z","title":"CT-3DFlow : Leveraging 3D Normalizing Flows for Unsupervised Detection\n  of Pathological Pulmonary CT scans","summary":"  Unsupervised pathology detection can be implemented by training a model on\nhealthy data only and measuring the deviation from the training set upon\ninference, for example with CNN-based feature extraction and one-class\nclassifiers, or reconstruction-score-based methods such as AEs, GANs and\nDiffusion models. Normalizing Flows (NF) have the ability to directly learn the\nprobability distribution of training examples through an invertible\narchitecture. We leverage this property in a novel 3D NF-based model named\nCT-3DFlow, specifically tailored for patient-level pulmonary pathology\ndetection in chest CT data. Our model is trained unsupervised on healthy 3D\npulmonary CT patches, and detects deviations from its log-likelihood\ndistribution as anomalies. We aggregate patches-level likelihood values from a\npatient's CT scan to provide a patient-level 'normal'/'abnormal' prediction.\nOut-of-distribution detection performance is evaluated using expert annotations\non a separate chest CT test dataset, outperforming other state-of-the-art\nmethods.\n","authors":["Aissam Djahnine","Alexandre Popoff","Emilien Jupin-Delevaux","Vincent Cottin","Olivier Nempont","Loic Boussel"],"pdf_url":"https://arxiv.org/pdf/2403.18514v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18509v1","updated":"2024-03-27T12:39:16Z","published":"2024-03-27T12:39:16Z","title":"Distributed Maximum Consensus over Noisy Links","summary":"  We introduce a distributed algorithm, termed noise-robust distributed maximum\nconsensus (RD-MC), for estimating the maximum value within a multi-agent\nnetwork in the presence of noisy communication links. Our approach entails\nredefining the maximum consensus problem as a distributed optimization problem,\nallowing a solution using the alternating direction method of multipliers.\nUnlike existing algorithms that rely on multiple sets of noise-corrupted\nestimates, RD-MC employs a single set, enhancing both robustness and\nefficiency. To further mitigate the effects of link noise and improve\nrobustness, we apply moving averaging to the local estimates. Through extensive\nsimulations, we demonstrate that RD-MC is significantly more robust to\ncommunication link noise compared to existing maximum-consensus algorithms.\n","authors":["Ehsan Lari","Reza Arablouei","Naveen K. D. Venkategowda","Stefan Werner"],"pdf_url":"https://arxiv.org/pdf/2403.18509v1.pdf","comment":"5 pages, 7 figures, submitted to EUSIPCO 2024 conference"},{"id":"http://arxiv.org/abs/2403.18506v1","updated":"2024-03-27T12:35:23Z","published":"2024-03-27T12:35:23Z","title":"Faster Convergence for Transformer Fine-tuning with Line Search Methods","summary":"  Recent works have shown that line search methods greatly increase performance\nof traditional stochastic gradient descent methods on a variety of datasets and\narchitectures [1], [2]. In this work we succeed in extending line search\nmethods to the novel and highly popular Transformer architecture and dataset\ndomains in natural language processing. More specifically, we combine the\nArmijo line search with the Adam optimizer and extend it by subdividing the\nnetworks architecture into sensible units and perform the line search\nseparately on these local units. Our optimization method outperforms the\ntraditional Adam optimizer and achieves significant performance improvements\nfor small data sets or small training budgets, while performing equal or better\nfor other tested cases. Our work is publicly available as a python package,\nwhich provides a hyperparameter-free pytorch optimizer that is compatible with\narbitrary network architectures.\n","authors":["Philip Kenneweg","Leonardo Galli","Tristan Kenneweg","Barbara Hammer"],"pdf_url":"https://arxiv.org/pdf/2403.18506v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.08579v2","updated":"2024-03-27T12:28:02Z","published":"2024-03-13T14:34:34Z","title":"Machine Learning Optimized Orthogonal Basis Piecewise Polynomial\n  Approximation","summary":"  Piecewise Polynomials (PPs) are utilized in several engineering disciplines,\nlike trajectory planning, to approximate position profiles given in the form of\na set of points. While the approximation target along with domain-specific\nrequirements, like Ck -continuity, can be formulated as a system of equations\nand a result can be computed directly, such closed-form solutions posses\nlimited flexibility with respect to polynomial degrees, polynomial bases or\nadding further domain-specific requirements. Sufficiently complex optimization\ngoals soon call for the use of numerical methods, like gradient descent. Since\ngradient descent lies at the heart of training Artificial Neural Networks\n(ANNs), modern Machine Learning (ML) frameworks like TensorFlow come with a set\nof gradient-based optimizers potentially suitable for a wide range of\noptimization problems beyond the training task for ANNs. Our approach is to\nutilize the versatility of PP models and combine it with the potential of\nmodern ML optimizers for the use in function approximation in 1D trajectory\nplanning in the context of electronic cam design. We utilize available\noptimizers of the ML framework TensorFlow directly, outside of the scope of\nANNs, to optimize model parameters of our PP model. In this paper, we show how\nan orthogonal polynomial basis contributes to improving approximation and\ncontinuity optimization performance. Utilizing Chebyshev polynomials of the\nfirst kind, we develop a novel regularization approach enabling clearly\nimproved convergence behavior. We show that, using this regularization\napproach, Chebyshev basis performs better than power basis for all relevant\noptimizers in the combined approximation and continuity optimization setting\nand demonstrate usability of the presented approach within the electronic cam\ndomain.\n","authors":["Hannes Waclawek","Stefan Huber"],"pdf_url":"https://arxiv.org/pdf/2403.08579v2.pdf","comment":"Submitted to LION18"},{"id":"http://arxiv.org/abs/2311.04698v3","updated":"2024-03-27T12:24:17Z","published":"2023-11-08T14:10:19Z","title":"Challenging Common Paradigms in Multi-Task Learning","summary":"  While multi-task learning (MTL) has gained significant attention in recent\nyears, its underlying mechanisms remain poorly understood. Recent methods did\nnot yield consistent performance improvements over single task learning (STL)\nbaselines, underscoring the importance of gaining more profound insights about\nchallenges specific to MTL. In our study, we challenge paradigms in MTL in the\ncontext of STL: First, the impact of the choice of optimizer has only been\nmildly investigated in MTL. We show the pivotal role of common STL tools such\nas the Adam optimizer in MTL empirically in various experiments. To further\ninvestigate Adam's effectiveness, we theoretical derive a partial loss-scale\ninvariance under mild assumptions. Second, the notion of gradient conflicts has\noften been phrased as a specific problem in MTL. We delve into the role of\ngradient conflicts in MTL and compare it to STL. For angular gradient alignment\nwe find no evidence that this is a unique problem in MTL. We emphasize\ndifferences in gradient magnitude as the main distinguishing factor. Lastly, we\ncompare the transferability of features learned through MTL and STL on common\nimage corruptions, and find light evidence that MTL can lead to superior\ntransferability. Overall, we find surprising similarities between STL and MTL\nsuggesting to consider methods from both fields in a broader context.\n","authors":["Cathrin Elich","Lukas Kirchdorfer","Jan M. Köhler","Lukas Schott"],"pdf_url":"https://arxiv.org/pdf/2311.04698v3.pdf","comment":"-"},{"id":"http://arxiv.org/abs/2403.18495v1","updated":"2024-03-27T12:15:22Z","published":"2024-03-27T12:15:22Z","title":"Direct mineral content prediction from drill core images via transfer\n  learning","summary":"  Deep subsurface exploration is important for mining, oil and gas industries,\nas well as in the assessment of geological units for the disposal of chemical\nor nuclear waste, or the viability of geothermal energy systems. Typically,\ndetailed examinations of subsurface formations or units are performed on\ncuttings or core materials extracted during drilling campaigns, as well as on\ngeophysical borehole data, which provide detailed information about the\npetrophysical properties of the rocks. Depending on the volume of rock samples\nand the analytical program, the laboratory analysis and diagnostics can be very\ntime-consuming. This study investigates the potential of utilizing machine\nlearning, specifically convolutional neural networks (CNN), to assess the\nlithology and mineral content solely from analysis of drill core images, aiming\nto support and expedite the subsurface geological exploration. The paper\noutlines a comprehensive methodology, encompassing data preprocessing, machine\nlearning methods, and transfer learning techniques. The outcome reveals a\nremarkable 96.7% accuracy in the classification of drill core segments into\ndistinct formation classes. Furthermore, a CNN model was trained for the\nevaluation of mineral content using a learning data set from multidimensional\nlog analysis data (silicate, total clay, carbonate). When benchmarked against\nlaboratory XRD measurements on samples from the cores, both the advanced\nmultidimensional log analysis model and the neural network approach developed\nhere provide equally good performance. This work demonstrates that deep\nlearning and particularly transfer learning can support extracting\npetrophysical properties, including mineral content and formation\nclassification, from drill core images, thus offering a road map for enhancing\nmodel performance and data set quality in image-based analysis of drill cores.\n","authors":["Romana Boiger","Sergey V. Churakov","Ignacio Ballester Llagaria","Georg Kosakowski","Raphael Wüst","Nikolaos I. Prasianakis"],"pdf_url":"https://arxiv.org/pdf/2403.18495v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18494v1","updated":"2024-03-27T12:10:30Z","published":"2024-03-27T12:10:30Z","title":"Learning in PINNs: Phase transition, total diffusion, and generalization","summary":"  We investigate the learning dynamics of fully-connected neural networks\nthrough the lens of gradient signal-to-noise ratio (SNR), examining the\nbehavior of first-order optimizers like Adam in non-convex objectives. By\ninterpreting the drift/diffusion phases in the information bottleneck theory,\nfocusing on gradient homogeneity, we identify a third phase termed ``total\ndiffusion\", characterized by equilibrium in the learning rates and homogeneous\ngradients. This phase is marked by an abrupt SNR increase, uniform residuals\nacross the sample space and the most rapid training convergence. We propose a\nresidual-based re-weighting scheme to accelerate this diffusion in quadratic\nloss functions, enhancing generalization. We also explore the information\ncompression phenomenon, pinpointing a significant saturation-induced\ncompression of activations at the total diffusion phase, with deeper layers\nexperiencing negligible information loss. Supported by experimental data on\nphysics-informed neural networks (PINNs), which underscore the importance of\ngradient homogeneity due to their PDE-based sample inter-dependence, our\nfindings suggest that recognizing phase transitions could refine ML\noptimization strategies for improved generalization.\n","authors":["Sokratis J. Anagnostopoulos","Juan Diego Toscano","Nikolaos Stergiopulos","George Em Karniadakis"],"pdf_url":"https://arxiv.org/pdf/2403.18494v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18489v1","updated":"2024-03-27T12:01:51Z","published":"2024-03-27T12:01:51Z","title":"Impact of Employing Weather Forecast Data as Input to the Estimation of\n  Evapotranspiration by Deep Neural Network Models","summary":"  Reference Evapotranspiration (ET0) is a key parameter for designing smart\nirrigation scheduling, since it is related by a coefficient to the water needs\nof a crop. The United Nations Food and Agriculture Organization, proposed a\nstandard method for ET0 computation (FAO56PM), based on the parameterization of\nthe Penman-Monteith equation, that is widely adopted in the literature. To\ncompute ET0 using the FAO56-PM method, four main weather parameters are needed:\ntemperature, humidity, wind, and solar radiation (SR). One way to make daily\nET0 estimations for future days is to use freely available weather forecast\nservices (WFSs), where many meteorological parameters are estimated up to the\nnext 15 days. A problem with this method is that currently, SR is not provided\nas a free forecast parameter on most of those online services or, normally,\nsuch forecasts present a financial cost penalty. For this reason, several ET0\nestimation models using machine and deep learning were developed and presented\nin the literature, that use as input features a reduced set of carefully\nselected weather parameters, that are compatible with common freely available\nWFSs. However, most studies on this topic have only evaluated model performance\nusing data from weather stations (WSs), without considering the effect of using\nweather forecast data. In this study, the performance of authors' previous\nmodels is evaluated when using weather forecast data from two online WFSs, in\nthe following scenarios: (i) direct ET0 estimation by an ANN model, and (ii)\nestimate SR by ANN model, and then use that estimation for ET0 computation,\nusing the FAO56-PM method. Employing data collected from two WFSs and a WS\nlocated in Vale do Lobo, Portugal, the latter approach achieved the best\nresult, with a coefficient of determination (R2) ranging between 0.893 and\n0.667, when considering forecasts up to 15 days.\n","authors":["Pedro J. Vaz","Gabriela Schütz","Carlos Guerrero","Pedro J. S. Cardoso"],"pdf_url":"https://arxiv.org/pdf/2403.18489v1.pdf","comment":"A partial version of the work submitted to ESRE/INTERNATIONAL\n  CONFERENCE ON ENVIRONMENTAL SCIENCES AND RENEWABLE ENERGY"},{"id":"http://arxiv.org/abs/2403.18486v1","updated":"2024-03-27T11:58:45Z","published":"2024-03-27T11:58:45Z","title":"Synthesizing EEG Signals from Event-Related Potential Paradigms with\n  Conditional Diffusion Models","summary":"  Data scarcity in the brain-computer interface field can be alleviated through\nthe use of generative models, specifically diffusion models. While diffusion\nmodels have previously been successfully applied to electroencephalogram (EEG)\ndata, existing models lack flexibility w.r.t.~sampling or require alternative\nrepresentations of the EEG data. To overcome these limitations, we introduce a\nnovel approach to conditional diffusion models that utilizes classifier-free\nguidance to directly generate subject-, session-, and class-specific EEG data.\nIn addition to commonly used metrics, domain-specific metrics are employed to\nevaluate the specificity of the generated samples. The results indicate that\nthe proposed model can generate EEG data that resembles real data for each\nsubject, session, and class.\n","authors":["Guido Klein","Pierre Guetschel","Gianluigi Silvestri","Michael Tangermann"],"pdf_url":"https://arxiv.org/pdf/2403.18486v1.pdf","comment":"submitted to 9th Graz BCI conference, 6 pages, 3 figures, first\n  figure is split into two subfigures, 1 table"},{"id":"http://arxiv.org/abs/2311.12028v2","updated":"2024-03-27T11:43:28Z","published":"2023-11-20T18:59:51Z","title":"Hourglass Tokenizer for Efficient Transformer-Based 3D Human Pose\n  Estimation","summary":"  Transformers have been successfully applied in the field of video-based 3D\nhuman pose estimation. However, the high computational costs of these video\npose transformers (VPTs) make them impractical on resource-constrained devices.\nIn this paper, we present a plug-and-play pruning-and-recovering framework,\ncalled Hourglass Tokenizer (HoT), for efficient transformer-based 3D human pose\nestimation from videos. Our HoT begins with pruning pose tokens of redundant\nframes and ends with recovering full-length tokens, resulting in a few pose\ntokens in the intermediate transformer blocks and thus improving the model\nefficiency. To effectively achieve this, we propose a token pruning cluster\n(TPC) that dynamically selects a few representative tokens with high semantic\ndiversity while eliminating the redundancy of video frames. In addition, we\ndevelop a token recovering attention (TRA) to restore the detailed\nspatio-temporal information based on the selected tokens, thereby expanding the\nnetwork output to the original full-length temporal resolution for fast\ninference. Extensive experiments on two benchmark datasets (i.e., Human3.6M and\nMPI-INF-3DHP) demonstrate that our method can achieve both high efficiency and\nestimation accuracy compared to the original VPT models. For instance, applying\nto MotionBERT and MixSTE on Human3.6M, our HoT can save nearly 50% FLOPs\nwithout sacrificing accuracy and nearly 40% FLOPs with only 0.2% accuracy drop,\nrespectively. Code and models are available at\nhttps://github.com/NationalGAILab/HoT.\n","authors":["Wenhao Li","Mengyuan Liu","Hong Liu","Pichao Wang","Jialun Cai","Nicu Sebe"],"pdf_url":"https://arxiv.org/pdf/2311.12028v2.pdf","comment":"Accepted by CVPR 2024, Open Sourced"},{"id":"http://arxiv.org/abs/2403.18452v1","updated":"2024-03-27T11:11:08Z","published":"2024-03-27T11:11:08Z","title":"SingularTrajectory: Universal Trajectory Predictor Using Diffusion Model","summary":"  There are five types of trajectory prediction tasks: deterministic,\nstochastic, domain adaptation, momentary observation, and few-shot. These\nassociated tasks are defined by various factors, such as the length of input\npaths, data split and pre-processing methods. Interestingly, even though they\ncommonly take sequential coordinates of observations as input and infer future\npaths in the same coordinates as output, designing specialized architectures\nfor each task is still necessary. For the other task, generality issues can\nlead to sub-optimal performances. In this paper, we propose SingularTrajectory,\na diffusion-based universal trajectory prediction framework to reduce the\nperformance gap across the five tasks. The core of SingularTrajectory is to\nunify a variety of human dynamics representations on the associated tasks. To\ndo this, we first build a Singular space to project all types of motion\npatterns from each task into one embedding space. We next propose an adaptive\nanchor working in the Singular space. Unlike traditional fixed anchor methods\nthat sometimes yield unacceptable paths, our adaptive anchor enables correct\nanchors, which are put into a wrong location, based on a traversability map.\nFinally, we adopt a diffusion-based predictor to further enhance the prototype\npaths using a cascaded denoising process. Our unified framework ensures the\ngenerality across various benchmark settings such as input modality, and\ntrajectory lengths. Extensive experiments on five public benchmarks demonstrate\nthat SingularTrajectory substantially outperforms existing models, highlighting\nits effectiveness in estimating general dynamics of human movements. Code is\npublicly available at https://github.com/inhwanbae/SingularTrajectory .\n","authors":["Inhwan Bae","Young-Jae Park","Hae-Gon Jeon"],"pdf_url":"https://arxiv.org/pdf/2403.18452v1.pdf","comment":"Accepted at CVPR 2024"},{"id":"http://arxiv.org/abs/2403.18451v1","updated":"2024-03-27T11:11:06Z","published":"2024-03-27T11:11:06Z","title":"CoRAST: Towards Foundation Model-Powered Correlated Data Analysis in\n  Resource-Constrained CPS and IoT","summary":"  Foundation models (FMs) emerge as a promising solution to harness distributed\nand diverse environmental data by leveraging prior knowledge to understand the\ncomplicated temporal and spatial correlations within heterogeneous datasets.\nUnlike distributed learning frameworks such as federated learning, which often\nstruggle with multimodal data, FMs can transform diverse inputs into\nembeddings. This process facilitates the integration of information from\nvarious modalities and the application of prior learning to new domains.\nHowever, deploying FMs in resource-constrained edge systems poses significant\nchallenges. To this end, we introduce CoRAST, a novel learning framework that\nutilizes FMs for enhanced analysis of distributed, correlated heterogeneous\ndata. Utilizing a server-based FM, CoRAST can exploit existing environment\ninformation to extract temporal, spatial, and cross-modal correlations among\nsensor data. This enables CoRAST to offer context-aware insights for localized\nclient tasks through FM-powered global representation learning. Our evaluation\non real-world weather dataset demonstrates CoRAST's ability to exploit\ncorrelated heterogeneous data through environmental representation learning to\nreduce the forecast errors by up to 50.3% compared to the baselines.\n","authors":["Yi Hu","Jinhang Zuo","Alanis Zhao","Bob Iannucci","Carlee Joe-Wong"],"pdf_url":"https://arxiv.org/pdf/2403.18451v1.pdf","comment":"accepted and to be published in 2024 IEEE International Workshop on\n  Foundation Models for Cyber-Physical Systems & Internet of Things (FMSys)"},{"id":"http://arxiv.org/abs/2403.09267v3","updated":"2024-03-27T11:11:02Z","published":"2024-03-14T10:44:10Z","title":"Deep Limit Order Book Forecasting","summary":"  We exploit cutting-edge deep learning methodologies to explore the\npredictability of high-frequency Limit Order Book mid-price changes for a\nheterogeneous set of stocks traded on the NASDAQ exchange. In so doing, we\nrelease `LOBFrame', an open-source code base to efficiently process large-scale\nLimit Order Book data and quantitatively assess state-of-the-art deep learning\nmodels' forecasting capabilities. Our results are twofold. We demonstrate that\nthe stocks' microstructural characteristics influence the efficacy of deep\nlearning methods and that their high forecasting power does not necessarily\ncorrespond to actionable trading signals. We argue that traditional machine\nlearning metrics fail to adequately assess the quality of forecasts in the\nLimit Order Book context. As an alternative, we propose an innovative\noperational framework that evaluates predictions' practicality by focusing on\nthe probability of accurately forecasting complete transactions. This work\noffers academics and practitioners an avenue to make informed and robust\ndecisions on the application of deep learning techniques, their scope and\nlimitations, effectively exploiting emergent statistical properties of the\nLimit Order Book.\n","authors":["Antonio Briola","Silvia Bartolucci","Tomaso Aste"],"pdf_url":"https://arxiv.org/pdf/2403.09267v3.pdf","comment":"43 pages, 14 figures, 12 Tables"},{"id":"http://arxiv.org/abs/2403.18447v1","updated":"2024-03-27T11:06:44Z","published":"2024-03-27T11:06:44Z","title":"Can Language Beat Numerical Regression? Language-Based Multimodal\n  Trajectory Prediction","summary":"  Language models have demonstrated impressive ability in context understanding\nand generative performance. Inspired by the recent success of language\nfoundation models, in this paper, we propose LMTraj (Language-based Multimodal\nTrajectory predictor), which recasts the trajectory prediction task into a sort\nof question-answering problem. Departing from traditional numerical regression\nmodels, which treat the trajectory coordinate sequence as continuous signals,\nwe consider them as discrete signals like text prompts. Specially, we first\ntransform an input space for the trajectory coordinate into the natural\nlanguage space. Here, the entire time-series trajectories of pedestrians are\nconverted into a text prompt, and scene images are described as text\ninformation through image captioning. The transformed numerical and image data\nare then wrapped into the question-answering template for use in a language\nmodel. Next, to guide the language model in understanding and reasoning\nhigh-level knowledge, such as scene context and social relationships between\npedestrians, we introduce an auxiliary multi-task question and answering. We\nthen train a numerical tokenizer with the prompt data. We encourage the\ntokenizer to separate the integer and decimal parts well, and leverage it to\ncapture correlations between the consecutive numbers in the language model.\nLastly, we train the language model using the numerical tokenizer and all of\nthe question-answer prompts. Here, we propose a beam-search-based most-likely\nprediction and a temperature-based multimodal prediction to implement both\ndeterministic and stochastic inferences. Applying our LMTraj, we show that the\nlanguage-based model can be a powerful pedestrian trajectory predictor, and\noutperforms existing numerical-based predictor methods. Code is publicly\navailable at https://github.com/inhwanbae/LMTrajectory .\n","authors":["Inhwan Bae","Junoh Lee","Hae-Gon Jeon"],"pdf_url":"https://arxiv.org/pdf/2403.18447v1.pdf","comment":"Accepted at CVPR 2024"},{"id":"http://arxiv.org/abs/2403.18444v1","updated":"2024-03-27T11:00:53Z","published":"2024-03-27T11:00:53Z","title":"FRESCO: Federated Reinforcement Energy System for Cooperative\n  Optimization","summary":"  The rise in renewable energy is creating new dynamics in the energy grid that\npromise to create a cleaner and more participative energy grid, where\ntechnology plays a crucial part in making the required flexibility to achieve\nthe vision of the next-generation grid. This work presents FRESCO, a framework\nthat aims to ease the implementation of energy markets using a hierarchical\ncontrol architecture of reinforcement learning agents trained using federated\nlearning. The core concept we are proving is that having greedy agents subject\nto changing conditions from a higher level agent creates a cooperative setup\nthat will allow for fulfilling all the individual objectives. This paper\npresents a general overview of the framework, the current progress, and some\ninsights we obtained from the recent results.\n","authors":["Nicolas Mauricio Cuadrado","Roberto Alejandro Gutierrez","Martin Takáč"],"pdf_url":"https://arxiv.org/pdf/2403.18444v1.pdf","comment":"Tiny Paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2403.18439v1","updated":"2024-03-27T10:47:06Z","published":"2024-03-27T10:47:06Z","title":"Generalized Policy Learning for Smart Grids: FL TRPO Approach","summary":"  The smart grid domain requires bolstering the capabilities of existing energy\nmanagement systems; Federated Learning (FL) aligns with this goal as it\ndemonstrates a remarkable ability to train models on heterogeneous datasets\nwhile maintaining data privacy, making it suitable for smart grid applications,\nwhich often involve disparate data distributions and interdependencies among\nfeatures that hinder the suitability of linear models. This paper introduces a\nframework that combines FL with a Trust Region Policy Optimization (FL TRPO)\naiming to reduce energy-associated emissions and costs. Our approach reveals\nlatent interconnections and employs personalized encoding methods to capture\nunique insights, understanding the relationships between features and optimal\nstrategies, allowing our model to generalize to previously unseen data.\nExperimental results validate the robustness of our approach, affirming its\nproficiency in effectively learning policy models for smart grid challenges.\n","authors":["Yunxiang Li","Nicolas Mauricio Cuadrado","Samuel Horváth","Martin Takáč"],"pdf_url":"https://arxiv.org/pdf/2403.18439v1.pdf","comment":"ICLR 2024 Workshop: Tackling Climate Change with Machine Learning"},{"id":"http://arxiv.org/abs/2403.18438v1","updated":"2024-03-27T10:45:16Z","published":"2024-03-27T10:45:16Z","title":"Global Vegetation Modeling with Pre-Trained Weather Transformers","summary":"  Accurate vegetation models can produce further insights into the complex\ninteraction between vegetation activity and ecosystem processes. Previous\nresearch has established that long-term trends and short-term variability of\ntemperature and precipitation affect vegetation activity. Motivated by the\nrecent success of Transformer-based Deep Learning models for medium-range\nweather forecasting, we adapt the publicly available pre-trained FourCastNet to\nmodel vegetation activity while accounting for the short-term dynamics of\nclimate variability. We investigate how the learned global representation of\nthe atmosphere's state can be transferred to model the normalized difference\nvegetation index (NDVI). Our model globally estimates vegetation activity at a\nresolution of \\SI{0.25}{\\degree} while relying only on meteorological data. We\ndemonstrate that leveraging pre-trained weather models improves the NDVI\nestimates compared to learning an NDVI model from scratch. Additionally, we\ncompare our results to other recent data-driven NDVI modeling approaches from\nmachine learning and ecology literature. We further provide experimental\nevidence on how much data and training time is necessary to turn FourCastNet\ninto an effective vegetation model. Code and models will be made available upon\npublication.\n","authors":["Pascal Janetzky","Florian Gallusser","Simon Hentschel","Andreas Hotho","Anna Krause"],"pdf_url":"https://arxiv.org/pdf/2403.18438v1.pdf","comment":"Tackling Climate Change with Machine Learning Workshop @ ICLR 2024"},{"id":"http://arxiv.org/abs/2403.18436v1","updated":"2024-03-27T10:40:27Z","published":"2024-03-27T10:40:27Z","title":"Collaborative Active Learning in Conditional Trust Environment","summary":"  In this paper, we investigate collaborative active learning, a paradigm in\nwhich multiple collaborators explore a new domain by leveraging their combined\nmachine learning capabilities without disclosing their existing data and\nmodels. Instead, the collaborators share prediction results from the new domain\nand newly acquired labels. This collaboration offers several advantages: (a) it\naddresses privacy and security concerns by eliminating the need for direct\nmodel and data disclosure; (b) it enables the use of different data sources and\ninsights without direct data exchange; and (c) it promotes cost-effectiveness\nand resource efficiency through shared labeling costs. To realize these\nbenefits, we introduce a collaborative active learning framework designed to\nfulfill the aforementioned objectives. We validate the effectiveness of the\nproposed framework through simulations. The results demonstrate that\ncollaboration leads to higher AUC scores compared to independent efforts,\nhighlighting the framework's ability to overcome the limitations of individual\nmodels. These findings support the use of collaborative approaches in active\nlearning, emphasizing their potential to enhance outcomes through collective\nexpertise and shared resources. Our work provides a foundation for further\nresearch on collaborative active learning and its practical applications in\nvarious domains where data privacy, cost efficiency, and model performance are\ncritical considerations.\n","authors":["Zan-Kai Chong","Hiroyuki Ohsaki","Bryan Ng"],"pdf_url":"https://arxiv.org/pdf/2403.18436v1.pdf","comment":"5 pages, 9 figures, conference"},{"id":"http://arxiv.org/abs/2403.18425v1","updated":"2024-03-27T10:26:42Z","published":"2024-03-27T10:26:42Z","title":"U-Sketch: An Efficient Approach for Sketch to Image Diffusion Models","summary":"  Diffusion models have demonstrated remarkable performance in text-to-image\nsynthesis, producing realistic and high resolution images that faithfully\nadhere to the corresponding text-prompts. Despite their great success, they\nstill fall behind in sketch-to-image synthesis tasks, where in addition to\ntext-prompts, the spatial layout of the generated images has to closely follow\nthe outlines of certain reference sketches. Employing an MLP latent edge\npredictor to guide the spatial layout of the synthesized image by predicting\nedge maps at each denoising step has been recently proposed. Despite yielding\npromising results, the pixel-wise operation of the MLP does not take into\naccount the spatial layout as a whole, and demands numerous denoising\niterations to produce satisfactory images, leading to time inefficiency. To\nthis end, we introduce U-Sketch, a framework featuring a U-Net type latent edge\npredictor, which is capable of efficiently capturing both local and global\nfeatures, as well as spatial correlations between pixels. Moreover, we propose\nthe addition of a sketch simplification network that offers the user the choice\nof preprocessing and simplifying input sketches for enhanced outputs. The\nexperimental results, corroborated by user feedback, demonstrate that our\nproposed U-Net latent edge predictor leads to more realistic results, that are\nbetter aligned with the spatial outlines of the reference sketches, while\ndrastically reducing the number of required denoising steps and, consequently,\nthe overall execution time.\n","authors":["Ilias Mitsouras","Eleftherios Tsonis","Paraskevi Tzouveli","Athanasios Voulodimos"],"pdf_url":"https://arxiv.org/pdf/2403.18425v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18423v1","updated":"2024-03-27T10:24:25Z","published":"2024-03-27T10:24:25Z","title":"SemRoDe: Macro Adversarial Training to Learn Representations That are\n  Robust to Word-Level Attacks","summary":"  Language models (LMs) are indispensable tools for natural language processing\ntasks, but their vulnerability to adversarial attacks remains a concern. While\ncurrent research has explored adversarial training techniques, their\nimprovements to defend against word-level attacks have been limited. In this\nwork, we propose a novel approach called Semantic Robust Defence (SemRoDe), a\nMacro Adversarial Training strategy to enhance the robustness of LMs. Drawing\ninspiration from recent studies in the image domain, we investigate and later\nconfirm that in a discrete data setting such as language, adversarial samples\ngenerated via word substitutions do indeed belong to an adversarial domain\nexhibiting a high Wasserstein distance from the base domain. Our method learns\na robust representation that bridges these two domains. We hypothesize that if\nsamples were not projected into an adversarial domain, but instead to a domain\nwith minimal shift, it would improve attack robustness. We align the domains by\nincorporating a new distance-based objective. With this, our model is able to\nlearn more generalized representations by aligning the model's high-level\noutput features and therefore better handling unseen adversarial samples. This\nmethod can be generalized across word embeddings, even when they share minimal\noverlap at both vocabulary and word-substitution levels. To evaluate the\neffectiveness of our approach, we conduct experiments on BERT and RoBERTa\nmodels on three datasets. The results demonstrate promising state-of-the-art\nrobustness.\n","authors":["Brian Formento","Wenjie Feng","Chuan Sheng Foo","Luu Anh Tuan","See-Kiong Ng"],"pdf_url":"https://arxiv.org/pdf/2403.18423v1.pdf","comment":"Published in NAACL 2024 (Main Track)"},{"id":"http://arxiv.org/abs/2402.01739v2","updated":"2024-03-27T10:21:24Z","published":"2024-01-29T12:05:02Z","title":"OpenMoE: An Early Effort on Open Mixture-of-Experts Language Models","summary":"  To help the open-source community have a better understanding of\nMixture-of-Experts (MoE) based large language models (LLMs), we train and\nrelease OpenMoE, a series of fully open-sourced and reproducible decoder-only\nMoE LLMs, ranging from 650M to 34B parameters and trained on up to over 1T\ntokens. Our investigation confirms that MoE-based LLMs can offer a more\nfavorable cost-effectiveness trade-off than dense LLMs, highlighting the\npotential effectiveness for future LLM development.\n  One more important contribution of this study is an in-depth analysis of the\nrouting mechanisms within our OpenMoE models, leading to three significant\nfindings: Context-Independent Specialization, Early Routing Learning, and\nDrop-towards-the-End. We discovered that routing decisions in MoE models are\npredominantly based on token IDs, with minimal context relevance. The\ntoken-to-expert assignments are determined early in the pre-training phase and\nremain largely unchanged. This imperfect routing can result in performance\ndegradation, particularly in sequential tasks like multi-turn conversations,\nwhere tokens appearing later in a sequence are more likely to be dropped.\nFinally, we rethink our design based on the above-mentioned observations and\nanalysis. To facilitate future MoE LLM development, we propose potential\nstrategies for mitigating the issues we found and further improving\noff-the-shelf MoE LLM designs.\n","authors":["Fuzhao Xue","Zian Zheng","Yao Fu","Jinjie Ni","Zangwei Zheng","Wangchunshu Zhou","Yang You"],"pdf_url":"https://arxiv.org/pdf/2402.01739v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.01191v2","updated":"2024-03-27T10:12:31Z","published":"2023-11-02T12:36:19Z","title":"VIGraph: Generative Self-supervised Learning for Class-Imbalanced Node\n  Classification","summary":"  Class imbalance in graph data presents significant challenges for node\nclassification. While existing methods, such as SMOTE-based approaches,\npartially mitigate this issue, they still exhibit limitations in constructing\nimbalanced graphs. Generative self-supervised learning (SSL) methods,\nexemplified by graph autoencoders (GAEs), offer a promising solution by\ndirectly generating minority nodes from the data itself, yet their potential\nremains underexplored. In this paper, we delve into the shortcomings of\nSMOTE-based approaches in the construction of imbalanced graphs. Furthermore,\nwe introduce VIGraph, a simple yet effective generative SSL approach that\nrelies on the Variational GAE as the fundamental model. VIGraph strictly\nadheres to the concept of imbalance when constructing imbalanced graphs and\ninnovatively leverages the variational inference (VI) ability of Variational\nGAE to generate nodes for minority classes. VIGraph introduces comprehensive\ntraining strategies, including cross-view contrastive learning at the decoding\nphase to capture semantic knowledge, adjacency matrix reconstruction to\npreserve graph structure, and alignment strategy to ensure stable training.\nVIGraph can generate high-quality nodes directly usable for classification,\neliminating the need to integrate the generated nodes back to the graph as well\nas additional retraining found in SMOTE-based methods. We conduct extensive\nexperiments, results from which demonstrate the superiority and generality of\nour approach.\n","authors":["Yulan Hu","Sheng Ouyang","Zhirui Yang","Yong Liu"],"pdf_url":"https://arxiv.org/pdf/2311.01191v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18415v1","updated":"2024-03-27T10:06:33Z","published":"2024-03-27T10:06:33Z","title":"The Topos of Transformer Networks","summary":"  The transformer neural network has significantly out-shined all other neural\nnetwork architectures as the engine behind large language models. We provide a\ntheoretical analysis of the expressivity of the transformer architecture\nthrough the lens of topos theory. From this viewpoint, we show that many common\nneural network architectures, such as the convolutional, recurrent and graph\nconvolutional networks, can be embedded in a pretopos of piecewise-linear\nfunctions, but that the transformer necessarily lives in its topos completion.\nIn particular, this suggests that the two network families instantiate\ndifferent fragments of logic: the former are first order, whereas transformers\nare higher-order reasoners. Furthermore, we draw parallels with architecture\nsearch and gradient descent, integrating our analysis in the framework of\ncybernetic agents.\n","authors":["Mattia Jacopo Villani","Peter McBurney"],"pdf_url":"https://arxiv.org/pdf/2403.18415v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.06075v2","updated":"2024-03-27T09:51:15Z","published":"2023-09-12T09:12:37Z","title":"A2V: A Semi-Supervised Domain Adaptation Framework for Brain Vessel\n  Segmentation via Two-Phase Training Angiography-to-Venography Translation","summary":"  We present a semi-supervised domain adaptation framework for brain vessel\nsegmentation from different image modalities. Existing state-of-the-art methods\nfocus on a single modality, despite the wide range of available cerebrovascular\nimaging techniques. This can lead to significant distribution shifts that\nnegatively impact the generalization across modalities. By relying on annotated\nangiographies and a limited number of annotated venographies, our framework\naccomplishes image-to-image translation and semantic segmentation, leveraging a\ndisentangled and semantically rich latent space to represent heterogeneous data\nand perform image-level adaptation from source to target domains. Moreover, we\nreduce the typical complexity of cycle-based architectures and minimize the use\nof adversarial training, which allows us to build an efficient and intuitive\nmodel with stable training. We evaluate our method on magnetic resonance\nangiographies and venographies. While achieving state-of-the-art performance in\nthe source domain, our method attains a Dice score coefficient in the target\ndomain that is only 8.9% lower, highlighting its promising potential for robust\ncerebrovascular image segmentation across different modalities.\n","authors":["Francesco Galati","Daniele Falcetta","Rosa Cortese","Barbara Casolla","Ferran Prados","Ninon Burgos","Maria A. Zuluaga"],"pdf_url":"https://arxiv.org/pdf/2309.06075v2.pdf","comment":"Accepted at the 34th British Machine Vision Conference (BMVC)"},{"id":"http://arxiv.org/abs/2310.05723v2","updated":"2024-03-27T09:48:34Z","published":"2023-10-09T13:47:05Z","title":"Planning to Go Out-of-Distribution in Offline-to-Online Reinforcement\n  Learning","summary":"  Offline pretraining with a static dataset followed by online fine-tuning\n(offline-to-online, or OtO) is a paradigm well matched to a real-world RL\ndeployment process. In this scenario, we aim to find the best-performing policy\nwithin a limited budget of online interactions. Previous work in the OtO\nsetting has focused on correcting for bias introduced by the policy-constraint\nmechanisms of offline RL algorithms. Such constraints keep the learned policy\nclose to the behavior policy that collected the dataset, but we show this can\nunnecessarily limit policy performance if the behavior policy is far from\noptimal. Instead, we forgo constraints and frame OtO RL as an exploration\nproblem that aims to maximize the benefit of online data-collection. We first\nstudy the major online RL exploration methods based on intrinsic rewards and\nUCB in the OtO setting, showing that intrinsic rewards add training instability\nthrough reward-function modification, and UCB methods are myopic and it is\nunclear which learned-component's ensemble to use for action selection. We then\nintroduce an algorithm for planning to go out-of-distribution (PTGOOD) that\navoids these issues. PTGOOD uses a non-myopic planning procedure that targets\nexploration in relatively high-reward regions of the state-action space\nunlikely to be visited by the behavior policy. By leveraging concepts from the\nConditional Entropy Bottleneck, PTGOOD encourages data collected online to\nprovide new information relevant to improving the final deployment policy\nwithout altering rewards. We show empirically in several continuous control\ntasks that PTGOOD significantly improves agent returns during online\nfine-tuning and avoids the suboptimal policy convergence that many of our\nbaselines exhibit in several environments.\n","authors":["Trevor McInroe","Adam Jelley","Stefano V. Albrecht","Amos Storkey"],"pdf_url":"https://arxiv.org/pdf/2310.05723v2.pdf","comment":"10 pages, 17 figures, preprint"},{"id":"http://arxiv.org/abs/2403.18406v1","updated":"2024-03-27T09:48:23Z","published":"2024-03-27T09:48:23Z","title":"An Image Grid Can Be Worth a Video: Zero-shot Video Question Answering\n  Using a VLM","summary":"  Stimulated by the sophisticated reasoning capabilities of recent Large\nLanguage Models (LLMs), a variety of strategies for bridging video modality\nhave been devised. A prominent strategy involves Video Language Models\n(VideoLMs), which train a learnable interface with video data to connect\nadvanced vision encoders with LLMs. Recently, an alternative strategy has\nsurfaced, employing readily available foundation models, such as VideoLMs and\nLLMs, across multiple stages for modality bridging. In this study, we introduce\na simple yet novel strategy where only a single Vision Language Model (VLM) is\nutilized. Our starting point is the plain insight that a video comprises a\nseries of images, or frames, interwoven with temporal information. The essence\nof video comprehension lies in adeptly managing the temporal aspects along with\nthe spatial details of each frame. Initially, we transform a video into a\nsingle composite image by arranging multiple frames in a grid layout. The\nresulting single image is termed as an image grid. This format, while\nmaintaining the appearance of a solitary image, effectively retains temporal\ninformation within the grid structure. Therefore, the image grid approach\nenables direct application of a single high-performance VLM without\nnecessitating any video-data training. Our extensive experimental analysis\nacross ten zero-shot video question answering benchmarks, including five\nopen-ended and five multiple-choice benchmarks, reveals that the proposed Image\nGrid Vision Language Model (IG-VLM) surpasses the existing methods in nine out\nof ten benchmarks.\n","authors":["Wonkyun Kim","Changin Choi","Wonseok Lee","Wonjong Rhee"],"pdf_url":"https://arxiv.org/pdf/2403.18406v1.pdf","comment":"Our code is available at https://github.com/imagegridworth/IG-VLM"},{"id":"http://arxiv.org/abs/2403.18402v1","updated":"2024-03-27T09:44:50Z","published":"2024-03-27T09:44:50Z","title":"On Spectrogram Analysis in a Multiple Classifier Fusion Framework for\n  Power Grid Classification Using Electric Network Frequency","summary":"  The Electric Network Frequency (ENF) serves as a unique signature inherent to\npower distribution systems. Here, a novel approach for power grid\nclassification is developed, leveraging ENF. Spectrograms are generated from\naudio and power recordings across different grids, revealing distinctive ENF\npatterns that aid in grid classification through a fusion of classifiers. Four\ntraditional machine learning classifiers plus a Convolutional Neural Network\n(CNN), optimized using Neural Architecture Search, are developed for One-vs-All\nclassification. This process generates numerous predictions per sample, which\nare then compiled and used to train a shallow multi-label neural network\nspecifically designed to model the fusion process, ultimately leading to the\nconclusive class prediction for each sample. Experimental findings reveal that\nboth validation and testing accuracy outperform those of current\nstate-of-the-art classifiers, underlining the effectiveness and robustness of\nthe proposed methodology.\n","authors":["Georgios Tzolopoulos","Christos Korgialas","Constantine Kotropoulos"],"pdf_url":"https://arxiv.org/pdf/2403.18402v1.pdf","comment":"13th International Conference on Pattern Recognition Applications and\n  Methods (ICPRAM)"},{"id":"http://arxiv.org/abs/2403.18397v1","updated":"2024-03-27T09:35:56Z","published":"2024-03-27T09:35:56Z","title":"Colour and Brush Stroke Pattern Recognition in Abstract Art using\n  Modified Deep Convolutional Generative Adversarial Networks","summary":"  Abstract Art is an immensely popular, discussed form of art that often has\nthe ability to depict the emotions of an artist. Many researchers have made\nattempts to study abstract art in the form of edge detection, brush stroke and\nemotion recognition algorithms using machine and deep learning. This papers\ndescribes the study of a wide distribution of abstract paintings using\nGenerative Adversarial Neural Networks(GAN). GANs have the ability to learn and\nreproduce a distribution enabling researchers and scientists to effectively\nexplore and study the generated image space. However, the challenge lies in\ndeveloping an efficient GAN architecture that overcomes common training\npitfalls. This paper addresses this challenge by introducing a modified-DCGAN\n(mDCGAN) specifically designed for high-quality artwork generation. The\napproach involves a thorough exploration of the modifications made, delving\ninto the intricate workings of DCGANs, optimisation techniques, and\nregularisation methods aimed at improving stability and realism in art\ngeneration enabling effective study of generated patterns. The proposed mDCGAN\nincorporates meticulous adjustments in layer configurations and architectural\nchoices, offering tailored solutions to the unique demands of art generation\nwhile effectively combating issues like mode collapse and gradient vanishing.\nFurther this paper explores the generated latent space by performing random\nwalks to understand vector relationships between brush strokes and colours in\nthe abstract art space and a statistical analysis of unstable outputs after a\ncertain period of GAN training and compare its significant difference. These\nfindings validate the effectiveness of the proposed approach, emphasising its\npotential to revolutionise the field of digital art generation and digital art\necosystem.\n","authors":["Srinitish Srinivasan","Varenya Pathak"],"pdf_url":"https://arxiv.org/pdf/2403.18397v1.pdf","comment":"28 pages, 5 tables, 7 figures"},{"id":"http://arxiv.org/abs/2403.18393v1","updated":"2024-03-27T09:30:50Z","published":"2024-03-27T09:30:50Z","title":"Tensor-based Graph Learning with Consistency and Specificity for\n  Multi-view Clustering","summary":"  Graph learning is widely recognized as a crucial technique in multi-view\nclustering. Existing graph learning methods typically involve constructing an\nadaptive neighbor graph based on probabilistic neighbors and then learning a\nconsensus graph to for clustering, however, they are confronted with two\nlimitations. Firstly, they often rely on Euclidean distance to measure\nsimilarity when constructing the adaptive neighbor graph, which proves\ninadequate in capturing the intrinsic structure among data points in many\nreal-world scenarios. Secondly, most of these methods focus solely on consensus\ngraph, ignoring view-specific graph information. In response to the\naforementioned drawbacks, we in this paper propose a novel tensor-based graph\nlearning framework that simultaneously considers consistency and specificity\nfor multi-view clustering. Specifically, we calculate the similarity distance\non the Stiefel manifold to preserve the intrinsic structure among data points.\nBy making an assumption that the learned neighbor graph of each view comprises\nboth a consistent graph and a view-specific graph, we formulate a new\ntensor-based target graph learning paradigm. Owing to the benefits of tensor\nsingular value decomposition (t-SVD) in uncovering high-order correlations,\nthis model is capable of achieving a complete understanding of the target\ngraph. Furthermore, we develop an iterative algorithm to solve the proposed\nobjective optimization problem. Experiments conducted on real-world datasets\nhave demonstrated the superior performance of the proposed method over some\nstate-of-the-art multi-view clustering methods. The source code has been\nreleased on https://github.com/lshi91/CSTGL-Code.\n","authors":["Long Shi","Lei Cao","Yunshan Ye","Yu Zhao","Badong Chen"],"pdf_url":"https://arxiv.org/pdf/2403.18393v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18383v1","updated":"2024-03-27T09:21:07Z","published":"2024-03-27T09:21:07Z","title":"Generative Multi-modal Models are Good Class-Incremental Learners","summary":"  In class-incremental learning (CIL) scenarios, the phenomenon of catastrophic\nforgetting caused by the classifier's bias towards the current task has long\nposed a significant challenge. It is mainly caused by the characteristic of\ndiscriminative models. With the growing popularity of the generative\nmulti-modal models, we would explore replacing discriminative models with\ngenerative ones for CIL. However, transitioning from discriminative to\ngenerative models requires addressing two key challenges. The primary challenge\nlies in transferring the generated textual information into the classification\nof distinct categories. Additionally, it requires formulating the task of CIL\nwithin a generative framework. To this end, we propose a novel generative\nmulti-modal model (GMM) framework for class-incremental learning. Our approach\ndirectly generates labels for images using an adapted generative model. After\nobtaining the detailed text, we use a text encoder to extract text features and\nemploy feature matching to determine the most similar label as the\nclassification prediction. In the conventional CIL settings, we achieve\nsignificantly better results in long-sequence task scenarios. Under the\nFew-shot CIL setting, we have improved by at least 14\\% accuracy over all the\ncurrent state-of-the-art methods with significantly less forgetting. Our code\nis available at \\url{https://github.com/DoubleClass/GMM}.\n","authors":["Xusheng Cao","Haori Lu","Linlan Huang","Xialei Liu","Ming-Ming Cheng"],"pdf_url":"https://arxiv.org/pdf/2403.18383v1.pdf","comment":"Accepted at CVPR 2024"},{"id":"http://arxiv.org/abs/2403.18379v1","updated":"2024-03-27T09:17:50Z","published":"2024-03-27T09:17:50Z","title":"IIP-Mixer:Intra-Inter Patch Mixing Architecture for Battery Remaining\n  Useful Life Prediction","summary":"  Accurately estimating the Remaining Useful Life (RUL) of lithium-ion\nbatteries is crucial for maintaining the safe and stable operation of\nrechargeable battery management systems. However, this task is often\nchallenging due to the complex temporal dynamics involved. Recently,\nattention-based networks, such as Transformers and Informer, have been the\npopular architecture in time series forecasting. Despite their effectiveness,\nthese models with abundant parameters necessitate substantial training time to\nunravel temporal patterns. To tackle these challenges, we propose a simple\nMLP-Mixer-based architecture named 'Intra-Inter Patch Mixer' (IIP-Mixer), which\nis an architecture based exclusively on multi-layer perceptrons (MLPs),\nextracting information by mixing operations along both intra-patch and\ninter-patch dimensions for battery RUL prediction. The proposed IIP-Mixer\ncomprises parallel dual-head mixer layers: the intra-patch mixing MLP,\ncapturing local temporal patterns in the short-term period, and the inter-patch\nmixing MLP, capturing global temporal patterns in the long-term period.\nNotably, to address the varying importance of features in RUL prediction, we\nintroduce a weighted loss function in the MLP-Mixer-based architecture, marking\nthe first time such an approach has been employed. Our experiments demonstrate\nthat IIP-Mixer achieves competitive performance in battery RUL prediction,\noutperforming other popular time-series frameworks\n","authors":["Guangzai Ye","Li Feng","Jianlan Guo","Yuqiang Chen"],"pdf_url":"https://arxiv.org/pdf/2403.18379v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18375v1","updated":"2024-03-27T09:14:36Z","published":"2024-03-27T09:14:36Z","title":"Stragglers-Aware Low-Latency Synchronous Federated Learning via\n  Layer-Wise Model Updates","summary":"  Synchronous federated learning (FL) is a popular paradigm for collaborative\nedge learning. It typically involves a set of heterogeneous devices locally\ntraining neural network (NN) models in parallel with periodic centralized\naggregations. As some of the devices may have limited computational resources\nand varying availability, FL latency is highly sensitive to stragglers.\nConventional approaches discard incomplete intra-model updates done by\nstragglers, alter the amount of local workload and architecture, or resort to\nasynchronous settings; which all affect the trained model performance under\ntight training latency constraints. In this work, we propose straggler-aware\nlayer-wise federated learning (SALF) that leverages the optimization procedure\nof NNs via backpropagation to update the global model in a layer-wise fashion.\nSALF allows stragglers to synchronously convey partial gradients, having each\nlayer of the global model be updated independently with a different\ncontributing set of users. We provide a theoretical analysis, establishing\nconvergence guarantees for the global model under mild assumptions on the\ndistribution of the participating devices, revealing that SALF converges at the\nsame asymptotic rate as FL with no timing limitations. This insight is matched\nwith empirical observations, demonstrating the performance gains of SALF\ncompared to alternative mechanisms mitigating the device heterogeneity gap in\nFL.\n","authors":["Natalie Lang","Alejandro Cohen","Nir Shlezinger"],"pdf_url":"https://arxiv.org/pdf/2403.18375v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.08533v4","updated":"2024-03-27T09:11:48Z","published":"2023-12-13T21:46:09Z","title":"World Models via Policy-Guided Trajectory Diffusion","summary":"  World models are a powerful tool for developing intelligent agents. By\npredicting the outcome of a sequence of actions, world models enable policies\nto be optimised via on-policy reinforcement learning (RL) using synthetic data,\ni.e. in \"in imagination\". Existing world models are autoregressive in that they\ninterleave predicting the next state with sampling the next action from the\npolicy. Prediction error inevitably compounds as the trajectory length grows.\nIn this work, we propose a novel world modelling approach that is not\nautoregressive and generates entire on-policy trajectories in a single pass\nthrough a diffusion model. Our approach, Policy-Guided Trajectory Diffusion\n(PolyGRAD), leverages a denoising model in addition to the gradient of the\naction distribution of the policy to diffuse a trajectory of initially random\nstates and actions into an on-policy synthetic trajectory. We analyse the\nconnections between PolyGRAD, score-based generative models, and\nclassifier-guided diffusion models. Our results demonstrate that PolyGRAD\noutperforms state-of-the-art baselines in terms of trajectory prediction error\nfor short trajectories, with the exception of autoregressive diffusion. For\nshort trajectories, PolyGRAD obtains similar errors to autoregressive\ndiffusion, but with lower computational requirements. For long trajectories,\nPolyGRAD obtains comparable performance to baselines. Our experiments\ndemonstrate that PolyGRAD enables performant policies to be trained via\non-policy RL in imagination for MuJoCo continuous control domains. Thus,\nPolyGRAD introduces a new paradigm for accurate on-policy world modelling\nwithout autoregressive sampling.\n","authors":["Marc Rigter","Jun Yamada","Ingmar Posner"],"pdf_url":"https://arxiv.org/pdf/2312.08533v4.pdf","comment":"Published in TMLR, March 2024"},{"id":"http://arxiv.org/abs/2102.12920v5","updated":"2024-03-27T09:07:29Z","published":"2021-02-25T15:18:13Z","title":"Emerging Trends in Federated Learning: From Model Fusion to Federated X\n  Learning","summary":"  Federated learning is a new learning paradigm that decouples data collection\nand model training via multi-party computation and model aggregation. As a\nflexible learning setting, federated learning has the potential to integrate\nwith other learning frameworks. We conduct a focused survey of federated\nlearning in conjunction with other learning algorithms. Specifically, we\nexplore various learning algorithms to improve the vanilla federated averaging\nalgorithm and review model fusion methods such as adaptive aggregation,\nregularization, clustered methods, and Bayesian methods. Following the emerging\ntrends, we also discuss federated learning in the intersection with other\nlearning paradigms, termed federated X learning, where X includes multitask\nlearning, meta-learning, transfer learning, unsupervised learning, and\nreinforcement learning. In addition to reviewing state-of-the-art studies, this\npaper also identifies key challenges and applications in this field, while also\nhighlighting promising future directions.\n","authors":["Shaoxiong Ji","Yue Tan","Teemu Saravirta","Zhiqin Yang","Yixin Liu","Lauri Vasankari","Shirui Pan","Guodong Long","Anwar Walid"],"pdf_url":"https://arxiv.org/pdf/2102.12920v5.pdf","comment":"To appear in the International Journal of Machine Learning and\n  Cybernetics"},{"id":"http://arxiv.org/abs/2403.17905v2","updated":"2024-03-27T09:07:02Z","published":"2024-03-26T17:45:06Z","title":"Scalable Non-Cartesian Magnetic Resonance Imaging with R2D2","summary":"  We propose a new approach for non-Cartesian magnetic resonance image\nreconstruction. While unrolled architectures provide robustness via\ndata-consistency layers, embedding measurement operators in Deep Neural Network\n(DNN) can become impractical at large scale. Alternative Plug-and-Play (PnP)\napproaches, where the denoising DNNs are blind to the measurement setting, are\nnot affected by this limitation and have also proven effective, but their\nhighly iterative nature also affects scalability. To address this scalability\nchallenge, we leverage the \"Residual-to-Residual DNN series for high-Dynamic\nrange imaging (R2D2)\" approach recently introduced in astronomical imaging.\nR2D2's reconstruction is formed as a series of residual images, iteratively\nestimated as outputs of DNNs taking the previous iteration's image estimate and\nassociated data residual as inputs. The method can be interpreted as a learned\nversion of the Matching Pursuit algorithm. We demonstrate R2D2 in simulation,\nconsidering radial k-space sampling acquisition sequences. Our preliminary\nresults suggest that R2D2 achieves: (i) suboptimal performance compared to its\nunrolled incarnation R2D2-Net, which is however non-scalable due to the\nnecessary embedding of NUFFT-based data-consistency layers; (ii) superior\nreconstruction quality to a scalable version of R2D2-Net embedding an FFT-based\napproximation for data consistency; (iii) superior reconstruction quality to\nPnP, while only requiring few iterations.\n","authors":["Yiwei Chen","Chao Tang","Amir Aghabiglou","Chung San Chu","Yves Wiaux"],"pdf_url":"https://arxiv.org/pdf/2403.17905v2.pdf","comment":"submitted to IEEE EUSIPCO 2024"},{"id":"http://arxiv.org/abs/2403.18370v1","updated":"2024-03-27T09:06:36Z","published":"2024-03-27T09:06:36Z","title":"Ship in Sight: Diffusion Models for Ship-Image Super Resolution","summary":"  In recent years, remarkable advancements have been achieved in the field of\nimage generation, primarily driven by the escalating demand for high-quality\noutcomes across various image generation subtasks, such as inpainting,\ndenoising, and super resolution. A major effort is devoted to exploring the\napplication of super-resolution techniques to enhance the quality of\nlow-resolution images. In this context, our method explores in depth the\nproblem of ship image super resolution, which is crucial for coastal and port\nsurveillance. We investigate the opportunity given by the growing interest in\ntext-to-image diffusion models, taking advantage of the prior knowledge that\nsuch foundation models have already learned. In particular, we present a\ndiffusion-model-based architecture that leverages text conditioning during\ntraining while being class-aware, to best preserve the crucial details of the\nships during the generation of the super-resoluted image. Since the specificity\nof this task and the scarcity availability of off-the-shelf data, we also\nintroduce a large labeled ship dataset scraped from online ship images, mostly\nfrom ShipSpotting\\footnote{\\url{www.shipspotting.com}} website. Our method\nachieves more robust results than other deep learning models previously\nemployed for super resolution, as proven by the multiple experiments performed.\nMoreover, we investigate how this model can benefit downstream tasks, such as\nclassification and object detection, thus emphasizing practical implementation\nin a real-world scenario. Experimental results show flexibility, reliability,\nand impressive performance of the proposed framework over state-of-the-art\nmethods for different tasks. The code is available at:\nhttps://github.com/LuigiSigillo/ShipinSight .\n","authors":["Luigi Sigillo","Riccardo Fosco Gramaccioni","Alessandro Nicolosi","Danilo Comminiello"],"pdf_url":"https://arxiv.org/pdf/2403.18370v1.pdf","comment":"Accepted at 2024 International Joint Conference on Neural Networks\n  (IJCNN)"},{"id":"http://arxiv.org/abs/2307.13352v2","updated":"2024-03-27T09:04:04Z","published":"2023-07-25T09:14:45Z","title":"High Dimensional Distributed Gradient Descent with Arbitrary Number of\n  Byzantine Attackers","summary":"  Robust distributed learning with Byzantine failures has attracted extensive\nresearch interests in recent years. However, most of existing methods suffer\nfrom curse of dimensionality, which is increasingly serious with the growing\ncomplexity of modern machine learning models. In this paper, we design a new\nmethod that is suitable for high dimensional problems, under arbitrary number\nof Byzantine attackers. The core of our design is a direct high dimensional\nsemi-verified mean estimation method. Our idea is to identify a subspace first.\nThe components of mean value perpendicular to this subspace can be estimated\nvia gradient vectors uploaded from worker machines, while the components within\nthis subspace are estimated using auxiliary dataset. We then use our new method\nas the aggregator of distributed learning problems. Our theoretical analysis\nshows that the new method has minimax optimal statistical rates. In particular,\nthe dependence on dimensionality is significantly improved compared with\nprevious works.\n","authors":["Puning Zhao","Zhiguo Wan"],"pdf_url":"https://arxiv.org/pdf/2307.13352v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.10158v2","updated":"2024-03-27T08:57:20Z","published":"2024-03-15T10:01:19Z","title":"Functional Graph Convolutional Networks: A unified multi-task and\n  multi-modal learning framework to facilitate health and social-care insights","summary":"  This paper introduces a novel Functional Graph Convolutional Network (funGCN)\nframework that combines Functional Data Analysis and Graph Convolutional\nNetworks to address the complexities of multi-task and multi-modal learning in\ndigital health and longitudinal studies. With the growing importance of health\nsolutions to improve health care and social support, ensure healthy lives, and\npromote well-being at all ages, funGCN offers a unified approach to handle\nmultivariate longitudinal data for multiple entities and ensures\ninterpretability even with small sample sizes. Key innovations include\ntask-specific embedding components that manage different data types, the\nability to perform classification, regression, and forecasting, and the\ncreation of a knowledge graph for insightful data interpretation. The efficacy\nof funGCN is validated through simulation experiments and a real-data\napplication.\n","authors":["Tobia Boschi","Francesca Bonin","Rodrigo Ordonez-Hurtado","Cécile Rousseau","Alessandra Pascale","John Dinsmore"],"pdf_url":"https://arxiv.org/pdf/2403.10158v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18364v1","updated":"2024-03-27T08:57:15Z","published":"2024-03-27T08:57:15Z","title":"Intent-Aware DRL-Based Uplink Dynamic Scheduler for 5G-NR","summary":"  We investigate the problem of supporting Industrial Internet of Things user\nequipment (IIoT UEs) with intent (i.e., requested quality of service (QoS)) and\nrandom traffic arrival. A deep reinforcement learning (DRL) based centralized\ndynamic scheduler for time-frequency resources is proposed to learn how to\nschedule the available communication resources among the IIoT UEs. The proposed\nscheduler leverages an RL framework to adapt to the dynamic changes in the\nwireless communication system and traffic arrivals. Moreover, a graph-based\nreduction scheme is proposed to reduce the state and action space of the RL\nframework to allow fast convergence and a better learning strategy. Simulation\nresults demonstrate the effectiveness of the proposed intelligent scheduler in\nguaranteeing the expressed intent of IIoT UEs compared to several traditional\nscheduling schemes, such as round-robin, semi-static, and heuristic approaches.\nThe proposed scheduler also outperforms the contention-free and\ncontention-based schemes in maximizing the number of successfully computed\ntasks.\n","authors":["Salwa Mostafa","Mateus P. Mota","Alvaro Valcarce","Mehdi Bennis"],"pdf_url":"https://arxiv.org/pdf/2403.18364v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.03325v2","updated":"2024-03-27T08:54:35Z","published":"2023-10-05T05:41:21Z","title":"Learning Concept-Based Causal Transition and Symbolic Reasoning for\n  Visual Planning","summary":"  Visual planning simulates how humans make decisions to achieve desired goals\nin the form of searching for visual causal transitions between an initial\nvisual state and a final visual goal state. It has become increasingly\nimportant in egocentric vision with its advantages in guiding agents to perform\ndaily tasks in complex environments. In this paper, we propose an interpretable\nand generalizable visual planning framework consisting of i) a novel\nSubstitution-based Concept Learner (SCL) that abstracts visual inputs into\ndisentangled concept representations, ii) symbol abstraction and reasoning that\nperforms task planning via the self-learned symbols, and iii) a Visual Causal\nTransition model (ViCT) that grounds visual causal transitions to semantically\nsimilar real-world actions. Given an initial state, we perform goal-conditioned\nvisual planning with a symbolic reasoning method fueled by the learned\nrepresentations and causal transitions to reach the goal state. To verify the\neffectiveness of the proposed model, we collect a large-scale visual planning\ndataset based on AI2-THOR, dubbed as CCTP. Extensive experiments on this\nchallenging dataset demonstrate the superior performance of our method in\nvisual task planning. Empirically, we show that our framework can generalize to\nunseen task trajectories, unseen object categories, and real-world data.\nFurther details of this work are provided at\nhttps://fqyqc.github.io/ConTranPlan/.\n","authors":["Yilue Qian","Peiyu Yu","Ying Nian Wu","Yao Su","Wei Wang","Lifeng Fan"],"pdf_url":"https://arxiv.org/pdf/2310.03325v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15837v2","updated":"2024-03-27T08:54:06Z","published":"2024-03-23T13:24:31Z","title":"Centered Masking for Language-Image Pre-Training","summary":"  We introduce Gaussian masking for Language-Image Pre-Training (GLIP) a novel,\nstraightforward, and effective technique for masking image patches during\npre-training of a vision-language model. GLIP builds on Fast Language-Image\nPre-Training (FLIP), which randomly masks image patches while training a CLIP\nmodel. GLIP replaces random masking with centered masking, that uses a Gaussian\ndistribution and is inspired by the importance of image patches at the center\nof the image. GLIP retains the same computational savings as FLIP, while\nimproving performance across a range of downstream datasets and tasks, as\ndemonstrated by our experimental results. We show the benefits of GLIP to be\neasy to obtain, requiring no delicate tuning of the Gaussian, and also\napplicable to data sets containing images without an obvious center focus.\n","authors":["Mingliang Liang","Martha Larson"],"pdf_url":"https://arxiv.org/pdf/2403.15837v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17767v2","updated":"2024-03-27T08:49:19Z","published":"2024-03-26T14:54:35Z","title":"Asymptotic Bayes risk of semi-supervised learning with uncertain\n  labeling","summary":"  This article considers a semi-supervised classification setting on a Gaussian\nmixture model, where the data is not labeled strictly as usual, but instead\nwith uncertain labels. Our main aim is to compute the Bayes risk for this\nmodel. We compare the behavior of the Bayes risk and the best known algorithm\nfor this model. This comparison eventually gives new insights over the\nalgorithm.\n","authors":["Victor Leger","Romain Couillet"],"pdf_url":"https://arxiv.org/pdf/2403.17767v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18355v1","updated":"2024-03-27T08:48:16Z","published":"2024-03-27T08:48:16Z","title":"Supervised Multiple Kernel Learning approaches for multi-omics data\n  integration","summary":"  Advances in high-throughput technologies have originated an ever-increasing\navailability of omics datasets. The integration of multiple heterogeneous data\nsources is currently an issue for biology and bioinformatics. Multiple kernel\nlearning (MKL) has shown to be a flexible and valid approach to consider the\ndiverse nature of multi-omics inputs, despite being an underused tool in\ngenomic data mining.We provide novel MKL approaches based on different kernel\nfusion strategies.To learn from the meta-kernel of input kernels, we\nadaptedunsupervised integration algorithms for supervised tasks with support\nvector machines.We also tested deep learning architectures for kernel fusion\nand classification.The results show that MKL-based models can compete with more\ncomplex, state-of-the-art, supervised multi-omics integrative approaches.\nMultiple kernel learning offers a natural framework for predictive models in\nmulti-omics genomic data. Our results offer a direction for bio-data mining\nresearch and further development of methods for heterogeneous data integration.\n","authors":["Mitja Briscik","Gabriele Tazza","Marie-Agnes Dillies","László Vidács","Sébastien Dejean"],"pdf_url":"https://arxiv.org/pdf/2403.18355v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.02151v2","updated":"2024-03-27T08:43:28Z","published":"2023-05-03T14:33:23Z","title":"Identifying the Correlation Between Language Distance and Cross-Lingual\n  Transfer in a Multilingual Representation Space","summary":"  Prior research has investigated the impact of various linguistic features on\ncross-lingual transfer performance. In this study, we investigate the manner in\nwhich this effect can be mapped onto the representation space. While past\nstudies have focused on the impact on cross-lingual alignment in multilingual\nlanguage models during fine-tuning, this study examines the absolute evolution\nof the respective language representation spaces produced by MLLMs. We place a\nspecific emphasis on the role of linguistic characteristics and investigate\ntheir inter-correlation with the impact on representation spaces and\ncross-lingual transfer performance. Additionally, this paper provides\npreliminary evidence of how these findings can be leveraged to enhance transfer\nto linguistically distant languages.\n","authors":["Fred Philippy","Siwen Guo","Shohreh Haddadan"],"pdf_url":"https://arxiv.org/pdf/2305.02151v2.pdf","comment":"SIGTYP Workshop 2023 (co-located with EACL 2023)"},{"id":"http://arxiv.org/abs/2403.18351v1","updated":"2024-03-27T08:42:47Z","published":"2024-03-27T08:42:47Z","title":"Generating Diverse Agricultural Data for Vision-Based Farming\n  Applications","summary":"  We present a specialized procedural model for generating synthetic\nagricultural scenes, focusing on soybean crops, along with various weeds. This\nmodel is capable of simulating distinct growth stages of these plants, diverse\nsoil conditions, and randomized field arrangements under varying lighting\nconditions. The integration of real-world textures and environmental factors\ninto the procedural generation process enhances the photorealism and\napplicability of the synthetic data. Our dataset includes 12,000 images with\nsemantic labels, offering a comprehensive resource for computer vision tasks in\nprecision agriculture, such as semantic segmentation for autonomous weed\ncontrol. We validate our model's effectiveness by comparing the synthetic data\nagainst real agricultural images, demonstrating its potential to significantly\naugment training data for machine learning models in agriculture. This approach\nnot only provides a cost-effective solution for generating high-quality,\ndiverse data but also addresses specific needs in agricultural vision tasks\nthat are not fully covered by general-purpose models.\n","authors":["Mikolaj Cieslak","Umabharathi Govindarajan","Alejandro Garcia","Anuradha Chandrashekar","Torsten Hädrich","Aleksander Mendoza-Drosik","Dominik L. Michels","Sören Pirk","Chia-Chun Fu","Wojciech Pałubicki"],"pdf_url":"https://arxiv.org/pdf/2403.18351v1.pdf","comment":"10 pages, 8 figures, 3 tables"},{"id":"http://arxiv.org/abs/2403.18347v1","updated":"2024-03-27T08:38:56Z","published":"2024-03-27T08:38:56Z","title":"A Quantum Fuzzy-based Approach for Real-Time Detection of Solar Coronal\n  Holes","summary":"  The detection and analysis of the solar coronal holes (CHs) is an important\nfield of study in the domain of solar physics. Mainly, it is required for the\nproper prediction of the geomagnetic storms which directly or indirectly affect\nvarious space and ground-based systems. For the detection of CHs till date, the\nsolar scientist depends on manual hand-drawn approaches. However, with the\nadvancement of image processing technologies, some automated image segmentation\nmethods have been used for the detection of CHs. In-spite of this, fast and\naccurate detection of CHs are till a major issues. Here in this work, a novel\nquantum computing-based fast fuzzy c-mean technique has been developed for fast\ndetection of the CHs region. The task has been carried out in two stages, in\nfirst stage the solar image has been segmented using a quantum computing based\nfast fuzzy c-mean (QCFFCM) and in the later stage the CHs has been extracted\nout from the segmented image based on image morphological operation. In the\nwork, quantum computing has been used to optimize the cost function of the fast\nfuzzy c-mean (FFCM) algorithm, where quantum approximate optimization algorithm\n(QAOA) has been used to optimize the quadratic part of the cost function. The\nproposed method has been tested for 193 \\AA{} SDO/AIA full-disk solar image\ndatasets and has been compared with the existing techniques. The outcome shows\nthe comparable performance of the proposed method with the existing one within\na very lesser time.\n","authors":["Sanmoy Bandyopadhyay","Suman Kundu"],"pdf_url":"https://arxiv.org/pdf/2403.18347v1.pdf","comment":"14 pages, 5 figures, 3 tables"},{"id":"http://arxiv.org/abs/2403.18343v1","updated":"2024-03-27T08:34:39Z","published":"2024-03-27T08:34:39Z","title":"The Artificial Neural Twin -- Process Optimization and Continual\n  Learning in Distributed Process Chains","summary":"  Industrial process optimization and control is crucial to increase economic\nand ecologic efficiency. However, data sovereignty, differing goals, or the\nrequired expert knowledge for implementation impede holistic implementation.\nFurther, the increasing use of data-driven AI-methods in process models and\nindustrial sensory often requires regular fine-tuning to accommodate\ndistribution drifts. We propose the Artificial Neural Twin, which combines\nconcepts from model predictive control, deep learning, and sensor networks to\naddress these issues. Our approach introduces differentiable data fusion to\nestimate the state of distributed process steps and their dependence on input\ndata. By treating the interconnected process steps as a quasi neural-network,\nwe can backpropagate loss gradients for process optimization or model\nfine-tuning to process parameters or AI models respectively. The concept is\ndemonstrated on a virtual machine park simulated in Unity, consisting of bulk\nmaterial processes in plastic recycling.\n","authors":["Johannes Emmert","Ronald Mendez","Houman Mirzaalian Dastjerdi","Christopher Syben","Andreas Maier"],"pdf_url":"https://arxiv.org/pdf/2403.18343v1.pdf","comment":"20 pages, 11 figures"},{"id":"http://arxiv.org/abs/2403.18337v1","updated":"2024-03-27T08:21:41Z","published":"2024-03-27T08:21:41Z","title":"Macroscale fracture surface segmentation via semi-supervised learning\n  considering the structural similarity","summary":"  To this date the safety assessment of materials, used for example in the\nnuclear power sector, commonly relies on a fracture mechanical analysis\nutilizing macroscopic concepts, where a global load quantity K or J is compared\nto the materials fracture toughness curve. Part of the experimental effort\ninvolved in these concepts is dedicated to the quantitative analysis of\nfracture surfaces. Within the scope of this study a methodology for the\nsemi-supervised training of deep learning models for fracture surface\nsegmentation on a macroscopic level was established. Therefore, three distinct\nand unique datasets were created to analyze the influence of structural\nsimilarity on the segmentation capability. The structural similarity differs\ndue to the assessed materials and specimen, as well as imaging-induced variance\ndue to fluctuations in image acquisition in different laboratories. The\ndatasets correspond to typical isolated laboratory conditions, complex\nreal-world circumstances, and a curated subset of the two. We implemented a\nweak-to-strong consistency regularization for semi-supervised learning. On the\nheterogeneous dataset we were able to train robust and well-generalizing models\nthat learned feature representations from images across different domains\nwithout observing a significant drop in prediction quality. Furthermore, our\napproach reduced the number of labeled images required for training by a factor\nof 6. To demonstrate the success of our method and the benefit of our approach\nfor the fracture mechanics assessment, we utilized the models for initial crack\nsize measurements with the area average method. For the laboratory setting, the\ndeep learning assisted measurements proved to have the same quality as manual\nmeasurements. For models trained on the heterogeneous dataset, very good\nmeasurement accuracies with mean deviations smaller than 1 % could be\nachieved...\n","authors":["Johannes Rosenberger","Johannes Tlatlik","Sebastian Münstermann"],"pdf_url":"https://arxiv.org/pdf/2403.18337v1.pdf","comment":"During review title changed to: Deep learning based initial crack\n  size measurements utilizing macroscale fracture surface segmentation"},{"id":"http://arxiv.org/abs/2403.18336v1","updated":"2024-03-27T08:21:01Z","published":"2024-03-27T08:21:01Z","title":"A Dataset for Pharmacovigilance in German, French, and Japanese:\n  Annotating Adverse Drug Reactions across Languages","summary":"  User-generated data sources have gained significance in uncovering Adverse\nDrug Reactions (ADRs), with an increasing number of discussions occurring in\nthe digital world. However, the existing clinical corpora predominantly revolve\naround scientific articles in English. This work presents a multilingual corpus\nof texts concerning ADRs gathered from diverse sources, including patient fora,\nsocial media, and clinical reports in German, French, and Japanese. Our corpus\ncontains annotations covering 12 entity types, four attribute types, and 13\nrelation types. It contributes to the development of real-world multilingual\nlanguage models for healthcare. We provide statistics to highlight certain\nchallenges associated with the corpus and conduct preliminary experiments\nresulting in strong baselines for extracting entities and relations between\nthese entities, both within and across languages.\n","authors":["Lisa Raithel","Hui-Syuan Yeh","Shuntaro Yada","Cyril Grouin","Thomas Lavergne","Aurélie Névéol","Patrick Paroubek","Philippe Thomas","Tomohiro Nishiyama","Sebastian Möller","Eiji Aramaki","Yuji Matsumoto","Roland Roller","Pierre Zweigenbaum"],"pdf_url":"https://arxiv.org/pdf/2403.18336v1.pdf","comment":"Accepted at LREC-COLING 2024"},{"id":"http://arxiv.org/abs/2403.18330v1","updated":"2024-03-27T08:11:25Z","published":"2024-03-27T08:11:25Z","title":"Tracking-Assisted Object Detection with Event Cameras","summary":"  Event-based object detection has recently garnered attention in the computer\nvision community due to the exceptional properties of event cameras, such as\nhigh dynamic range and no motion blur. However, feature asynchronism and\nsparsity cause invisible objects due to no relative motion to the camera,\nposing a significant challenge in the task. Prior works have studied various\nmemory mechanisms to preserve as many features as possible at the current time,\nguided by temporal clues. While these implicit-learned memories retain some\nshort-term information, they still struggle to preserve long-term features\neffectively. In this paper, we consider those invisible objects as\npseudo-occluded objects and aim to reveal their features. Firstly, we introduce\nvisibility attribute of objects and contribute an auto-labeling algorithm to\nappend additional visibility labels on an existing event camera dataset.\nSecondly, we exploit tracking strategies for pseudo-occluded objects to\nmaintain their permanence and retain their bounding boxes, even when features\nhave not been available for a very long time. These strategies can be treated\nas an explicit-learned memory guided by the tracking objective to record the\ndisplacements of objects across frames. Lastly, we propose a spatio-temporal\nfeature aggregation module to enrich the latent features and a consistency loss\nto increase the robustness of the overall pipeline. We conduct comprehensive\nexperiments to verify our method's effectiveness where still objects are\nretained but real occluded objects are discarded. The results demonstrate that\n(1) the additional visibility labels can assist in supervised training, and (2)\nour method outperforms state-of-the-art approaches with a significant\nimprovement of 7.9% absolute mAP.\n","authors":["Ting-Kang Yen","Igor Morawski","Shusil Dangi","Kai He","Chung-Yi Lin","Jia-Fong Yeh","Hung-Ting Su","Winston Hsu"],"pdf_url":"https://arxiv.org/pdf/2403.18330v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18326v1","updated":"2024-03-27T08:07:07Z","published":"2024-03-27T08:07:07Z","title":"Privacy-Preserving Distributed Nonnegative Matrix Factorization","summary":"  Nonnegative matrix factorization (NMF) is an effective data representation\ntool with numerous applications in signal processing and machine learning.\nHowever, deploying NMF in a decentralized manner over ad-hoc networks\nintroduces privacy concerns due to the conventional approach of sharing raw\ndata among network agents. To address this, we propose a privacy-preserving\nalgorithm for fully-distributed NMF that decomposes a distributed large data\nmatrix into left and right matrix factors while safeguarding each agent's local\ndata privacy. It facilitates collaborative estimation of the left matrix factor\namong agents and enables them to estimate their respective right factors\nwithout exposing raw data. To ensure data privacy, we secure information\nexchanges between neighboring agents utilizing the Paillier cryptosystem, a\nprobabilistic asymmetric algorithm for public-key cryptography that allows\ncomputations on encrypted data without decryption. Simulation results conducted\non synthetic and real-world datasets demonstrate the effectiveness of the\nproposed algorithm in achieving privacy-preserving distributed NMF over ad-hoc\nnetworks.\n","authors":["Ehsan Lari","Reza Arablouei","Stefan Werner"],"pdf_url":"https://arxiv.org/pdf/2403.18326v1.pdf","comment":"5 pages, 1 figure, submitted to EUSIPCO 2024 conference"},{"id":"http://arxiv.org/abs/2403.18322v1","updated":"2024-03-27T07:52:10Z","published":"2024-03-27T07:52:10Z","title":"Quantum Algorithms: A New Frontier in Financial Crime Prevention","summary":"  Financial crimes fast proliferation and sophistication require novel\napproaches that provide robust and effective solutions. This paper explores the\npotential of quantum algorithms in combating financial crimes. It highlights\nthe advantages of quantum computing by examining traditional and Machine\nLearning (ML) techniques alongside quantum approaches. The study showcases\nadvanced methodologies such as Quantum Machine Learning (QML) and Quantum\nArtificial Intelligence (QAI) as powerful solutions for detecting and\npreventing financial crimes, including money laundering, financial crime\ndetection, cryptocurrency attacks, and market manipulation. These quantum\napproaches leverage the inherent computational capabilities of quantum\ncomputers to overcome limitations faced by classical methods. Furthermore, the\npaper illustrates how quantum computing can support enhanced financial risk\nmanagement analysis. Financial institutions can improve their ability to\nidentify and mitigate risks, leading to more robust risk management strategies\nby exploiting the quantum advantage. This research underscores the\ntransformative impact of quantum algorithms on financial risk management. By\nembracing quantum technologies, organisations can enhance their capabilities to\ncombat evolving threats and ensure the integrity and stability of financial\nsystems.\n","authors":["Abraham Itzhak Weinberg","Alessio Faccia"],"pdf_url":"https://arxiv.org/pdf/2403.18322v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18321v1","updated":"2024-03-27T07:50:45Z","published":"2024-03-27T07:50:45Z","title":"Implementation of the Principal Component Analysis onto High-Performance\n  Computer Facilities for Hyperspectral Dimensionality Reduction: Results and\n  Comparisons","summary":"  Dimensionality reduction represents a critical preprocessing step in order to\nincrease the efficiency and the performance of many hyperspectral imaging\nalgorithms. However, dimensionality reduction algorithms, such as the Principal\nComponent Analysis (PCA), suffer from their computationally demanding nature,\nbecoming advisable for their implementation onto high-performance computer\narchitectures for applications under strict latency constraints. This work\npresents the implementation of the PCA algorithm onto two different\nhigh-performance devices, namely, an NVIDIA Graphics Processing Unit (GPU) and\na Kalray manycore, uncovering a highly valuable set of tips and tricks in order\nto take full advantage of the inherent parallelism of these high-performance\ncomputing platforms, and hence, reducing the time that is required to process a\ngiven hyperspectral image. Moreover, the achieved results obtained with\ndifferent hyperspectral images have been compared with the ones that were\nobtained with a field programmable gate array (FPGA)-based implementation of\nthe PCA algorithm that has been recently published, providing, for the first\ntime in the literature, a comprehensive analysis in order to highlight the pros\nand cons of each option.\n","authors":["E. Martel","R. Lazcano","J. Lopez","D. Madroñal","R. Salvador","S. Lopez","E. Juarez","R. Guerra","C. Sanz","R. Sarmiento"],"pdf_url":"https://arxiv.org/pdf/2403.18321v1.pdf","comment":"30 pages, 10 figures"},{"id":"http://arxiv.org/abs/2403.18316v1","updated":"2024-03-27T07:38:36Z","published":"2024-03-27T07:38:36Z","title":"Multi-Modal Contrastive Learning for Online Clinical Time-Series\n  Applications","summary":"  Electronic Health Record (EHR) datasets from Intensive Care Units (ICU)\ncontain a diverse set of data modalities. While prior works have successfully\nleveraged multiple modalities in supervised settings, we apply advanced\nself-supervised multi-modal contrastive learning techniques to ICU data,\nspecifically focusing on clinical notes and time-series for clinically relevant\nonline prediction tasks. We introduce a loss function Multi-Modal Neighborhood\nContrastive Loss (MM-NCL), a soft neighborhood function, and showcase the\nexcellent linear probe and zero-shot performance of our approach.\n","authors":["Fabian Baldenweg","Manuel Burger","Gunnar Rätsch","Rita Kuznetsova"],"pdf_url":"https://arxiv.org/pdf/2403.18316v1.pdf","comment":"Accepted as a Workshop Paper at TS4H@ICLR2024"},{"id":"http://arxiv.org/abs/2403.12820v2","updated":"2024-03-27T07:35:47Z","published":"2024-03-19T15:21:00Z","title":"A Physics-embedded Deep Learning Framework for Cloth Simulation","summary":"  Delicate cloth simulations have long been desired in computer graphics.\nVarious methods were proposed to improve engaged force interactions, collision\nhandling, and numerical integrations. Deep learning has the potential to\nachieve fast and real-time simulation, but common neural network structures\noften demand many parameters to capture cloth dynamics. This paper proposes a\nphysics-embedded learning framework that directly encodes physical features of\ncloth simulation. The convolutional neural network is used to represent spatial\ncorrelations of the mass-spring system, after which three branches are designed\nto learn linear, nonlinear, and time derivate features of cloth physics. The\nframework can also integrate with other external forces and collision handling\nthrough either traditional simulators or sub neural networks. The model is\ntested across different cloth animation cases, without training with new data.\nAgreement with baselines and predictive realism successfully validate its\ngeneralization ability. Inference efficiency of the proposed model also defeats\ntraditional physics simulation. This framework is also designed to easily\nintegrate with other visual refinement techniques like wrinkle carving, which\nleaves significant chances to incorporate prevailing macing learning techniques\nin 3D cloth amination.\n","authors":["Zhiwei Zhao"],"pdf_url":"https://arxiv.org/pdf/2403.12820v2.pdf","comment":"A derivation is incomplete, and updations are being processed"},{"id":"http://arxiv.org/abs/2403.18310v1","updated":"2024-03-27T07:22:32Z","published":"2024-03-27T07:22:32Z","title":"A thermodynamically consistent physics-informed deep learning material\n  model for short fiber/polymer nanocomposites","summary":"  This work proposes a physics-informed deep learning (PIDL)-based constitutive\nmodel for investigating the viscoelastic-viscoplastic behavior of short\nfiber-reinforced nanoparticle-filled epoxies under various ambient conditions.\nThe deep-learning model is trained to enforce thermodynamic principles, leading\nto a thermodynamically consistent constitutive model. To accomplish this, a\nlong short-term memory network is combined with a feed-forward neural network\nto predict internal variables required for characterizing the internal\ndissipation of the nanocomposite materials. In addition, another feed-forward\nneural network is used to indicate the free-energy function, which enables\ndefining the thermodynamic state of the entire system. The PIDL model is\ninitially developed for the three-dimensional case by generating synthetic data\nfrom a classical constitutive model. The model is then trained by extracting\nthe data directly from cyclic loading-unloading experimental tests. Numerical\nexamples show that the PIDL model can accurately predict the mechanical\nbehavior of epoxy-based nanocomposites for different volume fractions of fibers\nand nanoparticles under various hygrothermal conditions.\n","authors":["Betim Bahtiri","Behrouz Arash","Sven Scheffler","Maximilian Jux","Raimund Rolfes"],"pdf_url":"https://arxiv.org/pdf/2403.18310v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2305.08102"},{"id":"http://arxiv.org/abs/2310.17072v3","updated":"2024-03-27T07:04:58Z","published":"2023-10-26T00:28:37Z","title":"MMP++: Motion Manifold Primitives with Parametric Curve Models","summary":"  Motion Manifold Primitives (MMP), a manifold-based approach for encoding\nbasic motion skills, can produce diverse trajectories, enabling the system to\nadapt to unseen constraints. Nonetheless, we argue that current MMP models lack\ncrucial functionalities of movement primitives, such as temporal and via-points\nmodulation, found in traditional approaches. This shortfall primarily stems\nfrom MMP's reliance on discrete-time trajectories. To overcome these\nlimitations, we introduce Motion Manifold Primitives++ (MMP++), a new model\nthat integrates the strengths of both MMP and traditional methods by\nincorporating parametric curve representations into the MMP framework.\nFurthermore, we identify a significant challenge with MMP++: performance\ndegradation due to geometric distortions in the latent space, meaning that\nsimilar motions are not closely positioned. To address this, Isometric Motion\nManifold Primitives++ (IMMP++) is proposed to ensure the latent space\naccurately preserves the manifold's geometry. Our experimental results across\nvarious applications, including 2-DoF planar motions, 7-DoF robot arm motions,\nand SE(3) trajectory planning, show that MMP++ and IMMP++ outperform existing\nmethods in trajectory generation tasks, achieving substantial improvements in\nsome cases. Moreover, they enable the modulation of latent coordinates and\nvia-points, thereby allowing efficient online adaptation to dynamic\nenvironments.\n","authors":["Yonghyeon Lee"],"pdf_url":"https://arxiv.org/pdf/2310.17072v3.pdf","comment":"12 pages. This work has been submitted to the IEEE for possible\n  publication"},{"id":"http://arxiv.org/abs/2403.18302v1","updated":"2024-03-27T06:58:01Z","published":"2024-03-27T06:58:01Z","title":"Super-Resolution of SOHO/MDI Magnetograms of Solar Active Regions Using\n  SDO/HMI Data and an Attention-Aided Convolutional Neural Network","summary":"  Image super-resolution has been an important subject in image processing and\nrecognition. Here, we present an attention-aided convolutional neural network\n(CNN) for solar image super-resolution. Our method, named SolarCNN, aims to\nenhance the quality of line-of-sight (LOS) magnetograms of solar active regions\n(ARs) collected by the Michelson Doppler Imager (MDI) on board the Solar and\nHeliospheric Observatory (SOHO). The ground-truth labels used for training\nSolarCNN are the LOS magnetograms collected by the Helioseismic and Magnetic\nImager (HMI) on board the Solar Dynamics Observatory (SDO). Solar ARs consist\nof strong magnetic fields in which magnetic energy can suddenly be released to\nproduce extreme space weather events, such as solar flares, coronal mass\nejections, and solar energetic particles. SOHO/MDI covers Solar Cycle 23, which\nis stronger with more eruptive events than Cycle 24. Enhanced SOHO/MDI\nmagnetograms allow for better understanding and forecasting of violent events\nof space weather. Experimental results show that SolarCNN improves the quality\nof SOHO/MDI magnetograms in terms of the structural similarity index measure\n(SSIM), Pearson's correlation coefficient (PCC), and the peak signal-to-noise\nratio (PSNR).\n","authors":["Chunhui Xu","Jason T. L. Wang","Haimin Wang","Haodi Jiang","Qin Li","Yasser Abduallah","Yan Xu"],"pdf_url":"https://arxiv.org/pdf/2403.18302v1.pdf","comment":"17 pages, 7 figures"},{"id":"http://arxiv.org/abs/2302.06912v4","updated":"2024-03-27T06:57:30Z","published":"2023-02-14T08:56:50Z","title":"Regret-Based Defense in Adversarial Reinforcement Learning","summary":"  Deep Reinforcement Learning (DRL) policies have been shown to be vulnerable\nto small adversarial noise in observations. Such adversarial noise can have\ndisastrous consequences in safety-critical environments. For instance, a\nself-driving car receiving adversarially perturbed sensory observations about\nnearby signs (e.g., a stop sign physically altered to be perceived as a speed\nlimit sign) or objects (e.g., cars altered to be recognized as trees) can be\nfatal. Existing approaches for making RL algorithms robust to an\nobservation-perturbing adversary have focused on reactive approaches that\niteratively improve against adversarial examples generated at each iteration.\nWhile such approaches have been shown to provide improvements over regular RL\nmethods, they are reactive and can fare significantly worse if certain\ncategories of adversarial examples are not generated during training. To that\nend, we pursue a more proactive approach that relies on directly optimizing a\nwell-studied robustness measure, regret instead of expected value. We provide a\nprincipled approach that minimizes maximum regret over a \"neighborhood\" of\nobservations to the received \"observation\". Our regret criterion can be used to\nmodify existing value- and policy-based Deep RL methods. We demonstrate that\nour approaches provide a significant improvement in performance across a wide\nvariety of benchmarks against leading approaches for robust Deep RL.\n","authors":["Roman Belaire","Pradeep Varakantham","Thanh Nguyen","David Lo"],"pdf_url":"https://arxiv.org/pdf/2302.06912v4.pdf","comment":"Accepted at AAMAS 2024"},{"id":"http://arxiv.org/abs/2403.18301v1","updated":"2024-03-27T06:55:23Z","published":"2024-03-27T06:55:23Z","title":"Selective Mixup Fine-Tuning for Optimizing Non-Decomposable Objectives","summary":"  The rise in internet usage has led to the generation of massive amounts of\ndata, resulting in the adoption of various supervised and semi-supervised\nmachine learning algorithms, which can effectively utilize the colossal amount\nof data to train models. However, before deploying these models in the real\nworld, these must be strictly evaluated on performance measures like worst-case\nrecall and satisfy constraints such as fairness. We find that current\nstate-of-the-art empirical techniques offer sub-optimal performance on these\npractical, non-decomposable performance objectives. On the other hand, the\ntheoretical techniques necessitate training a new model from scratch for each\nperformance objective. To bridge the gap, we propose SelMix, a selective\nmixup-based inexpensive fine-tuning technique for pre-trained models, to\noptimize for the desired objective. The core idea of our framework is to\ndetermine a sampling distribution to perform a mixup of features between\nsamples from particular classes such that it optimizes the given objective. We\ncomprehensively evaluate our technique against the existing empirical and\ntheoretically principled methods on standard benchmark datasets for imbalanced\nclassification. We find that proposed SelMix fine-tuning significantly improves\nthe performance for various practical non-decomposable objectives across\nbenchmarks.\n","authors":["Shrinivas Ramasubramanian","Harsh Rangwani","Sho Takemori","Kunal Samanta","Yuhei Umeda","Venkatesh Babu Radhakrishnan"],"pdf_url":"https://arxiv.org/pdf/2403.18301v1.pdf","comment":"ICLR 2024 SpotLight"},{"id":"http://arxiv.org/abs/2403.18296v1","updated":"2024-03-27T06:46:59Z","published":"2024-03-27T06:46:59Z","title":"GeNet: A Graph Neural Network-based Anti-noise Task-Oriented Semantic\n  Communication Paradigm","summary":"  Traditional approaches to semantic communication tasks rely on the knowledge\nof the signal-to-noise ratio (SNR) to mitigate channel noise. However, these\nmethods necessitate training under specific SNR conditions, entailing\nconsiderable time and computational resources. In this paper, we propose GeNet,\na Graph Neural Network (GNN)-based paradigm for semantic communication aimed at\ncombating noise, thereby facilitating Task-Oriented Communication (TOC). We\npropose a novel approach where we first transform the input data image into\ngraph structures. Then we leverage a GNN-based encoder to extract semantic\ninformation from the source data. This extracted semantic information is then\ntransmitted through the channel. At the receiver's end, a GNN-based decoder is\nutilized to reconstruct the relevant semantic information from the source data\nfor TOC. Through experimental evaluation, we show GeNet's effectiveness in\nanti-noise TOC while decoupling the SNR dependency. We further evaluate GeNet's\nperformance by varying the number of nodes, revealing its versatility as a new\nparadigm for semantic communication. Additionally, we show GeNet's robustness\nto geometric transformations by testing it with different rotation angles,\nwithout resorting to data augmentation.\n","authors":["Chunhang Zheng","Kechao Cai"],"pdf_url":"https://arxiv.org/pdf/2403.18296v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18286v1","updated":"2024-03-27T06:25:40Z","published":"2024-03-27T06:25:40Z","title":"Few-Shot Recalibration of Language Models","summary":"  Recent work has uncovered promising ways to extract well-calibrated\nconfidence estimates from language models (LMs), where the model's confidence\nscore reflects how likely it is to be correct. However, while LMs may appear\nwell-calibrated over broad distributions, this often hides significant\nmiscalibration within narrower slices (e.g., systemic over-confidence in math\ncan balance out systemic under-confidence in history, yielding perfect\ncalibration in aggregate). To attain well-calibrated confidence estimates for\nany slice of a distribution, we propose a new framework for few-shot\nslice-specific recalibration. Specifically, we train a recalibration model that\ntakes in a few unlabeled examples from any given slice and predicts a curve\nthat remaps confidence scores to be more accurate for that slice. Our trained\nmodel can recalibrate for arbitrary new slices, without using any labeled data\nfrom that slice. This enables us to identify domain-specific confidence\nthresholds above which the LM's predictions can be trusted, and below which it\nshould abstain. Experiments show that our few-shot recalibrator consistently\noutperforms existing calibration methods, for instance improving calibration\nerror for PaLM2-Large on MMLU by 16%, as compared to temperature scaling.\n","authors":["Xiang Lisa Li","Urvashi Khandelwal","Kelvin Guu"],"pdf_url":"https://arxiv.org/pdf/2403.18286v1.pdf","comment":"preprint"},{"id":"http://arxiv.org/abs/2403.18269v1","updated":"2024-03-27T05:50:23Z","published":"2024-03-27T05:50:23Z","title":"Clustering Change Sign Detection by Fusing Mixture Complexity","summary":"  This paper proposes an early detection method for cluster structural changes.\nCluster structure refers to discrete structural characteristics, such as the\nnumber of clusters, when data are represented using finite mixture models, such\nas Gaussian mixture models. We focused on scenarios in which the cluster\nstructure gradually changed over time. For finite mixture models, the concept\nof mixture complexity (MC) measures the continuous cluster size by considering\nthe cluster proportion bias and overlap between clusters. In this paper, we\npropose MC fusion as an extension of MC to handle situations in which multiple\nmixture numbers are possible in a finite mixture model. By incorporating the\nfusion of multiple models, our approach accurately captured the cluster\nstructure during transitional periods of gradual change. Moreover, we introduce\na method for detecting changes in the cluster structure by examining the\ntransition of MC fusion. We demonstrate the effectiveness of our method through\nempirical analysis using both artificial and real-world datasets.\n","authors":["Kento Urano","Ryo Yuki","Kenji Yamanishi"],"pdf_url":"https://arxiv.org/pdf/2403.18269v1.pdf","comment":"23 pages"},{"id":"http://arxiv.org/abs/2312.12558v2","updated":"2024-03-27T05:48:21Z","published":"2023-12-19T19:53:58Z","title":"Sample Efficient Reinforcement Learning with Partial Dynamics Knowledge","summary":"  The problem of sample complexity of online reinforcement learning is often\nstudied in the literature without taking into account any partial knowledge\nabout the system dynamics that could potentially accelerate the learning\nprocess. In this paper, we study the sample complexity of online Q-learning\nmethods when some prior knowledge about the dynamics is available or can be\nlearned efficiently. We focus on systems that evolve according to an additive\ndisturbance model of the form $S_{h+1} = f(S_h, A_h) + W_h$, where $f$\nrepresents the underlying system dynamics, and $W_h$ are unknown disturbances\nindependent of states and actions. In the setting of finite episodic Markov\ndecision processes with $S$ states, $A$ actions, and episode length $H$, we\npresent an optimistic Q-learning algorithm that achieves\n$\\tilde{\\mathcal{O}}(\\text{Poly}(H)\\sqrt{T})$ regret under perfect knowledge of\n$f$, where $T$ is the total number of interactions with the system. This is in\ncontrast to the typical $\\tilde{\\mathcal{O}}(\\text{Poly}(H)\\sqrt{SAT})$ regret\nfor existing Q-learning methods. Further, if only a noisy estimate $\\hat{f}$ of\n$f$ is available, our method can learn an approximately optimal policy in a\nnumber of samples that is independent of the cardinalities of state and action\nspaces. The sub-optimality gap depends on the approximation error $\\hat{f}-f$,\nas well as the Lipschitz constant of the corresponding optimal value function.\nOur approach does not require modeling of the transition probabilities and\nenjoys the same memory complexity as model-free methods.\n","authors":["Meshal Alharbi","Mardavij Roozbehani","Munther Dahleh"],"pdf_url":"https://arxiv.org/pdf/2312.12558v2.pdf","comment":"Published in the 38th Annual AAAI Conference on Artificial\n  Intelligence"},{"id":"http://arxiv.org/abs/2305.14258v2","updated":"2024-03-27T05:45:37Z","published":"2023-05-23T17:11:33Z","title":"Weakly Supervised AUC Optimization: A Unified Partial AUC Approach","summary":"  Since acquiring perfect supervision is usually difficult, real-world machine\nlearning tasks often confront inaccurate, incomplete, or inexact supervision,\ncollectively referred to as weak supervision. In this work, we present WSAUC, a\nunified framework for weakly supervised AUC optimization problems, which covers\nnoisy label learning, positive-unlabeled learning, multi-instance learning, and\nsemi-supervised learning scenarios. Within the WSAUC framework, we first frame\nthe AUC optimization problems in various weakly supervised scenarios as a\ncommon formulation of minimizing the AUC risk on contaminated sets, and\ndemonstrate that the empirical risk minimization problems are consistent with\nthe true AUC. Then, we introduce a new type of partial AUC, specifically, the\nreversed partial AUC (rpAUC), which serves as a robust training objective for\nAUC maximization in the presence of contaminated labels. WSAUC offers a\nuniversal solution for AUC optimization in various weakly supervised scenarios\nby maximizing the empirical rpAUC. Theoretical and experimental results under\nmultiple settings support the effectiveness of WSAUC on a range of weakly\nsupervised AUC optimization tasks.\n","authors":["Zheng Xie","Yu Liu","Hao-Yuan He","Ming Li","Zhi-Hua Zhou"],"pdf_url":"https://arxiv.org/pdf/2305.14258v2.pdf","comment":"Accepted by IEEE TPAMI"},{"id":"http://arxiv.org/abs/2403.18267v1","updated":"2024-03-27T05:41:50Z","published":"2024-03-27T05:41:50Z","title":"DSF-GAN: DownStream Feedback Generative Adversarial Network","summary":"  Utility and privacy are two crucial measurements of the quality of synthetic\ntabular data. While significant advancements have been made in privacy\nmeasures, generating synthetic samples with high utility remains challenging.\nTo enhance the utility of synthetic samples, we propose a novel architecture\ncalled the DownStream Feedback Generative Adversarial Network (DSF-GAN). This\napproach incorporates feedback from a downstream prediction model during\ntraining to augment the generator's loss function with valuable information.\nThus, DSF-GAN utilizes a downstream prediction task to enhance the utility of\nsynthetic samples. To evaluate our method, we tested it using two popular\ndatasets. Our experiments demonstrate improved model performance when training\non synthetic samples generated by DSF-GAN, compared to those generated by the\nsame GAN architecture without feedback. The evaluation was conducted on the\nsame validation set comprising real samples. All code and datasets used in this\nresearch will be made openly available for ease of reproduction.\n","authors":["Oriel Perets","Nadav Rappoport"],"pdf_url":"https://arxiv.org/pdf/2403.18267v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18266v1","updated":"2024-03-27T05:38:48Z","published":"2024-03-27T05:38:48Z","title":"Branch-Tuning: Balancing Stability and Plasticity for Continual\n  Self-Supervised Learning","summary":"  Self-supervised learning (SSL) has emerged as an effective paradigm for\nderiving general representations from vast amounts of unlabeled data. However,\nas real-world applications continually integrate new content, the high\ncomputational and resource demands of SSL necessitate continual learning rather\nthan complete retraining. This poses a challenge in striking a balance between\nstability and plasticity when adapting to new information. In this paper, we\nemploy Centered Kernel Alignment for quantitatively analyzing model stability\nand plasticity, revealing the critical roles of batch normalization layers for\nstability and convolutional layers for plasticity. Motivated by this, we\npropose Branch-tuning, an efficient and straightforward method that achieves a\nbalance between stability and plasticity in continual SSL. Branch-tuning\nconsists of branch expansion and compression, and can be easily applied to\nvarious SSL methods without the need of modifying the original methods,\nretaining old data or models. We validate our method through incremental\nexperiments on various benchmark datasets, demonstrating its effectiveness and\npractical value in real-world scenarios. We hope our work offers new insights\nfor future continual self-supervised learning research. The code will be made\npublicly available.\n","authors":["Wenzhuo Liu","Fei Zhu","Cheng-Lin Liu"],"pdf_url":"https://arxiv.org/pdf/2403.18266v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.02561v2","updated":"2024-03-27T05:23:40Z","published":"2024-02-04T16:27:37Z","title":"Foundation Model Makes Clustering A Better Initialization For Cold-Start\n  Active Learning","summary":"  Active learning selects the most informative samples from the unlabelled\ndataset to annotate in the context of a limited annotation budget. While\nnumerous methods have been proposed for subsequent sample selection based on an\ninitialized model, scant attention has been paid to the indispensable phase of\nactive learning: selecting samples for model cold-start initialization. Most of\nthe previous studies resort to random sampling or naive clustering. However,\nrandom sampling is prone to fluctuation, and naive clustering suffers from\nconvergence speed, particularly when dealing with high-dimensional data such as\nimaging data. In this work, we propose to integrate foundation models with\nclustering methods to select samples for cold-start active learning\ninitialization. Foundation models refer to those trained on massive datasets by\nthe self-supervised paradigm and capable of generating informative and\ncompacted embeddings for various downstream tasks. Leveraging these embeddings\nto replace raw features such as pixel values, clustering quickly converges and\nidentifies better initial samples. For a comprehensive comparison, we included\na classic ImageNet-supervised model to acquire embeddings. Experiments on two\nclinical tasks of image classification and segmentation demonstrated that\nfoundation model-based clustering efficiently pinpointed informative initial\nsamples, leading to models showcasing enhanced performance than the baseline\nmethods. We envisage that this study provides an effective paradigm for future\ncold-start active learning.\n","authors":["Han Yuan","Chuan Hong"],"pdf_url":"https://arxiv.org/pdf/2402.02561v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17458v2","updated":"2024-03-27T04:54:59Z","published":"2024-03-26T07:46:27Z","title":"Expectations Versus Reality: Evaluating Intrusion Detection Systems in\n  Practice","summary":"  Our paper provides empirical comparisons between recent IDSs to provide an\nobjective comparison between them to help users choose the most appropriate\nsolution based on their requirements. Our results show that no one solution is\nthe best, but is dependent on external variables such as the types of attacks,\ncomplexity, and network environment in the dataset. For example, BoT_IoT and\nStratosphere IoT datasets both capture IoT-related attacks, but the deep neural\nnetwork performed the best when tested using the BoT_IoT dataset while HELAD\nperformed the best when tested using the Stratosphere IoT dataset. So although\nwe found that a deep neural network solution had the highest average F1 scores\non tested datasets, it is not always the best-performing one. We further\ndiscuss difficulties in using IDS from literature and project repositories,\nwhich complicated drawing definitive conclusions regarding IDS selection.\n","authors":["Jake Hesford","Daniel Cheng","Alan Wan","Larry Huynh","Seungho Kim","Hyoungshick Kim","Jin B. Hong"],"pdf_url":"https://arxiv.org/pdf/2403.17458v2.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2312.07950v3","updated":"2024-03-27T04:51:51Z","published":"2023-12-13T07:56:27Z","title":"CBQ: Cross-Block Quantization for Large Language Models","summary":"  Post-training quantization (PTQ) has played a key role in compressing large\nlanguage models (LLMs) with ultra-low costs. However, existing PTQ methods only\nfocus on handling the outliers within one layer or one block, which ignores the\ndependency of blocks and leads to severe performance degradation in low-bit\nsettings. In this paper, we propose CBQ, a cross-block reconstruction-based PTQ\nmethod for LLMs. CBQ employs a cross-block dependency using a homologous\nreconstruction scheme, establishing long-range dependencies across multiple\nblocks to minimize error accumulation. Furthermore, CBQ incorporates a\ncoarse-to-fine preprocessing (CFP) strategy for suppressing weight and\nactivation outliers, coupled with an adaptive LoRA-Rounding technique for\nprecise weight quantization. These innovations enable CBQ to not only handle\nextreme outliers effectively but also improve overall quantization accuracy.\nExtensive experiments show that CBQ achieves superior low-bit quantization\n(W4A4, W4A8, W2A16) and outperforms existing state-of-the-art methods across\nvarious LLMs and datasets. Notably, CBQ quantizes the 4-bit LLAMA1-65B model\nwithin only 4.3 hours on a single GPU, achieving a commendable tradeoff between\nperformance and quantization efficiency.\n","authors":["Xin Ding","Xiaoyu Liu","Zhijun Tu","Yun Zhang","Wei Li","Jie Hu","Hanting Chen","Yehui Tang","Zhiwei Xiong","Baoqun Yin","Yunhe Wang"],"pdf_url":"https://arxiv.org/pdf/2312.07950v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18252v1","updated":"2024-03-27T04:49:23Z","published":"2024-03-27T04:49:23Z","title":"Beyond Embeddings: The Promise of Visual Table in Multi-Modal Models","summary":"  Visual representation learning has been a cornerstone in computer vision,\nevolving from supervised learning with human-annotated labels to aligning\nimage-text pairs from the Internet. Despite recent advancements in multi-modal\nlarge language models (MLLMs), the visual representations they rely on, such as\nCLIP embeddings, often lack access to external world knowledge critical for\nreal-world visual reasoning. In this work, we propose Visual Table, a novel\nvisual representation tailored for MLLMs. It provides hierarchical text\ndescriptions of holistic visual scenes, consisting of a scene description and\nmultiple object-centric descriptions that encompass categories, attributes, and\nknowledge at instance level. We further develop a scalable generator for visual\ntable generation and train it on small-scale annotations from GPT4V. Extensive\nevaluations demonstrate that, with generated visual tables as additional visual\nrepresentations, our model can consistently outperform the state-of-the-art\n(SOTA) MLLMs across diverse benchmarks. When visual tables serve as standalone\nvisual representations, our model can closely match or even beat the SOTA MLLMs\nthat are built on CLIP visual embeddings. Our code is available at\nhttps://github.com/LaVi-Lab/Visual-Table.\n","authors":["Yiwu Zhong","Zi-Yuan Hu","Michael R. Lyu","Liwei Wang"],"pdf_url":"https://arxiv.org/pdf/2403.18252v1.pdf","comment":"Project page: https://github.com/LaVi-Lab/Visual-Table"},{"id":"http://arxiv.org/abs/2401.16025v2","updated":"2024-03-27T04:36:17Z","published":"2024-01-29T10:17:54Z","title":"Simple Policy Optimization","summary":"  PPO (Proximal Policy Optimization) algorithm has demonstrated excellent\nperformance in many fields, and it is considered as a simple version of TRPO\n(Trust Region Policy Optimization) algorithm. However, the ratio clipping\noperation in PPO may not always effectively enforce the trust region\nconstraints, this can be a potential factor affecting the stability of the\nalgorithm. In this paper, we propose Simple Policy Optimization (SPO)\nalgorithm, which introduces a novel clipping method for KL divergence between\nthe old and current policies. Extensive experimental results in Atari 2600\nenvironments indicate that, compared to the mainstream variants of PPO, SPO\nachieves better sample efficiency, extremely low KL divergence, and higher\npolicy entropy, and is robust to the increase in network depth or complexity.\nMore importantly, SPO maintains the simplicity of an unconstrained first-order\nalgorithm. Code is available at\nhttps://github.com/MyRepositories-hub/Simple-Policy-Optimization.\n","authors":["Zhengpeng Xie"],"pdf_url":"https://arxiv.org/pdf/2401.16025v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18241v1","updated":"2024-03-27T04:09:34Z","published":"2024-03-27T04:09:34Z","title":"NeuSDFusion: A Spatial-Aware Generative Model for 3D Shape Completion,\n  Reconstruction, and Generation","summary":"  3D shape generation aims to produce innovative 3D content adhering to\nspecific conditions and constraints. Existing methods often decompose 3D shapes\ninto a sequence of localized components, treating each element in isolation\nwithout considering spatial consistency. As a result, these approaches exhibit\nlimited versatility in 3D data representation and shape generation, hindering\ntheir ability to generate highly diverse 3D shapes that comply with the\nspecified constraints. In this paper, we introduce a novel spatial-aware 3D\nshape generation framework that leverages 2D plane representations for enhanced\n3D shape modeling. To ensure spatial coherence and reduce memory usage, we\nincorporate a hybrid shape representation technique that directly learns a\ncontinuous signed distance field representation of the 3D shape using\northogonal 2D planes. Additionally, we meticulously enforce spatial\ncorrespondences across distinct planes using a transformer-based autoencoder\nstructure, promoting the preservation of spatial relationships in the generated\n3D shapes. This yields an algorithm that consistently outperforms\nstate-of-the-art 3D shape generation methods on various tasks, including\nunconditional shape generation, multi-modal shape completion, single-view\nreconstruction, and text-to-shape synthesis.\n","authors":["Ruikai Cui","Weizhe Liu","Weixuan Sun","Senbo Wang","Taizhang Shang","Yang Li","Xibin Song","Han Yan","Zhennan Wu","Shenzhou Chen","Hongdong Li","Pan Ji"],"pdf_url":"https://arxiv.org/pdf/2403.18241v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.08657v6","updated":"2024-03-27T03:53:23Z","published":"2022-06-17T09:42:35Z","title":"BridgeTower: Building Bridges Between Encoders in Vision-Language\n  Representation Learning","summary":"  Vision-Language (VL) models with the Two-Tower architecture have dominated\nvisual-language representation learning in recent years. Current VL models\neither use lightweight uni-modal encoders and learn to extract, align and fuse\nboth modalities simultaneously in a deep cross-modal encoder, or feed the\nlast-layer uni-modal representations from the deep pre-trained uni-modal\nencoders into the top cross-modal encoder. Both approaches potentially restrict\nvision-language representation learning and limit model performance. In this\npaper, we propose BridgeTower, which introduces multiple bridge layers that\nbuild a connection between the top layers of uni-modal encoders and each layer\nof the cross-modal encoder. This enables effective bottom-up cross-modal\nalignment and fusion between visual and textual representations of different\nsemantic levels of pre-trained uni-modal encoders in the cross-modal encoder.\nPre-trained with only 4M images, BridgeTower achieves state-of-the-art\nperformance on various downstream vision-language tasks. In particular, on the\nVQAv2 test-std set, BridgeTower achieves an accuracy of 78.73%, outperforming\nthe previous state-of-the-art model METER by 1.09% with the same pre-training\ndata and almost negligible additional parameters and computational costs.\nNotably, when further scaling the model, BridgeTower achieves an accuracy of\n81.15%, surpassing models that are pre-trained on orders-of-magnitude larger\ndatasets. Code and checkpoints are available at\nhttps://github.com/microsoft/BridgeTower.\n","authors":["Xiao Xu","Chenfei Wu","Shachar Rosenman","Vasudev Lal","Wanxiang Che","Nan Duan"],"pdf_url":"https://arxiv.org/pdf/2206.08657v6.pdf","comment":"Accepted by AAAI 2023, Oral"},{"id":"http://arxiv.org/abs/2301.11104v4","updated":"2024-03-27T03:47:20Z","published":"2023-01-26T13:58:46Z","title":"Discovering and Mitigating Visual Biases through Keyword Explanation","summary":"  Addressing biases in computer vision models is crucial for real-world AI\ndeployments. However, mitigating visual biases is challenging due to their\nunexplainable nature, often identified indirectly through visualization or\nsample statistics, which necessitates additional human supervision for\ninterpretation. To tackle this issue, we propose the Bias-to-Text (B2T)\nframework, which interprets visual biases as keywords. Specifically, we extract\ncommon keywords from the captions of mispredicted images to identify potential\nbiases in the model. We then validate these keywords by measuring their\nsimilarity to the mispredicted images using a vision-language scoring model.\nThe keyword explanation form of visual bias offers several advantages, such as\na clear group naming for bias discovery and a natural extension for debiasing\nusing these group names. Our experiments demonstrate that B2T can identify\nknown biases, such as gender bias in CelebA, background bias in Waterbirds, and\ndistribution shifts in ImageNet-R/C. Additionally, B2T uncovers novel biases in\nlarger datasets, such as Dollar Street and ImageNet. For example, we discovered\na contextual bias between \"bee\" and \"flower\" in ImageNet. We also highlight\nvarious applications of B2T keywords, including debiased training, CLIP\nprompting, and model comparison.\n","authors":["Younghyun Kim","Sangwoo Mo","Minkyu Kim","Kyungmin Lee","Jaeho Lee","Jinwoo Shin"],"pdf_url":"https://arxiv.org/pdf/2301.11104v4.pdf","comment":"CVPR 2024. First two authors contributed equally"},{"id":"http://arxiv.org/abs/2403.18233v1","updated":"2024-03-27T03:39:57Z","published":"2024-03-27T03:39:57Z","title":"Benchmarking Image Transformers for Prostate Cancer Detection from\n  Ultrasound Data","summary":"  PURPOSE: Deep learning methods for classifying prostate cancer (PCa) in\nultrasound images typically employ convolutional networks (CNNs) to detect\ncancer in small regions of interest (ROI) along a needle trace region. However,\nthis approach suffers from weak labelling, since the ground-truth\nhistopathology labels do not describe the properties of individual ROIs.\nRecently, multi-scale approaches have sought to mitigate this issue by\ncombining the context awareness of transformers with a CNN feature extractor to\ndetect cancer from multiple ROIs using multiple-instance learning (MIL). In\nthis work, we present a detailed study of several image transformer\narchitectures for both ROI-scale and multi-scale classification, and a\ncomparison of the performance of CNNs and transformers for ultrasound-based\nprostate cancer classification. We also design a novel multi-objective learning\nstrategy that combines both ROI and core predictions to further mitigate label\nnoise. METHODS: We evaluate 3 image transformers on ROI-scale cancer\nclassification, then use the strongest model to tune a multi-scale classifier\nwith MIL. We train our MIL models using our novel multi-objective learning\nstrategy and compare our results to existing baselines. RESULTS: We find that\nfor both ROI-scale and multi-scale PCa detection, image transformer backbones\nlag behind their CNN counterparts. This deficit in performance is even more\nnoticeable for larger models. When using multi-objective learning, we can\nimprove performance of MIL, with a 77.9% AUROC, a sensitivity of 75.9%, and a\nspecificity of 66.3%. CONCLUSION: Convolutional networks are better suited for\nmodelling sparse datasets of prostate ultrasounds, producing more robust\nfeatures than transformers in PCa detection. Multi-scale methods remain the\nbest architecture for this task, with multi-objective learning presenting an\neffective way to improve performance.\n","authors":["Mohamed Harmanani","Paul F. R. Wilson","Fahimeh Fooladgar","Amoon Jamzad","Mahdi Gilany","Minh Nguyen Nhat To","Brian Wodlinger","Purang Abolmaesumi","Parvin Mousavi"],"pdf_url":"https://arxiv.org/pdf/2403.18233v1.pdf","comment":"early draft, 7 pages; Accepted to SPIE Medical Imaging 2024"},{"id":"http://arxiv.org/abs/2403.18228v1","updated":"2024-03-27T03:31:16Z","published":"2024-03-27T03:31:16Z","title":"Fourier or Wavelet bases as counterpart self-attention in spikformer for\n  efficient visual classification","summary":"  Energy-efficient spikformer has been proposed by integrating the biologically\nplausible spiking neural network (SNN) and artificial Transformer, whereby the\nSpiking Self-Attention (SSA) is used to achieve both higher accuracy and lower\ncomputational cost. However, it seems that self-attention is not always\nnecessary, especially in sparse spike-form calculation manners. In this paper,\nwe innovatively replace vanilla SSA (using dynamic bases calculating from Query\nand Key) with spike-form Fourier Transform, Wavelet Transform, and their\ncombinations (using fixed triangular or wavelets bases), based on a key\nhypothesis that both of them use a set of basis functions for information\ntransformation. Hence, the Fourier-or-Wavelet-based spikformer (FWformer) is\nproposed and verified in visual classification tasks, including both static\nimage and event-based video datasets. The FWformer can achieve comparable or\neven higher accuracies ($0.4\\%$-$1.5\\%$), higher running speed ($9\\%$-$51\\%$\nfor training and $19\\%$-$70\\%$ for inference), reduced theoretical energy\nconsumption ($20\\%$-$25\\%$), and reduced GPU memory usage ($4\\%$-$26\\%$),\ncompared to the standard spikformer. Our result indicates the continuous\nrefinement of new Transformers, that are inspired either by biological\ndiscovery (spike-form), or information theory (Fourier or Wavelet Transform),\nis promising.\n","authors":["Qingyu Wang","Duzhen Zhang","Tilelin Zhang","Bo Xu"],"pdf_url":"https://arxiv.org/pdf/2403.18228v1.pdf","comment":"18 pages, 2 figures. arXiv admin note: substantial text overlap with\n  arXiv:2308.02557"},{"id":"http://arxiv.org/abs/2403.18223v1","updated":"2024-03-27T03:25:45Z","published":"2024-03-27T03:25:45Z","title":"A Transformer-Based Framework for Payload Malware Detection and\n  Classification","summary":"  As malicious cyber threats become more sophisticated in breaching computer\nnetworks, the need for effective intrusion detection systems (IDSs) becomes\ncrucial. Techniques such as Deep Packet Inspection (DPI) have been introduced\nto allow IDSs analyze the content of network packets, providing more context\nfor identifying potential threats. IDSs traditionally rely on using\nanomaly-based and signature-based detection techniques to detect unrecognized\nand suspicious activity. Deep learning techniques have shown great potential in\nDPI for IDSs due to their efficiency in learning intricate patterns from the\npacket content being transmitted through the network. In this paper, we propose\na revolutionary DPI algorithm based on transformers adapted for the purpose of\ndetecting malicious traffic with a classifier head. Transformers learn the\ncomplex content of sequence data and generalize them well to similar scenarios\nthanks to their self-attention mechanism. Our proposed method uses the raw\npayload bytes that represent the packet contents and is deployed as\nman-in-the-middle. The payload bytes are used to detect malicious packets and\nclassify their types. Experimental results on the UNSW-NB15 and CIC-IOT23\ndatasets demonstrate that our transformer-based model is effective in\ndistinguishing malicious from benign traffic in the test dataset, attaining an\naverage accuracy of 79\\% using binary classification and 72\\% on the\nmulti-classification experiment, both using solely payload bytes.\n","authors":["Kyle Stein","Arash Mahyari","Guillermo Francia III","Eman El-Sheikh"],"pdf_url":"https://arxiv.org/pdf/2403.18223v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18222v1","updated":"2024-03-27T03:19:36Z","published":"2024-03-27T03:19:36Z","title":"Uncertainty-Aware Deployment of Pre-trained Language-Conditioned\n  Imitation Learning Policies","summary":"  Large-scale robotic policies trained on data from diverse tasks and robotic\nplatforms hold great promise for enabling general-purpose robots; however,\nreliable generalization to new environment conditions remains a major\nchallenge. Toward addressing this challenge, we propose a novel approach for\nuncertainty-aware deployment of pre-trained language-conditioned imitation\nlearning agents. Specifically, we use temperature scaling to calibrate these\nmodels and exploit the calibrated model to make uncertainty-aware decisions by\naggregating the local information of candidate actions. We implement our\napproach in simulation using three such pre-trained models, and showcase its\npotential to significantly enhance task completion rates. The accompanying code\nis accessible at the link:\nhttps://github.com/BobWu1998/uncertainty_quant_all.git\n","authors":["Bo Wu","Bruce D. Lee","Kostas Daniilidis","Bernadette Bucher","Nikolai Matni"],"pdf_url":"https://arxiv.org/pdf/2403.18222v1.pdf","comment":"8 pages, 7 figures"},{"id":"http://arxiv.org/abs/2312.03256v2","updated":"2024-03-27T03:14:14Z","published":"2023-12-06T03:09:19Z","title":"CAFE: Towards Compact, Adaptive, and Fast Embedding for Large-scale\n  Recommendation Models","summary":"  Recently, the growing memory demands of embedding tables in Deep Learning\nRecommendation Models (DLRMs) pose great challenges for model training and\ndeployment. Existing embedding compression solutions cannot simultaneously meet\nthree key design requirements: memory efficiency, low latency, and adaptability\nto dynamic data distribution. This paper presents CAFE, a Compact, Adaptive,\nand Fast Embedding compression framework that addresses the above requirements.\nThe design philosophy of CAFE is to dynamically allocate more memory resources\nto important features (called hot features), and allocate less memory to\nunimportant ones. In CAFE, we propose a fast and lightweight sketch data\nstructure, named HotSketch, to capture feature importance and report hot\nfeatures in real time. For each reported hot feature, we assign it a unique\nembedding. For the non-hot features, we allow multiple features to share one\nembedding by using hash embedding technique. Guided by our design philosophy,\nwe further propose a multi-level hash embedding framework to optimize the\nembedding tables of non-hot features. We theoretically analyze the accuracy of\nHotSketch, and analyze the model convergence against deviation. Extensive\nexperiments show that CAFE significantly outperforms existing embedding\ncompression methods, yielding 3.92% and 3.68% superior testing AUC on Criteo\nKaggle dataset and CriteoTB dataset at a compression ratio of 10000x. The\nsource codes of CAFE are available at GitHub.\n","authors":["Hailin Zhang","Zirui Liu","Boxuan Chen","Yikai Zhao","Tong Zhao","Tong Yang","Bin Cui"],"pdf_url":"https://arxiv.org/pdf/2312.03256v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18219v1","updated":"2024-03-27T03:07:18Z","published":"2024-03-27T03:07:18Z","title":"From Two-Dimensional to Three-Dimensional Environment with Q-Learning:\n  Modeling Autonomous Navigation with Reinforcement Learning and no Libraries","summary":"  Reinforcement learning (RL) algorithms have become indispensable tools in\nartificial intelligence, empowering agents to acquire optimal decision-making\npolicies through interactions with their environment and feedback mechanisms.\nThis study explores the performance of RL agents in both two-dimensional (2D)\nand three-dimensional (3D) environments, aiming to research the dynamics of\nlearning across different spatial dimensions. A key aspect of this\ninvestigation is the absence of pre-made libraries for learning, with the\nalgorithm developed exclusively through computational mathematics. The\nmethodological framework centers on RL principles, employing a Q-learning agent\nclass and distinct environment classes tailored to each spatial dimension. The\nresearch aims to address the question: How do reinforcement learning agents\nadapt and perform in environments of varying spatial dimensions, particularly\nin 2D and 3D settings? Through empirical analysis, the study evaluates agents'\nlearning trajectories and adaptation processes, revealing insights into the\nefficacy of RL algorithms in navigating complex, multi-dimensional spaces.\nReflections on the findings prompt considerations for future research,\nparticularly in understanding the dynamics of learning in higher-dimensional\nenvironments.\n","authors":["Ergon Cugler de Moraes Silva"],"pdf_url":"https://arxiv.org/pdf/2403.18219v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18216v1","updated":"2024-03-27T02:59:04Z","published":"2024-03-27T02:59:04Z","title":"Minimax Optimal Fair Classification with Bounded Demographic Disparity","summary":"  Mitigating the disparate impact of statistical machine learning methods is\ncrucial for ensuring fairness. While extensive research aims to reduce\ndisparity, the effect of using a \\emph{finite dataset} -- as opposed to the\nentire population -- remains unclear. This paper explores the statistical\nfoundations of fair binary classification with two protected groups, focusing\non controlling demographic disparity, defined as the difference in acceptance\nrates between the groups. Although fairness may come at the cost of accuracy\neven with infinite data, we show that using a finite sample incurs additional\ncosts due to the need to estimate group-specific acceptance thresholds. We\nstudy the minimax optimal classification error while constraining demographic\ndisparity to a user-specified threshold. To quantify the impact of fairness\nconstraints, we introduce a novel measure called \\emph{fairness-aware excess\nrisk} and derive a minimax lower bound on this measure that all classifiers\nmust satisfy. Furthermore, we propose FairBayes-DDP+, a group-wise thresholding\nmethod with an offset that we show attains the minimax lower bound. Our lower\nbound proofs involve several innovations. Experiments support that\nFairBayes-DDP+ controls disparity at the user-specified level, while being\nfaster and having a more favorable fairness-accuracy tradeoff than several\nbaselines.\n","authors":["Xianli Zeng","Guang Cheng","Edgar Dobriban"],"pdf_url":"https://arxiv.org/pdf/2403.18216v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18658v1","updated":"2024-03-27T15:03:29Z","published":"2024-03-27T15:03:29Z","title":"Theoretical Guarantees for the Subspace-Constrained Tyler's Estimator","summary":"  This work analyzes the subspace-constrained Tyler's estimator (STE) designed\nfor recovering a low-dimensional subspace within a dataset that may be highly\ncorrupted with outliers. It assumes a weak inlier-outlier model and allows the\nfraction of inliers to be smaller than a fraction that leads to computational\nhardness of the robust subspace recovery problem. It shows that in this\nsetting, if the initialization of STE, which is an iterative algorithm,\nsatisfies a certain condition, then STE can effectively recover the underlying\nsubspace. It further shows that under the generalized haystack model, STE\ninitialized by the Tyler's M-estimator (TME), can recover the subspace when the\nfraction of iniliers is too small for TME to handle.\n","authors":["Gilad Lerman","Feng Yu","Teng Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.18658v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.16502v3","updated":"2024-03-27T13:40:27Z","published":"2023-10-25T09:44:16Z","title":"Assessing the overall and partial causal well-specification of nonlinear\n  additive noise models","summary":"  We propose a method to detect model misspecifications in nonlinear causal\nadditive and potentially heteroscedastic noise models. We aim to identify\npredictor variables for which we can infer the causal effect even in cases of\nsuch misspecification. We develop a general framework based on knowledge of the\nmultivariate observational data distribution. We then propose an algorithm for\nfinite sample data, discuss its asymptotic properties, and illustrate its\nperformance on simulated and real data.\n","authors":["Christoph Schultheiss","Peter Bühlmann"],"pdf_url":"https://arxiv.org/pdf/2310.16502v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.02158v4","updated":"2024-03-27T07:31:34Z","published":"2023-05-03T14:46:16Z","title":"Shotgun crystal structure prediction using machine-learned formation\n  energies","summary":"  Stable or metastable crystal structures of assembled atoms can be predicted\nby finding the global or local minima of the energy surface defined on the\nspace of the atomic configurations. Generally, this requires repeated\nfirst-principles energy calculations that are impractical for large systems,\nsuch as those containing more than 30 atoms in the unit cell. Here, we have\nmade significant progress in solving the crystal structure prediction problem\nwith a simple but powerful machine-learning workflow; using a machine-learning\nsurrogate for first-principles energy calculations, we performed non-iterative,\nsingle-shot screening using a large library of virtually created crystal\nstructures. The present method relies on two key technical components: transfer\nlearning, which enables a highly accurate energy prediction of pre-relaxed\ncrystalline states given only a small set of training samples from\nfirst-principles calculations, and generative models to create promising and\ndiverse crystal structures for screening. Here, first-principles calculations\nwere performed only to generate the training samples, and for the optimization\nof a dozen or fewer finally narrowed-down crystal structures. Our shotgun\nmethod proved to be computationally less demanding compared to conventional\nmethods, which heavily rely on iterations of first-principles calculations, and\nachieved an exceptional prediction accuracy, reaching 92.2% in a benchmark task\ninvolving the prediction of 90 different crystal structures.\n","authors":["Chang Liu","Hiromasa Tamaki","Tomoyasu Yokoyama","Kensuke Wakasugi","Satoshi Yotsuhashi","Minoru Kusaba","Ryo Yoshida"],"pdf_url":"https://arxiv.org/pdf/2305.02158v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18248v1","updated":"2024-03-27T04:39:13Z","published":"2024-03-27T04:39:13Z","title":"Statistical Inference of Optimal Allocations I: Regularities and their\n  Implications","summary":"  In this paper, we develp a functional differentiability approach for solving\nstatistical optimal allocation problems. We first derive Hadamard\ndifferentiability of the value function through a detailed analysis of the\ngeneral properties of the sorting operator. Central to our framework are the\nconcept of Hausdorff measure and the area and coarea integration formulas from\ngeometric measure theory. Building on our Hadamard differentiability results,\nwe demonstrate how the functional delta method can be used to directly derive\nthe asymptotic properties of the value function process for binary constrained\noptimal allocation problems, as well as the two-step ROC curve estimator.\nMoreover, leveraging profound insights from geometric functional analysis on\nconvex and local Lipschitz functionals, we obtain additional generic Fr\\'echet\ndifferentiability results for the value functions of optimal allocation\nproblems. These compelling findings motivate us to study carefully the first\norder approximation of the optimal social welfare. In this paper, we then\npresent a double / debiased estimator for the value functions. Importantly, the\nconditions outlined in the Hadamard differentiability section validate the\nmargin assumption from the statistical classification literature employing\nplug-in methods that justifies a faster convergence rate.\n","authors":["Kai Feng","Han Hong"],"pdf_url":"https://arxiv.org/pdf/2403.18248v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.08214v2","updated":"2024-03-27T01:59:13Z","published":"2023-11-14T14:50:46Z","title":"Frequentist Guarantees of Distributed (Non)-Bayesian Inference","summary":"  Motivated by the need to analyze large, decentralized datasets, distributed\nBayesian inference has become a critical research area across multiple fields,\nincluding statistics, electrical engineering, and economics. This paper\nestablishes Frequentist properties, such as posterior consistency, asymptotic\nnormality, and posterior contraction rates, for the distributed (non-)Bayes\nInference problem among agents connected via a communication network. Our\nresults show that, under appropriate assumptions on the communication graph,\ndistributed Bayesian inference retains parametric efficiency while enhancing\nrobustness in uncertainty quantification. We also explore the trade-off between\nstatistical efficiency and communication efficiency by examining how the design\nand size of the communication graph impact the posterior contraction rate.\nFurthermore, We extend our analysis to time-varying graphs and apply our\nresults to exponential family models, distributed logistic regression, and\ndecentralized detection models.\n","authors":["Bohan Wu","César A. Uribe"],"pdf_url":"https://arxiv.org/pdf/2311.08214v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.11138v3","updated":"2024-03-27T00:29:33Z","published":"2023-08-22T02:39:42Z","title":"NLP-based detection of systematic anomalies among the narratives of\n  consumer complaints","summary":"  We develop an NLP-based procedure for detecting systematic nonmeritorious\nconsumer complaints, simply called systematic anomalies, among complaint\nnarratives. While classification algorithms are used to detect pronounced\nanomalies, in the case of smaller and frequent systematic anomalies, the\nalgorithms may falter due to a variety of reasons, including technical ones as\nwell as natural limitations of human analysts. Therefore, as the next step\nafter classification, we convert the complaint narratives into quantitative\ndata, which are then analyzed using an algorithm for detecting systematic\nanomalies. We illustrate the entire procedure using complaint narratives from\nthe Consumer Complaint Database of the Consumer Financial Protection Bureau.\n","authors":["Peiheng Gao","Ning Sun","Xuefeng Wang","Chen Yang","Ričardas Zitikis"],"pdf_url":"https://arxiv.org/pdf/2308.11138v3.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2403.18755v1","updated":"2024-03-27T16:54:45Z","published":"2024-03-27T16:54:45Z","title":"Many-Objective Evolutionary Influence Maximization: Balancing Spread,\n  Budget, Fairness, and Time","summary":"  The Influence Maximization (IM) problem seeks to discover the set of nodes in\na graph that can spread the information propagation at most. This problem is\nknown to be NP-hard, and it is usually studied by maximizing the influence\n(spread) and, optionally, optimizing a second objective, such as minimizing the\nseed set size or maximizing the influence fairness. However, in many practical\nscenarios multiple aspects of the IM problem must be optimized at the same\ntime. In this work, we propose a first case study where several IM-specific\nobjective functions, namely budget, fairness, communities, and time, are\noptimized on top of the maximization of influence and minimization of the seed\nset size. To this aim, we introduce MOEIM (Many-Objective Evolutionary\nAlgorithm for Influence Maximization) a Multi-Objective Evolutionary Algorithm\n(MOEA) based on NSGA-II incorporating graph-aware operators and a smart\ninitialization. We compare MOEIM in two experimental settings, including a\ntotal of nine graph datasets, two heuristic methods, a related MOEA, and a\nstate-of-the-art Deep Learning approach. The experiments show that MOEIM\noverall outperforms the competitors in most of the tested many-objective\nsettings. To conclude, we also investigate the correlation between the\nobjectives, leading to novel insights into the topic. The codebase is available\nat https://github.com/eliacunegatti/MOEIM.\n","authors":["Elia Cunegatti","Leonardo Lucio Custode","Giovanni Iacca"],"pdf_url":"https://arxiv.org/pdf/2403.18755v1.pdf","comment":"To appear in Genetic and Evolutionary Computation Conference (GECCO\n  24 Companion), July 14 18, 2024, Melbourne, VIC, Australia. ACM, New York,\n  NY, USA"},{"id":"http://arxiv.org/abs/2403.18609v1","updated":"2024-03-27T14:26:41Z","published":"2024-03-27T14:26:41Z","title":"A survey on learning models of spiking neural membrane systems and\n  spiking neural networks","summary":"  Spiking neural networks (SNN) are a biologically inspired model of neural\nnetworks with certain brain-like properties. In the past few decades, this\nmodel has received increasing attention in computer science community, owing\nalso to the successful phenomenon of deep learning. In SNN, communication\nbetween neurons takes place through the spikes and spike trains. This\ndifferentiates these models from the ``standard'' artificial neural networks\n(ANN) where the frequency of spikes is replaced by real-valued signals. Spiking\nneural P systems (SNPS) can be considered a branch of SNN based more on the\nprinciples of formal automata, with many variants developed within the\nframework of the membrane computing theory. In this paper, we first briefly\ncompare structure and function, advantages and drawbacks of SNN and SNPS. A key\npart of the article is a survey of recent results and applications of machine\nlearning and deep learning models of both SNN and SNPS formalisms.\n","authors":["Prithwineel Paul","Petr Sosik","Lucie Ciencialova"],"pdf_url":"https://arxiv.org/pdf/2403.18609v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18228v1","updated":"2024-03-27T03:31:16Z","published":"2024-03-27T03:31:16Z","title":"Fourier or Wavelet bases as counterpart self-attention in spikformer for\n  efficient visual classification","summary":"  Energy-efficient spikformer has been proposed by integrating the biologically\nplausible spiking neural network (SNN) and artificial Transformer, whereby the\nSpiking Self-Attention (SSA) is used to achieve both higher accuracy and lower\ncomputational cost. However, it seems that self-attention is not always\nnecessary, especially in sparse spike-form calculation manners. In this paper,\nwe innovatively replace vanilla SSA (using dynamic bases calculating from Query\nand Key) with spike-form Fourier Transform, Wavelet Transform, and their\ncombinations (using fixed triangular or wavelets bases), based on a key\nhypothesis that both of them use a set of basis functions for information\ntransformation. Hence, the Fourier-or-Wavelet-based spikformer (FWformer) is\nproposed and verified in visual classification tasks, including both static\nimage and event-based video datasets. The FWformer can achieve comparable or\neven higher accuracies ($0.4\\%$-$1.5\\%$), higher running speed ($9\\%$-$51\\%$\nfor training and $19\\%$-$70\\%$ for inference), reduced theoretical energy\nconsumption ($20\\%$-$25\\%$), and reduced GPU memory usage ($4\\%$-$26\\%$),\ncompared to the standard spikformer. Our result indicates the continuous\nrefinement of new Transformers, that are inspired either by biological\ndiscovery (spike-form), or information theory (Fourier or Wavelet Transform),\nis promising.\n","authors":["Qingyu Wang","Duzhen Zhang","Tilelin Zhang","Bo Xu"],"pdf_url":"https://arxiv.org/pdf/2403.18228v1.pdf","comment":"18 pages, 2 figures. arXiv admin note: substantial text overlap with\n  arXiv:2308.02557"},{"id":"http://arxiv.org/abs/2403.18208v1","updated":"2024-03-27T02:39:23Z","published":"2024-03-27T02:39:23Z","title":"An Evolutionary Network Architecture Search Framework with Adaptive\n  Multimodal Fusion for Hand Gesture Recognition","summary":"  Hand gesture recognition (HGR) based on multimodal data has attracted\nconsiderable attention owing to its great potential in applications. Various\nmanually designed multimodal deep networks have performed well in multimodal\nHGR (MHGR), but most of existing algorithms require a lot of expert experience\nand time-consuming manual trials. To address these issues, we propose an\nevolutionary network architecture search framework with the adaptive multimodel\nfusion (AMF-ENAS). Specifically, we design an encoding space that\nsimultaneously considers fusion positions and ratios of the multimodal data,\nallowing for the automatic construction of multimodal networks with different\narchitectures through decoding. Additionally, we consider three input streams\ncorresponding to intra-modal surface electromyography (sEMG), intra-modal\naccelerometer (ACC), and inter-modal sEMG-ACC. To automatically adapt to\nvarious datasets, the ENAS framework is designed to automatically search a MHGR\nnetwork with appropriate fusion positions and ratios. To the best of our\nknowledge, this is the first time that ENAS has been utilized in MHGR to tackle\nissues related to the fusion position and ratio of multimodal data.\nExperimental results demonstrate that AMF-ENAS achieves state-of-the-art\nperformance on the Ninapro DB2, DB3, and DB7 datasets.\n","authors":["Yizhang Xia","Shihao Song","Zhanglu Hou","Junwen Xu","Juan Zou","Yuan Liu","Shengxiang Yang"],"pdf_url":"https://arxiv.org/pdf/2403.18208v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18162v1","updated":"2024-03-27T00:05:48Z","published":"2024-03-27T00:05:48Z","title":"Optimizing Cyber Response Time on Temporal Active Directory Networks\n  Using Decoys","summary":"  Microsoft Active Directory (AD) is the default security management system for\nWindow domain network. We study the problem of placing decoys in AD network to\ndetect potential attacks. We model the problem as a Stackelberg game between an\nattacker and a defender on AD attack graphs where the defender employs a set of\ndecoys to detect the attacker on their way to Domain Admin (DA). Contrary to\nprevious works, we consider time-varying (temporal) attack graphs. We proposed\na novel metric called response time, to measure the effectiveness of our decoy\nplacement in temporal attack graphs. Response time is defined as the duration\nfrom the moment attackers trigger the first decoy to when they compromise the\nDA. Our goal is to maximize the defender's response time to the worst-case\nattack paths. We establish the NP-hard nature of the defender's optimization\nproblem, leading us to develop Evolutionary Diversity Optimization (EDO)\nalgorithms. EDO algorithms identify diverse sets of high-quality solutions for\nthe optimization problem. Despite the polynomial nature of the fitness\nfunction, it proves experimentally slow for larger graphs. To enhance\nscalability, we proposed an algorithm that exploits the static nature of AD\ninfrastructure in the temporal setting. Then, we introduce tailored repair\noperations, ensuring the convergence to better results while maintaining\nscalability for larger graphs.\n","authors":["Huy Q. Ngo","Mingyu Guo","Hung Nguyen"],"pdf_url":"https://arxiv.org/pdf/2403.18162v1.pdf","comment":"To be appear in ACM GECCO 2024"}]},"2024-03-26T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2403.09887v2","updated":"2024-03-26T23:52:35Z","published":"2024-03-14T21:44:48Z","title":"Sabiá-2: A New Generation of Portuguese Large Language Models","summary":"  We introduce Sabi\\'a-2, a family of large language models trained on\nPortuguese texts. The models are evaluated on a diverse range of exams,\nincluding entry-level tests for Brazilian universities, professional\ncertification exams, and graduate-level exams for various disciplines such as\naccounting, economics, engineering, law and medicine. Our results reveal that\nour best model so far, Sabi\\'a-2 Medium, matches or surpasses GPT-4's\nperformance in 23 out of 64 exams and outperforms GPT-3.5 in 58 out of 64\nexams. Notably, specialization has a significant impact on a model's\nperformance without the need to increase its size, allowing us to offer\nSabi\\'a-2 Medium at a price per token that is 10 times cheaper than GPT-4.\nFinally, we identified that math and coding are key abilities that need\nimprovement.\n","authors":["Thales Sales Almeida","Hugo Abonizio","Rodrigo Nogueira","Ramon Pires"],"pdf_url":"https://arxiv.org/pdf/2403.09887v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18159v1","updated":"2024-03-26T23:51:44Z","published":"2024-03-26T23:51:44Z","title":"Oh! We Freeze: Improving Quantized Knowledge Distillation via Signal\n  Propagation Analysis for Large Language Models","summary":"  Large generative models, such as large language models (LLMs) and diffusion\nmodels have as revolutionized the fields of NLP and computer vision\nrespectively. However, their slow inference, high computation and memory\nrequirement makes it challenging to deploy them on edge devices. In this study,\nwe propose a light-weight quantization aware fine tuning technique using\nknowledge distillation (KD-QAT) to improve the performance of 4-bit weight\nquantized LLMs using commonly available datasets to realize a popular language\nuse case, on device chat applications. To improve this paradigm of finetuning,\nas main contributions, we provide insights into stability of KD-QAT by\nempirically studying the gradient propagation during training to better\nunderstand the vulnerabilities of KD-QAT based approaches to low-bit\nquantization errors. Based on our insights, we propose ov-freeze, a simple\ntechnique to stabilize the KD-QAT process. Finally, we experiment with the\npopular 7B LLaMAv2-Chat model at 4-bit quantization level and demonstrate that\nov-freeze results in near float-point precision performance, i.e., less than\n0.7% loss of accuracy on Commonsense Reasoning benchmarks.\n","authors":["Kartikeya Bhardwaj","Nilesh Prasad Pandey","Sweta Priyadarshi","Kyunggeun Lee","Jun Ma","Harris Teague"],"pdf_url":"https://arxiv.org/pdf/2403.18159v1.pdf","comment":"Accepted at Practical ML for Low Resource Settings Workshop at ICLR\n  2024"},{"id":"http://arxiv.org/abs/2403.18148v1","updated":"2024-03-26T23:14:34Z","published":"2024-03-26T23:14:34Z","title":"Large Language Models Produce Responses Perceived to be Empathic","summary":"  Large Language Models (LLMs) have demonstrated surprising performance on many\ntasks, including writing supportive messages that display empathy. Here, we had\nthese models generate empathic messages in response to posts describing common\nlife experiences, such as workplace situations, parenting, relationships, and\nother anxiety- and anger-eliciting situations. Across two studies (N=192, 202),\nwe showed human raters a variety of responses written by several models (GPT4\nTurbo, Llama2, and Mistral), and had people rate these responses on how\nempathic they seemed to be. We found that LLM-generated responses were\nconsistently rated as more empathic than human-written responses. Linguistic\nanalyses also show that these models write in distinct, predictable ``styles\",\nin terms of their use of punctuation, emojis, and certain words. These results\nhighlight the potential of using LLMs to enhance human peer support in contexts\nwhere empathy is important.\n","authors":["Yoon Kyung Lee","Jina Suh","Hongli Zhan","Junyi Jessy Li","Desmond C. Ong"],"pdf_url":"https://arxiv.org/pdf/2403.18148v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18145v1","updated":"2024-03-26T23:10:41Z","published":"2024-03-26T23:10:41Z","title":"A Real-Time Rescheduling Algorithm for Multi-robot Plan Execution","summary":"  One area of research in multi-agent path finding is to determine how\nreplanning can be efficiently achieved in the case of agents being delayed\nduring execution. One option is to reschedule the passing order of agents,\ni.e., the sequence in which agents visit the same location. In response, we\npropose Switchable-Edge Search (SES), an A*-style algorithm designed to find\noptimal passing orders. We prove the optimality of SES and evaluate its\nefficiency via simulations. The best variant of SES takes less than 1 second\nfor small- and medium-sized problems and runs up to 4 times faster than\nbaselines for large-sized problems.\n","authors":["Ying Feng","Adittyo Paul","Zhe Chen","Jiaoyang Li"],"pdf_url":"https://arxiv.org/pdf/2403.18145v1.pdf","comment":"ICAPS 2024"},{"id":"http://arxiv.org/abs/2303.09618v2","updated":"2024-03-26T22:59:52Z","published":"2023-03-16T19:47:41Z","title":"HIVE: Harnessing Human Feedback for Instructional Visual Editing","summary":"  Incorporating human feedback has been shown to be crucial to align text\ngenerated by large language models to human preferences. We hypothesize that\nstate-of-the-art instructional image editing models, where outputs are\ngenerated based on an input image and an editing instruction, could similarly\nbenefit from human feedback, as their outputs may not adhere to the correct\ninstructions and preferences of users. In this paper, we present a novel\nframework to harness human feedback for instructional visual editing (HIVE).\nSpecifically, we collect human feedback on the edited images and learn a reward\nfunction to capture the underlying user preferences. We then introduce scalable\ndiffusion model fine-tuning methods that can incorporate human preferences\nbased on the estimated reward. Besides, to mitigate the bias brought by the\nlimitation of data, we contribute a new 1M training dataset, a 3.6K reward\ndataset for rewards learning, and a 1K evaluation dataset to boost the\nperformance of instructional image editing. We conduct extensive empirical\nexperiments quantitatively and qualitatively, showing that HIVE is favored over\nprevious state-of-the-art instructional image editing approaches by a large\nmargin.\n","authors":["Shu Zhang","Xinyi Yang","Yihao Feng","Can Qin","Chia-Chih Chen","Ning Yu","Zeyuan Chen","Huan Wang","Silvio Savarese","Stefano Ermon","Caiming Xiong","Ran Xu"],"pdf_url":"https://arxiv.org/pdf/2303.09618v2.pdf","comment":"In CVPR, 2024"},{"id":"http://arxiv.org/abs/2403.18140v1","updated":"2024-03-26T22:54:12Z","published":"2024-03-26T22:54:12Z","title":"Juru: Legal Brazilian Large Language Model from Reputable Sources","summary":"  The high computational cost associated with pretraining large language models\nlimits their research. Two strategies have emerged to address this issue:\ndomain specialization and pretraining with high-quality data. To explore these\nstrategies, we specialized the Sabi\\'a-2 Small model with 1.9 billion unique\ntokens from reputable Brazilian legal sources and conducted few-shot\nevaluations on legal and general knowledge exams. Our model, Juru, demonstrates\nthe benefits of domain specialization with a reduced amount of pretraining\ndata. However, this specialization comes at the expense of degrading\nperformance in other knowledge areas within the same language. This study\ncontributes to the growing body of scientific evidence showing that pretraining\ndata selection may enhance the performance of large language models, enabling\nthe exploration of these models at a lower cost.\n","authors":["Roseval Malaquias Junior","Ramon Pires","Roseli Romero","Rodrigo Nogueira"],"pdf_url":"https://arxiv.org/pdf/2403.18140v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.05677v2","updated":"2024-03-26T22:53:56Z","published":"2023-12-09T20:51:48Z","title":"Batched Low-Rank Adaptation of Foundation Models","summary":"  Low-Rank Adaptation (LoRA) has recently gained attention for fine-tuning\nfoundation models by incorporating trainable low-rank matrices, thereby\nreducing the number of trainable parameters. While LoRA offers numerous\nadvantages, its applicability for real-time serving to a diverse and global\nuser base is constrained by its incapability to handle multiple task-specific\nadapters efficiently. This imposes a performance bottleneck in scenarios\nrequiring personalized, task-specific adaptations for each incoming request. To\nmitigate this constraint, we introduce Fast LoRA (FLoRA), a framework in which\neach input example in a minibatch can be associated with its unique low-rank\nadaptation weights, allowing for efficient batching of heterogeneous requests.\nWe empirically demonstrate that FLoRA retains the performance merits of LoRA,\nshowcasing competitive results on the MultiPL-E code generation benchmark\nspanning over 8 languages and a multilingual speech recognition task across 6\nlanguages.\n","authors":["Yeming Wen","Swarat Chaudhuri"],"pdf_url":"https://arxiv.org/pdf/2312.05677v2.pdf","comment":"16 pages, 3 figures"},{"id":"http://arxiv.org/abs/2403.18136v1","updated":"2024-03-26T22:41:41Z","published":"2024-03-26T22:41:41Z","title":"Securing GNNs: Explanation-Based Identification of Backdoored Training\n  Graphs","summary":"  Graph Neural Networks (GNNs) have gained popularity in numerous domains, yet\nthey are vulnerable to backdoor attacks that can compromise their performance\nand ethical application. The detection of these attacks is crucial for\nmaintaining the reliability and security of GNN classification tasks, but\neffective detection techniques are lacking. Following an initial investigation,\nwe observed that while graph-level explanations can offer limited insights,\ntheir effectiveness in detecting backdoor triggers is inconsistent and\nincomplete. To bridge this gap, we extract and transform secondary outputs of\nGNN explanation mechanisms, designing seven novel metrics that more effectively\ndetect backdoor attacks. Additionally, we develop an adaptive attack to\nrigorously evaluate our approach. We test our method on multiple benchmark\ndatasets and examine its efficacy against various attack models. Our results\nshow that our method can achieve high detection performance, marking a\nsignificant advancement in safeguarding GNNs against backdoor attacks.\n","authors":["Jane Downer","Ren Wang","Binghui Wang"],"pdf_url":"https://arxiv.org/pdf/2403.18136v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18133v1","updated":"2024-03-26T22:28:43Z","published":"2024-03-26T22:28:43Z","title":"AE SemRL: Learning Semantic Association Rules with Autoencoders","summary":"  Association Rule Mining (ARM) is the task of learning associations among data\nfeatures in the form of logical rules. Mining association rules from\nhigh-dimensional numerical data, for example, time series data from a large\nnumber of sensors in a smart environment, is a computationally intensive task.\nIn this study, we propose an Autoencoder-based approach to learn and extract\nassociation rules from time series data (AE SemRL). Moreover, we argue that in\nthe presence of semantic information related to time series data sources,\nsemantics can facilitate learning generalizable and explainable association\nrules. Despite enriching time series data with additional semantic features, AE\nSemRL makes learning association rules from high-dimensional data feasible. Our\nexperiments show that semantic association rules can be extracted from a latent\nrepresentation created by an Autoencoder and this method has in the order of\nhundreds of times faster execution time than state-of-the-art ARM approaches in\nmany scenarios. We believe that this study advances a new way of extracting\nassociations from representations and has the potential to inspire more\nresearch in this field.\n","authors":["Erkan Karabulut","Victoria Degeler","Paul Groth"],"pdf_url":"https://arxiv.org/pdf/2403.18133v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18132v1","updated":"2024-03-26T22:26:39Z","published":"2024-03-26T22:26:39Z","title":"Recommendation of data-free class-incremental learning algorithms by\n  simulating future data","summary":"  Class-incremental learning deals with sequential data streams composed of\nbatches of classes. Various algorithms have been proposed to address the\nchallenging case where samples from past classes cannot be stored. However,\nselecting an appropriate algorithm for a user-defined setting is an open\nproblem, as the relative performance of these algorithms depends on the\nincremental settings. To solve this problem, we introduce an algorithm\nrecommendation method that simulates the future data stream. Given an initial\nset of classes, it leverages generative models to simulate future classes from\nthe same visual domain. We evaluate recent algorithms on the simulated stream\nand recommend the one which performs best in the user-defined incremental\nsetting. We illustrate the effectiveness of our method on three large datasets\nusing six algorithms and six incremental settings. Our method outperforms\ncompetitive baselines, and performance is close to that of an oracle choosing\nthe best algorithm in each setting. This work contributes to facilitate the\npractical deployment of incremental learning.\n","authors":["Eva Feillet","Adrian Popescu","Céline Hudelot"],"pdf_url":"https://arxiv.org/pdf/2403.18132v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18120v1","updated":"2024-03-26T22:01:13Z","published":"2024-03-26T22:01:13Z","title":"Don't Trust: Verify -- Grounding LLM Quantitative Reasoning with\n  Autoformalization","summary":"  Large language models (LLM), such as Google's Minerva and OpenAI's GPT\nfamilies, are becoming increasingly capable of solving mathematical\nquantitative reasoning problems. However, they still make unjustified logical\nand computational errors in their reasoning steps and answers. In this paper,\nwe leverage the fact that if the training corpus of LLMs contained sufficiently\nmany examples of formal mathematics (e.g. in Isabelle, a formal theorem proving\nenvironment), they can be prompted to translate i.e. autoformalize informal\nmathematical statements into formal Isabelle code -- which can be verified\nautomatically for internal consistency. This provides a mechanism to\nautomatically reject solutions whose formalized versions are inconsistent\nwithin themselves or with the formalized problem statement. We evaluate our\nmethod on GSM8K, MATH and MultiArith datasets and demonstrate that our approach\nprovides a consistently better heuristic than vanilla majority voting -- the\npreviously best method to identify correct answers, by more than 12% on GSM8K.\nIn our experiments it improves results consistently across all datasets and LLM\nmodel sizes. The code can be found at https://github.com/jinpz/dtv.\n","authors":["Jin Peng Zhou","Charles Staats","Wenda Li","Christian Szegedy","Kilian Q. Weinberger","Yuhuai Wu"],"pdf_url":"https://arxiv.org/pdf/2403.18120v1.pdf","comment":"ICLR 2024"},{"id":"http://arxiv.org/abs/2403.18152v1","updated":"2024-03-26T23:32:52Z","published":"2024-03-26T23:32:52Z","title":"Large Language Models as Financial Data Annotators: A Study on\n  Effectiveness and Efficiency","summary":"  Collecting labeled datasets in finance is challenging due to scarcity of\ndomain experts and higher cost of employing them. While Large Language Models\n(LLMs) have demonstrated remarkable performance in data annotation tasks on\ngeneral domain datasets, their effectiveness on domain specific datasets\nremains underexplored. To address this gap, we investigate the potential of\nLLMs as efficient data annotators for extracting relations in financial\ndocuments. We compare the annotations produced by three LLMs (GPT-4, PaLM 2,\nand MPT Instruct) against expert annotators and crowdworkers. We demonstrate\nthat the current state-of-the-art LLMs can be sufficient alternatives to\nnon-expert crowdworkers. We analyze models using various prompts and parameter\nsettings and find that customizing the prompts for each relation group by\nproviding specific examples belonging to those groups is paramount.\nFurthermore, we introduce a reliability index (LLM-RelIndex) used to identify\noutputs that may require expert attention. Finally, we perform an extensive\ntime, cost and error analysis and provide recommendations for the collection\nand usage of automated annotations in domain-specific settings.\n","authors":["Toyin Aguda","Suchetha Siddagangappa","Elena Kochkina","Simerjot Kaur","Dongsheng Wang","Charese Smiley","Sameena Shah"],"pdf_url":"https://arxiv.org/pdf/2403.18152v1.pdf","comment":"Accepted to LREC-COLING 2024"},{"id":"http://arxiv.org/abs/2310.19055v2","updated":"2024-03-26T22:59:36Z","published":"2023-10-29T16:02:46Z","title":"A Few-Shot Learning Focused Survey on Recent Named Entity Recognition\n  and Relation Classification Methods","summary":"  Named Entity Recognition (NER) and Relation Classification (RC) are important\nsteps in extracting information from unstructured text and formatting it into a\nmachine-readable format. We present a survey of recent deep learning models\nthat address named entity recognition and relation classification, with focus\non few-shot learning performance. Our survey is helpful for researchers in\nknowing the recent techniques in text mining and extracting structured\ninformation from raw text.\n","authors":["Sakher Khalil Alqaaidi","Elika Bozorgi","Afsaneh Shams","Krzysztof Kochut"],"pdf_url":"https://arxiv.org/pdf/2310.19055v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.05882v2","updated":"2024-03-26T22:54:48Z","published":"2023-06-09T13:24:27Z","title":"Good, but not always Fair: An Evaluation of Gender Bias for three\n  commercial Machine Translation Systems","summary":"  Machine Translation (MT) continues to make significant strides in quality and\nis increasingly adopted on a larger scale. Consequently, analyses have been\nredirected to more nuanced aspects, intricate phenomena, as well as potential\nrisks that may arise from the widespread use of MT tools. Along this line, this\npaper offers a meticulous assessment of three commercial MT systems - Google\nTranslate, DeepL, and Modern MT - with a specific focus on gender translation\nand bias. For three language pairs (English/Spanish, English/Italian, and\nEnglish/French), we scrutinize the behavior of such systems at several levels\nof granularity and on a variety of naturally occurring gender phenomena in\ntranslation. Our study takes stock of the current state of online MT tools, by\nrevealing significant discrepancies in the gender translation of the three\nsystems, with each system displaying varying degrees of bias despite their\noverall translation quality.\n","authors":["Silvia Alma Piazzolla","Beatrice Savoldi","Luisa Bentivogli"],"pdf_url":"https://arxiv.org/pdf/2306.05882v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18125v1","updated":"2024-03-26T22:08:33Z","published":"2024-03-26T22:08:33Z","title":"For those who don't know (how) to ask: Building a dataset of technology\n  questions for digital newcomers","summary":"  While the rise of large language models (LLMs) has created rich new\nopportunities to learn about digital technology, many on the margins of this\ntechnology struggle to gain and maintain competency due to lexical or\nconceptual barriers that prevent them from asking appropriate questions.\nAlthough there have been many efforts to understand factuality of LLM-created\ncontent and ability of LLMs to answer questions, it is not well understood how\nunclear or nonstandard language queries affect the model outputs. We propose\nthe creation of a dataset that captures questions of digital newcomers and\noutsiders, utilizing data we have compiled from a decade's worth of one-on-one\ntutoring. In this paper we lay out our planned efforts and some potential uses\nof this dataset.\n","authors":["Evan Lucas","Kelly S. Steelman","Leo C. Ureel","Charles Wallace"],"pdf_url":"https://arxiv.org/pdf/2403.18125v1.pdf","comment":"Presented at the AI4ED workshop at AAAI 2024"},{"id":"http://arxiv.org/abs/2403.18121v1","updated":"2024-03-26T22:01:13Z","published":"2024-03-26T22:01:13Z","title":"ChatGPT Role-play Dataset: Analysis of User Motives and Model\n  Naturalness","summary":"  Recent advances in interactive large language models like ChatGPT have\nrevolutionized various domains; however, their behavior in natural and\nrole-play conversation settings remains underexplored. In our study, we address\nthis gap by deeply investigating how ChatGPT behaves during conversations in\ndifferent settings by analyzing its interactions in both a normal way and a\nrole-play setting. We introduce a novel dataset of broad range of human-AI\nconversations annotated with user motives and model naturalness to examine (i)\nhow humans engage with the conversational AI model, and (ii) how natural are AI\nmodel responses. Our study highlights the diversity of user motives when\ninteracting with ChatGPT and variable AI naturalness, showing not only the\nnuanced dynamics of natural conversations between humans and AI, but also\nproviding new avenues for improving the effectiveness of human-AI\ncommunication.\n","authors":["Yufei Tao","Ameeta Agrawal","Judit Dombi","Tetyana Sydorenko","Jung In Lee"],"pdf_url":"https://arxiv.org/pdf/2403.18121v1.pdf","comment":"Accepted by LREC-COLING 2024"},{"id":"http://arxiv.org/abs/2306.03997v3","updated":"2024-03-26T21:32:51Z","published":"2023-06-06T20:19:33Z","title":"Sentiment Analysis in Finance: From Transformers Back to eXplainable\n  Lexicons (XLex)","summary":"  Lexicon-based sentiment analysis (SA) in finance leverages specialized,\nmanually annotated lexicons created by human experts to extract sentiment from\nfinancial texts. Although lexicon-based methods are simple to implement and\nfast to operate on textual data, they require considerable manual annotation\nefforts to create, maintain, and update the lexicons. These methods are also\nconsidered inferior to the deep learning-based approaches, such as transformer\nmodels, which have become dominant in various NLP tasks due to their remarkable\nperformance. However, transformers require extensive data and computational\nresources for both training and testing. Additionally, they involve significant\nprediction times, making them unsuitable for real-time production environments\nor systems with limited processing capabilities. In this paper, we introduce a\nnovel methodology named eXplainable Lexicons (XLex) that combines the\nadvantages of both lexicon-based methods and transformer models. We propose an\napproach that utilizes transformers and SHapley Additive exPlanations (SHAP)\nfor explainability to learn financial lexicons. Our study presents four main\ncontributions. Firstly, we demonstrate that transformer-aided explainable\nlexicons can enhance the vocabulary coverage of the benchmark Loughran-McDonald\n(LM) lexicon, reducing the human involvement in annotating, maintaining, and\nupdating the lexicons. Secondly, we show that the resulting lexicon outperforms\nthe standard LM lexicon in SA of financial datasets. Thirdly, we illustrate\nthat the lexicon-based approach is significantly more efficient in terms of\nmodel speed and size compared to transformers. Lastly, the XLex approach is\ninherently more interpretable than transformer models as lexicon models rely on\npredefined rules, allowing for better insights into the results of SA and\nmaking the XLex approach a viable tool for financial decision-making.\n","authors":["Maryan Rizinski","Hristijan Peshov","Kostadin Mishev","Milos Jovanovik","Dimitar Trajanov"],"pdf_url":"https://arxiv.org/pdf/2306.03997v3.pdf","comment":"Published by IEEE Access DOI: 10.1109/ACCESS.2024.3349970 Link:\n  https://ieeexplore.ieee.org/document/10380556"},{"id":"http://arxiv.org/abs/2403.18105v1","updated":"2024-03-26T21:04:29Z","published":"2024-03-26T21:04:29Z","title":"Large Language Models for Education: A Survey and Outlook","summary":"  The advent of Large Language Models (LLMs) has brought in a new era of\npossibilities in the realm of education. This survey paper summarizes the\nvarious technologies of LLMs in educational settings from multifaceted\nperspectives, encompassing student and teacher assistance, adaptive learning,\nand commercial tools. We systematically review the technological advancements\nin each perspective, organize related datasets and benchmarks, and identify the\nrisks and challenges associated with deploying LLMs in education. Furthermore,\nwe outline future research opportunities, highlighting the potential promising\ndirections. Our survey aims to provide a comprehensive technological picture\nfor educators, researchers, and policymakers to harness the power of LLMs to\nrevolutionize educational practices and foster a more effective personalized\nlearning environment.\n","authors":["Shen Wang","Tianlong Xu","Hang Li","Chaoli Zhang","Joleen Liang","Jiliang Tang","Philip S. Yu","Qingsong Wen"],"pdf_url":"https://arxiv.org/pdf/2403.18105v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18098v1","updated":"2024-03-26T20:47:32Z","published":"2024-03-26T20:47:32Z","title":"GPTs and Language Barrier: A Cross-Lingual Legal QA Examination","summary":"  In this paper, we explore the application of Generative Pre-trained\nTransformers (GPTs) in cross-lingual legal Question-Answering (QA) systems\nusing the COLIEE Task 4 dataset. In the COLIEE Task 4, given a statement and a\nset of related legal articles that serve as context, the objective is to\ndetermine whether the statement is legally valid, i.e., if it can be inferred\nfrom the provided contextual articles or not, which is also known as an\nentailment task. By benchmarking four different combinations of English and\nJapanese prompts and data, we provide valuable insights into GPTs' performance\nin multilingual legal QA scenarios, contributing to the development of more\nefficient and accurate cross-lingual QA solutions in the legal domain.\n","authors":["Ha-Thanh Nguyen","Hiroaki Yamada","Ken Satoh"],"pdf_url":"https://arxiv.org/pdf/2403.18098v1.pdf","comment":"NLP 2024, Kobe, Japan"},{"id":"http://arxiv.org/abs/2403.18093v1","updated":"2024-03-26T20:25:53Z","published":"2024-03-26T20:25:53Z","title":"Enhancing Legal Document Retrieval: A Multi-Phase Approach with Large\n  Language Models","summary":"  Large language models with billions of parameters, such as GPT-3.5, GPT-4,\nand LLaMA, are increasingly prevalent. Numerous studies have explored effective\nprompting techniques to harness the power of these LLMs for various research\nproblems. Retrieval, specifically in the legal data domain, poses a challenging\ntask for the direct application of Prompting techniques due to the large number\nand substantial length of legal articles. This research focuses on maximizing\nthe potential of prompting by placing it as the final phase of the retrieval\nsystem, preceded by the support of two phases: BM25 Pre-ranking and BERT-based\nRe-ranking. Experiments on the COLIEE 2023 dataset demonstrate that integrating\nprompting techniques on LLMs into the retrieval system significantly improves\nretrieval accuracy. However, error analysis reveals several existing issues in\nthe retrieval system that still need resolution.\n","authors":["Hai-Long Nguyen","Duc-Minh Nguyen","Tan-Minh Nguyen","Ha-Thanh Nguyen","Thi-Hai-Yen Vuong","Ken Satoh"],"pdf_url":"https://arxiv.org/pdf/2403.18093v1.pdf","comment":"JURISIN 2024"},{"id":"http://arxiv.org/abs/2402.09654v2","updated":"2024-03-26T20:12:18Z","published":"2024-02-15T01:38:50Z","title":"GPT-4's assessment of its performance in a USMLE-based case study","summary":"  This study investigates GPT-4's assessment of its performance in healthcare\napplications. A simple prompting technique was used to prompt the LLM with\nquestions taken from the United States Medical Licensing Examination (USMLE)\nquestionnaire and it was tasked to evaluate its confidence score before posing\nthe question and after asking the question. The questionnaire was categorized\ninto two groups-questions with feedback (WF) and questions with no feedback(NF)\npost-question. The model was asked to provide absolute and relative confidence\nscores before and after each question. The experimental findings were analyzed\nusing statistical tools to study the variability of confidence in WF and NF\ngroups. Additionally, a sequential analysis was conducted to observe the\nperformance variation for the WF and NF groups. Results indicate that feedback\ninfluences relative confidence but doesn't consistently increase or decrease\nit. Understanding the performance of LLM is paramount in exploring its utility\nin sensitive areas like healthcare. This study contributes to the ongoing\ndiscourse on the reliability of AI, particularly of LLMs like GPT-4, within\nhealthcare, offering insights into how feedback mechanisms might be optimized\nto enhance AI-assisted medical education and decision support.\n","authors":["Uttam Dhakal","Aniket Kumar Singh","Suman Devkota","Yogesh Sapkota","Bishal Lamichhane","Suprinsa Paudyal","Chandra Dhakal"],"pdf_url":"https://arxiv.org/pdf/2402.09654v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18063v1","updated":"2024-03-26T19:29:21Z","published":"2024-03-26T19:29:21Z","title":"Spectral Convolutional Transformer: Harmonizing Real vs. Complex\n  Multi-View Spectral Operators for Vision Transformer","summary":"  Transformers used in vision have been investigated through diverse\narchitectures - ViT, PVT, and Swin. These have worked to improve the attention\nmechanism and make it more efficient. Differently, the need for including local\ninformation was felt, leading to incorporating convolutions in transformers\nsuch as CPVT and CvT. Global information is captured using a complex Fourier\nbasis to achieve global token mixing through various methods, such as AFNO,\nGFNet, and Spectformer. We advocate combining three diverse views of data -\nlocal, global, and long-range dependence. We also investigate the simplest\nglobal representation using only the real domain spectral representation -\nobtained through the Hartley transform. We use a convolutional operator in the\ninitial layers to capture local information. Through these two contributions,\nwe are able to optimize and obtain a spectral convolution transformer (SCT)\nthat provides improved performance over the state-of-the-art methods while\nreducing the number of parameters. Through extensive experiments, we show that\nSCT-C-small gives state-of-the-art performance on the ImageNet dataset and\nreaches 84.5\\% top-1 accuracy, while SCT-C-Large reaches 85.9\\% and SCT-C-Huge\nreaches 86.4\\%. We evaluate SCT on transfer learning on datasets such as\nCIFAR-10, CIFAR-100, Oxford Flower, and Stanford Car. We also evaluate SCT on\ndownstream tasks i.e. instance segmentation on the MSCOCO dataset. The project\npage is available on this webpage.\\url{https://github.com/badripatro/sct}\n","authors":["Badri N. Patro","Vinay P. Namboodiri","Vijay S. Agneeswaran"],"pdf_url":"https://arxiv.org/pdf/2403.18063v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.12492v2","updated":"2024-03-26T19:28:15Z","published":"2024-01-23T05:20:35Z","title":"Comparing Pre-trained Human Language Models: Is it Better with Human\n  Context as Groups, Individual Traits, or Both?","summary":"  Incorporating human context into language models is the next frontier for\nhuman-centered natural language processing. Currently, two pre-training methods\nexist: group-wise attributes (e.g., over-45-year-olds) or individual traits.\nGroup attributes are coarse -- not all 45-year-olds write the same way -- while\nmodeling individual traits allows for a more personalized representation, but\nrequires more complex modeling and data. So far, it is unclear which\npre-training approach benefits what tasks. We compare pre-training models with\nhuman context via 1) group attributes, 2) individual users, and 3) a combined\napproach on 5 user- and document-level tasks. We find that pre-training with\nboth group and individual features significantly improves the two user-level\nregression tasks like age estimation and personality assessment. Pre-training\non individual users significantly improves the three document-level\nclassification tasks like stance and topic detection. It even does well for\ndownstream tasks without historical user data. Our results suggest both\napproaches have specific use cases, opening new avenues for human-centered\nlanguage modeling.\n","authors":["Nikita Soni","Niranjan Balasubramanian","H. Andrew Schwartz","Dirk Hovy"],"pdf_url":"https://arxiv.org/pdf/2401.12492v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18058v1","updated":"2024-03-26T19:24:18Z","published":"2024-03-26T19:24:18Z","title":"COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning","summary":"  Recently, there have been significant advancements in large language models\n(LLMs), particularly focused on the English language. These advancements have\nenabled these LLMs to understand and execute complex instructions with\nunprecedented accuracy and fluency. However, despite these advancements, there\nremains a noticeable gap in the development of Chinese instruction tuning. The\nunique linguistic features and cultural depth of the Chinese language pose\nchallenges for instruction tuning tasks. Existing datasets are either derived\nfrom English-centric LLMs or are ill-suited for aligning with the interaction\npatterns of real-world Chinese users. To bridge this gap, we introduce\nCOIG-CQIA, a high-quality Chinese instruction tuning dataset. Our aim is to\nbuild a diverse, wide-ranging instruction-tuning dataset to better align model\nbehavior with human interactions. To this end, we collect a high-quality\nhuman-written corpus from various sources on the Chinese Internet, including\nQ&A communities, Wikis, examinations, and existing NLP datasets. This corpus\nwas rigorously filtered and carefully processed to form the COIG-CQIA dataset.\nFurthermore, we train models of various scales on different subsets of CQIA,\nfollowing in-depth evaluation and analyses. The findings from our experiments\noffer valuable insights for selecting and developing Chinese instruction-tuning\ndatasets. We also find that models trained on CQIA-Subset achieve competitive\nresults in human assessment as well as knowledge and security benchmarks. Data\nare available at https://huggingface.co/datasets/m-a-p/COIG-CQIA\n","authors":["Yuelin Bai","Xinrun Du","Yiming Liang","Yonggang Jin","Ziqiang Liu","Junting Zhou","Tianyu Zheng","Xincheng Zhang","Nuo Ma","Zekun Wang","Ruibin Yuan","Haihong Wu","Hongquan Lin","Wenhao Huang","Jiajun Zhang","Wenhu Chen","Chenghua Lin","Jie Fu","Min Yang","Shiwen Ni","Ge Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.18058v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18051v1","updated":"2024-03-26T19:08:20Z","published":"2024-03-26T19:08:20Z","title":"Supervisory Prompt Training","summary":"  The performance of Large Language Models (LLMs) relies heavily on the quality\nof prompts, which are often manually engineered and task-specific, making them\ncostly and non-scalable. We propose a novel approach, Supervisory Prompt\nTraining (SPT). SPT automates the generation of highly effective prompts using\na dual LLM system. In this system, one LLM, the generator, performs a task\nwhile the other, the corrector, provides feedback and generates improved\nprompts. In contrast to earlier techniques, both the generator and corrector\ncollaboratively and continuously improve their prompts over time. We also\nintroduce the concept of \\textit{impact scores} to measure the sentence-level\neffectiveness of the prompts. Our method was tested on four benchmarks, testing\nthe level of hallucinations in LLMs. Notably, we were able to increase the\naccuracy of GPT-4 on GSM8K from 65.8\\% to 94.1\\% (28.3\\% increase). SPT\nadvances LLMs by refining prompts to enhance performance and reduce\nhallucinations, offering an efficient and scalable alternative to traditional\nmodel fine-tuning.\n","authors":["Jean Ghislain Billa","Min Oh","Liang Du"],"pdf_url":"https://arxiv.org/pdf/2403.18051v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18031v1","updated":"2024-03-26T18:38:14Z","published":"2024-03-26T18:38:14Z","title":"The Impact of Syntactic and Semantic Proximity on Machine Translation\n  with Back-Translation","summary":"  Unsupervised on-the-fly back-translation, in conjunction with multilingual\npretraining, is the dominant method for unsupervised neural machine\ntranslation. Theoretically, however, the method should not work in general. We\ntherefore conduct controlled experiments with artificial languages to determine\nwhat properties of languages make back-translation an effective training\nmethod, covering lexical, syntactic, and semantic properties. We find, contrary\nto popular belief, that (i) parallel word frequency distributions, (ii)\npartially shared vocabulary, and (iii) similar syntactic structure across\nlanguages are not sufficient to explain the success of back-translation. We\nshow however that even crude semantic signal (similar lexical fields across\nlanguages) does improve alignment of two languages through back-translation. We\nconjecture that rich semantic dependencies, parallel across languages, are at\nthe root of the success of unsupervised methods based on back-translation.\nOverall, the success of unsupervised machine translation was far from being\nanalytically guaranteed. Instead, it is another proof that languages of the\nworld share deep similarities, and we hope to show how to identify which of\nthese similarities can serve the development of unsupervised, cross-linguistic\ntools.\n","authors":["Nicolas Guerin","Shane Steinert-Threlkeld","Emmanuel Chemla"],"pdf_url":"https://arxiv.org/pdf/2403.18031v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.10438v6","updated":"2024-03-26T18:36:31Z","published":"2022-11-18T18:59:33Z","title":"SmoothQuant: Accurate and Efficient Post-Training Quantization for Large\n  Language Models","summary":"  Large language models (LLMs) show excellent performance but are compute- and\nmemory-intensive. Quantization can reduce memory and accelerate inference.\nHowever, existing methods cannot maintain accuracy and hardware efficiency at\nthe same time. We propose SmoothQuant, a training-free, accuracy-preserving,\nand general-purpose post-training quantization (PTQ) solution to enable 8-bit\nweight, 8-bit activation (W8A8) quantization for LLMs. Based on the fact that\nweights are easy to quantize while activations are not, SmoothQuant smooths the\nactivation outliers by offline migrating the quantization difficulty from\nactivations to weights with a mathematically equivalent transformation.\nSmoothQuant enables an INT8 quantization of both weights and activations for\nall the matrix multiplications in LLMs, including OPT, BLOOM, GLM, MT-NLG,\nLlama-1/2, Falcon, Mistral, and Mixtral models. We demonstrate up to 1.56x\nspeedup and 2x memory reduction for LLMs with negligible loss in accuracy.\nSmoothQuant enables serving 530B LLM within a single node. Our work offers a\nturn-key solution that reduces hardware costs and democratizes LLMs. Code is\navailable at https://github.com/mit-han-lab/smoothquant.\n","authors":["Guangxuan Xiao","Ji Lin","Mickael Seznec","Hao Wu","Julien Demouth","Song Han"],"pdf_url":"https://arxiv.org/pdf/2211.10438v6.pdf","comment":"ICML 2023. First two authors contributed equally to this work"},{"id":"http://arxiv.org/abs/2403.18025v1","updated":"2024-03-26T18:23:16Z","published":"2024-03-26T18:23:16Z","title":"Improving Pre-trained Language Model Sensitivity via Mask Specific\n  losses: A case study on Biomedical NER","summary":"  Adapting language models (LMs) to novel domains is often achieved through\nfine-tuning a pre-trained LM (PLM) on domain-specific data. Fine-tuning\nintroduces new knowledge into an LM, enabling it to comprehend and efficiently\nperform a target domain task. Fine-tuning can however be inadvertently\ninsensitive if it ignores the wide array of disparities (e.g in word meaning)\nbetween source and target domains. For instance, words such as chronic and\npressure may be treated lightly in social conversations, however, clinically,\nthese words are usually an expression of concern. To address insensitive\nfine-tuning, we propose Mask Specific Language Modeling (MSLM), an approach\nthat efficiently acquires target domain knowledge by appropriately weighting\nthe importance of domain-specific terms (DS-terms) during fine-tuning. MSLM\njointly masks DS-terms and generic words, then learns mask-specific losses by\nensuring LMs incur larger penalties for inaccurately predicting DS-terms\ncompared to generic words. Results of our analysis show that MSLM improves LMs\nsensitivity and detection of DS-terms. We empirically show that an optimal\nmasking rate not only depends on the LM, but also on the dataset and the length\nof sequences. Our proposed masking strategy outperforms advanced masking\nstrategies such as span- and PMI-based masking.\n","authors":["Micheal Abaho","Danushka Bollegala","Gary Leeming","Dan Joyce","Iain E Buchan"],"pdf_url":"https://arxiv.org/pdf/2403.18025v1.pdf","comment":"Paper alrerady accepted for publishing by the NAACL 2024 conference\n  (main conference paper)"},{"id":"http://arxiv.org/abs/2403.18024v1","updated":"2024-03-26T18:22:05Z","published":"2024-03-26T18:22:05Z","title":"Enriching Word Usage Graphs with Cluster Definitions","summary":"  We present a dataset of word usage graphs (WUGs), where the existing WUGs for\nmultiple languages are enriched with cluster labels functioning as sense\ndefinitions. They are generated from scratch by fine-tuned encoder-decoder\nlanguage models. The conducted human evaluation has shown that these\ndefinitions match the existing clusters in WUGs better than the definitions\nchosen from WordNet by two baseline systems. At the same time, the method is\nstraightforward to use and easy to extend to new languages. The resulting\nenriched datasets can be extremely helpful for moving on to explainable\nsemantic change modeling.\n","authors":["Mariia Fedorova","Andrey Kutuzov","Nikolay Arefyev","Dominik Schlechtweg"],"pdf_url":"https://arxiv.org/pdf/2403.18024v1.pdf","comment":"LREC-COLING 2024"},{"id":"http://arxiv.org/abs/2403.14814v2","updated":"2024-03-26T18:10:10Z","published":"2024-03-21T19:59:52Z","title":"The opportunities and risks of large language models in mental health","summary":"  Global rates of mental health concerns are rising and there is increasing\nrealization that existing models of mental healthcare will not adequately\nexpand to meet the demand. With the emergence of large language models (LLMs)\nhas come great optimism regarding their promise to create novel, large-scale\nsolutions to support mental health. Despite their nascence, LLMs have already\nbeen applied to mental health-related tasks. In this review, we summarize the\nextant literature on efforts to use LLMs to provide mental health education,\nassessment, and intervention and highlight key opportunities for positive\nimpact in each area. We then highlight risks associated with LLMs application\nto mental health and encourage adoption of strategies to mitigate these risks.\nThe urgent need for mental health support must be balanced with responsible\ndevelopment, testing, and deployment of mental health LLMs. Especially critical\nis ensuring that mental health LLMs are fine-tuned for mental health, enhance\nmental health equity, adhere to ethical standards, and that people, including\nthose with lived experience with mental health concerns, are involved in all\nstages from development through deployment. Prioritizing these efforts will\nminimize potential harms to mental health and maximize the likelihood that LLMs\nwill positively impact mental health globally.\n","authors":["Hannah R. Lawrence","Renee A. Schneider","Susan B. Rubin","Maja J. Mataric","Daniel J. McDuff","Megan Jones Bell"],"pdf_url":"https://arxiv.org/pdf/2403.14814v2.pdf","comment":"12 pages, 2 tables, 4 figures"},{"id":"http://arxiv.org/abs/2403.18018v1","updated":"2024-03-26T18:07:10Z","published":"2024-03-26T18:07:10Z","title":"DORE: A Dataset For Portuguese Definition Generation","summary":"  Definition modelling (DM) is the task of automatically generating a\ndictionary definition for a specific word. Computational systems that are\ncapable of DM can have numerous applications benefiting a wide range of\naudiences. As DM is considered a supervised natural language generation\nproblem, these systems require large annotated datasets to train the machine\nlearning (ML) models. Several DM datasets have been released for English and\nother high-resource languages. While Portuguese is considered a\nmid/high-resource language in most natural language processing tasks and is\nspoken by more than 200 million native speakers, there is no DM dataset\navailable for Portuguese. In this research, we fill this gap by introducing\nDORE; the first dataset for Definition MOdelling for PoRtuguEse containing more\nthan 100,000 definitions. We also evaluate several deep learning based DM\nmodels on DORE and report the results. The dataset and the findings of this\npaper will facilitate research and study of Portuguese in wider contexts.\n","authors":["Anna Beatriz Dimas Furtado","Tharindu Ranasinghe","Frédéric Blain","Ruslan Mitkov"],"pdf_url":"https://arxiv.org/pdf/2403.18018v1.pdf","comment":"Accepted to LREC-COLING 2024 (The 2024 Joint International Conference\n  on Computational Linguistics, Language Resources and Evaluation)"},{"id":"http://arxiv.org/abs/2305.14718v4","updated":"2024-03-26T18:07:01Z","published":"2023-05-24T04:42:17Z","title":"Leftover-Lunch: Advantage-based Offline Reinforcement Learning for\n  Language Models","summary":"  Reinforcement Learning with Human Feedback (RLHF) is the most prominent\nmethod for Language Model (LM) alignment. However, RLHF is an unstable and\ndata-hungry process that continually requires new high-quality LM-generated\ndata for finetuning. We introduce Advantage-Leftover Lunch RL (A-LoL), a new\nclass of offline policy gradient algorithms that enable RL training on any\npre-existing data. By assuming the entire LM output sequence as a single\naction, A-LoL allows incorporating sequence-level classifiers or human-designed\nscoring functions as rewards. Subsequently, by using LM's value estimate, A-LoL\nonly trains on positive advantage (leftover) data points, making it resilient\nto noise. Overall, A-LoL is an easy-to-implement, sample-efficient, and stable\nLM training recipe.\n  We demonstrate the effectiveness of A-LoL and its variants with a set of four\ndifferent language generation tasks. We compare against both online RL (PPO)\nand recent preference-based (DPO, PRO) and reward-based (GOLD) offline RL\nbaselines. On the commonly-used RLHF benchmark, Helpful and Harmless Assistant\n(HHA), LMs trained with A-LoL methods achieve the highest diversity while also\nbeing rated more safe and helpful than the baselines according to humans.\nAdditionally, in the remaining three tasks, A-LoL could optimize multiple\ndistinct reward functions even when using noisy or suboptimal training data.\n  We also release our experimental code. https://github.com/abaheti95/LoL-RL\n","authors":["Ashutosh Baheti","Ximing Lu","Faeze Brahman","Ronan Le Bras","Maarten Sap","Mark Riedl"],"pdf_url":"https://arxiv.org/pdf/2305.14718v4.pdf","comment":"published at ICLR 2024"},{"id":"http://arxiv.org/abs/2402.13452v2","updated":"2024-03-26T17:59:14Z","published":"2024-02-21T01:11:28Z","title":"LocalTweets to LocalHealth: A Mental Health Surveillance Framework Based\n  on Twitter Data","summary":"  Prior research on Twitter (now X) data has provided positive evidence of its\nutility in developing supplementary health surveillance systems. In this study,\nwe present a new framework to surveil public health, focusing on mental health\n(MH) outcomes. We hypothesize that locally posted tweets are indicative of\nlocal MH outcomes and collect tweets posted from 765 neighborhoods (census\nblock groups) in the USA. We pair these tweets from each neighborhood with the\ncorresponding MH outcome reported by the Center for Disease Control (CDC) to\ncreate a benchmark dataset, LocalTweets. With LocalTweets, we present the first\npopulation-level evaluation task for Twitter-based MH surveillance systems. We\nthen develop an efficient and effective method, LocalHealth, for predicting MH\noutcomes based on LocalTweets. When used with GPT3.5, LocalHealth achieves the\nhighest F1-score and accuracy of 0.7429 and 79.78\\%, respectively, a 59\\%\nimprovement in F1-score over the GPT3.5 in zero-shot setting. We also utilize\nLocalHealth to extrapolate CDC's estimates to proxy unreported neighborhoods,\nachieving an F1-score of 0.7291. Our work suggests that Twitter data can be\neffectively leveraged to simulate neighborhood-level MH outcomes.\n","authors":["Vijeta Deshpande","Minhwa Lee","Zonghai Yao","Zihao Zhang","Jason Brian Gibbons","Hong Yu"],"pdf_url":"https://arxiv.org/pdf/2402.13452v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.08763v3","updated":"2024-03-26T17:58:48Z","published":"2024-03-13T17:58:57Z","title":"Simple and Scalable Strategies to Continually Pre-train Large Language\n  Models","summary":"  Large language models (LLMs) are routinely pre-trained on billions of tokens,\nonly to start the process over again once new data becomes available. A much\nmore efficient solution is to continually pre-train these models, saving\nsignificant compute compared to re-training. However, the distribution shift\ninduced by new data typically results in degraded performance on previous data\nor poor adaptation to the new data. In this work, we show that a simple and\nscalable combination of learning rate (LR) re-warming, LR re-decaying, and\nreplay of previous data is sufficient to match the performance of fully\nre-training from scratch on all available data, as measured by the final loss\nand the average score on several language model (LM) evaluation benchmarks.\nSpecifically, we show this for a weak but realistic distribution shift between\ntwo commonly used LLM pre-training datasets (English$\\rightarrow$English) and a\nstronger distribution shift (English$\\rightarrow$German) at the $405$M\nparameter model scale with large dataset sizes (hundreds of billions of\ntokens). Selecting the weak but realistic shift for larger-scale experiments,\nwe also find that our continual learning strategies match the re-training\nbaseline for a 10B parameter LLM. Our results demonstrate that LLMs can be\nsuccessfully updated via simple and scalable continual learning strategies,\nmatching the re-training baseline using only a fraction of the compute.\nFinally, inspired by previous work, we propose alternatives to the cosine\nlearning rate schedule that help circumvent forgetting induced by LR re-warming\nand that are not bound to a fixed token budget.\n","authors":["Adam Ibrahim","Benjamin Thérien","Kshitij Gupta","Mats L. Richter","Quentin Anthony","Timothée Lesort","Eugene Belilovsky","Irina Rish"],"pdf_url":"https://arxiv.org/pdf/2403.08763v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17919v1","updated":"2024-03-26T17:55:02Z","published":"2024-03-26T17:55:02Z","title":"LISA: Layerwise Importance Sampling for Memory-Efficient Large Language\n  Model Fine-Tuning","summary":"  The machine learning community has witnessed impressive advancements since\nthe first appearance of large language models (LLMs), yet their huge memory\nconsumption has become a major roadblock to large-scale training. Parameter\nEfficient Fine-Tuning techniques such as Low-Rank Adaptation (LoRA) have been\nproposed to alleviate this problem, but their performance still fails to match\nfull parameter training in most large-scale fine-tuning settings. Attempting to\ncomplement this deficiency, we investigate layerwise properties of LoRA on\nfine-tuning tasks and observe an uncommon skewness of weight norms across\ndifferent layers. Utilizing this key observation, a surprisingly simple\ntraining strategy is discovered, which outperforms both LoRA and full parameter\ntraining in a wide range of settings with memory costs as low as LoRA. We name\nit Layerwise Importance Sampled AdamW (LISA), a promising alternative for LoRA,\nwhich applies the idea of importance sampling to different layers in LLMs and\nrandomly freeze most middle layers during optimization. Experimental results\nshow that with similar or less GPU memory consumption, LISA surpasses LoRA or\neven full parameter tuning in downstream fine-tuning tasks, where LISA\nconsistently outperforms LoRA by over $11\\%$-$37\\%$ in terms of MT-Bench\nscores. On large models, specifically LLaMA-2-70B, LISA achieves on-par or\nbetter performance than LoRA on MT-Bench, GSM8K, and PubMedQA, demonstrating\nits effectiveness across different domains.\n","authors":["Rui Pan","Xiang Liu","Shizhe Diao","Renjie Pi","Jipeng Zhang","Chi Han","Tong Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.17919v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16248v2","updated":"2024-03-26T17:46:26Z","published":"2024-03-24T17:39:51Z","title":"Large Language Models Offer an Alternative to the Traditional Approach\n  of Topic Modelling","summary":"  Topic modelling, as a well-established unsupervised technique, has found\nextensive use in automatically detecting significant topics within a corpus of\ndocuments. However, classic topic modelling approaches (e.g., LDA) have certain\ndrawbacks, such as the lack of semantic understanding and the presence of\noverlapping topics. In this work, we investigate the untapped potential of\nlarge language models (LLMs) as an alternative for uncovering the underlying\ntopics within extensive text corpora. To this end, we introduce a framework\nthat prompts LLMs to generate topics from a given set of documents and\nestablish evaluation protocols to assess the clustering efficacy of LLMs. Our\nfindings indicate that LLMs with appropriate prompts can stand out as a viable\nalternative, capable of generating relevant topic titles and adhering to human\nguidelines to refine and merge topics. Through in-depth experiments and\nevaluation, we summarise the advantages and constraints of employing LLMs in\ntopic extraction.\n","authors":["Yida Mu","Chun Dong","Kalina Bontcheva","Xingyi Song"],"pdf_url":"https://arxiv.org/pdf/2403.16248v2.pdf","comment":"Accepted at LREC-COLING 2024"},{"id":"http://arxiv.org/abs/2403.17887v1","updated":"2024-03-26T17:20:04Z","published":"2024-03-26T17:20:04Z","title":"The Unreasonable Ineffectiveness of the Deeper Layers","summary":"  We empirically study a simple layer-pruning strategy for popular families of\nopen-weight pretrained LLMs, finding minimal degradation of performance on\ndifferent question-answering benchmarks until after a large fraction (up to\nhalf) of the layers are removed. To prune these models, we identify the optimal\nblock of layers to prune by considering similarity across layers; then, to\n\"heal\" the damage, we perform a small amount of finetuning. In particular, we\nuse parameter-efficient finetuning (PEFT) methods, specifically quantization\nand Low Rank Adapters (QLoRA), such that each of our experiments can be\nperformed on a single A100 GPU. From a practical perspective, these results\nsuggest that layer pruning methods can complement other PEFT strategies to\nfurther reduce computational resources of finetuning on the one hand, and can\nimprove the memory and latency of inference on the other hand. From a\nscientific perspective, the robustness of these LLMs to the deletion of layers\nimplies either that current pretraining methods are not properly leveraging the\nparameters in the deeper layers of the network or that the shallow layers play\na critical role in storing knowledge.\n","authors":["Andrey Gromov","Kushal Tirumala","Hassan Shapourian","Paolo Glorioso","Daniel A. Roberts"],"pdf_url":"https://arxiv.org/pdf/2403.17887v1.pdf","comment":"12 + 10 pages, 5 + 4 figures"},{"id":"http://arxiv.org/abs/2403.17860v1","updated":"2024-03-26T16:49:25Z","published":"2024-03-26T16:49:25Z","title":"Exploring LLMs as a Source of Targeted Synthetic Textual Data to\n  Minimize High Confidence Misclassifications","summary":"  Natural Language Processing (NLP) models optimized for predictive performance\noften make high confidence errors and suffer from vulnerability to adversarial\nand out-of-distribution data. Existing work has mainly focused on mitigation of\nsuch errors using either humans or an automated approach. In this study, we\nexplore the usage of large language models (LLMs) for data augmentation as a\npotential solution to the issue of NLP models making wrong predictions with\nhigh confidence during classification tasks. We compare the effectiveness of\nsynthetic data generated by LLMs with that of human data obtained via the same\nprocedure. For mitigation, humans or LLMs provide natural language\ncharacterizations of high confidence misclassifications to generate synthetic\ndata, which are then used to extend the training set. We conduct an extensive\nevaluation of our approach on three classification tasks and demonstrate its\neffectiveness in reducing the number of high confidence misclassifications\npresent in the model, all while maintaining the same level of accuracy.\nMoreover, we find that the cost gap between humans and LLMs surpasses an order\nof magnitude, as LLMs attain human-like performance while being more scalable.\n","authors":["Philip Lippmann","Matthijs Spaan","Jie Yang"],"pdf_url":"https://arxiv.org/pdf/2403.17860v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17859v1","updated":"2024-03-26T16:48:13Z","published":"2024-03-26T16:48:13Z","title":"ChroniclingAmericaQA: A Large-scale Question Answering Dataset based on\n  Historical American Newspaper Pages","summary":"  Question answering (QA) and Machine Reading Comprehension (MRC) tasks have\nsignificantly advanced in recent years due to the rapid development of deep\nlearning techniques and, more recently, large language models. At the same\ntime, many benchmark datasets have become available for QA and MRC tasks.\nHowever, most existing large-scale benchmark datasets have been created\npredominantly using synchronous document collections like Wikipedia or the Web.\nArchival document collections, such as historical newspapers, contain valuable\ninformation from the past that is still not widely used to train large language\nmodels. To further contribute to advancing QA and MRC tasks and to overcome the\nlimitation of previous datasets, we introduce ChroniclingAmericaQA, a\nlarge-scale dataset with 485K question-answer pairs created based on the\nhistorical newspaper collection Chronicling America. Our dataset is constructed\nfrom a subset of the Chronicling America newspaper collection spanning 120\nyears. One of the significant challenges for utilizing digitized historical\nnewspaper collections is the low quality of OCR text. Therefore, to enable\nrealistic testing of QA models, our dataset can be used in three different\nways: answering questions from raw and noisy content, answering questions from\ncleaner, corrected version of the content, as well as answering questions from\nscanned images of newspaper pages. This and the fact that ChroniclingAmericaQA\nspans the longest time period among available QA datasets make it quite a\nunique and useful resource.\n","authors":["Bhawna Piryani","Jamshid Mozafari","Adam Jatowt"],"pdf_url":"https://arxiv.org/pdf/2403.17859v1.pdf","comment":"Accepted at SIGIR 2024"},{"id":"http://arxiv.org/abs/2403.17856v1","updated":"2024-03-26T16:45:27Z","published":"2024-03-26T16:45:27Z","title":"Verbing Weirds Language (Models): Evaluation of English Zero-Derivation\n  in Five LLMs","summary":"  Lexical-syntactic flexibility, in the form of conversion (or zero-derivation)\nis a hallmark of English morphology. In conversion, a word with one part of\nspeech is placed in a non-prototypical context, where it is coerced to behave\nas if it had a different part of speech. However, while this process affects a\nlarge part of the English lexicon, little work has been done to establish the\ndegree to which language models capture this type of generalization. This paper\nreports the first study on the behavior of large language models with reference\nto conversion. We design a task for testing lexical-syntactic flexibility --\nthe degree to which models can generalize over words in a construction with a\nnon-prototypical part of speech. This task is situated within a natural\nlanguage inference paradigm. We test the abilities of five language models --\ntwo proprietary models (GPT-3.5 and GPT-4), three open-source models (Mistral\n7B, Falcon 40B, and Llama 2 70B). We find that GPT-4 performs best on the task,\nfollowed by GPT-3.5, but that the open source language models are also able to\nperform it and that the 7B parameter Mistral displays as little difference\nbetween its baseline performance on the natural language inference task and the\nnon-prototypical syntactic category task, as the massive GPT-4.\n","authors":["David R. Mortensen","Valentina Izrailevitch","Yunze Xiao","Hinrich Schütze","Leonie Weissweiler"],"pdf_url":"https://arxiv.org/pdf/2403.17856v1.pdf","comment":"LREC-COLING 2024"},{"id":"http://arxiv.org/abs/2401.06795v2","updated":"2024-03-26T16:44:34Z","published":"2024-01-08T18:42:55Z","title":"AI and Generative AI for Research Discovery and Summarization","summary":"  AI and generative AI tools, including chatbots like ChatGPT that rely on\nlarge language models (LLMs), have burst onto the scene this year, creating\nincredible opportunities to increase work productivity and improve our lives.\nStatisticians and data scientists have begun experiencing the benefits from the\navailability of these tools in numerous ways, such as the generation of\nprogramming code from text prompts to analyze data or fit statistical models.\nOne area that these tools can make a substantial impact is in research\ndiscovery and summarization. Standalone tools and plugins to chatbots are being\ndeveloped that allow researchers to more quickly find relevant literature than\npre-2023 search tools. Furthermore, generative AI tools have improved to the\npoint where they can summarize and extract the key points from research\narticles in succinct language. Finally, chatbots based on highly parameterized\nLLMs can be used to simulate abductive reasoning, which provides researchers\nthe ability to make connections among related technical topics, which can also\nbe used for research discovery. We review the developments in AI and generative\nAI for research discovery and summarization, and propose directions where these\ntypes of tools are likely to head in the future that may be of interest to\nstatistician and data scientists.\n","authors":["Mark Glickman","Yi Zhang"],"pdf_url":"https://arxiv.org/pdf/2401.06795v2.pdf","comment":"29 pages, 9 figures"},{"id":"http://arxiv.org/abs/2403.17853v1","updated":"2024-03-26T16:42:30Z","published":"2024-03-26T16:42:30Z","title":"Using Domain Knowledge to Guide Dialog Structure Induction via Neural\n  Probabilistic Soft Logic","summary":"  Dialog Structure Induction (DSI) is the task of inferring the latent dialog\nstructure (i.e., a set of dialog states and their temporal transitions) of a\ngiven goal-oriented dialog. It is a critical component for modern dialog system\ndesign and discourse analysis. Existing DSI approaches are often purely\ndata-driven, deploy models that infer latent states without access to domain\nknowledge, underperform when the training corpus is limited/noisy, or have\ndifficulty when test dialogs exhibit distributional shifts from the training\ndomain. This work explores a neural-symbolic approach as a potential solution\nto these problems. We introduce Neural Probabilistic Soft Logic Dialogue\nStructure Induction (NEUPSL DSI), a principled approach that injects symbolic\nknowledge into the latent space of a generative neural model. We conduct a\nthorough empirical investigation on the effect of NEUPSL DSI learning on hidden\nrepresentation quality, few-shot learning, and out-of-domain generalization\nperformance. Over three dialog structure induction datasets and across\nunsupervised and semi-supervised settings for standard and cross-domain\ngeneralization, the injection of symbolic knowledge using NEUPSL DSI provides a\nconsistent boost in performance over the canonical baselines.\n","authors":["Connor Pryor","Quan Yuan","Jeremiah Liu","Mehran Kazemi","Deepak Ramachandran","Tania Bedrax-Weiss","Lise Getoor"],"pdf_url":"https://arxiv.org/pdf/2403.17853v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.11278v3","updated":"2024-03-26T16:40:50Z","published":"2023-07-21T00:34:38Z","title":"Generator-Retriever-Generator Approach for Open-Domain Question\n  Answering","summary":"  Open-domain question answering (QA) tasks usually require the retrieval of\nrelevant information from a large corpus to generate accurate answers. We\npropose a novel approach called Generator-Retriever-Generator (GRG) that\ncombines document retrieval techniques with a large language model (LLM), by\nfirst prompting the model to generate contextual documents based on a given\nquestion. In parallel, a dual-encoder network retrieves documents that are\nrelevant to the question from an external corpus. The generated and retrieved\ndocuments are then passed to the second LLM, which generates the final answer.\nBy combining document retrieval and LLM generation, our approach addresses the\nchallenges of open-domain QA, such as generating informative and contextually\nrelevant answers. GRG outperforms the state-of-the-art generate-then-read and\nretrieve-then-read pipelines (GENREAD and RFiD) improving their performance by\nat least by +5.2, +4.2, and +1.6 on TriviaQA, NQ, and WebQ datasets,\nrespectively. We provide code, datasets, and checkpoints at\nhttps://github.com/abdoelsayed2016/GRG.\n","authors":["Abdelrahman Abdallah","Adam Jatowt"],"pdf_url":"https://arxiv.org/pdf/2307.11278v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17848v1","updated":"2024-03-26T16:37:54Z","published":"2024-03-26T16:37:54Z","title":"ArabicaQA: A Comprehensive Dataset for Arabic Question Answering","summary":"  In this paper, we address the significant gap in Arabic natural language\nprocessing (NLP) resources by introducing ArabicaQA, the first large-scale\ndataset for machine reading comprehension and open-domain question answering in\nArabic. This comprehensive dataset, consisting of 89,095 answerable and 3,701\nunanswerable questions created by crowdworkers to look similar to answerable\nones, along with additional labels of open-domain questions marks a crucial\nadvancement in Arabic NLP resources. We also present AraDPR, the first dense\npassage retrieval model trained on the Arabic Wikipedia corpus, specifically\ndesigned to tackle the unique challenges of Arabic text retrieval. Furthermore,\nour study includes extensive benchmarking of large language models (LLMs) for\nArabic question answering, critically evaluating their performance in the\nArabic language context. In conclusion, ArabicaQA, AraDPR, and the benchmarking\nof LLMs in Arabic question answering offer significant advancements in the\nfield of Arabic NLP. The dataset and code are publicly accessible for further\nresearch https://github.com/DataScienceUIBK/ArabicaQA.\n","authors":["Abdelrahman Abdallah","Mahmoud Kasem","Mahmoud Abdalla","Mohamed Mahmoud","Mohamed Elkasaby","Yasser Elbendary","Adam Jatowt"],"pdf_url":"https://arxiv.org/pdf/2403.17848v1.pdf","comment":"Accepted at SIGIR 2024"},{"id":"http://arxiv.org/abs/2403.17846v1","updated":"2024-03-26T16:36:43Z","published":"2024-03-26T16:36:43Z","title":"Hierarchical Open-Vocabulary 3D Scene Graphs for Language-Grounded Robot\n  Navigation","summary":"  Recent open-vocabulary robot mapping methods enrich dense geometric maps with\npre-trained visual-language features. While these maps allow for the prediction\nof point-wise saliency maps when queried for a certain language concept,\nlarge-scale environments and abstract queries beyond the object level still\npose a considerable hurdle, ultimately limiting language-grounded robotic\nnavigation. In this work, we present HOV-SG, a hierarchical open-vocabulary 3D\nscene graph mapping approach for language-grounded robot navigation. Leveraging\nopen-vocabulary vision foundation models, we first obtain state-of-the-art\nopen-vocabulary segment-level maps in 3D and subsequently construct a 3D scene\ngraph hierarchy consisting of floor, room, and object concepts, each enriched\nwith open-vocabulary features. Our approach is able to represent multi-story\nbuildings and allows robotic traversal of those using a cross-floor Voronoi\ngraph. HOV-SG is evaluated on three distinct datasets and surpasses previous\nbaselines in open-vocabulary semantic accuracy on the object, room, and floor\nlevel while producing a 75% reduction in representation size compared to dense\nopen-vocabulary maps. In order to prove the efficacy and generalization\ncapabilities of HOV-SG, we showcase successful long-horizon\nlanguage-conditioned robot navigation within real-world multi-storage\nenvironments. We provide code and trial video data at http://hovsg.github.io/.\n","authors":["Abdelrhman Werby","Chenguang Huang","Martin Büchner","Abhinav Valada","Wolfram Burgard"],"pdf_url":"https://arxiv.org/pdf/2403.17846v1.pdf","comment":"Code and video are available at http://hovsg.github.io/"},{"id":"http://arxiv.org/abs/2309.09800v3","updated":"2024-03-26T16:05:51Z","published":"2023-09-18T14:18:19Z","title":"AMuRD: Annotated Arabic-English Receipt Dataset for Key Information\n  Extraction and Classification","summary":"  The extraction of key information from receipts is a complex task that\ninvolves the recognition and extraction of text from scanned receipts. This\nprocess is crucial as it enables the retrieval of essential content and\norganizing it into structured documents for easy access and analysis. In this\npaper, we present AMuRD, a novel multilingual human-annotated dataset\nspecifically designed for information extraction from receipts. This dataset\ncomprises $47,720$ samples and addresses the key challenges in information\nextraction and item classification - the two critical aspects of data analysis\nin the retail industry. Each sample includes annotations for item names and\nattributes such as price, brand, and more. This detailed annotation facilitates\na comprehensive understanding of each item on the receipt. Furthermore, the\ndataset provides classification into $44$ distinct product categories. This\nclassification feature allows for a more organized and efficient analysis of\nthe items, enhancing the usability of the dataset for various applications. In\nour study, we evaluated various language model architectures, e.g., by\nfine-tuning LLaMA models on the AMuRD dataset. Our approach yielded exceptional\nresults, with an F1 score of 97.43\\% and accuracy of 94.99\\% in information\nextraction and classification, and an even higher F1 score of 98.51\\% and\naccuracy of 97.06\\% observed in specific tasks. The dataset and code are\npublicly accessible for further\nresearchhttps://github.com/Update-For-Integrated-Business-AI/AMuRD.\n","authors":["Abdelrahman Abdallah","Mahmoud Abdalla","Mohamed Elkasaby","Yasser Elbendary","Adam Jatowt"],"pdf_url":"https://arxiv.org/pdf/2309.09800v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.03742v2","updated":"2024-03-26T16:03:57Z","published":"2023-08-07T17:46:49Z","title":"Training BERT Models to Carry Over a Coding System Developed on One\n  Corpus to Another","summary":"  This paper describes how we train BERT models to carry over a coding system\ndeveloped on the paragraphs of a Hungarian literary journal to another. The aim\nof the coding system is to track trends in the perception of literary\ntranslation around the political transformation in 1989 in Hungary. To evaluate\nnot only task performance but also the consistence of the annotation, moreover,\nto get better predictions from an ensemble, we use 10-fold crossvalidation.\nExtensive hyperparameter tuning is used to obtain the best possible results and\nfair comparisons. To handle label imbalance, we use loss functions and metrics\nrobust to it. Evaluation of the effect of domain shift is carried out by\nsampling a test set from the target domain. We establish the sample size by\nestimating the bootstrapped confidence interval via simulations. This way, we\nshow that our models can carry over one annotation system to the target domain.\nComparisons are drawn to provide insights such as learning multilabel\ncorrelations and confidence penalty improve resistance to domain shift, and\ndomain adaptation on OCR-ed text on another domain improves performance almost\nto the same extent as that on the corpus under study. See our code at\nhttps://codeberg.org/zsamboki/bert-annotator-ensemble.\n","authors":["Dalma Galambos","Pál Zsámboki"],"pdf_url":"https://arxiv.org/pdf/2308.03742v2.pdf","comment":"Camera-ready version, to be presented at the 2024 Joint International\n  Conference on Computational Linguistics, Language Resources and Evaluation\n  (LREC-COLING 2024)"},{"id":"http://arxiv.org/abs/2311.15964v2","updated":"2024-03-26T15:58:26Z","published":"2023-11-27T16:07:37Z","title":"Efficient Pre-training for Localized Instruction Generation of Videos","summary":"  Procedural videos show step-by-step demonstrations of tasks like recipe\npreparation. Understanding such videos is challenging, involving the precise\nlocalization of steps and the generation of textual instructions. Manually\nannotating steps and writing instructions is costly, which limits the size of\ncurrent datasets and hinders effective learning. Leveraging large but noisy\nvideo-transcript datasets for pre-training can boost performance, but demands\nsignificant computational resources. Furthermore, transcripts contain\nirrelevant content and exhibit style variation compared to instructions written\nby human annotators. To mitigate both issues, we propose a technique,\nSieve-&-Swap, to automatically curate a smaller dataset: (i) Sieve filters\nirrelevant transcripts and (ii) Swap enhances the quality of the text\ninstruction by automatically replacing the transcripts with human-written\ninstructions from a text-only recipe dataset. The curated dataset, three orders\nof magnitude smaller than current web-scale datasets, enables efficient\ntraining of large-scale models with competitive performance. We complement our\nSieve-\\&-Swap approach with a Procedure Transformer (ProcX) for end-to-end step\nlocalization and instruction generation for procedural videos. When this model\nis pre-trained on our curated dataset, it achieves state-of-the-art performance\nin zero-shot and finetuning settings on YouCook2 and Tasty, while using a\nfraction of the computational resources.\n","authors":["Anil Batra","Davide Moltisanti","Laura Sevilla-Lara","Marcus Rohrbach","Frank Keller"],"pdf_url":"https://arxiv.org/pdf/2311.15964v2.pdf","comment":"This version has some missing experiments and elaborative technical\n  details"},{"id":"http://arxiv.org/abs/2403.17816v1","updated":"2024-03-26T15:53:02Z","published":"2024-03-26T15:53:02Z","title":"Graph Language Model (GLM): A new graph-based approach to detect social\n  instabilities","summary":"  This scientific report presents a novel methodology for the early prediction\nof important political events using News datasets. The methodology leverages\nnatural language processing, graph theory, clique analysis, and semantic\nrelationships to uncover hidden predictive signals within the data. Initially,\nwe designed a preliminary version of the method and tested it on a few events.\nThis analysis revealed limitations in the initial research phase. We then\nenhanced the model in two key ways: first, we added a filtration step to only\nconsider politically relevant news before further processing; second, we\nadjusted the input features to make the alert system more sensitive to\nsignificant spikes in the data. After finalizing the improved methodology, we\ntested it on eleven events including US protests, the Ukraine war, and French\nprotests. Results demonstrate the superiority of our approach compared to\nbaseline methods. Through targeted refinements, our model can now provide\nearlier and more accurate predictions of major political events based on subtle\npatterns in news data.\n","authors":["Wallyson Lemes de Oliveira","Vahid Shamsaddini","Ali Ghofrani","Rahul Singh Inda","Jithendra Sai Veeramaneni","Étienne Voutaz"],"pdf_url":"https://arxiv.org/pdf/2403.17816v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17811v1","updated":"2024-03-26T15:50:37Z","published":"2024-03-26T15:50:37Z","title":"Are Compressed Language Models Less Subgroup Robust?","summary":"  To reduce the inference cost of large language models, model compression is\nincreasingly used to create smaller scalable models. However, little is known\nabout their robustness to minority subgroups defined by the labels and\nattributes of a dataset. In this paper, we investigate the effects of 18\ndifferent compression methods and settings on the subgroup robustness of BERT\nlanguage models. We show that worst-group performance does not depend on model\nsize alone, but also on the compression method used. Additionally, we find that\nmodel compression does not always worsen the performance on minority subgroups.\nAltogether, our analysis serves to further research into the subgroup\nrobustness of model compression.\n","authors":["Leonidas Gee","Andrea Zugarini","Novi Quadrianto"],"pdf_url":"https://arxiv.org/pdf/2403.17811v1.pdf","comment":"The 2023 Conference on Empirical Methods in Natural Language\n  Processing (EMNLP 2023)"},{"id":"http://arxiv.org/abs/2401.11911v4","updated":"2024-03-26T15:47:14Z","published":"2024-01-22T12:54:04Z","title":"Blinded by Generated Contexts: How Language Models Merge Generated and\n  Retrieved Contexts for Open-Domain QA?","summary":"  While auxiliary information has become a key to enhancing Large Language\nModels (LLMs), relatively little is known about how LLMs merge these contexts,\nspecifically contexts generated by LLMs and those retrieved from external\nsources. To investigate this, we formulate a systematic framework to identify\nwhether LLMs' responses, derived from the integration of generated and\nretrieved contexts, are attributed to either generated or retrieved contexts.\nTo easily trace the origin of the response, we construct datasets with\nconflicting contexts, i.e., each question is paired with both generated and\nretrieved contexts, yet only one of them contains the correct answer. Our\nexperiments reveal a significant bias in several LLMs (GPT-4/3.5 and Llama2) to\nfavor generated contexts, even when they provide incorrect information. We\nfurther identify two key factors contributing to this bias: i) contexts\ngenerated by LLMs typically show greater similarity to the questions,\nincreasing their likelihood of being selected; ii) the segmentation process\nused in retrieved contexts disrupts their completeness, thereby hindering their\nfull utilization in LLMs. Our analysis enhances the understanding of how LLMs\nmerge diverse contexts, offering valuable insights for advancing current\naugmentation methods for LLMs.\n","authors":["Hexiang Tan","Fei Sun","Wanli Yang","Yuanzhuo Wang","Qi Cao","Xueqi Cheng"],"pdf_url":"https://arxiv.org/pdf/2401.11911v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17806v1","updated":"2024-03-26T15:44:58Z","published":"2024-03-26T15:44:58Z","title":"Have Faith in Faithfulness: Going Beyond Circuit Overlap When Finding\n  Model Mechanisms","summary":"  Many recent language model (LM) interpretability studies have adopted the\ncircuits framework, which aims to find the minimal computational subgraph, or\ncircuit, that explains LM behavior on a given task. Most studies determine\nwhich edges belong in a LM's circuit by performing causal interventions on each\nedge independently, but this scales poorly with model size. Edge attribution\npatching (EAP), gradient-based approximation to interventions, has emerged as a\nscalable but imperfect solution to this problem. In this paper, we introduce a\nnew method - EAP with integrated gradients (EAP-IG) - that aims to better\nmaintain a core property of circuits: faithfulness. A circuit is faithful if\nall model edges outside the circuit can be ablated without changing the model's\nperformance on the task; faithfulness is what justifies studying circuits,\nrather than the full model. Our experiments demonstrate that circuits found\nusing EAP are less faithful than those found using EAP-IG, even though both\nhave high node overlap with circuits found previously using causal\ninterventions. We conclude more generally that when using circuits to compare\nthe mechanisms models use to solve tasks, faithfulness, not overlap, is what\nshould be measured.\n","authors":["Michael Hanna","Sandro Pezzelle","Yonatan Belinkov"],"pdf_url":"https://arxiv.org/pdf/2403.17806v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17804v1","updated":"2024-03-26T15:42:01Z","published":"2024-03-26T15:42:01Z","title":"Improving Text-to-Image Consistency via Automatic Prompt Optimization","summary":"  Impressive advances in text-to-image (T2I) generative models have yielded a\nplethora of high performing models which are able to generate aesthetically\nappealing, photorealistic images. Despite the progress, these models still\nstruggle to produce images that are consistent with the input prompt,\noftentimes failing to capture object quantities, relations and attributes\nproperly. Existing solutions to improve prompt-image consistency suffer from\nthe following challenges: (1) they oftentimes require model fine-tuning, (2)\nthey only focus on nearby prompt samples, and (3) they are affected by\nunfavorable trade-offs among image quality, representation diversity, and\nprompt-image consistency. In this paper, we address these challenges and\nintroduce a T2I optimization-by-prompting framework, OPT2I, which leverages a\nlarge language model (LLM) to improve prompt-image consistency in T2I models.\nOur framework starts from a user prompt and iteratively generates revised\nprompts with the goal of maximizing a consistency score. Our extensive\nvalidation on two datasets, MSCOCO and PartiPrompts, shows that OPT2I can boost\nthe initial consistency score by up to 24.9% in terms of DSG score while\npreserving the FID and increasing the recall between generated and real data.\nOur work paves the way toward building more reliable and robust T2I systems by\nharnessing the power of LLMs.\n","authors":["Oscar Mañas","Pietro Astolfi","Melissa Hall","Candace Ross","Jack Urbanek","Adina Williams","Aishwarya Agrawal","Adriana Romero-Soriano","Michal Drozdzal"],"pdf_url":"https://arxiv.org/pdf/2403.17804v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.07703v2","updated":"2024-03-26T15:31:34Z","published":"2023-11-13T19:41:34Z","title":"Measuring Entrainment in Spontaneous Code-switched Speech","summary":"  It is well-known that speakers who entrain to one another have more\nsuccessful conversations than those who do not. Previous research has shown\nthat interlocutors entrain on linguistic features in both written and spoken\nmonolingual domains. More recent work on code-switched communication has also\nshown preliminary evidence of entrainment on certain aspects of code-switching\n(CSW). However, such studies of entrainment in code-switched domains have been\nextremely few and restricted to human-machine textual interactions. Our work\nstudies code-switched spontaneous speech between humans, finding that (1)\npatterns of written and spoken entrainment in monolingual settings largely\ngeneralize to code-switched settings, and (2) some patterns of entrainment on\ncode-switching in dialogue agent-generated text generalize to spontaneous\ncode-switched speech. Our findings give rise to important implications for the\npotentially \"universal\" nature of entrainment as a communication phenomenon,\nand potential applications in inclusive and interactive speech technology.\n","authors":["Debasmita Bhattacharya","Siying Ding","Alayna Nguyen","Julia Hirschberg"],"pdf_url":"https://arxiv.org/pdf/2311.07703v2.pdf","comment":"Edits: camera-ready manuscript for NAACL 2024"},{"id":"http://arxiv.org/abs/2403.01748v2","updated":"2024-03-26T15:26:21Z","published":"2024-03-04T05:55:01Z","title":"Decode Neural signal as Speech","summary":"  Decoding language from brain dynamics is an important open direction in the\nrealm of brain-computer interface (BCI), especially considering the rapid\ngrowth of large language models. Compared to invasive-based signals which\nrequire electrode implantation surgery, non-invasive neural signals (e.g. EEG,\nMEG) have attracted increasing attention considering their safety and\ngenerality. However, the exploration is not adequate in three aspects: 1)\nprevious methods mainly focus on EEG but none of the previous works address\nthis problem on MEG with better signal quality; 2) prior works have\npredominantly used ``teacher-forcing\" during generative decoding, which is\nimpractical; 3) prior works are mostly ``BART-based\" not fully auto-regressive,\nwhich performs better in other sequence tasks. In this paper, we explore the\nbrain-to-text translation of MEG signals in a speech-decoding formation. Here\nwe are the first to investigate a cross-attention-based ``whisper\" model for\ngenerating text directly from MEG signals without teacher forcing. Our model\nachieves impressive BLEU-1 scores of 60.30 and 52.89 without pretraining \\&\nteacher-forcing on two major datasets (\\textit{GWilliams} and\n\\textit{Schoffelen}). This paper conducts a comprehensive review to understand\nhow speech decoding formation performs on the neural decoding tasks, including\npretraining initialization, training \\& evaluation set splitting, augmentation,\nand scaling law.\n","authors":["Yiqian Yang","Yiqun Duan","Qiang Zhang","Renjing Xu","Hui Xiong"],"pdf_url":"https://arxiv.org/pdf/2403.01748v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16167v2","updated":"2024-03-26T15:14:25Z","published":"2024-03-24T14:21:06Z","title":"Exploiting Semantic Reconstruction to Mitigate Hallucinations in\n  Vision-Language Models","summary":"  Hallucinations in vision-language models pose a significant challenge to\ntheir reliability, particularly in the generation of long captions. Current\nmethods fall short of accurately identifying and mitigating these\nhallucinations. To address this issue, we introduce ESREAL, a novel\nunsupervised learning framework designed to suppress the generation of\nhallucinations through accurate localization and penalization of hallucinated\ntokens. Initially, ESREAL creates a reconstructed image based on the generated\ncaption and aligns its corresponding regions with those of the original image.\nThis semantic reconstruction aids in identifying both the presence and type of\ntoken-level hallucinations within the generated caption. Subsequently, ESREAL\ncomputes token-level hallucination scores by assessing the semantic similarity\nof aligned regions based on the type of hallucination. Finally, ESREAL employs\na proximal policy optimization algorithm, where it selectively penalizes\nhallucinated tokens according to their token-level hallucination scores. Our\nframework notably reduces hallucinations in LLaVA, InstructBLIP, and mPLUG-Owl2\nby 32.81%, 27.08%, and 7.46% on the CHAIR metric. This improvement is achieved\nsolely through signals derived from the image itself, without the need for any\nimage-text pairs.\n","authors":["Minchan Kim","Minyeong Kim","Junik Bae","Suhwan Choi","Sungkyung Kim","Buru Chang"],"pdf_url":"https://arxiv.org/pdf/2403.16167v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17768v1","updated":"2024-03-26T14:54:48Z","published":"2024-03-26T14:54:48Z","title":"SciNews: From Scholarly Complexities to Public Narratives -- A Dataset\n  for Scientific News Report Generation","summary":"  Scientific news reports serve as a bridge, adeptly translating complex\nresearch articles into reports that resonate with the broader public. The\nautomated generation of such narratives enhances the accessibility of scholarly\ninsights. In this paper, we present a new corpus to facilitate this paradigm\ndevelopment. Our corpus comprises a parallel compilation of academic\npublications and their corresponding scientific news reports across nine\ndisciplines. To demonstrate the utility and reliability of our dataset, we\nconduct an extensive analysis, highlighting the divergences in readability and\nbrevity between scientific news narratives and academic manuscripts. We\nbenchmark our dataset employing state-of-the-art text generation models. The\nevaluation process involves both automatic and human evaluation, which lays the\ngroundwork for future explorations into the automated generation of scientific\nnews reports. The dataset and code related to this work are available at\nhttps://dongqi.me/projects/SciNews.\n","authors":["Dongqi Pu","Yifan Wang","Jia Loy","Vera Demberg"],"pdf_url":"https://arxiv.org/pdf/2403.17768v1.pdf","comment":"LREC-COLING 2024 Main Conference Paper"},{"id":"http://arxiv.org/abs/2403.17760v1","updated":"2024-03-26T14:51:12Z","published":"2024-03-26T14:51:12Z","title":"Constructions Are So Difficult That Even Large Language Models Get Them\n  Right for the Wrong Reasons","summary":"  In this paper, we make a contribution that can be understood from two\nperspectives: from an NLP perspective, we introduce a small challenge dataset\nfor NLI with large lexical overlap, which minimises the possibility of models\ndiscerning entailment solely based on token distinctions, and show that GPT-4\nand Llama 2 fail it with strong bias. We then create further challenging\nsub-tasks in an effort to explain this failure. From a Computational\nLinguistics perspective, we identify a group of constructions with three\nclasses of adjectives which cannot be distinguished by surface features. This\nenables us to probe for LLM's understanding of these constructions in various\nways, and we find that they fail in a variety of ways to distinguish between\nthem, suggesting that they don't adequately represent their meaning or capture\nthe lexical properties of phrasal heads.\n","authors":["Shijia Zhou","Leonie Weissweiler","Taiqi He","Hinrich Schütze","David R. Mortensen","Lori Levin"],"pdf_url":"https://arxiv.org/pdf/2403.17760v1.pdf","comment":"LREC-COLING 2024"},{"id":"http://arxiv.org/abs/2403.11996v2","updated":"2024-03-26T14:46:04Z","published":"2024-03-18T17:30:27Z","title":"Accelerating Scientific Discovery with Generative Knowledge Extraction,\n  Graph-Based Representation, and Multimodal Intelligent Graph Reasoning","summary":"  Leveraging generative Artificial Intelligence (AI), we have transformed a\ndataset comprising 1,000 scientific papers into an ontological knowledge graph.\nThrough an in-depth structural analysis, we have calculated node degrees,\nidentified communities and connectivities, and evaluated clustering\ncoefficients and betweenness centrality of pivotal nodes, uncovering\nfascinating knowledge architectures. The graph has an inherently scale-free\nnature, is highly connected, and can be used for graph reasoning by taking\nadvantage of transitive and isomorphic properties that reveal unprecedented\ninterdisciplinary relationships that can be used to answer queries, identify\ngaps in knowledge, propose never-before-seen material designs, and predict\nmaterial behaviors. We compute deep node embeddings for combinatorial node\nsimilarity ranking for use in a path sampling strategy links dissimilar\nconcepts that have previously not been related. One comparison revealed\nstructural parallels between biological materials and Beethoven's 9th Symphony,\nhighlighting shared patterns of complexity through isomorphic mapping. In\nanother example, the algorithm proposed a hierarchical mycelium-based composite\nbased on integrating path sampling with principles extracted from Kandinsky's\n'Composition VII' painting. The resulting material integrates an innovative set\nof concepts that include a balance of chaos/order, adjustable porosity,\nmechanical strength, and complex patterned chemical functionalization. We\nuncover other isomorphisms across science, technology and art, revealing a\nnuanced ontology of immanence that reveal a context-dependent heterarchical\ninterplay of constituents. Graph-based generative AI achieves a far higher\ndegree of novelty, explorative capacity, and technical detail, than\nconventional approaches and establishes a widely useful framework for\ninnovation by revealing hidden connections.\n","authors":["Markus J. Buehler"],"pdf_url":"https://arxiv.org/pdf/2403.11996v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17752v1","updated":"2024-03-26T14:43:48Z","published":"2024-03-26T14:43:48Z","title":"Can multiple-choice questions really be useful in detecting the\n  abilities of LLMs?","summary":"  Multiple-choice questions (MCQs) are widely used in the evaluation of large\nlanguage models (LLMs) due to their simplicity and efficiency. However, there\nare concerns about whether MCQs can truly measure LLM's capabilities,\nparticularly in knowledge-intensive scenarios where long-form generation (LFG)\nanswers are required. The misalignment between the task and the evaluation\nmethod demands a thoughtful analysis of MCQ's efficacy, which we undertake in\nthis paper by evaluating nine LLMs on four question-answering (QA) datasets in\ntwo languages: Chinese and English. We identify a significant issue: LLMs\nexhibit an order sensitivity in bilingual MCQs, favoring answers located at\nspecific positions, i.e., the first position. We further quantify the gap\nbetween MCQs and long-form generation questions (LFGQs) by comparing their\ndirect outputs, token logits, and embeddings. Our results reveal a relatively\nlow correlation between answers from MCQs and LFGQs for identical questions.\nAdditionally, we propose two methods to quantify the consistency and confidence\nof LLMs' output, which can be generalized to other QA evaluation benchmarks.\nNotably, our analysis challenges the idea that the higher the consistency, the\ngreater the accuracy. We also find MCQs to be less reliable than LFGQs in terms\nof expected calibration error. Finally, the misalignment between MCQs and LFGQs\nis not only reflected in the evaluation performance but also in the embedding\nspace. Our code and models can be accessed at\nhttps://github.com/Meetyou-AI-Lab/Can-MC-Evaluate-LLMs.\n","authors":["Wangyue Li","Liangzhi Li","Tong Xiang","Xiao Liu","Wei Deng","Noa Garcia"],"pdf_url":"https://arxiv.org/pdf/2403.17752v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17748v1","updated":"2024-03-26T14:40:10Z","published":"2024-03-26T14:40:10Z","title":"UCxn: Typologically Informed Annotation of Constructions Atop Universal\n  Dependencies","summary":"  The Universal Dependencies (UD) project has created an invaluable collection\nof treebanks with contributions in over 140 languages. However, the UD\nannotations do not tell the full story. Grammatical constructions that convey\nmeaning through a particular combination of several morphosyntactic elements --\nfor example, interrogative sentences with special markers and/or word orders --\nare not labeled holistically. We argue for (i) augmenting UD annotations with a\n'UCxn' annotation layer for such meaning-bearing grammatical constructions, and\n(ii) approaching this in a typologically informed way so that morphosyntactic\nstrategies can be compared across languages. As a case study, we consider five\nconstruction families in ten languages, identifying instances of each\nconstruction in UD treebanks through the use of morphosyntactic patterns. In\naddition to findings regarding these particular constructions, our study yields\nimportant insights on methodology for describing and identifying constructions\nin language-general and language-particular ways, and lays the foundation for\nfuture constructional enrichment of UD treebanks.\n","authors":["Leonie Weissweiler","Nina Böbel","Kirian Guiller","Santiago Herrera","Wesley Scivetti","Arthur Lorenzi","Nurit Melnik","Archna Bhatia","Hinrich Schütze","Lori Levin","Amir Zeldes","Joakim Nivre","William Croft","Nathan Schneider"],"pdf_url":"https://arxiv.org/pdf/2403.17748v1.pdf","comment":"LREC-COLING 2024"},{"id":"http://arxiv.org/abs/2310.02129v4","updated":"2024-03-26T14:38:23Z","published":"2023-10-03T15:10:46Z","title":"Unveiling the Pitfalls of Knowledge Editing for Large Language Models","summary":"  As the cost associated with fine-tuning Large Language Models (LLMs)\ncontinues to rise, recent research efforts have pivoted towards developing\nmethodologies to edit implicit knowledge embedded within LLMs. Yet, there's\nstill a dark cloud lingering overhead -- will knowledge editing trigger\nbutterfly effect? since it is still unclear whether knowledge editing might\nintroduce side effects that pose potential risks or not. This paper pioneers\nthe investigation into the potential pitfalls associated with knowledge editing\nfor LLMs. To achieve this, we introduce new benchmark datasets and propose\ninnovative evaluation metrics. Our results underline two pivotal concerns: (1)\nKnowledge Conflict: Editing groups of facts that logically clash can magnify\nthe inherent inconsistencies in LLMs-a facet neglected by previous methods. (2)\nKnowledge Distortion: Altering parameters with the aim of editing factual\nknowledge can irrevocably warp the innate knowledge structure of LLMs.\nExperimental results vividly demonstrate that knowledge editing might\ninadvertently cast a shadow of unintended consequences on LLMs, which warrant\nattention and efforts for future works. Code and data are available at\nhttps://github.com/zjunlp/PitfallsKnowledgeEditing.\n","authors":["Zhoubo Li","Ningyu Zhang","Yunzhi Yao","Mengru Wang","Xi Chen","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2310.02129v4.pdf","comment":"ICLR 2024"}],"Computer Science and Game Theory":[{"id":"http://arxiv.org/abs/2403.15198v2","updated":"2024-03-26T21:15:35Z","published":"2024-03-22T13:34:41Z","title":"On the Weighted Top-Difference Distance: Axioms, Aggregation, and\n  Approximation","summary":"  We study a family of distance functions on rankings that allow for asymmetric\ntreatments of alternatives and consider the distinct relevance of the top and\nbottom positions for ordered lists. We provide a full axiomatic\ncharacterization of our distance. In doing so, we retrieve new\ncharacterizations of existing axioms and show how to effectively weaken them\nfor our purposes. This analysis highlights the generality of our distance as it\nembeds many (semi)metrics previously proposed in the literature. Subsequently,\nwe show that, notwithstanding its level of generality, our distance is still\nreadily applicable. We apply it to preference aggregation, studying the\nfeatures of the associated median voting rule. It is shown how the derived\npreference function satisfies many desirable features in the context of voting\nrules, ranging from fairness to majority and Pareto-related properties. We show\nhow to compute consensus rankings exactly, and provide generalized\nDiaconis-Graham inequalities that can be leveraged to obtain approximation\nalgorithms. Finally, we propose some truncation ideas for our distances\ninspired by Lu and Boutilier (2010). These can be leveraged to devise a\nPolynomial-Time-Approximation Scheme for the corresponding rank aggregation\nproblem.\n","authors":["Andrea Aveni","Ludovico Crippa","Giulio Principi"],"pdf_url":"https://arxiv.org/pdf/2403.15198v2.pdf","comment":"64 pages"},{"id":"http://arxiv.org/abs/2403.18086v1","updated":"2024-03-26T20:18:05Z","published":"2024-03-26T20:18:05Z","title":"Generalizing Better Response Paths and Weakly Acyclic Games","summary":"  Weakly acyclic games generalize potential games and are fundamental to the\nstudy of game theoretic control. In this paper, we present a generalization of\nweakly acyclic games, and we observe its importance in multi-agent learning\nwhen agents employ experimental strategy updates in periods where they fail to\nbest respond. While weak acyclicity is defined in terms of path connectivity\nproperties of a game's better response graph, our generalization is defined\nusing a generalized better response graph. We provide sufficient conditions for\nthis notion of generalized weak acyclicity in both two-player games and\n$n$-player games. To demonstrate that our generalization is not trivial, we\nprovide examples of games admitting a pure Nash equilibrium that are not\ngeneralized weakly acyclic. The generalization presented in this work is\nclosely related to the recent theory of satisficing paths, and the\ncounterexamples presented here constitute the first negative results in that\ntheory.\n","authors":["Bora Yongacoglu","Gürdal Arslan","Lacra Pavel","Serdar Yüksel"],"pdf_url":"https://arxiv.org/pdf/2403.18086v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18079v1","updated":"2024-03-26T19:58:39Z","published":"2024-03-26T19:58:39Z","title":"Paths to Equilibrium in Normal-Form Games","summary":"  In multi-agent reinforcement learning (MARL), agents repeatedly interact\nacross time and revise their strategies as new data arrives, producing a\nsequence of strategy profiles. This paper studies sequences of strategies\nsatisfying a pairwise constraint inspired by policy updating in reinforcement\nlearning, where an agent who is best responding in period $t$ does not switch\nits strategy in the next period $t+1$. This constraint merely requires that\noptimizing agents do not switch strategies, but does not constrain the other\nnon-optimizing agents in any way, and thus allows for exploration. Sequences\nwith this property are called satisficing paths, and arise naturally in many\nMARL algorithms. A fundamental question about strategic dynamics is such: for a\ngiven game and initial strategy profile, is it always possible to construct a\nsatisficing path that terminates at an equilibrium strategy? The resolution of\nthis question has implications about the capabilities or limitations of a class\nof MARL algorithms. We answer this question in the affirmative for mixed\nextensions of finite normal-form games.%\n","authors":["Bora Yongacoglu","Gürdal Arslan","Lacra Pavel","Serdar Yüksel"],"pdf_url":"https://arxiv.org/pdf/2403.18079v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.02879v2","updated":"2024-03-26T19:08:00Z","published":"2023-10-04T15:17:28Z","title":"Online Mechanism Design with Predictions","summary":"  Aiming to overcome some of the limitations of worst-case analysis, the\nrecently proposed framework of \"algorithms with predictions\" allows algorithms\nto be augmented with a (possibly erroneous) machine-learned prediction that\nthey can use as a guide. In this framework, the goal is to obtain improved\nguarantees when the prediction is correct, which is called \\emph{consistency},\nwhile simultaneously guaranteeing some worst-case bounds even when the\nprediction is arbitrarily wrong, which is called \\emph{robustness}. The vast\nmajority of the work on this framework has focused on a refined analysis of\nonline algorithms augmented with predictions regarding the future input. A\nsubsequent line of work has also successfully adapted this framework to\nmechanism design, where the prediction is regarding the private information of\nstrategic agents. In this paper, we initiate the study of online mechanism\ndesign with predictions, which combines the challenges of online algorithms\nwith predictions and mechanism design with predictions.\n  We consider the well-studied problem of designing a revenue-maximizing\nauction to sell a single item to strategic bidders who arrive and depart over\ntime, each with an unknown, private, value for the item. We study the\nlearning-augmented version of this problem where the auction designer is given\na prediction regarding the maximum value over all agents. Our main result is a\nstrategyproof mechanism whose revenue guarantees are $\\alpha$-consistent with\nrespect to the highest value and $(1-\\alpha^2)/4$-robust with respect to the\nsecond-highest value, for $\\alpha \\in [0,1]$. We show that this tradeoff is\noptimal within a broad and natural family of auctions, meaning that any\n$\\alpha$-consistent mechanism in that family has robustness at most\n$(1-\\alpha^2)/4$. Finally, we extend our mechanism to also achieve expected\nrevenues proportional to the prediction quality.\n","authors":["Eric Balkanski","Vasilis Gkatzelis","Xizhi Tan","Cherlin Zhu"],"pdf_url":"https://arxiv.org/pdf/2310.02879v2.pdf","comment":"25 pages, 1 figure"},{"id":"http://arxiv.org/abs/2403.17515v1","updated":"2024-03-26T09:18:50Z","published":"2024-03-26T09:18:50Z","title":"Prediction-sharing During Training and Inference","summary":"  Two firms are engaged in a competitive prediction task. Each firm has two\nsources of data -- labeled historical data and unlabeled inference-time data --\nand uses the former to derive a prediction model, and the latter to make\npredictions on new instances. We study data-sharing contracts between the\nfirms. The novelty of our study is to introduce and highlight the differences\nbetween contracts that share prediction models only, contracts to share\ninference-time predictions only, and contracts to share both. Our analysis\nproceeds on three levels. First, we develop a general Bayesian framework that\nfacilitates our study. Second, we narrow our focus to two natural settings\nwithin this framework: (i) a setting in which the accuracy of each firm's\nprediction model is common knowledge, but the correlation between the\nrespective models is unknown; and (ii) a setting in which two hypotheses exist\nregarding the optimal predictor, and one of the firms has a structural\nadvantage in deducing it. Within these two settings we study optimal contract\nchoice. More specifically, we find the individually rational and Pareto-optimal\ncontracts for some notable cases, and describe specific settings where each of\nthe different sharing contracts emerge as optimal. Finally, in the third level\nof our analysis we demonstrate the applicability of our concepts in a synthetic\nsimulation using real loan data.\n","authors":["Yotam Gafni","Ronen Gradwohl","Moshe Tennenholtz"],"pdf_url":"https://arxiv.org/pdf/2403.17515v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17302v1","updated":"2024-03-26T01:14:18Z","published":"2024-03-26T01:14:18Z","title":"So Long Sucker: Endgame Analysis","summary":"  So Long Sucker is a strategy board game requiring 4 players, each with $c$\nchips of their designated color, and a board made of $k$ empty piles. With a\nclear set-up come intricate rules, such as: players taking turns but not in a\nfixed order, agreements between some players being made and broken at any time,\nand a player winning the game even without any chips in hand.\n  One of the main points of interest in studying this game, is finding when a\nplayer has a winning strategy. The game begins with four players that get\neliminated successively until the winner is left. To study winning strategies,\nit is of interest to look at endgame situations. We present the following game\nset-up: there are two players left in the game, Blue and Red, and only their\nrespective chip colors. In this paper, we characterize Blue's winning\nsituations and strategies through inductive reasoning.\n","authors":["Jean-Lou De Carufel","Marie Rose Jerade"],"pdf_url":"https://arxiv.org/pdf/2403.17302v1.pdf","comment":"49 pages"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2309.16046v3","updated":"2024-03-26T20:58:15Z","published":"2023-09-27T21:58:18Z","title":"Confidence and second-order errors in cortical circuits","summary":"  Minimization of cortical prediction errors has been considered a key\ncomputational goal of the cerebral cortex underlying perception, action and\nlearning. However, it is still unclear how the cortex should form and use\ninformation about uncertainty in this process. Here, we formally derive neural\ndynamics that minimize prediction errors under the assumption that cortical\nareas must not only predict the activity in other areas and sensory streams but\nalso jointly project their confidence (inverse expected uncertainty) in their\npredictions. In the resulting neuronal dynamics, the integration of bottom-up\nand top-down cortical streams is dynamically modulated based on confidence in\naccordance with the Bayesian principle. Moreover, the theory predicts the\nexistence of cortical second-order errors, comparing confidence and actual\nperformance. These errors are propagated through the cortical hierarchy\nalongside classical prediction errors and are used to learn the weights of\nsynapses responsible for formulating confidence. We propose a detailed mapping\nof the theory to cortical circuitry, discuss entailed functional\ninterpretations and provide potential directions for experimental work.\n","authors":["Arno Granier","Mihai A. Petrovici","Walter Senn","Katharina A. Wilmes"],"pdf_url":"https://arxiv.org/pdf/2309.16046v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.05465v2","updated":"2024-03-26T18:43:35Z","published":"2024-03-08T17:28:49Z","title":"Algorithm-Hardware Co-Design of Distribution-Aware Logarithmic-Posit\n  Encodings for Efficient DNN Inference","summary":"  Traditional Deep Neural Network (DNN) quantization methods using integer,\nfixed-point, or floating-point data types struggle to capture diverse DNN\nparameter distributions at low precision, and often require large silicon\noverhead and intensive quantization-aware training. In this study, we introduce\nLogarithmic Posits (LP), an adaptive, hardware-friendly data type inspired by\nposits that dynamically adapts to DNN weight/activation distributions by\nparameterizing LP bit fields. We also develop a novel genetic-algorithm based\nframework, LP Quantization (LPQ), to find optimal layer-wise LP parameters\nwhile reducing representational divergence between quantized and full-precision\nmodels through a novel global-local contrastive objective. Additionally, we\ndesign a unified mixed-precision LP accelerator (LPA) architecture comprising\nof processing elements (PEs) incorporating LP in the computational datapath.\nOur algorithm-hardware co-design demonstrates on average <1% drop in top-1\naccuracy across various CNN and ViT models. It also achieves ~ 2x improvements\nin performance per unit area and 2.2x gains in energy efficiency compared to\nstate-of-the-art quantization accelerators using different data types.\n","authors":["Akshat Ramachandran","Zishen Wan","Geonhwa Jeong","John Gustafson","Tushar Krishna"],"pdf_url":"https://arxiv.org/pdf/2403.05465v2.pdf","comment":"2024 61st IEEE/ACM Design Automation Conference (DAC)"},{"id":"http://arxiv.org/abs/2310.02156v4","updated":"2024-03-26T17:36:54Z","published":"2023-10-03T15:43:59Z","title":"Probabilistically Rewired Message-Passing Neural Networks","summary":"  Message-passing graph neural networks (MPNNs) emerged as powerful tools for\nprocessing graph-structured input. However, they operate on a fixed input graph\nstructure, ignoring potential noise and missing information. Furthermore, their\nlocal aggregation mechanism can lead to problems such as over-squashing and\nlimited expressive power in capturing relevant graph structures. Existing\nsolutions to these challenges have primarily relied on heuristic methods, often\ndisregarding the underlying data distribution. Hence, devising principled\napproaches for learning to infer graph structures relevant to the given\nprediction task remains an open challenge. In this work, leveraging recent\nprogress in exact and differentiable $k$-subset sampling, we devise\nprobabilistically rewired MPNNs (PR-MPNNs), which learn to add relevant edges\nwhile omitting less beneficial ones. For the first time, our theoretical\nanalysis explores how PR-MPNNs enhance expressive power, and we identify\nprecise conditions under which they outperform purely randomized approaches.\nEmpirically, we demonstrate that our approach effectively mitigates issues like\nover-squashing and under-reaching. In addition, on established real-world\ndatasets, our method exhibits competitive or superior predictive performance\ncompared to traditional MPNN models and recent graph transformer architectures.\n","authors":["Chendi Qian","Andrei Manolache","Kareem Ahmed","Zhe Zeng","Guy Van den Broeck","Mathias Niepert","Christopher Morris"],"pdf_url":"https://arxiv.org/pdf/2310.02156v4.pdf","comment":"ICLR 2024"},{"id":"http://arxiv.org/abs/2403.15505v2","updated":"2024-03-26T13:42:09Z","published":"2024-03-22T01:20:45Z","title":"A Nonlinear African Vulture Optimization Algorithm Combining Henon\n  Chaotic Mapping Theory and Reverse Learning Competition Strategy","summary":"  In order to alleviate the main shortcomings of the AVOA, a nonlinear African\nvulture optimization algorithm combining Henon chaotic mapping theory and\nreverse learning competition strategy (HWEAVOA) is proposed. Firstly, the Henon\nchaotic mapping theory and elite population strategy are proposed to improve\nthe randomness and diversity of the vulture's initial population; Furthermore,\nthe nonlinear adaptive incremental inertial weight factor is introduced in the\nlocation update phase to rationally balance the exploration and exploitation\nabilities, and avoid individual falling into a local optimum; The reverse\nlearning competition strategy is designed to expand the discovery fields for\nthe optimal solution and strengthen the ability to jump out of the local\noptimal solution. HWEAVOA and other advanced comparison algorithms are used to\nsolve classical and CEC2022 test functions. Compared with other algorithms, the\nconvergence curves of the HWEAVOA drop faster and the line bodies are smoother.\nThese experimental results show the proposed HWEAVOA is ranked first in all\ntest functions, which is superior to the comparison algorithms in convergence\nspeed, optimization ability, and solution stability. Meanwhile, HWEAVOA has\nreached the general level in the algorithm complexity, and its overall\nperformance is competitive in the swarm intelligence algorithms.\n","authors":["Baiyi Wang","Zipeng Zhang","Patrick Siarry","Xinhua Liu","Grzegorz Królczyk","Dezheng Hua","Frantisek Brumercik","Zhixiong Li"],"pdf_url":"https://arxiv.org/pdf/2403.15505v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.06074v2","updated":"2024-03-26T13:26:31Z","published":"2023-11-10T14:16:46Z","title":"Two-compartment neuronal spiking model expressing brain-state specific\n  apical-amplification, -isolation and -drive regimes","summary":"  Mounting experimental evidence suggests that brain-state-specific neural\nmechanisms, supported by connectomic architectures, play a crucial role in\nintegrating past and contextual knowledge with the current, incoming flow of\nevidence (e.g., from sensory systems). These mechanisms operate across multiple\nspatial and temporal scales, necessitating dedicated support at the levels of\nindividual neurons and synapses. A notable feature within the neocortex is the\nstructure of large, deep pyramidal neurons, which exhibit a distinctive\nseparation between an apical dendritic compartment and a basal\ndendritic/perisomatic compartment. This separation is characterized by distinct\npatterns of incoming connections and brain-state-specific activation\nmechanisms, namely, apical amplification, isolation, and drive, which are\nassociated with wakefulness, deeper NREM sleep stages, and REM sleep,\nrespectively. The cognitive roles of apical mechanisms have been demonstrated\nin behaving animals. In contrast, classical models of learning in spiking\nnetworks are based on single-compartment neurons, lacking the ability to\ndescribe the integration of apical and basal/somatic information. This work\naims to provide the computational community with a two-compartment spiking\nneuron model that incorporates features essential for supporting\nbrain-state-specific learning. This model includes a piece-wise linear transfer\nfunction (ThetaPlanes) at the highest abstraction level, making it suitable for\nuse in large-scale bio-inspired artificial intelligence systems. A machine\nlearning evolutionary algorithm, guided by a set of fitness functions, selected\nthe parameters that define neurons expressing the desired apical mechanisms.\n","authors":["Elena Pastorelli","Alper Yegenoglu","Nicole Kolodziej","Willem Wybo","Francesco Simula","Sandra Diaz","Johan Frederik Storm","Pier Stanislao Paolucci"],"pdf_url":"https://arxiv.org/pdf/2311.06074v2.pdf","comment":"23 pages, 9 figures (29 single images), 4 tables, paper"},{"id":"http://arxiv.org/abs/2403.17656v1","updated":"2024-03-26T12:39:02Z","published":"2024-03-26T12:39:02Z","title":"SGHormer: An Energy-Saving Graph Transformer Driven by Spikes","summary":"  Graph Transformers (GTs) with powerful representation learning ability make a\nhuge success in wide range of graph tasks. However, the costs behind\noutstanding performances of GTs are higher energy consumption and computational\noverhead. The complex structure and quadratic complexity during attention\ncalculation in vanilla transformer seriously hinder its scalability on the\nlarge-scale graph data. Though existing methods have made strides in\nsimplifying combinations among blocks or attention-learning paradigm to improve\nGTs' efficiency, a series of energy-saving solutions originated from\nbiologically plausible structures are rarely taken into consideration when\nconstructing GT framework. To this end, we propose a new spiking-based graph\ntransformer (SGHormer). It turns full-precision embeddings into sparse and\nbinarized spikes to reduce memory and computational costs. The spiking graph\nself-attention and spiking rectify blocks in SGHormer explicitly capture global\nstructure information and recover the expressive power of spiking embeddings,\nrespectively. In experiments, SGHormer achieves comparable performances to\nother full-precision GTs with extremely low computational energy consumption.\nThe results show that SGHomer makes a remarkable progress in the field of\nlow-energy GTs.\n","authors":["Huizhe Zhang","Jintang Li","Liang Chen","Zibin Zheng"],"pdf_url":"https://arxiv.org/pdf/2403.17656v1.pdf","comment":"9 pages, 3 figures"},{"id":"http://arxiv.org/abs/2310.12541v3","updated":"2024-03-26T12:04:44Z","published":"2023-10-19T07:46:54Z","title":"Large Language Model for Multi-objective Evolutionary Optimization","summary":"  Multiobjective evolutionary algorithms (MOEAs) are major methods for solving\nmultiobjective optimization problems (MOPs). Many MOEAs have been proposed in\nthe past decades, of which the search operators need a carefully handcrafted\ndesign with domain knowledge. Recently, some attempts have been made to replace\nthe manually designed operators in MOEAs with learning-based operators (e.g.,\nneural network models). However, much effort is still required for designing\nand training such models, and the learned operators might not generalize well\non new problems. To tackle the above challenges, this work investigates a novel\napproach that leverages the powerful large language model (LLM) to design MOEA\noperators. With proper prompt engineering, we successfully let a general LLM\nserve as a black-box search operator for decomposition-based MOEA (MOEA/D) in a\nzero-shot manner. In addition, by learning from the LLM behavior, we further\ndesign an explicit white-box operator with randomness and propose a new version\nof decomposition-based MOEA, termed MOEA/D-LO. Experimental studies on\ndifferent test benchmarks show that our proposed method can achieve competitive\nperformance with widely used MOEAs. It is also promising to see the operator\nonly learned from a few instances can have robust generalization performance on\nunseen problems with quite different patterns and settings. The results reveal\nthe potential benefits of using pre-trained LLMs in the design of MOEAs.To\nfoster reproducibility and accessibility, the source code is\nhttps://github.com/FeiLiu36/LLM4MOEA.\n","authors":["Fei Liu","Xi Lin","Zhenkun Wang","Shunyu Yao","Xialiang Tong","Mingxuan Yuan","Qingfu Zhang"],"pdf_url":"https://arxiv.org/pdf/2310.12541v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.12086v2","updated":"2024-03-26T07:54:02Z","published":"2023-11-20T13:45:21Z","title":"Masked Autoencoders Are Robust Neural Architecture Search Learners","summary":"  Neural Architecture Search (NAS) currently relies heavily on labeled data,\nwhich is both expensive and time-consuming to acquire. In this paper, we\npropose a novel NAS framework based on Masked Autoencoders (MAE) that\neliminates the need for labeled data during the search process. By replacing\nthe supervised learning objective with an image reconstruction task, our\napproach enables the robust discovery of network architectures without\ncompromising performance and generalization ability. Additionally, we address\nthe problem of performance collapse encountered in the widely-used\nDifferentiable Architecture Search (DARTS) method in the unsupervised paradigm\nby introducing a multi-scale decoder. Through extensive experiments conducted\non various search spaces and datasets, we demonstrate the effectiveness and\nrobustness of the proposed method, providing empirical evidence of its\nsuperiority over baseline approaches.\n","authors":["Yiming Hu","Xiangxiang Chu","Bo Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.12086v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17447v1","updated":"2024-03-26T07:26:00Z","published":"2024-03-26T07:26:00Z","title":"Chain of Compression: A Systematic Approach to Combinationally Compress\n  Convolutional Neural Networks","summary":"  Convolutional neural networks (CNNs) have achieved significant popularity,\nbut their computational and memory intensity poses challenges for\nresource-constrained computing systems, particularly with the prerequisite of\nreal-time performance. To release this burden, model compression has become an\nimportant research focus. Many approaches like quantization, pruning, early\nexit, and knowledge distillation have demonstrated the effect of reducing\nredundancy in neural networks. Upon closer examination, it becomes apparent\nthat each approach capitalizes on its unique features to compress the neural\nnetwork, and they can also exhibit complementary behavior when combined. To\nexplore the interactions and reap the benefits from the complementary features,\nwe propose the Chain of Compression, which works on the combinational sequence\nto apply these common techniques to compress the neural network. Validated on\nthe image-based regression and classification networks across different data\nsets, our proposed Chain of Compression can significantly compress the\ncomputation cost by 100-1000 times with ignorable accuracy loss compared with\nthe baseline model.\n","authors":["Yingtao Shen","Minqing Sun","Jie Zhao","An Zou"],"pdf_url":"https://arxiv.org/pdf/2403.17447v1.pdf","comment":"10 pages, 15 figures"},{"id":"http://arxiv.org/abs/2303.02490v2","updated":"2024-03-26T03:41:26Z","published":"2023-03-04T20:08:57Z","title":"Diffusion Models Generate Images Like Painters: an Analytical Theory of\n  Outline First, Details Later","summary":"  How do diffusion generative models convert pure noise into meaningful images?\nIn a variety of pretrained diffusion models (including conditional latent space\nmodels like Stable Diffusion), we observe that the reverse diffusion process\nthat underlies image generation has the following properties: (i) individual\ntrajectories tend to be low-dimensional and resemble 2D `rotations'; (ii)\nhigh-variance scene features like layout tend to emerge earlier, while\nlow-variance details tend to emerge later; and (iii) early perturbations tend\nto have a greater impact on image content than later perturbations. To\nunderstand these phenomena, we derive and study a closed-form solution to the\nprobability flow ODE for a Gaussian distribution, which shows that the reverse\ndiffusion state rotates towards a gradually-specified target on the image\nmanifold. It also shows that generation involves first committing to an\noutline, and then to finer and finer details. We find that this solution\naccurately describes the initial phase of image generation for pretrained\nmodels, and can in principle be used to make image generation more efficient by\nskipping reverse diffusion steps. Finally, we use our solution to characterize\nthe image manifold in Stable Diffusion. Our viewpoint reveals an unexpected\nsimilarity between generation by GANs and diffusion and provides a conceptual\nlink between diffusion and image retrieval.\n","authors":["Binxu Wang","John J. Vastola"],"pdf_url":"https://arxiv.org/pdf/2303.02490v2.pdf","comment":"44 pages, 28 figures. A briefer version was presented at NeurIPS23\n  Workshop on Diffusion Models [arXiv:2311.10892]"},{"id":"http://arxiv.org/abs/2403.11138v3","updated":"2024-03-26T02:40:04Z","published":"2024-03-17T08:41:48Z","title":"Spiking Wavelet Transformer","summary":"  Spiking neural networks (SNNs) offer an energy-efficient alternative to\nconventional deep learning by mimicking the event-driven processing of the\nbrain. Incorporating the Transformers with SNNs has shown promise for accuracy,\nyet it is incompetent to capture high-frequency patterns like moving edge and\npixel-level brightness changes due to their reliance on global self-attention\noperations. Porting frequency representations in SNN is challenging yet crucial\nfor event-driven vision. To address this issue, we propose the Spiking Wavelet\nTransformer (SWformer), an attention-free architecture that effectively learns\ncomprehensive spatial-frequency features in a spike-driven manner by leveraging\nthe sparse wavelet transform. The critical component is a Frequency-Aware Token\nMixer (FATM) with three branches: 1) spiking wavelet learner for\nspatial-frequency domain learning, 2) convolution-based learner for spatial\nfeature extraction, and 3) spiking pointwise convolution for cross-channel\ninformation aggregation. We also adopt negative spike dynamics to strengthen\nthe frequency representation further. This enables the SWformer to outperform\nvanilla Spiking Transformers in capturing high-frequency visual components, as\nevidenced by our empirical results. Experiments on both static and neuromorphic\ndatasets demonstrate SWformer's effectiveness in capturing spatial-frequency\npatterns in a multiplication-free, event-driven fashion, outperforming\nstate-of-the-art SNNs. SWformer achieves an over 50% reduction in energy\nconsumption, a 21.1% reduction in parameter count, and a 2.40% performance\nimprovement on the ImageNet dataset compared to vanilla Spiking Transformers.\n","authors":["Yuetong Fang","Ziqing Wang","Lingfeng Zhang","Jiahang Cao","Honglei Chen","Renjing Xu"],"pdf_url":"https://arxiv.org/pdf/2403.11138v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17328v1","updated":"2024-03-26T02:22:08Z","published":"2024-03-26T02:22:08Z","title":"Learning Traffic Signal Control via Genetic Programming","summary":"  The control of traffic signals is crucial for improving transportation\nefficiency. Recently, learning-based methods, especially Deep Reinforcement\nLearning (DRL), garnered substantial success in the quest for more efficient\ntraffic signal control strategies. However, the design of rewards in DRL highly\ndemands domain knowledge to converge to an effective policy, and the final\npolicy also presents difficulties in terms of explainability. In this work, a\nnew learning-based method for signal control in complex intersections is\nproposed. In our approach, we design a concept of phase urgency for each signal\nphase. During signal transitions, the traffic light control strategy selects\nthe next phase to be activated based on the phase urgency. We then proposed to\nrepresent the urgency function as an explainable tree structure. The urgency\nfunction can calculate the phase urgency for a specific phase based on the\ncurrent road conditions. Genetic programming is adopted to perform\ngradient-free optimization of the urgency function. We test our algorithm on\nmultiple public traffic signal control datasets. The experimental results\nindicate that the tree-shaped urgency function evolved by genetic programming\noutperforms the baselines, including a state-of-the-art method in the\ntransportation field and a well-known DRL-based method.\n","authors":["Xiao-Cheng Liao","Yi Mei","Mengjie Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.17328v1.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2306.13829v3","updated":"2024-03-26T23:39:35Z","published":"2023-06-24T01:14:26Z","title":"Selective inference using randomized group lasso estimators for general\n  models","summary":"  Selective inference methods are developed for group lasso estimators for use\nwith a wide class of distributions and loss functions. The method includes the\nuse of exponential family distributions, as well as quasi-likelihood modeling\nfor overdispersed count data, for example, and allows for categorical or\ngrouped covariates as well as continuous covariates. A randomized\ngroup-regularized optimization problem is studied. The added randomization\nallows us to construct a post-selection likelihood which we show to be adequate\nfor selective inference when conditioning on the event of the selection of the\ngrouped covariates. This likelihood also provides a selective point estimator,\naccounting for the selection by the group lasso. Confidence regions for the\nregression parameters in the selected model take the form of Wald-type regions\nand are shown to have bounded volume. The selective inference method for\ngrouped lasso is illustrated on data from the national health and nutrition\nexamination survey while simulations showcase its behaviour and favorable\ncomparison with other methods.\n","authors":["Yiling Huang","Sarah Pirenne","Snigdha Panigrahi","Gerda Claeskens"],"pdf_url":"https://arxiv.org/pdf/2306.13829v3.pdf","comment":"64pages, 4 figures, 3 tables"},{"id":"http://arxiv.org/abs/2403.18127v1","updated":"2024-03-26T22:15:47Z","published":"2024-03-26T22:15:47Z","title":"A Correction of Pseudo Log-Likelihood Method","summary":"  Pseudo log-likelihood is a type of maximum likelihood estimation (MLE) method\nused in various fields including contextual bandits, influence maximization of\nsocial networks, and causal bandits. However, in previous literature\n\\citep{li2017provably, zhang2022online, xiong2022combinatorial,\nfeng2023combinatorial1, feng2023combinatorial2}, the log-likelihood function\nmay not be bounded, which may result in the algorithm they proposed not\nwell-defined. In this paper, we give a counterexample that the maximum pseudo\nlog-likelihood estimation fails and then provide a solution to correct the\nalgorithms in \\citep{li2017provably, zhang2022online, xiong2022combinatorial,\nfeng2023combinatorial1, feng2023combinatorial2}.\n","authors":["Shi Feng","Nuoya Xiong","Zhijie Zhang","Wei Chen"],"pdf_url":"https://arxiv.org/pdf/2403.18127v1.pdf","comment":"7 pages"},{"id":"http://arxiv.org/abs/2402.09654v2","updated":"2024-03-26T20:12:18Z","published":"2024-02-15T01:38:50Z","title":"GPT-4's assessment of its performance in a USMLE-based case study","summary":"  This study investigates GPT-4's assessment of its performance in healthcare\napplications. A simple prompting technique was used to prompt the LLM with\nquestions taken from the United States Medical Licensing Examination (USMLE)\nquestionnaire and it was tasked to evaluate its confidence score before posing\nthe question and after asking the question. The questionnaire was categorized\ninto two groups-questions with feedback (WF) and questions with no feedback(NF)\npost-question. The model was asked to provide absolute and relative confidence\nscores before and after each question. The experimental findings were analyzed\nusing statistical tools to study the variability of confidence in WF and NF\ngroups. Additionally, a sequential analysis was conducted to observe the\nperformance variation for the WF and NF groups. Results indicate that feedback\ninfluences relative confidence but doesn't consistently increase or decrease\nit. Understanding the performance of LLM is paramount in exploring its utility\nin sensitive areas like healthcare. This study contributes to the ongoing\ndiscourse on the reliability of AI, particularly of LLMs like GPT-4, within\nhealthcare, offering insights into how feedback mechanisms might be optimized\nto enhance AI-assisted medical education and decision support.\n","authors":["Uttam Dhakal","Aniket Kumar Singh","Suman Devkota","Yogesh Sapkota","Bishal Lamichhane","Suprinsa Paudyal","Chandra Dhakal"],"pdf_url":"https://arxiv.org/pdf/2402.09654v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18072v1","updated":"2024-03-26T19:49:58Z","published":"2024-03-26T19:49:58Z","title":"Goal-Oriented Bayesian Optimal Experimental Design for Nonlinear Models\n  using Markov Chain Monte Carlo","summary":"  Optimal experimental design (OED) provides a systematic approach to quantify\nand maximize the value of experimental data. Under a Bayesian approach,\nconventional OED maximizes the expected information gain (EIG) on model\nparameters. However, we are often interested in not the parameters themselves,\nbut predictive quantities of interest (QoIs) that depend on the parameters in a\nnonlinear manner. We present a computational framework of predictive\ngoal-oriented OED (GO-OED) suitable for nonlinear observation and prediction\nmodels, which seeks the experimental design providing the greatest EIG on the\nQoIs. In particular, we propose a nested Monte Carlo estimator for the QoI EIG,\nfeaturing Markov chain Monte Carlo for posterior sampling and kernel density\nestimation for evaluating the posterior-predictive density and its\nKullback-Leibler divergence from the prior-predictive. The GO-OED design is\nthen found by maximizing the EIG over the design space using Bayesian\noptimization. We demonstrate the effectiveness of the overall nonlinear GO-OED\nmethod, and illustrate its differences versus conventional non-GO-OED, through\nvarious test problems and an application of sensor placement for source\ninversion in a convection-diffusion field.\n","authors":["Shijie Zhong","Wanggang Shen","Tommie Catanach","Xun Huan"],"pdf_url":"https://arxiv.org/pdf/2403.18072v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.15328v3","updated":"2024-03-26T18:19:54Z","published":"2023-06-27T09:34:32Z","title":"Simulating counterfactuals","summary":"  Counterfactual inference considers a hypothetical intervention in a parallel\nworld that shares some evidence with the factual world. If the evidence\nspecifies a conditional distribution on a manifold, counterfactuals may be\nanalytically intractable. We present an algorithm for simulating values from a\ncounterfactual distribution where conditions can be set on both discrete and\ncontinuous variables. We show that the proposed algorithm can be presented as a\nparticle filter leading to asymptotically valid inference. The algorithm is\napplied to fairness analysis in credit-scoring.\n","authors":["Juha Karvanen","Santtu Tikka","Matti Vihola"],"pdf_url":"https://arxiv.org/pdf/2306.15328v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.01364v3","updated":"2024-03-26T17:45:01Z","published":"2022-11-02T17:59:09Z","title":"An optimal control perspective on diffusion-based generative modeling","summary":"  We establish a connection between stochastic optimal control and generative\nmodels based on stochastic differential equations (SDEs), such as recently\ndeveloped diffusion probabilistic models. In particular, we derive a\nHamilton-Jacobi-Bellman equation that governs the evolution of the\nlog-densities of the underlying SDE marginals. This perspective allows to\ntransfer methods from optimal control theory to generative modeling. First, we\nshow that the evidence lower bound is a direct consequence of the well-known\nverification theorem from control theory. Further, we can formulate\ndiffusion-based generative modeling as a minimization of the Kullback-Leibler\ndivergence between suitable measures in path space. Finally, we develop a novel\ndiffusion-based method for sampling from unnormalized densities -- a problem\nfrequently occurring in statistics and computational sciences. We demonstrate\nthat our time-reversed diffusion sampler (DIS) can outperform other\ndiffusion-based sampling approaches on multiple numerical examples.\n","authors":["Julius Berner","Lorenz Richter","Karen Ullrich"],"pdf_url":"https://arxiv.org/pdf/2211.01364v3.pdf","comment":"Accepted for oral presentation at NeurIPS 2022 Workshop on\n  Score-Based Methods"},{"id":"http://arxiv.org/abs/2403.17887v1","updated":"2024-03-26T17:20:04Z","published":"2024-03-26T17:20:04Z","title":"The Unreasonable Ineffectiveness of the Deeper Layers","summary":"  We empirically study a simple layer-pruning strategy for popular families of\nopen-weight pretrained LLMs, finding minimal degradation of performance on\ndifferent question-answering benchmarks until after a large fraction (up to\nhalf) of the layers are removed. To prune these models, we identify the optimal\nblock of layers to prune by considering similarity across layers; then, to\n\"heal\" the damage, we perform a small amount of finetuning. In particular, we\nuse parameter-efficient finetuning (PEFT) methods, specifically quantization\nand Low Rank Adapters (QLoRA), such that each of our experiments can be\nperformed on a single A100 GPU. From a practical perspective, these results\nsuggest that layer pruning methods can complement other PEFT strategies to\nfurther reduce computational resources of finetuning on the one hand, and can\nimprove the memory and latency of inference on the other hand. From a\nscientific perspective, the robustness of these LLMs to the deletion of layers\nimplies either that current pretraining methods are not properly leveraging the\nparameters in the deeper layers of the network or that the shallow layers play\na critical role in storing knowledge.\n","authors":["Andrey Gromov","Kushal Tirumala","Hassan Shapourian","Paolo Glorioso","Daniel A. Roberts"],"pdf_url":"https://arxiv.org/pdf/2403.17887v1.pdf","comment":"12 + 10 pages, 5 + 4 figures"},{"id":"http://arxiv.org/abs/2210.06459v2","updated":"2024-03-26T16:49:11Z","published":"2022-10-12T17:56:04Z","title":"Differentially private multivariate medians","summary":"  Statistical tools which satisfy rigorous privacy guarantees are necessary for\nmodern data analysis. It is well-known that robustness against contamination is\nlinked to differential privacy. Despite this fact, using multivariate medians\nfor differentially private and robust multivariate location estimation has not\nbeen systematically studied. We develop novel finite-sample performance\nguarantees for differentially private multivariate depth-based medians, which\nare essentially sharp. Our results cover commonly used depth functions, such as\nthe halfspace (or Tukey) depth, spatial depth, and the integrated dual depth.\nWe show that under Cauchy marginals, the cost of heavy-tailed location\nestimation outweighs the cost of privacy. We demonstrate our results\nnumerically using a Gaussian contamination model in dimensions up to d = 100,\nand compare them to a state-of-the-art private mean estimation algorithm. As a\nby-product of our investigation, we prove concentration inequalities for the\noutput of the exponential mechanism about the maximizer of the population\nobjective function. This bound applies to objective functions that satisfy a\nmild regularity condition.\n","authors":["Kelly Ramsay","Aukosh Jagannath","Shoja'eddin Chenouri"],"pdf_url":"https://arxiv.org/pdf/2210.06459v2.pdf","comment":"42 pages, 3 figures, 2 tables"},{"id":"http://arxiv.org/abs/2403.17852v1","updated":"2024-03-26T16:40:08Z","published":"2024-03-26T16:40:08Z","title":"Counterfactual Fairness through Transforming Data Orthogonal to Bias","summary":"  Machine learning models have shown exceptional prowess in solving complex\nissues across various domains. Nonetheless, these models can sometimes exhibit\nbiased decision-making, leading to disparities in treatment across different\ngroups. Despite the extensive research on fairness, the nuanced effects of\nmultivariate and continuous sensitive variables on decision-making outcomes\nremain insufficiently studied. We introduce a novel data pre-processing\nalgorithm, Orthogonal to Bias (OB), designed to remove the influence of a group\nof continuous sensitive variables, thereby facilitating counterfactual fairness\nin machine learning applications. Our approach is grounded in the assumption of\na jointly normal distribution within a structural causal model (SCM), proving\nthat counterfactual fairness can be achieved by ensuring the data is\nuncorrelated with sensitive variables. The OB algorithm is model-agnostic,\ncatering to a wide array of machine learning models and tasks, and includes a\nsparse variant to enhance numerical stability through regularization. Through\nempirical evaluation on simulated and real-world datasets - including the adult\nincome and the COMPAS recidivism datasets - our methodology demonstrates its\ncapacity to enable fairer outcomes without compromising accuracy.\n","authors":["Shuyi Chen","Shixiang Zhu"],"pdf_url":"https://arxiv.org/pdf/2403.17852v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17820v1","updated":"2024-03-26T15:55:54Z","published":"2024-03-26T15:55:54Z","title":"Towards Multilevel Modelling of Train Passing Events on the\n  Staffordshire Bridge","summary":"  We suggest a multilevel model, to represent aggregate train-passing events\nfrom the Staffordshire bridge monitoring system. We formulate a combined model\nfrom simple units, representing strain envelopes (of each train passing) for\ntwo types of commuter train. The measurements are treated as a longitudinal\ndataset and represented with a (low-rank approximation) hierarchical Gaussian\nprocess. For each unit in the combined model, we encode domain expertise as\nboundary condition constraints and work towards a general representation of the\nstrain response. Looking forward, this should allow for the simulation of train\ntypes that were previously unobserved in the training data. For example, trains\nwith more passengers or freights with a heavier payload. The strain event\nsimulations are valuable since they can inform further experiments (including\nFEM calibration, fatigue analysis, or design) to test the bridge in\nhypothesised scenarios.\n","authors":["Lawrence A. Bull","Chiho Jeon","Mark Girolami","Andrew Duncan","Jennifer Schooling","Miguel Bravo Haro"],"pdf_url":"https://arxiv.org/pdf/2403.17820v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.09557v2","updated":"2024-03-26T13:54:44Z","published":"2022-11-17T14:27:52Z","title":"Optimal Design of Volt/VAR Control Rules of Inverters using Deep\n  Learning","summary":"  Distribution grids are challenged by rapid voltage fluctuations induced by\nvariable power injections from distributed energy resources (DERs). To regulate\nvoltage, the IEEE Standard 1547 recommends each DER inject reactive power\naccording to piecewise-affine Volt/VAR control rules. Although the standard\nsuggests a default shape, the rule can be customized per bus. This task of\noptimal rule design (ORD) is challenging as Volt/VAR rules introduce nonlinear\ndynamics, and lurk trade-offs between stability and steady-state voltage\nprofiles. ORD is formulated as a mixed-integer nonlinear program (MINLP), but\nscales unfavorably with the problem size. Towards a more efficient solution, we\nreformulate ORD as a deep learning problem. The idea is to design a DNN that\nemulates Volt/VAR dynamics. The DNN takes grid scenarios as inputs, rule\nparameters as weights, and outputs equilibrium voltages. Optimal rule\nparameters can be found by training the DNN so its output approaches unity for\nvarious scenarios. The DNN is only used to optimize rules and is never employed\nin the field. While dealing with ORD, we also review and expand on stability\nconditions and convergence rates for Volt/VAR dynamics on single- and\nmulti-phase feeders. Tests showcase the merit of DNN-based ORD by benchmarking\nit against its MINLP counterpart.\n","authors":["Sarthak Gupta","Vassilis Kekatos","Spyros Chatzivasileiadis"],"pdf_url":"https://arxiv.org/pdf/2211.09557v2.pdf","comment":"Accepted in the IEEE Trans. on Smart Grid"},{"id":"http://arxiv.org/abs/2306.16378v2","updated":"2024-03-26T12:29:35Z","published":"2023-06-28T17:14:49Z","title":"Spatiotemporal Besov Priors for Bayesian Inverse Problems","summary":"  Fast development in science and technology has driven the need for proper\nstatistical tools to capture special data features such as abrupt changes or\nsharp contrast. Many inverse problems in data science require spatiotemporal\nsolutions derived from a sequence of time-dependent objects with these spatial\nfeatures, e.g., dynamic reconstruction of computerized tomography (CT) images\nwith edges. Conventional methods based on Gaussian processes (GP) often fall\nshort in providing satisfactory solutions since they tend to offer over-smooth\npriors. Recently, the Besov process (BP), defined by wavelet expansions with\nrandom coefficients, has emerged as a more suitable prior for Bayesian inverse\nproblems of this nature. While BP excels in handling spatial inhomogeneity, it\ndoes not automatically incorporate temporal correlation inherited in the\ndynamically changing objects. In this paper, we generalize BP to a novel\nspatiotemporal Besov process (STBP) by replacing the random coefficients in the\nseries expansion with stochastic time functions as Q-exponential process (Q-EP)\nwhich governs the temporal correlation structure. We thoroughly investigate the\nmathematical and statistical properties of STBP. A white-noise representation\nof STBP is also proposed to facilitate the inference. Simulations, two\nlimited-angle CT reconstruction examples and a highly non-linear inverse\nproblem involving Navier-Stokes equation are used to demonstrate the advantage\nof the proposed STBP in preserving spatial features while accounting for\ntemporal changes compared with the classic STGP and a time-uncorrelated\napproach.\n","authors":["Shiwei Lan","Mirjeta Pasha","Shuyi Li","Weining Shen"],"pdf_url":"https://arxiv.org/pdf/2306.16378v2.pdf","comment":"47 pages, 15 figures"},{"id":"http://arxiv.org/abs/2403.17592v1","updated":"2024-03-26T11:01:53Z","published":"2024-03-26T11:01:53Z","title":"On the Benefits of Over-parameterization for Out-of-Distribution\n  Generalization","summary":"  In recent years, machine learning models have achieved success based on the\nindependently and identically distributed assumption. However, this assumption\ncan be easily violated in real-world applications, leading to the\nOut-of-Distribution (OOD) problem. Understanding how modern over-parameterized\nDNNs behave under non-trivial natural distributional shifts is essential, as\ncurrent theoretical understanding is insufficient. Existing theoretical works\noften provide meaningless results for over-parameterized models in OOD\nscenarios or even contradict empirical findings. To this end, we are\ninvestigating the performance of the over-parameterized model in terms of OOD\ngeneralization under the general benign overfitting conditions. Our analysis\nfocuses on a random feature model and examines non-trivial natural\ndistributional shifts, where the benign overfitting estimators demonstrate a\nconstant excess OOD loss, despite achieving zero excess in-distribution (ID)\nloss. We demonstrate that in this scenario, further increasing the model's\nparameterization can significantly reduce the OOD loss. Intuitively, the\nvariance term of ID loss remains low due to orthogonality of long-tail\nfeatures, meaning overfitting noise during training generally doesn't raise\ntesting loss. However, in OOD cases, distributional shift increases the\nvariance term. Thankfully, the inherent shift is unrelated to individual x,\nmaintaining the orthogonality of long-tail features. Expanding the hidden\ndimension can additionally improve this orthogonality by mapping the features\ninto higher-dimensional spaces, thereby reducing the variance term. We further\nshow that model ensembles also improve OOD loss, akin to increasing model\ncapacity. These insights explain the empirical phenomenon of enhanced OOD\ngeneralization through model ensembles, supported by consistent simulations\nwith theoretical results.\n","authors":["Yifan Hao","Yong Lin","Difan Zou","Tong Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.17592v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.01050v6","updated":"2024-03-26T09:48:49Z","published":"2023-07-03T14:28:36Z","title":"Transport meets Variational Inference: Controlled Monte Carlo Diffusions","summary":"  Connecting optimal transport and variational inference, we present a\nprincipled and systematic framework for sampling and generative modelling\ncentred around divergences on path space. Our work culminates in the\ndevelopment of the \\emph{Controlled Monte Carlo Diffusion} sampler (CMCD) for\nBayesian computation, a score-based annealing technique that crucially adapts\nboth forward and backward dynamics in a diffusion model. On the way, we clarify\nthe relationship between the EM-algorithm and iterative proportional fitting\n(IPF) for Schr{\\\"o}dinger bridges, deriving as well a regularised objective\nthat bypasses the iterative bottleneck of standard IPF-updates. Finally, we\nshow that CMCD has a strong foundation in the Jarzinsky and Crooks identities\nfrom statistical physics, and that it convincingly outperforms competing\napproaches across a wide array of experiments.\n","authors":["Francisco Vargas","Shreyas Padhy","Denis Blessing","Nikolas Nüsken"],"pdf_url":"https://arxiv.org/pdf/2307.01050v6.pdf","comment":"Workshop on New Frontiers in Learning, Control, and Dynamical Systems\n  at the International Conference on Machine Learning (ICML), Honolulu, Hawaii,\n  USA, 2023"},{"id":"http://arxiv.org/abs/2204.00406v3","updated":"2024-03-26T08:48:53Z","published":"2022-04-01T13:08:49Z","title":"A Semismooth Newton Stochastic Proximal Point Algorithm with Variance\n  Reduction","summary":"  We develop an implementable stochastic proximal point (SPP) method for a\nclass of weakly convex, composite optimization problems. The proposed\nstochastic proximal point algorithm incorporates a variance reduction mechanism\nand the resulting SPP updates are solved using an inexact semismooth Newton\nframework. We establish detailed convergence results that take the inexactness\nof the SPP steps into account and that are in accordance with existing\nconvergence guarantees of (proximal) stochastic variance-reduced gradient\nmethods. Numerical experiments show that the proposed algorithm competes\nfavorably with other state-of-the-art methods and achieves higher robustness\nwith respect to the step size selection.\n","authors":["Andre Milzarek","Fabian Schaipp","Michael Ulbrich"],"pdf_url":"https://arxiv.org/pdf/2204.00406v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2102.01432v2","updated":"2024-03-26T08:21:24Z","published":"2021-02-02T11:05:34Z","title":"Bayesian data-driven discovery of partial differential equations with\n  variable coefficients","summary":"  The discovery of Partial Differential Equations (PDEs) is an essential task\nfor applied science and engineering. However, data-driven discovery of PDEs is\ngenerally challenging, primarily stemming from the sensitivity of the\ndiscovered equation to noise and the complexities of model selection. In this\nwork, we propose an advanced Bayesian sparse learning algorithm for PDE\ndiscovery with variable coefficients, predominantly when the coefficients are\nspatially or temporally dependent. Specifically, we apply threshold Bayesian\ngroup Lasso regression with a spike-and-slab prior (tBGL-SS) and leverage a\nGibbs sampler for Bayesian posterior estimation of PDE coefficients. This\napproach not only enhances the robustness of point estimation with valid\nuncertainty quantification but also relaxes the computational burden from\nBayesian inference through the integration of coefficient thresholds as an\napproximate MCMC method. Moreover, from the quantified uncertainties, we\npropose a Bayesian total error bar criteria for model selection, which\noutperforms classic metrics including the root mean square and the Akaike\ninformation criterion. The capability of this method is illustrated by the\ndiscovery of several classical benchmark PDEs with spatially or temporally\nvarying coefficients from solution data obtained from the reference\nsimulations. In the experiments, we show that the tBGL-SS method is more robust\nthan the baseline methods under noisy environments and provides better model\nselection criteria along the regularization path.\n","authors":["Aoxue Chen","Yifan Du","Liyao Mars Gao","Guang Lin"],"pdf_url":"https://arxiv.org/pdf/2102.01432v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.02766v3","updated":"2024-03-26T08:05:11Z","published":"2023-11-05T20:51:03Z","title":"Riemannian Laplace Approximation with the Fisher Metric","summary":"  Laplace's method approximates a target density with a Gaussian distribution\nat its mode. It is computationally efficient and asymptotically exact for\nBayesian inference due to the Bernstein-von Mises theorem, but for complex\ntargets and finite-data posteriors it is often too crude an approximation. A\nrecent generalization of the Laplace Approximation transforms the Gaussian\napproximation according to a chosen Riemannian geometry providing a richer\napproximation family, while still retaining computational efficiency. However,\nas shown here, its properties depend heavily on the chosen metric, indeed the\nmetric adopted in previous work results in approximations that are overly\nnarrow as well as being biased even at the limit of infinite data. We correct\nthis shortcoming by developing the approximation family further, deriving two\nalternative variants that are exact at the limit of infinite data, extending\nthe theoretical analysis of the method, and demonstrating practical\nimprovements in a range of experiments.\n","authors":["Hanlin Yu","Marcelo Hartmann","Bernardo Williams","Mark Girolami","Arto Klami"],"pdf_url":"https://arxiv.org/pdf/2311.02766v3.pdf","comment":"AISTATS 2024, with additional fixes"},{"id":"http://arxiv.org/abs/2403.17423v1","updated":"2024-03-26T06:40:03Z","published":"2024-03-26T06:40:03Z","title":"Test-time Adaptation Meets Image Enhancement: Improving Accuracy via\n  Uncertainty-aware Logit Switching","summary":"  Deep neural networks have achieved remarkable success in a variety of\ncomputer vision applications. However, there is a problem of degrading accuracy\nwhen the data distribution shifts between training and testing. As a solution\nof this problem, Test-time Adaptation~(TTA) has been well studied because of\nits practicality. Although TTA methods increase accuracy under distribution\nshift by updating the model at test time, using high-uncertainty predictions is\nknown to degrade accuracy. Since the input image is the root of the\ndistribution shift, we incorporate a new perspective on enhancing the input\nimage into TTA methods to reduce the prediction's uncertainty. We hypothesize\nthat enhancing the input image reduces prediction's uncertainty and increase\nthe accuracy of TTA methods. On the basis of our hypothesis, we propose a novel\nmethod: Test-time Enhancer and Classifier Adaptation~(TECA). In TECA, the\nclassification model is combined with the image enhancement model that\ntransforms input images into recognition-friendly ones, and these models are\nupdated by existing TTA methods. Furthermore, we found that the prediction from\nthe enhanced image does not always have lower uncertainty than the prediction\nfrom the original image. Thus, we propose logit switching, which compares the\nuncertainty measure of these predictions and outputs the lower one. In our\nexperiments, we evaluate TECA with various TTA methods and show that TECA\nreduces prediction's uncertainty and increases accuracy of TTA methods despite\nhaving no hyperparameters and little parameter overhead.\n","authors":["Shohei Enomoto","Naoya Hasegawa","Kazuki Adachi","Taku Sasaki","Shin'ya Yamaguchi","Satoshi Suzuki","Takeharu Eda"],"pdf_url":"https://arxiv.org/pdf/2403.17423v1.pdf","comment":"Accepted to IJCNN2024"},{"id":"http://arxiv.org/abs/2403.17410v1","updated":"2024-03-26T06:06:01Z","published":"2024-03-26T06:06:01Z","title":"On permutation-invariant neural networks","summary":"  Conventional machine learning algorithms have traditionally been designed\nunder the assumption that input data follows a vector-based format, with an\nemphasis on vector-centric paradigms. However, as the demand for tasks\ninvolving set-based inputs has grown, there has been a paradigm shift in the\nresearch community towards addressing these challenges. In recent years, the\nemergence of neural network architectures such as Deep Sets and Transformers\nhas presented a significant advancement in the treatment of set-based data.\nThese architectures are specifically engineered to naturally accommodate sets\nas input, enabling more effective representation and processing of set\nstructures. Consequently, there has been a surge of research endeavors\ndedicated to exploring and harnessing the capabilities of these architectures\nfor various tasks involving the approximation of set functions. This\ncomprehensive survey aims to provide an overview of the diverse problem\nsettings and ongoing research efforts pertaining to neural networks that\napproximate set functions. By delving into the intricacies of these approaches\nand elucidating the associated challenges, the survey aims to equip readers\nwith a comprehensive understanding of the field. Through this comprehensive\nperspective, we hope that researchers can gain valuable insights into the\npotential applications, inherent limitations, and future directions of\nset-based neural networks. Indeed, from this survey we gain two insights: i)\nDeep Sets and its variants can be generalized by differences in the aggregation\nfunction, and ii) the behavior of Deep Sets is sensitive to the choice of the\naggregation function. From these observations, we show that Deep Sets, one of\nthe well-known permutation-invariant neural networks, can be generalized in the\nsense of a quasi-arithmetic mean.\n","authors":["Masanari Kimura","Ryotaro Shimizu","Yuki Hirakawa","Ryosuke Goto","Yuki Saito"],"pdf_url":"https://arxiv.org/pdf/2403.17410v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.10025v3","updated":"2024-03-26T03:18:24Z","published":"2023-04-20T00:39:20Z","title":"Identification and multiply robust estimation in causal mediation\n  analysis across principal strata","summary":"  We consider assessing causal mediation in the presence of a post-treatment\nevent (examples include noncompliance, a clinical event, or a terminal event).\nWe identify natural mediation effects for the entire study population and for\neach principal stratum characterized by the joint potential values of the\npost-treatment event. We derive efficient influence functions for each\nmediation estimand, which motivate a set of multiply robust estimators for\ninference. The multiply robust estimators are consistent under four types of\nmisspecifications and are efficient when all nuisance models are correctly\nspecified. We illustrate our methods via simulations and two real data\nexamples.\n","authors":["Chao Cheng","Fan Li"],"pdf_url":"https://arxiv.org/pdf/2304.10025v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.00736v3","updated":"2024-03-26T02:33:12Z","published":"2023-09-01T21:16:02Z","title":"Prediction Error Estimation in Random Forests","summary":"  In this paper, error estimates of classification Random Forests are\nquantitatively assessed. Based on the initial theoretical framework built by\nBates et al. (2023), the true error rate and expected error rate are\ntheoretically and empirically investigated in the context of a variety of error\nestimation methods common to Random Forests. We show that in the classification\ncase, Random Forests' estimates of prediction error is closer on average to the\ntrue error rate instead of the average prediction error. This is opposite the\nfindings of Bates et al. (2023) which are given for logistic regression. We\nfurther show that our result holds across different error estimation strategies\nsuch as cross-validation, bagging, and data splitting.\n","authors":["Ian Krupkin","Johanna Hardin"],"pdf_url":"https://arxiv.org/pdf/2309.00736v3.pdf","comment":"arXiv admin note: text overlap with arXiv:2104.00673 by other authors"},{"id":"http://arxiv.org/abs/2403.09960v3","updated":"2024-03-26T02:01:22Z","published":"2024-03-15T01:50:41Z","title":"Multivariate Gaussian Approximation for Random Forest via Region-based\n  Stabilization","summary":"  We derive Gaussian approximation bounds for random forest predictions based\non a set of training points given by a Poisson process, under fairly mild\nregularity assumptions on the data generating process. Our approach is based on\nthe key observation that the random forest predictions satisfy a certain\ngeometric property called region-based stabilization. In the process of\ndeveloping our results for the random forest, we also establish a probabilistic\nresult, which might be of independent interest, on multivariate Gaussian\napproximation bounds for general functionals of Poisson process that are\nregion-based stabilizing. This general result makes use of the Malliavin-Stein\nmethod, and is potentially applicable to various related statistical problems.\n","authors":["Zhaoyang Shi","Chinmoy Bhattacharjee","Krishnakumar Balasubramanian","Wolfgang Polonik"],"pdf_url":"https://arxiv.org/pdf/2403.09960v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.01453v2","updated":"2024-03-26T01:44:52Z","published":"2023-11-02T17:59:04Z","title":"PPI++: Efficient Prediction-Powered Inference","summary":"  We present PPI++: a computationally lightweight methodology for estimation\nand inference based on a small labeled dataset and a typically much larger\ndataset of machine-learning predictions. The methods automatically adapt to the\nquality of available predictions, yielding easy-to-compute confidence sets --\nfor parameters of any dimensionality -- that always improve on classical\nintervals using only the labeled data. PPI++ builds on prediction-powered\ninference (PPI), which targets the same problem setting, improving its\ncomputational and statistical efficiency. Real and synthetic experiments\ndemonstrate the benefits of the proposed adaptations.\n","authors":["Anastasios N. Angelopoulos","John C. Duchi","Tijana Zrnic"],"pdf_url":"https://arxiv.org/pdf/2311.01453v2.pdf","comment":"Code available at https://github.com/aangelopoulos/ppi_py"},{"id":"http://arxiv.org/abs/2403.17285v1","updated":"2024-03-26T00:25:32Z","published":"2024-03-26T00:25:32Z","title":"An Analysis of Switchback Designs in Reinforcement Learning","summary":"  This paper offers a detailed investigation of switchback designs in A/B\ntesting, which alternate between baseline and new policies over time. Our aim\nis to thoroughly evaluate the effects of these designs on the accuracy of their\nresulting average treatment effect (ATE) estimators. We propose a novel \"weak\nsignal analysis\" framework, which substantially simplifies the calculations of\nthe mean squared errors (MSEs) of these ATEs in Markov decision process\nenvironments. Our findings suggest that (i) when the majority of reward errors\nare positively correlated, the switchback design is more efficient than the\nalternating-day design which switches policies in a daily basis. Additionally,\nincreasing the frequency of policy switches tends to reduce the MSE of the ATE\nestimator. (ii) When the errors are uncorrelated, however, all these designs\nbecome asymptotically equivalent. (iii) In cases where the majority of errors\nare negative correlated, the alternating-day design becomes the optimal choice.\nThese insights are crucial, offering guidelines for practitioners on designing\nexperiments in A/B testing. Our analysis accommodates a variety of policy value\nestimators, including model-based estimators, least squares temporal difference\nlearning estimators, and double reinforcement learning estimators, thereby\noffering a comprehensive understanding of optimal design strategies for policy\nevaluation in reinforcement learning.\n","authors":["Qianglin Wen","Chengchun Shi","Ying Yang","Niansheng Tang","Hongtu Zhu"],"pdf_url":"https://arxiv.org/pdf/2403.17285v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.07905v2","updated":"2024-03-26T00:21:41Z","published":"2023-06-13T16:56:13Z","title":"Omega: Optimistic EMA Gradients","summary":"  Stochastic min-max optimization has gained interest in the machine learning\ncommunity with the advancements in GANs and adversarial training. Although game\noptimization is fairly well understood in the deterministic setting, some\nissues persist in the stochastic regime. Recent work has shown that stochastic\ngradient descent-ascent methods such as the optimistic gradient are highly\nsensitive to noise or can fail to converge. Although alternative strategies\nexist, they can be prohibitively expensive. We introduce Omega, a method with\noptimistic-like updates that mitigates the impact of noise by incorporating an\nEMA of historic gradients in its update rule. We also explore a variation of\nthis algorithm that incorporates momentum. Although we do not provide\nconvergence guarantees, our experiments on stochastic games show that Omega\noutperforms the optimistic gradient method when applied to linear players.\n","authors":["Juan Ramirez","Rohan Sukumaran","Quentin Bertrand","Gauthier Gidel"],"pdf_url":"https://arxiv.org/pdf/2306.07905v2.pdf","comment":"Oral at the LatinX in AI workshop @ ICML 2023"}]},"2024-03-25T00:00:00Z":{"Computer Science and Game Theory":[{"id":"http://arxiv.org/abs/2208.03406v2","updated":"2024-03-25T20:32:00Z","published":"2022-08-05T23:32:33Z","title":"Multilinear formulations for computing Nash equilibrium of multi-player\n  matrix games","summary":"  We present multilinear and mixed-integer multilinear programs to find a Nash\nequilibrium in multi-player noncooperative games. We compare the formulations\nto common algorithms in Gambit, and conclude that a multilinear feasibility\nprogram finds a Nash equilibrium faster than any of the methods we compare it\nto, including the quantal response equilibrium method, which is recommended for\nlarge games. Hence, the multilinear feasibility program is an alternative\nmethod to find a Nash equilibrium in multi-player games, and outperforms many\ncommon algorithms. The mixed-integer formulations are generalisations of known\nmixed-integer programs for two-player games, however unlike two-player games,\nthese mixed-integer programs do not give better performance than existing\nalgorithms.\n","authors":["Miriam Fischer","Akshay Gupte"],"pdf_url":"https://arxiv.org/pdf/2208.03406v2.pdf","comment":"15 page conference paper accepted"},{"id":"http://arxiv.org/abs/2403.16980v1","updated":"2024-03-25T17:42:27Z","published":"2024-03-25T17:42:27Z","title":"Economic DAO Governance: A Contestable Control Approach","summary":"  In this article, we propose a new form of DAO governance that uses a\nsequential auction mechanism to overcome entrenched control issues that have\nemerged for DAOs by creating a regime of temporary contestable control. The\nmechanism avoids potential public choice problems inherent in voting approaches\nbut at the same time provides a vehicle that can enhance and secure value than\ninheres to DAO voting and other DAO non-market governance procedures. It is\nrobust to empty voting and is code feasible. It facilitates the ability of DAOs\nto meet their normative and operational goals in the face of diverse regulatory\napproaches. Designed to shift control to the party with the most promising\nbusiness plan, at the same time it distributes surplus in a way that tends to\npromote investment by other parties.\n","authors":["Jeff Strnad"],"pdf_url":"https://arxiv.org/pdf/2403.16980v1.pdf","comment":"84 pages, 2 figures"},{"id":"http://arxiv.org/abs/2309.02613v2","updated":"2024-03-25T16:32:26Z","published":"2023-09-05T23:13:02Z","title":"Project-Fair and Truthful Mechanisms for Budget Aggregation","summary":"  We study the budget aggregation problem in which a set of strategic voters\nmust split a finite divisible resource (such as money or time) among a set of\ncompeting projects. Our goal is twofold: We seek truthful mechanisms that\nprovide fairness guarantees to the projects. For the first objective, we focus\non the class of moving phantom mechanisms [Freeman et al., 2021], which are --\nto this day -- essentially the only known truthful mechanisms in this setting.\nFor project fairness, we consider the mean division as a fair baseline, and\nbound the maximum difference between the funding received by any project and\nthis baseline. We propose a novel and simple moving phantom mechanism that\nprovides optimal project fairness guarantees. As a corollary of our results, we\nshow that our new mechanism minimizes the $\\ell_1$ distance to the mean (a\nmeasure suggested by Caragiannis et al. [2022]) for three projects and gives\nthe first non-trivial bounds on this quantity for more than three projects.\n","authors":["Rupert Freeman","Ulrike Schmidt-Kraepelin"],"pdf_url":"https://arxiv.org/pdf/2309.02613v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16843v1","updated":"2024-03-25T15:04:11Z","published":"2024-03-25T15:04:11Z","title":"Do LLM Agents Have Regret? A Case Study in Online Learning and Games","summary":"  Large language models (LLMs) have been increasingly employed for\n(interactive) decision-making, via the development of LLM-based autonomous\nagents. Despite their emerging successes, the performance of LLM agents in\ndecision-making has not been fully investigated through quantitative metrics,\nespecially in the multi-agent setting when they interact with each other, a\ntypical scenario in real-world LLM-agent applications. To better understand the\nlimits of LLM agents in these interactive environments, we propose to study\ntheir interactions in benchmark decision-making settings in online learning and\ngame theory, through the performance metric of \\emph{regret}. We first\nempirically study the {no-regret} behaviors of LLMs in canonical\n(non-stationary) online learning problems, as well as the emergence of\nequilibria when LLM agents interact through playing repeated games. We then\nprovide some theoretical insights into the no-regret behaviors of LLM agents,\nunder certain assumptions on the supervised pre-training and the rationality\nmodel of human decision-makers who generate the data. Notably, we also identify\n(simple) cases where advanced LLMs such as GPT-4 fail to be no-regret. To\npromote the no-regret behaviors, we propose a novel \\emph{unsupervised}\ntraining loss of \\emph{regret-loss}, which, in contrast to the supervised\npre-training loss, does not require the labels of (optimal) actions. We then\nestablish the statistical guarantee of generalization bound for regret-loss\nminimization, followed by the optimization guarantee that minimizing such a\nloss may automatically lead to known no-regret learning algorithms. Our further\nexperiments demonstrate the effectiveness of our regret-loss, especially in\naddressing the above ``regrettable'' cases.\n","authors":["Chanwoo Park","Xiangyu Liu","Asuman Ozdaglar","Kaiqing Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.16843v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16799v1","updated":"2024-03-25T14:19:48Z","published":"2024-03-25T14:19:48Z","title":"Efficient Method for Finding Optimal Strategies in Chopstick Auctions\n  with Uniform Objects Values","summary":"  We propose an algorithm for computing Nash equilibria (NE) in a class of\nconflicts with multiple battlefields with uniform battlefield values and a\nnon-linear aggregation function. By expanding the symmetrization idea of Hart\n[9], proposed for the Colonel Blotto game, to the wider class of symmetric\nconflicts with multiple battlefields, we reduce the number of strategies of the\nplayers by an exponential factor. We propose a clash matrix algorithm which\nallows for computing the payoffs in the symmetrized model in polynomial time.\nCombining symmetrization and clash matrix algorithm with the double oracle\nalgorithm we obtain an algorithm for computing NE in the models in question\nthat achieves a significant speed-up as compared to the standard, LP-based,\napproach. We also introduce a heuristic to further speed up the process.\nOverall, our approach offers an efficient and novel method for computing NE in\na specific class of conflicts, with potential practical applications in various\nfields.\n","authors":["Stanisław Kaźmierowski","Marcin Dziubiński"],"pdf_url":"https://arxiv.org/pdf/2403.16799v1.pdf","comment":"Accepted for AAMAS-24 conference"},{"id":"http://arxiv.org/abs/2403.16373v1","updated":"2024-03-25T02:37:18Z","published":"2024-03-25T02:37:18Z","title":"A new social welfare function with a number of desirable properties","summary":"  By relaxing the dominating set in three ways (e.g., from \"each member beats\nevery non-member\" to \"each member beats or ties every non-member, with an\nadditional requirement that at least one member beat every non-member\"), we\npropose a new social welfare function, which satisfies a number of desirable\nproperties including Condorcet winner principle, Condorcet loser principle,\nstrong Gehrlein-stability (hence Smith set principle), anonymity, neutrality,\nweak Pareto, strong Pareto, non-dictatorship, and [independence of irrelevant\nalternatives (IIA) when the pairwise majority relation is an ordering on the\nalternative set]. If the pairwise majority relation is complete and transitive,\nthe proposed method yields a collective preference relation that coincides with\nthe input majority relation. It thus shares the same collective preference\nfunction on the dichotomous domain with the approval voting and the majority\nvoting. It runs in polynomial time and thus possesses a competitive advantage\nover a number of computationally intractable voting rules such as the Dodgson's\nrule, the Kemeny's rule, the Slater's rule, the Banks rule, and the Schwartz's\ntournament equilibrium set (TEQ) rule. When it is used in tournaments, its\nwinner belongs to the uncovered set, the top cycle set, the Smith set, and the\nSchwartz set. In addition, in a tournament where the number of alternatives is\nnot more than 4, its winner set is a subset, sometimes proper, of the Copeland\nwinner set. Whether this attractive argument is still valid in\nfour-more-alternative tournaments remains an open question.\n","authors":["Fujun Hou"],"pdf_url":"https://arxiv.org/pdf/2403.16373v1.pdf","comment":"A new social choice function (and a corresponding social welfare\n  function) is proposed. It has a number of desirable properties. An open\n  question is also posed"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2403.17164v1","updated":"2024-03-25T20:29:04Z","published":"2024-03-25T20:29:04Z","title":"Multi-Objective Quality-Diversity for Crystal Structure Prediction","summary":"  Crystal structures are indispensable across various domains, from batteries\nto solar cells, and extensive research has been dedicated to predicting their\nproperties based on their atomic configurations. However, prevailing Crystal\nStructure Prediction methods focus on identifying the most stable solutions\nthat lie at the global minimum of the energy function. This approach overlooks\nother potentially interesting materials that lie in neighbouring local minima\nand have different material properties such as conductivity or resistance to\ndeformation. By contrast, Quality-Diversity algorithms provide a promising\navenue for Crystal Structure Prediction as they aim to find a collection of\nhigh-performing solutions that have diverse characteristics. However, it may\nalso be valuable to optimise for the stability of crystal structures alongside\nother objectives such as magnetism or thermoelectric efficiency. Therefore, in\nthis work, we harness the power of Multi-Objective Quality-Diversity algorithms\nin order to find crystal structures which have diverse features and achieve\ndifferent trade-offs of objectives. We analyse our approach on 5 crystal\nsystems and demonstrate that it is not only able to re-discover known real-life\nstructures, but also find promising new ones. Moreover, we propose a method for\nilluminating the objective space to gain an understanding of what trade-offs\ncan be achieved.\n","authors":["Hannah Janmohamed","Marta Wolinska","Shikha Surana","Thomas Pierrot","Aron Walsh","Antoine Cully"],"pdf_url":"https://arxiv.org/pdf/2403.17164v1.pdf","comment":"Accepted GECCO 2024"},{"id":"http://arxiv.org/abs/2403.09863v2","updated":"2024-03-25T17:55:25Z","published":"2024-03-14T20:50:03Z","title":"Towards White Box Deep Learning","summary":"  This paper introduces semantic features as a candidate conceptual framework\nfor building inherently interpretable neural networks. A proof of concept model\nfor informative subproblem of MNIST consists of 4 such layers with the total of\n5K learnable parameters. The model is well-motivated, inherently interpretable,\nrequires little hyperparameter tuning and achieves human-level adversarial test\naccuracy - with no form of adversarial training! These results and the general\nnature of the approach warrant further research on semantic features. The code\nis available at https://github.com/314-Foundation/white-box-nn\n","authors":["Maciej Satkiewicz"],"pdf_url":"https://arxiv.org/pdf/2403.09863v2.pdf","comment":"13 pages, 9 figures, independent research, v2 changes: more adequate\n  title; added: related research in Introduction, Ablation Study, Discussion,\n  examples in Further Research, Appendix C; minor wording changes (including\n  abstract)"},{"id":"http://arxiv.org/abs/2312.15001v2","updated":"2024-03-25T17:01:08Z","published":"2023-12-22T16:33:50Z","title":"Discovering modular solutions that generalize compositionally","summary":"  Many complex tasks can be decomposed into simpler, independent parts.\nDiscovering such underlying compositional structure has the potential to enable\ncompositional generalization. Despite progress, our most powerful systems\nstruggle to compose flexibly. It therefore seems natural to make models more\nmodular to help capture the compositional nature of many tasks. However, it is\nunclear under which circumstances modular systems can discover hidden\ncompositional structure. To shed light on this question, we study a\nteacher-student setting with a modular teacher where we have full control over\nthe composition of ground truth modules. This allows us to relate the problem\nof compositional generalization to that of identification of the underlying\nmodules. In particular we study modularity in hypernetworks representing a\ngeneral class of multiplicative interactions. We show theoretically that\nidentification up to linear transformation purely from demonstrations is\npossible without having to learn an exponential number of module combinations.\nWe further demonstrate empirically that under the theoretically identified\nconditions, meta-learning from finite data can discover modular policies that\ngeneralize compositionally in a number of complex environments.\n","authors":["Simon Schug","Seijin Kobayashi","Yassir Akram","Maciej Wołczyk","Alexandra Proca","Johannes von Oswald","Razvan Pascanu","João Sacramento","Angelika Steger"],"pdf_url":"https://arxiv.org/pdf/2312.15001v2.pdf","comment":"Published as a conference paper at ICLR 2024; Code available at\n  https://github.com/smonsays/modular-hyperteacher"},{"id":"http://arxiv.org/abs/2403.16933v1","updated":"2024-03-25T16:57:02Z","published":"2024-03-25T16:57:02Z","title":"Backpropagation through space, time, and the brain","summary":"  Effective learning in neuronal networks requires the adaptation of individual\nsynapses given their relative contribution to solving a task. However, physical\nneuronal systems -- whether biological or artificial -- are constrained by\nspatio-temporal locality. How such networks can perform efficient credit\nassignment, remains, to a large extent, an open question. In Machine Learning,\nthe answer is almost universally given by the error backpropagation algorithm,\nthrough both space (BP) and time (BPTT). However, BP(TT) is well-known to rely\non biologically implausible assumptions, in particular with respect to\nspatiotemporal (non-)locality, while forward-propagation models such as\nreal-time recurrent learning (RTRL) suffer from prohibitive memory constraints.\nWe introduce Generalized Latent Equilibrium (GLE), a computational framework\nfor fully local spatio-temporal credit assignment in physical, dynamical\nnetworks of neurons. We start by defining an energy based on neuron-local\nmismatches, from which we derive both neuronal dynamics via stationarity and\nparameter dynamics via gradient descent. The resulting dynamics can be\ninterpreted as a real-time, biologically plausible approximation of BPTT in\ndeep cortical networks with continuous-time neuronal dynamics and continuously\nactive, local synaptic plasticity. In particular, GLE exploits the ability of\nbiological neurons to phase-shift their output rate with respect to their\nmembrane potential, which is essential in both directions of information\npropagation. For the forward computation, it enables the mapping of\ntime-continuous inputs to neuronal space, performing an effective\nspatiotemporal convolution. For the backward computation, it permits the\ntemporal inversion of feedback signals, which consequently approximate the\nadjoint states necessary for useful parameter updates.\n","authors":["Benjamin Ellenberger","Paul Haider","Jakob Jordan","Kevin Max","Ismael Jaras","Laura Kriener","Federico Benitez","Mihai A. Petrovici"],"pdf_url":"https://arxiv.org/pdf/2403.16933v1.pdf","comment":"15 pages, 7 figures"},{"id":"http://arxiv.org/abs/2403.16798v1","updated":"2024-03-25T14:17:38Z","published":"2024-03-25T14:17:38Z","title":"Cluster-Based Normalization Layer for Neural Networks","summary":"  Deep learning faces significant challenges during the training of neural\nnetworks, including internal covariate shift, label shift, vanishing/exploding\ngradients, overfitting, and computational complexity. While conventional\nnormalization methods, such as Batch Normalization, aim to tackle some of these\nissues, they often depend on assumptions that constrain their adaptability.\nMixture Normalization faces computational hurdles in its pursuit of handling\nmultiple Gaussian distributions. This paper introduces Cluster-Based\nNormalization (CB-Norm) in two variants - Supervised Cluster-Based\nNormalization (SCB-Norm) and Unsupervised Cluster-Based Normalization\n(UCB-Norm) - proposing a groundbreaking one-step normalization approach.\nCB-Norm leverages a Gaussian mixture model to specifically address challenges\nrelated to gradient stability and learning acceleration. For SCB-Norm, a\nsupervised variant, the novel mechanism involves introducing predefined data\npartitioning, termed clusters, to normalize activations based on the assigned\ncluster. This cluster-driven approach creates a space that conforms to a\nGaussian mixture model. On the other hand, UCB-Norm, an unsupervised\ncounterpart, dynamically clusters neuron activations during training, adapting\nto task-specific challenges without relying on predefined data partitions\n(clusters). This dual approach ensures flexibility in addressing diverse\nlearning scenarios. CB-Norm innovatively uses a one-step normalization\napproach, where parameters of each mixture component (cluster in activation\nspace) serve as weights for deep neural networks. This adaptive clustering\nprocess tackles both clustering and resolution of deep neural network tasks\nconcurrently during training, signifying a notable advancement in the field.\n","authors":["Bilal Faye","Hanane Azzag","Mustapha Lebbah"],"pdf_url":"https://arxiv.org/pdf/2403.16798v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.00992v3","updated":"2024-03-25T13:31:05Z","published":"2022-02-02T12:24:03Z","title":"Tight Convergence Rate Bounds for Optimization Under Power Law Spectral\n  Conditions","summary":"  Performance of optimization on quadratic problems sensitively depends on the\nlow-lying part of the spectrum. For large (effectively infinite-dimensional)\nproblems, this part of the spectrum can often be naturally represented or\napproximated by power law distributions, resulting in power law convergence\nrates for iterative solutions of these problems by gradient-based algorithms.\nIn this paper, we propose a new spectral condition providing tighter upper\nbounds for problems with power law optimization trajectories. We use this\ncondition to build a complete picture of upper and lower bounds for a wide\nrange of optimization algorithms -- Gradient Descent, Steepest Descent, Heavy\nBall, and Conjugate Gradients -- with an emphasis on the underlying schedules\nof learning rate and momentum. In particular, we demonstrate how an optimally\naccelerated method, its schedule, and convergence upper bound can be obtained\nin a unified manner for a given shape of the spectrum. Also, we provide first\nproofs of tight lower bounds for convergence rates of Steepest Descent and\nConjugate Gradients under spectral power laws with general exponents. Our\nexperiments show that the obtained convergence bounds and acceleration\nstrategies are not only relevant for exactly quadratic optimization problems,\nbut also fairly accurate when applied to the training of neural networks.\n","authors":["Maksim Velikanov","Dmitry Yarotsky"],"pdf_url":"https://arxiv.org/pdf/2202.00992v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17040v1","updated":"2024-03-25T12:15:10Z","published":"2024-03-25T12:15:10Z","title":"Enhancing Graph Representation Learning with Attention-Driven Spiking\n  Neural Networks","summary":"  Graph representation learning has become a crucial task in machine learning\nand data mining due to its potential for modeling complex structures such as\nsocial networks, chemical compounds, and biological systems. Spiking neural\nnetworks (SNNs) have recently emerged as a promising alternative to traditional\nneural networks for graph learning tasks, benefiting from their ability to\nefficiently encode and process temporal and spatial information. In this paper,\nwe propose a novel approach that integrates attention mechanisms with SNNs to\nimprove graph representation learning. Specifically, we introduce an attention\nmechanism for SNN that can selectively focus on important nodes and\ncorresponding features in a graph during the learning process. We evaluate our\nproposed method on several benchmark datasets and show that it achieves\ncomparable performance compared to existing graph learning techniques.\n","authors":["Huifeng Yin","Mingkun Xu","Jing Pei","Lei Deng"],"pdf_url":"https://arxiv.org/pdf/2403.17040v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16674v1","updated":"2024-03-25T12:13:20Z","published":"2024-03-25T12:13:20Z","title":"Understanding the Functional Roles of Modelling Components in Spiking\n  Neural Networks","summary":"  Spiking neural networks (SNNs), inspired by the neural circuits of the brain,\nare promising in achieving high computational efficiency with biological\nfidelity. Nevertheless, it is quite difficult to optimize SNNs because the\nfunctional roles of their modelling components remain unclear. By designing and\nevaluating several variants of the classic model, we systematically investigate\nthe functional roles of key modelling components, leakage, reset, and\nrecurrence, in leaky integrate-and-fire (LIF) based SNNs. Through extensive\nexperiments, we demonstrate how these components influence the accuracy,\ngeneralization, and robustness of SNNs. Specifically, we find that the leakage\nplays a crucial role in balancing memory retention and robustness, the reset\nmechanism is essential for uninterrupted temporal processing and computational\nefficiency, and the recurrence enriches the capability to model complex\ndynamics at a cost of robustness degradation. With these interesting\nobservations, we provide optimization suggestions for enhancing the performance\nof SNNs in different scenarios. This work deepens the understanding of how SNNs\nwork, which offers valuable guidance for the development of more effective and\nrobust neuromorphic models.\n","authors":["Huifeng Yin","Hanle Zheng","Jiayi Mao","Siyuan Ding","Xing Liu","Mingkun Xu","Yifan Hu","Jing Pei","Lei Deng"],"pdf_url":"https://arxiv.org/pdf/2403.16674v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.12061v2","updated":"2024-03-25T11:50:42Z","published":"2024-02-07T20:41:00Z","title":"Design-Space Exploration of SNN Models using Application-Specific\n  Multi-Core Architectures","summary":"  With the motivation and the difficulties that currently exist in\ncomprehending and utilizing the promising features of SNNs, we proposed a novel\nrun-time multi-core architecture-based simulator called \"RAVSim\" (Runtime\nAnalysis and Visualization Simulator), a cutting-edge SNN simulator, developed\nusing LabVIEW and it is publicly available on their website as an official\nmodule. RAVSim is a runtime virtual simulation environment tool that enables\nthe user to interact with the model, observe its behavior of output\nconcentration, and modify the set of parametric values at any time while the\nsimulation is in execution. Recently some popular tools have been presented,\nbut we believe that none of the tools allow users to interact with the model\nsimulation in run time.\n","authors":[" Sanaullah","Shamini Koravuna","Ulrich Rückert","Thorsten Jungeblut"],"pdf_url":"https://arxiv.org/pdf/2403.12061v2.pdf","comment":"Abstract Presentation in 2023 Neuro-Inspired Computing Elements\n  (NICE) Conference"},{"id":"http://arxiv.org/abs/2403.16552v1","updated":"2024-03-25T08:57:27Z","published":"2024-03-25T08:57:27Z","title":"QKFormer: Hierarchical Spiking Transformer using Q-K Attention","summary":"  Spiking Transformers, which integrate Spiking Neural Networks (SNNs) with\nTransformer architectures, have attracted significant attention due to their\npotential for energy efficiency and high performance. However, existing models\nin this domain still suffer from suboptimal performance. We introduce several\ninnovations to improve the performance: i) We propose a novel spike-form Q-K\nattention mechanism, tailored for SNNs, which efficiently models the importance\nof token or channel dimensions through binary vectors with linear complexity.\nii) We incorporate the hierarchical structure, which significantly benefits the\nperformance of both the brain and artificial neural networks, into spiking\ntransformers to obtain multi-scale spiking representation. iii) We design a\nversatile and powerful patch embedding module with a deformed shortcut\nspecifically for spiking transformers. Together, we develop QKFormer, a\nhierarchical spiking transformer based on Q-K attention with direct training.\nQKFormer shows significantly superior performance over existing\nstate-of-the-art SNN models on various mainstream datasets. Notably, with\ncomparable size to Spikformer (66.34 M, 74.81%), QKFormer (64.96 M) achieves a\ngroundbreaking top-1 accuracy of 85.65% on ImageNet-1k, substantially\noutperforming Spikformer by 10.84%. To our best knowledge, this is the first\ntime that directly training SNNs have exceeded 85% accuracy on ImageNet-1K. The\ncode and models are publicly available at\nhttps://github.com/zhouchenlin2096/QKFormer\n","authors":["Chenlin Zhou","Han Zhang","Zhaokun Zhou","Liutao Yu","Liwei Huang","Xiaopeng Fan","Li Yuan","Zhengyu Ma","Huihui Zhou","Yonghong Tian"],"pdf_url":"https://arxiv.org/pdf/2403.16552v1.pdf","comment":"10 pages, code: https://github.com/zhouchenlin2096/QKFormer"},{"id":"http://arxiv.org/abs/2403.16417v1","updated":"2024-03-25T04:34:20Z","published":"2024-03-25T04:34:20Z","title":"Leveraging Large Language Model to Generate a Novel Metaheuristic\n  Algorithm with CRISPE Framework","summary":"  In this paper, we borrow the large language model (LLM) ChatGPT-3.5 to\nautomatically and quickly design a new metaheuristic algorithm (MA) with only a\nsmall amount of input. The novel animal-inspired MA named zoological search\noptimization (ZSO) draws inspiration from the collective behaviors of animals\nfor solving continuous optimization problems. Specifically, the basic ZSO\nalgorithm involves two search operators: the prey-predator interaction operator\nand the social flocking operator to balance exploration and exploitation well.\nBesides, the standard prompt engineering framework CRISPE (i.e., Capacity and\nRole, Insight, Statement, Personality, and Experiment) is responsible for the\nspecific prompt design. Furthermore, we designed four variants of the ZSO\nalgorithm with slight human-interacted adjustment. In numerical experiments, we\ncomprehensively investigate the performance of ZSO-derived algorithms on\nCEC2014 benchmark functions, CEC2022 benchmark functions, and six engineering\noptimization problems. 20 popular and state-of-the-art MAs are employed as\ncompetitors. The experimental results and statistical analysis confirm the\nefficiency and effectiveness of ZSO-derived algorithms. At the end of this\npaper, we explore the prospects for the development of the metaheuristics\ncommunity under the LLM era.\n","authors":["Rui Zhong","Yuefeng Xu","Chao Zhang","Jun Yu"],"pdf_url":"https://arxiv.org/pdf/2403.16417v1.pdf","comment":"24 pages"},{"id":"http://arxiv.org/abs/2204.10438v4","updated":"2024-03-25T02:37:09Z","published":"2022-04-21T23:59:17Z","title":"EVOTER: Evolution of Transparent Explainable Rule-sets","summary":"  Most AI systems are black boxes generating reasonable outputs for given\ninputs. Some domains, however, have explainability and trustworthiness\nrequirements that cannot be directly met by these approaches. Various methods\nhave therefore been developed to interpret black-box models after training.\nThis paper advocates an alternative approach where the models are transparent\nand explainable to begin with. This approach, EVOTER, evolves rule-sets based\non simple logical expressions. The approach is evaluated in several\nprediction/classification and prescription/policy search domains with and\nwithout a surrogate. It is shown to discover meaningful rule sets that perform\nsimilarly to black-box models. The rules can provide insight into the domain,\nand make biases hidden in the data explicit. It may also be possible to edit\nthem directly to remove biases and add constraints. EVOTER thus forms a\npromising foundation for building trustworthy AI systems for real-world\napplications in the future.\n","authors":["Hormoz Shahrzad","Babak Hodjat","Risto Miikkulainen"],"pdf_url":"https://arxiv.org/pdf/2204.10438v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.06900v3","updated":"2024-03-25T00:28:12Z","published":"2022-08-14T19:04:15Z","title":"Convolutional Spiking Neural Networks for Detecting Anticipatory Brain\n  Potentials Using Electroencephalogram","summary":"  Spiking neural networks (SNNs) are receiving increased attention because they\nmimic synaptic connections in biological systems and produce spike trains,\nwhich can be approximated by binary values for computational efficiency.\nRecently, the addition of convolutional layers to combine the feature\nextraction power of convolutional networks with the computational efficiency of\nSNNs has been introduced. This paper studies the feasibility of using a\nconvolutional spiking neural network (CSNN) to detect anticipatory slow\ncortical potentials (SCPs) related to braking intention in human participants\nusing an electroencephalogram (EEG). Data was collected during an experiment\nwherein participants operated a remote-controlled vehicle on a testbed designed\nto simulate an urban environment. Participants were alerted to an incoming\nbraking event via an audio countdown to elicit anticipatory potentials that\nwere measured using an EEG. The CSNN's performance was compared to a standard\nCNN, EEGNet and three graph neural networks via 10-fold cross-validation. The\nCSNN outperformed all the other neural networks, and had a predictive accuracy\nof 99.06 percent with a true positive rate of 98.50 percent, a true negative\nrate of 99.20 percent and an F1-score of 0.98. Performance of the CSNN was\ncomparable to the CNN in an ablation study using a subset of EEG channels that\nlocalized SCPs. Classification performance of the CSNN degraded only slightly\nwhen the floating-point EEG data were converted into spike trains via delta\nmodulation to mimic synaptic connections.\n","authors":["Nathan Lutes","Venkata Sriram Siddhardh Nadendla","K. Krishnamurthy"],"pdf_url":"https://arxiv.org/pdf/2208.06900v3.pdf","comment":"16 pages, 6 figures, Scientific Reports submission"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2311.15404v2","updated":"2024-03-25T22:55:43Z","published":"2023-11-26T20:00:53Z","title":"Applying statistical learning theory to deep learning","summary":"  Although statistical learning theory provides a robust framework to\nunderstand supervised learning, many theoretical aspects of deep learning\nremain unclear, in particular how different architectures may lead to inductive\nbias when trained using gradient based methods. The goal of these lectures is\nto provide an overview of some of the main questions that arise when attempting\nto understand deep learning from a learning theory perspective. After a brief\nreminder on statistical learning theory and stochastic optimization, we discuss\nimplicit bias in the context of benign overfitting. We then move to a general\ndescription of the mirror descent algorithm, showing how we may go back and\nforth between a parameter space and the corresponding function space for a\ngiven learning problem, as well as how the geometry of the learning problem may\nbe represented by a metric tensor. Building on this framework, we provide a\ndetailed study of the implicit bias of gradient descent on linear diagonal\nnetworks for various regression tasks, showing how the loss function, scale of\nparameters at initialization and depth of the network may lead to various forms\nof implicit bias, in particular transitioning between kernel or feature\nlearning.\n","authors":["Cédric Gerbelot","Avetik Karagulyan","Stefani Karp","Kavya Ravichandran","Menachem Stern","Nathan Srebro"],"pdf_url":"https://arxiv.org/pdf/2311.15404v2.pdf","comment":"66 pages, 20 figures"},{"id":"http://arxiv.org/abs/2403.17247v1","updated":"2024-03-25T22:49:56Z","published":"2024-03-25T22:49:56Z","title":"DASA: Delay-Adaptive Multi-Agent Stochastic Approximation","summary":"  We consider a setting in which $N$ agents aim to speedup a common Stochastic\nApproximation (SA) problem by acting in parallel and communicating with a\ncentral server. We assume that the up-link transmissions to the server are\nsubject to asynchronous and potentially unbounded time-varying delays. To\nmitigate the effect of delays and stragglers while reaping the benefits of\ndistributed computation, we propose \\texttt{DASA}, a Delay-Adaptive algorithm\nfor multi-agent Stochastic Approximation. We provide a finite-time analysis of\n\\texttt{DASA} assuming that the agents' stochastic observation processes are\nindependent Markov chains. Significantly advancing existing results,\n\\texttt{DASA} is the first algorithm whose convergence rate depends only on the\nmixing time $\\tmix$ and on the average delay $\\tau_{avg}$ while jointly\nachieving an $N$-fold convergence speedup under Markovian sampling. Our work is\nrelevant for various SA applications, including multi-agent and distributed\ntemporal difference (TD) learning, Q-learning and stochastic optimization with\ncorrelated data.\n","authors":["Nicolo Dal Fabbro","Arman Adibi","H. Vincent Poor","Sanjeev R. Kulkarni","Aritra Mitra","George J. Pappas"],"pdf_url":"https://arxiv.org/pdf/2403.17247v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17091v1","updated":"2024-03-25T18:28:45Z","published":"2024-03-25T18:28:45Z","title":"Offline Reinforcement Learning: Role of State Aggregation and Trajectory\n  Data","summary":"  We revisit the problem of offline reinforcement learning with value function\nrealizability but without Bellman completeness. Previous work by Xie and Jiang\n(2021) and Foster et al. (2022) left open the question whether a bounded\nconcentrability coefficient along with trajectory-based offline data admits a\npolynomial sample complexity. In this work, we provide a negative answer to\nthis question for the task of offline policy evaluation. In addition to\naddressing this question, we provide a rather complete picture for offline\npolicy evaluation with only value function realizability. Our primary findings\nare threefold: 1) The sample complexity of offline policy evaluation is\ngoverned by the concentrability coefficient in an aggregated Markov Transition\nModel jointly determined by the function class and the offline data\ndistribution, rather than that in the original MDP. This unifies and\ngeneralizes the ideas of Xie and Jiang (2021) and Foster et al. (2022), 2) The\nconcentrability coefficient in the aggregated Markov Transition Model may grow\nexponentially with the horizon length, even when the concentrability\ncoefficient in the original MDP is small and the offline data is admissible\n(i.e., the data distribution equals the occupancy measure of some policy), 3)\nUnder value function realizability, there is a generic reduction that can\nconvert any hard instance with admissible data to a hard instance with\ntrajectory data, implying that trajectory data offers no extra benefits over\nadmissible data. These three pieces jointly resolve the open problem, though\neach of them could be of independent interest.\n","authors":["Zeyu Jia","Alexander Rakhlin","Ayush Sekhari","Chen-Yu Wei"],"pdf_url":"https://arxiv.org/pdf/2403.17091v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03157v2","updated":"2024-03-25T18:14:54Z","published":"2023-02-06T23:34:51Z","title":"A distribution-free mixed-integer optimization approach to hierarchical\n  modelling of clustered and longitudinal data","summary":"  Recent advancements in Mixed Integer Optimization (MIO) algorithms, paired\nwith hardware enhancements, have led to significant speedups in resolving MIO\nproblems. These strategies have been utilized for optimal subset selection,\nspecifically for choosing $k$ features out of $p$ in linear regression given\n$n$ observations. In this paper, we broaden this method to facilitate\ncluster-aware regression, where selection aims to choose $\\lambda$ out of $K$\nclusters in a linear mixed effects (LMM) model with $n_k$ observations for each\ncluster. Through comprehensive testing on a multitude of synthetic and real\ndatasets, we exhibit that our method efficiently solves problems within\nminutes. Through numerical experiments, we also show that the MIO approach\noutperforms both Gaussian- and Laplace-distributed LMMs in terms of generating\nsparse solutions with high predictive power. Traditional LMMs typically assume\nthat clustering effects are independent of individual features. However, we\nintroduce an innovative algorithm that evaluates cluster effects for new data\npoints, thereby increasing the robustness and precision of this model. The\ninferential and predictive efficacy of this approach is further illustrated\nthrough its application in student scoring and protein expression.\n","authors":["Madhav Sankaranarayanan","Intekhab Hossain","Tom Chen"],"pdf_url":"https://arxiv.org/pdf/2302.03157v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.05401v5","updated":"2024-03-25T18:07:22Z","published":"2023-10-09T04:40:20Z","title":"Entropy-MCMC: Sampling from Flat Basins with Ease","summary":"  Bayesian deep learning counts on the quality of posterior distribution\nestimation. However, the posterior of deep neural networks is highly\nmulti-modal in nature, with local modes exhibiting varying generalization\nperformance. Given a practical budget, targeting at the original posterior can\nlead to suboptimal performance, as some samples may become trapped in \"bad\"\nmodes and suffer from overfitting. Leveraging the observation that \"good\" modes\nwith low generalization error often reside in flat basins of the energy\nlandscape, we propose to bias sampling on the posterior toward these flat\nregions. Specifically, we introduce an auxiliary guiding variable, the\nstationary distribution of which resembles a smoothed posterior free from sharp\nmodes, to lead the MCMC sampler to flat basins. By integrating this guiding\nvariable with the model parameter, we create a simple joint distribution that\nenables efficient sampling with minimal computational overhead. We prove the\nconvergence of our method and further show that it converges faster than\nseveral existing flatness-aware methods in the strongly convex setting.\nEmpirical results demonstrate that our method can successfully sample from flat\nbasins of the posterior, and outperforms all compared baselines on multiple\nbenchmarks including classification, calibration, and out-of-distribution\ndetection.\n","authors":["Bolian Li","Ruqi Zhang"],"pdf_url":"https://arxiv.org/pdf/2310.05401v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16995v1","updated":"2024-03-25T17:58:22Z","published":"2024-03-25T17:58:22Z","title":"Language Rectified Flow: Advancing Diffusion Language Generation with\n  Probabilistic Flows","summary":"  Recent works have demonstrated success in controlling sentence attributes\n($e.g.$, sentiment) and structure ($e.g.$, syntactic structure) based on the\ndiffusion language model. A key component that drives theimpressive performance\nfor generating high-quality samples from noise is iteratively denoise for\nthousands of steps. While beneficial, the complexity of starting from the noise\nand the learning steps has limited its implementation to many NLP real-world\napplications. This paper proposes Language Rectified Flow ({\\ours}). Our method\nis based on the reformulation of the standard probabilistic flow models.\nLanguage rectified flow learns (neural) ordinary differential equation models\nto transport between the source distribution and the target distribution, hence\nproviding a unified and effective solution to generative modeling and domain\ntransfer. From the source distribution, our language rectified flow yields fast\nsimulation and effectively decreases the inference time. Experiments on three\nchallenging fine-grained control tasks and multiple high-quality text editing\nshow that our method consistently outperforms its baselines. Extensive\nexperiments and ablation studies demonstrate that our method can be general,\neffective, and beneficial for many NLP tasks.\n","authors":["Shujian Zhang","Lemeng Wu","Chengyue Gong","Xingchao Liu"],"pdf_url":"https://arxiv.org/pdf/2403.16995v1.pdf","comment":"Accepted to NAACL 2024"},{"id":"http://arxiv.org/abs/2403.16981v1","updated":"2024-03-25T17:42:32Z","published":"2024-03-25T17:42:32Z","title":"The Sample Complexity of Simple Binary Hypothesis Testing","summary":"  The sample complexity of simple binary hypothesis testing is the smallest\nnumber of i.i.d. samples required to distinguish between two distributions $p$\nand $q$ in either: (i) the prior-free setting, with type-I error at most\n$\\alpha$ and type-II error at most $\\beta$; or (ii) the Bayesian setting, with\nBayes error at most $\\delta$ and prior distribution $(\\alpha, 1-\\alpha)$. This\nproblem has only been studied when $\\alpha = \\beta$ (prior-free) or $\\alpha =\n1/2$ (Bayesian), and the sample complexity is known to be characterized by the\nHellinger divergence between $p$ and $q$, up to multiplicative constants. In\nthis paper, we derive a formula that characterizes the sample complexity (up to\nmultiplicative constants that are independent of $p$, $q$, and all error\nparameters) for: (i) all $0 \\le \\alpha, \\beta \\le 1/8$ in the prior-free\nsetting; and (ii) all $\\delta \\le \\alpha/4$ in the Bayesian setting. In\nparticular, the formula admits equivalent expressions in terms of certain\ndivergences from the Jensen--Shannon and Hellinger families. The main technical\nresult concerns an $f$-divergence inequality between members of the\nJensen--Shannon and Hellinger families, which is proved by a combination of\ninformation-theoretic tools and case-by-case analyses. We explore applications\nof our results to robust and distributed (locally-private and\ncommunication-constrained) hypothesis testing.\n","authors":["Ankit Pensia","Varun Jog","Po-Ling Loh"],"pdf_url":"https://arxiv.org/pdf/2403.16981v1.pdf","comment":"Comments welcome"},{"id":"http://arxiv.org/abs/2403.16916v1","updated":"2024-03-25T16:36:13Z","published":"2024-03-25T16:36:13Z","title":"SCOD: From Heuristics to Theory","summary":"  This paper addresses the problem of designing reliable prediction models that\nabstain from predictions when faced with uncertain or out-of-distribution\nsamples - a recently proposed problem known as Selective Classification in the\npresence of Out-of-Distribution data (SCOD). We make three key contributions to\nSCOD. Firstly, we demonstrate that the optimal SCOD strategy involves a Bayes\nclassifier for in-distribution (ID) data and a selector represented as a\nstochastic linear classifier in a 2D space, using i) the conditional risk of\nthe ID classifier, and ii) the likelihood ratio of ID and out-of-distribution\n(OOD) data as input. This contrasts with suboptimal strategies from current OOD\ndetection methods and the Softmax Information Retaining Combination (SIRC),\nspecifically developed for SCOD. Secondly, we establish that in a\ndistribution-free setting, the SCOD problem is not Probably Approximately\nCorrect learnable when relying solely on an ID data sample. Third, we introduce\nPOSCOD, a simple method for learning a plugin estimate of the optimal SCOD\nstrategy from both an ID data sample and an unlabeled mixture of ID and OOD\ndata. Our empirical results confirm the theoretical findings and demonstrate\nthat our proposed method, POSCOD, out performs existing OOD methods in\neffectively addressing the SCOD problem.\n","authors":["Vojtech Franc","Jakub Paplham","Daniel Prusa"],"pdf_url":"https://arxiv.org/pdf/2403.16916v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09962v3","updated":"2024-03-25T16:07:31Z","published":"2022-12-20T02:30:13Z","title":"Distributional Robustness Bounds Generalization Errors","summary":"  Bayesian methods, distributionally robust optimization methods, and\nregularization methods are three pillars of trustworthy machine learning\ncombating distributional uncertainty, e.g., the uncertainty of an empirical\ndistribution compared to the true underlying distribution. This paper\ninvestigates the connections among the three frameworks and, in particular,\nexplores why these frameworks tend to have smaller generalization errors.\nSpecifically, first, we suggest a quantitative definition for \"distributional\nrobustness\", propose the concept of \"robustness measure\", and formalize several\nphilosophical concepts in distributionally robust optimization. Second, we show\nthat Bayesian methods are distributionally robust in the probably approximately\ncorrect (PAC) sense; in addition, by constructing a Dirichlet-process-like\nprior in Bayesian nonparametrics, it can be proven that any regularized\nempirical risk minimization method is equivalent to a Bayesian method. Third,\nwe show that generalization errors of machine learning models can be\ncharacterized using the distributional uncertainty of the nominal distribution\nand the robustness measures of these machine learning models, which is a new\nperspective to bound generalization errors, and therefore, explain the reason\nwhy distributionally robust machine learning models, Bayesian models, and\nregularization models tend to have smaller generalization errors in a unified\nmanner.\n","authors":["Shixiong Wang","Haowei Wang"],"pdf_url":"https://arxiv.org/pdf/2212.09962v3.pdf","comment":"Updated Version"},{"id":"http://arxiv.org/abs/2311.10610v2","updated":"2024-03-25T16:05:04Z","published":"2023-11-17T16:04:31Z","title":"A Poincaré Inequality and Consistency Results for Signal Sampling on\n  Large Graphs","summary":"  Large-scale graph machine learning is challenging as the complexity of\nlearning models scales with the graph size. Subsampling the graph is a viable\nalternative, but sampling on graphs is nontrivial as graphs are non-Euclidean.\nExisting graph sampling techniques require not only computing the spectra of\nlarge matrices but also repeating these computations when the graph changes,\ne.g., grows. In this paper, we introduce a signal sampling theory for a type of\ngraph limit -- the graphon. We prove a Poincar\\'e inequality for graphon\nsignals and show that complements of node subsets satisfying this inequality\nare unique sampling sets for Paley-Wiener spaces of graphon signals. Exploiting\nconnections with spectral clustering and Gaussian elimination, we prove that\nsuch sampling sets are consistent in the sense that unique sampling sets on a\nconvergent graph sequence converge to unique sampling sets on the graphon. We\nthen propose a related graphon signal sampling algorithm for large graphs, and\ndemonstrate its good empirical performance on graph machine learning tasks.\n","authors":["Thien Le","Luana Ruiz","Stefanie Jegelka"],"pdf_url":"https://arxiv.org/pdf/2311.10610v2.pdf","comment":"23 pages"},{"id":"http://arxiv.org/abs/2403.17042v1","updated":"2024-03-25T15:58:26Z","published":"2024-03-25T15:58:26Z","title":"Provably Robust Score-Based Diffusion Posterior Sampling for\n  Plug-and-Play Image Reconstruction","summary":"  In a great number of tasks in science and engineering, the goal is to infer\nan unknown image from a small number of measurements collected from a known\nforward model describing certain sensing or imaging modality. Due to resource\nconstraints, this task is often extremely ill-posed, which necessitates the\nadoption of expressive prior information to regularize the solution space.\nScore-based diffusion models, due to its impressive empirical success, have\nemerged as an appealing candidate of an expressive prior in image\nreconstruction. In order to accommodate diverse tasks at once, it is of great\ninterest to develop efficient, consistent and robust algorithms that\nincorporate {\\em unconditional} score functions of an image prior distribution\nin conjunction with flexible choices of forward models.\n  This work develops an algorithmic framework for employing score-based\ndiffusion models as an expressive data prior in general nonlinear inverse\nproblems. Motivated by the plug-and-play framework in the imaging community, we\nintroduce a diffusion plug-and-play method (\\textsf{DPnP}) that alternatively\ncalls two samplers, a proximal consistency sampler based solely on the\nlikelihood function of the forward model, and a denoising diffusion sampler\nbased solely on the score functions of the image prior. The key insight is that\ndenoising under white Gaussian noise can be solved {\\em rigorously} via both\nstochastic (i.e., DDPM-type) and deterministic (i.e., DDIM-type) samplers using\nthe unconditional score functions. We establish both asymptotic and\nnon-asymptotic performance guarantees of \\textsf{DPnP}, and provide numerical\nexperiments to illustrate its promise in solving both linear and nonlinear\nimage reconstruction tasks. To the best of our knowledge, \\textsf{DPnP} is the\nfirst provably-robust posterior sampling method for nonlinear inverse problems\nusing unconditional diffusion priors.\n","authors":["Xingyu Xu","Yuejie Chi"],"pdf_url":"https://arxiv.org/pdf/2403.17042v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.01327v2","updated":"2024-03-25T15:55:22Z","published":"2023-10-02T16:45:19Z","title":"TACTiS-2: Better, Faster, Simpler Attentional Copulas for Multivariate\n  Time Series","summary":"  We introduce a new model for multivariate probabilistic time series\nprediction, designed to flexibly address a range of tasks including\nforecasting, interpolation, and their combinations. Building on copula theory,\nwe propose a simplified objective for the recently-introduced transformer-based\nattentional copulas (TACTiS), wherein the number of distributional parameters\nnow scales linearly with the number of variables instead of factorially. The\nnew objective requires the introduction of a training curriculum, which goes\nhand-in-hand with necessary changes to the original architecture. We show that\nthe resulting model has significantly better training dynamics and achieves\nstate-of-the-art performance across diverse real-world forecasting tasks, while\nmaintaining the flexibility of prior work, such as seamless handling of\nunaligned and unevenly-sampled time series. Code is made available at\nhttps://github.com/ServiceNow/TACTiS.\n","authors":["Arjun Ashok","Étienne Marcotte","Valentina Zantedeschi","Nicolas Chapados","Alexandre Drouin"],"pdf_url":"https://arxiv.org/pdf/2310.01327v2.pdf","comment":"28 pages, 15 figures, The Twelfth International Conference on\n  Learning Representations (ICLR 2024)"},{"id":"http://arxiv.org/abs/2403.16883v1","updated":"2024-03-25T15:53:32Z","published":"2024-03-25T15:53:32Z","title":"Discrete Latent Graph Generative Modeling with Diffusion Bridges","summary":"  Learning graph generative models over latent spaces has received less\nattention compared to models that operate on the original data space and has so\nfar demonstrated lacklustre performance. We present GLAD a latent space graph\ngenerative model. Unlike most previous latent space graph generative models,\nGLAD operates on a discrete latent space that preserves to a significant extent\nthe discrete nature of the graph structures making no unnatural assumptions\nsuch as latent space continuity. We learn the prior of our discrete latent\nspace by adapting diffusion bridges to its structure. By operating over an\nappropriately constructed latent space we avoid relying on decompositions that\nare often used in models that operate in the original data space. We present\nexperiments on a series of graph benchmark datasets which clearly show the\nsuperiority of the discrete latent space and obtain state of the art graph\ngenerative performance, making GLAD the first latent space graph generative\nmodel with competitive performance. Our source code is published at:\n\\url{https://github.com/v18nguye/GLAD}.\n","authors":["Van Khoa Nguyen","Yoann Boget","Frantzeska Lavda","Alexandros Kalousis"],"pdf_url":"https://arxiv.org/pdf/2403.16883v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16871v1","updated":"2024-03-25T15:37:43Z","published":"2024-03-25T15:37:43Z","title":"Conformal Off-Policy Prediction for Multi-Agent Systems","summary":"  Off-Policy Prediction (OPP), i.e., predicting the outcomes of a target policy\nusing only data collected under a nominal (behavioural) policy, is a paramount\nproblem in data-driven analysis of safety-critical systems where the deployment\nof a new policy may be unsafe. To achieve dependable off-policy predictions,\nrecent work on Conformal Off-Policy Prediction (COPP) leverage the conformal\nprediction framework to derive prediction regions with probabilistic guarantees\nunder the target process. Existing COPP methods can account for the\ndistribution shifts induced by policy switching, but are limited to\nsingle-agent systems and scalar outcomes (e.g., rewards). In this work, we\nintroduce MA-COPP, the first conformal prediction method to solve OPP problems\ninvolving multi-agent systems, deriving joint prediction regions for all\nagents' trajectories when one or more \"ego\" agents change their policies.\nUnlike the single-agent scenario, this setting introduces higher complexity as\nthe distribution shifts affect predictions for all agents, not just the ego\nagents, and the prediction task involves full multi-dimensional trajectories,\nnot just reward values. A key contribution of MA-COPP is to avoid enumeration\nor exhaustive search of the output space of agent trajectories, which is\ninstead required by existing COPP methods to construct the prediction region.\nWe achieve this by showing that an over-approximation of the true JPR can be\nconstructed, without enumeration, from the maximum density ratio of the JPR\ntrajectories. We evaluate the effectiveness of MA-COPP in multi-agent systems\nfrom the PettingZoo library and the F1TENTH autonomous racing environment,\nachieving nominal coverage in higher dimensions and various shift settings.\n","authors":["Tom Kuipers","Renukanandan Tumu","Shuo Yang","Milad Kazemi","Rahul Mangharam","Nicola Paoletti"],"pdf_url":"https://arxiv.org/pdf/2403.16871v1.pdf","comment":"Submitted to the 63rd IEEE Conference on Decision and Control (CDC)"},{"id":"http://arxiv.org/abs/2403.16825v1","updated":"2024-03-25T14:49:01Z","published":"2024-03-25T14:49:01Z","title":"Weak Convergence Analysis of Online Neural Actor-Critic Algorithms","summary":"  We prove that a single-layer neural network trained with the online actor\ncritic algorithm converges in distribution to a random ordinary differential\nequation (ODE) as the number of hidden units and the number of training steps\n$\\rightarrow \\infty$. In the online actor-critic algorithm, the distribution of\nthe data samples dynamically changes as the model is updated, which is a key\nchallenge for any convergence analysis. We establish the geometric ergodicity\nof the data samples under a fixed actor policy. Then, using a Poisson equation,\nwe prove that the fluctuations of the model updates around the limit\ndistribution due to the randomly-arriving data samples vanish as the number of\nparameter updates $\\rightarrow \\infty$. Using the Poisson equation and weak\nconvergence techniques, we prove that the actor neural network and critic\nneural network converge to the solutions of a system of ODEs with random\ninitial conditions. Analysis of the limit ODE shows that the limit critic\nnetwork will converge to the true value function, which will provide the actor\nan asymptotically unbiased estimate of the policy gradient. We then prove that\nthe limit actor network will converge to a stationary point.\n","authors":["Samuel Chun-Hei Lam","Justin Sirignano","Ziheng Wang"],"pdf_url":"https://arxiv.org/pdf/2403.16825v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.08347v3","updated":"2024-03-25T13:18:39Z","published":"2023-02-16T15:05:37Z","title":"The autoregressive neural network architecture of the Boltzmann\n  distribution of pairwise interacting spins systems","summary":"  Generative Autoregressive Neural Networks (ARNNs) have recently demonstrated\nexceptional results in image and language generation tasks, contributing to the\ngrowing popularity of generative models in both scientific and commercial\napplications. This work presents an exact mapping of the Boltzmann distribution\nof binary pairwise interacting systems into autoregressive form. The resulting\nARNN architecture has weights and biases of its first layer corresponding to\nthe Hamiltonian's couplings and external fields, featuring widely used\nstructures such as the residual connections and a recurrent architecture with\nclear physical meanings. Moreover, its architecture's explicit formulation\nenables the use of statistical physics techniques to derive new ARNNs for\nspecific systems. As examples, new effective ARNN architectures are derived\nfrom two well-known mean-field systems, the Curie-Weiss and\nSherrington-Kirkpatrick models, showing superior performance in approximating\nthe Boltzmann distributions of the corresponding physics model compared to\nother commonly used architectures. The connection established between the\nphysics of the system and the neural network architecture provides a means to\nderive new architectures for different interacting systems and interpret\nexisting ones from a physical perspective.\n","authors":["Indaco Biazzo"],"pdf_url":"https://arxiv.org/pdf/2302.08347v3.pdf","comment":"20 pages, 10 figure plus the Supplementary Information"},{"id":"http://arxiv.org/abs/2306.10180v3","updated":"2024-03-25T13:02:27Z","published":"2023-06-16T21:20:49Z","title":"Samplet basis pursuit: Multiresolution scattered data approximation with\n  sparsity constraints","summary":"  We consider scattered data approximation in samplet coordinates with\n$\\ell_1$-regularization. The application of an $\\ell_1$-regularization term\nenforces sparsity of the coefficients with respect to the samplet basis.\nSamplets are wavelet-type signed measures, which are tailored to scattered\ndata. They provide similar properties as wavelets in terms of localization,\nmultiresolution analysis, and data compression. By using the Riesz isometry, we\nembed samplets into reproducing kernel Hilbert spaces and discuss the\nproperties of the resulting functions. We argue that the class of signals that\nare sparse with respect to the embedded samplet basis is considerably larger\nthan the class of signals that are sparse with respect to the basis of kernel\ntranslates. Vice versa, every signal that is a linear combination of only a few\nkernel translates is sparse in samplet coordinates. Therefore, samplets enable\nthe use of well-established multiresolution techniques on general scattered\ndata sets.\n  We propose the rapid solution of the problem under consideration by combining\nsoft-shrinkage with the semi-smooth Newton method. Leveraging on the sparse\nrepresentation of kernel matrices in samplet coordinates, this approach\nconverges faster than the fast iterative shrinkage thresholding algorithm and\nis feasible for large-scale data. Numerical benchmarks are presented and\ndemonstrate the superiority of the multiresolution approach over the\nsingle-scale approach. As large-scale applications, the surface reconstruction\nfrom scattered data and the reconstruction of scattered temperature data using\na dictionary of multiple kernels are considered.\n","authors":["Davide Baroli","Helmut Harbrecht","Michael Multerer"],"pdf_url":"https://arxiv.org/pdf/2306.10180v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16688v1","updated":"2024-03-25T12:23:19Z","published":"2024-03-25T12:23:19Z","title":"Optimal convex $M$-estimation via score matching","summary":"  In the context of linear regression, we construct a data-driven convex loss\nfunction with respect to which empirical risk minimisation yields optimal\nasymptotic variance in the downstream estimation of the regression\ncoefficients. Our semiparametric approach targets the best decreasing\napproximation of the derivative of the log-density of the noise distribution.\nAt the population level, this fitting process is a nonparametric extension of\nscore matching, corresponding to a log-concave projection of the noise\ndistribution with respect to the Fisher divergence. The procedure is\ncomputationally efficient, and we prove that our procedure attains the minimal\nasymptotic covariance among all convex $M$-estimators. As an example of a\nnon-log-concave setting, for Cauchy errors, the optimal convex loss function is\nHuber-like, and our procedure yields an asymptotic efficiency greater than 0.87\nrelative to the oracle maximum likelihood estimator of the regression\ncoefficients that uses knowledge of this error distribution; in this sense, we\nobtain robustness without sacrificing much efficiency. Numerical experiments\nconfirm the practical merits of our proposal.\n","authors":["Oliver Y. Feng","Yu-Chun Kao","Min Xu","Richard J. Samworth"],"pdf_url":"https://arxiv.org/pdf/2403.16688v1.pdf","comment":"69 pages, 12 figures and 4 tables"},{"id":"http://arxiv.org/abs/2403.16681v1","updated":"2024-03-25T12:15:55Z","published":"2024-03-25T12:15:55Z","title":"A note on generalization bounds for losses with finite moments","summary":"  This paper studies the truncation method from Alquier [1] to derive\nhigh-probability PAC-Bayes bounds for unbounded losses with heavy tails.\nAssuming that the $p$-th moment is bounded, the resulting bounds interpolate\nbetween a slow rate $1 / \\sqrt{n}$ when $p=2$, and a fast rate $1 / n$ when $p\n\\to \\infty$ and the loss is essentially bounded. Moreover, the paper derives a\nhigh-probability PAC-Bayes bound for losses with a bounded variance. This bound\nhas an exponentially better dependence on the confidence parameter and the\ndependency measure than previous bounds in the literature. Finally, the paper\nextends all results to guarantees in expectation and single-draw PAC-Bayes. In\norder to so, it obtains analogues of the PAC-Bayes fast rate bound for bounded\nlosses from [2] in these settings.\n","authors":["Borja Rodríguez-Gálvez","Omar Rivasplata","Ragnar Thobaben","Mikael Skoglund"],"pdf_url":"https://arxiv.org/pdf/2403.16681v1.pdf","comment":"9 pages: 5 of main text, 1 of references, and 3 of appendices"},{"id":"http://arxiv.org/abs/2311.17744v2","updated":"2024-03-25T11:04:17Z","published":"2023-11-29T15:49:31Z","title":"Variational Bayes image restoration with compressive autoencoders","summary":"  Regularization of inverse problems is of paramount importance in\ncomputational imaging. The ability of neural networks to learn efficient image\nrepresentations has been recently exploited to design powerful data-driven\nregularizers. While state-of-the-art plug-and-play methods rely on an implicit\nregularization provided by neural denoisers, alternative Bayesian approaches\nconsider Maximum A Posteriori (MAP) estimation in the latent space of a\ngenerative model, thus with an explicit regularization. However,\nstate-of-the-art deep generative models require a huge amount of training data\ncompared to denoisers. Besides, their complexity hampers the optimization\ninvolved in latent MAP derivation. In this work, we first propose to use\ncompressive autoencoders instead. These networks, which can be seen as\nvariational autoencoders with a flexible latent prior, are smaller and easier\nto train than state-of-the-art generative models. As a second contribution, we\nintroduce the Variational Bayes Latent Estimation (VBLE) algorithm, which\nperforms latent estimation within the framework of variational inference.\nThanks to a simple yet efficient parameterization of the variational posterior,\nVBLE allows for fast and easy (approximate) posterior sampling. Experimental\nresults on image datasets BSD and FFHQ demonstrate that VBLE reaches similar\nperformance than state-of-the-art plug-and-play methods, while being able to\nquantify uncertainties faster than other existing posterior sampling\ntechniques.\n","authors":["Maud Biquard","Marie Chabert","Thomas Oberlin"],"pdf_url":"https://arxiv.org/pdf/2311.17744v2.pdf","comment":null},{"id":"http://arxiv.org/abs/1902.05605v4","updated":"2024-03-25T10:20:18Z","published":"2019-02-14T21:05:50Z","title":"CrossQ: Batch Normalization in Deep Reinforcement Learning for Greater\n  Sample Efficiency and Simplicity","summary":"  Sample efficiency is a crucial problem in deep reinforcement learning. Recent\nalgorithms, such as REDQ and DroQ, found a way to improve the sample efficiency\nby increasing the update-to-data (UTD) ratio to 20 gradient update steps on the\ncritic per environment sample. However, this comes at the expense of a greatly\nincreased computational cost. To reduce this computational burden, we introduce\nCrossQ: A lightweight algorithm for continuous control tasks that makes careful\nuse of Batch Normalization and removes target networks to surpass the current\nstate-of-the-art in sample efficiency while maintaining a low UTD ratio of 1.\nNotably, CrossQ does not rely on advanced bias-reduction schemes used in\ncurrent methods. CrossQ's contributions are threefold: (1) it matches or\nsurpasses current state-of-the-art methods in terms of sample efficiency, (2)\nit substantially reduces the computational cost compared to REDQ and DroQ, (3)\nit is easy to implement, requiring just a few lines of code on top of SAC.\n","authors":["Aditya Bhatt","Daniel Palenicek","Boris Belousov","Max Argus","Artemij Amiranashvili","Thomas Brox","Jan Peters"],"pdf_url":"https://arxiv.org/pdf/1902.05605v4.pdf","comment":"Published at ICLR 2024. Project page at\n  http://aditya.bhatts.org/CrossQ and code release at\n  https://github.com/adityab/CrossQ"},{"id":"http://arxiv.org/abs/2403.16523v1","updated":"2024-03-25T08:06:08Z","published":"2024-03-25T08:06:08Z","title":"Causal Discovery from Poisson Branching Structural Causal Model Using\n  High-Order Cumulant with Path Analysis","summary":"  Count data naturally arise in many fields, such as finance, neuroscience, and\nepidemiology, and discovering causal structure among count data is a crucial\ntask in various scientific and industrial scenarios. One of the most common\ncharacteristics of count data is the inherent branching structure described by\na binomial thinning operator and an independent Poisson distribution that\ncaptures both branching and noise. For instance, in a population count\nscenario, mortality and immigration contribute to the count, where survival\nfollows a Bernoulli distribution, and immigration follows a Poisson\ndistribution. However, causal discovery from such data is challenging due to\nthe non-identifiability issue: a single causal pair is Markov equivalent, i.e.,\n$X\\rightarrow Y$ and $Y\\rightarrow X$ are distributed equivalent. Fortunately,\nin this work, we found that the causal order from $X$ to its child $Y$ is\nidentifiable if $X$ is a root vertex and has at least two directed paths to\n$Y$, or the ancestor of $X$ with the most directed path to $X$ has a directed\npath to $Y$ without passing $X$. Specifically, we propose a Poisson Branching\nStructure Causal Model (PB-SCM) and perform a path analysis on PB-SCM using\nhigh-order cumulants. Theoretical results establish the connection between the\npath and cumulant and demonstrate that the path information can be obtained\nfrom the cumulant. With the path information, causal order is identifiable\nunder some graphical conditions. A practical algorithm for learning causal\nstructure under PB-SCM is proposed and the experiments demonstrate and verify\nthe effectiveness of the proposed method.\n","authors":["Jie Qiao","Yu Xiang","Zhengming Chen","Ruichu Cai","Zhifeng Hao"],"pdf_url":"https://arxiv.org/pdf/2403.16523v1.pdf","comment":"Accepted by AAAI-2024"},{"id":"http://arxiv.org/abs/2305.00979v2","updated":"2024-03-25T07:47:57Z","published":"2023-04-29T23:56:55Z","title":"Spectral clustering in the Gaussian mixture block model","summary":"  Gaussian mixture block models are distributions over graphs that strive to\nmodel modern networks: to generate a graph from such a model, we associate each\nvertex $i$ with a latent feature vector $u_i \\in \\mathbb{R}^d$ sampled from a\nmixture of Gaussians, and we add edge $(i,j)$ if and only if the feature\nvectors are sufficiently similar, in that $\\langle u_i,u_j \\rangle \\ge \\tau$\nfor a pre-specified threshold $\\tau$. The different components of the Gaussian\nmixture represent the fact that there may be different types of nodes with\ndifferent distributions over features -- for example, in a social network each\ncomponent represents the different attributes of a distinct community. Natural\nalgorithmic tasks associated with these networks are embedding (recovering the\nlatent feature vectors) and clustering (grouping nodes by their mixture\ncomponent).\n  In this paper we initiate the study of clustering and embedding graphs\nsampled from high-dimensional Gaussian mixture block models, where the\ndimension of the latent feature vectors $d\\to \\infty$ as the size of the\nnetwork $n \\to \\infty$. This high-dimensional setting is most appropriate in\nthe context of modern networks, in which we think of the latent feature space\nas being high-dimensional. We analyze the performance of canonical spectral\nclustering and embedding algorithms for such graphs in the case of 2-component\nspherical Gaussian mixtures, and begin to sketch out the\ninformation-computation landscape for clustering and embedding in these models.\n","authors":["Shuangping Li","Tselil Schramm"],"pdf_url":"https://arxiv.org/pdf/2305.00979v2.pdf","comment":"48 pages"},{"id":"http://arxiv.org/abs/2403.16459v1","updated":"2024-03-25T06:42:02Z","published":"2024-03-25T06:42:02Z","title":"On the rates of convergence for learning with convolutional neural\n  networks","summary":"  We study the approximation and learning capacities of convolutional neural\nnetworks (CNNs). Our first result proves a new approximation bound for CNNs\nwith certain constraint on the weights. Our second result gives a new analysis\non the covering number of feed-forward neural networks, which include CNNs as\nspecial cases. The analysis carefully takes into account the size of the\nweights and hence gives better bounds than existing literature in some\nsituations. Using these two results, we are able to derive rates of convergence\nfor estimators based on CNNs in many learning problems. In particular, we\nestablish minimax optimal convergence rates of the least squares based on CNNs\nfor learning smooth functions in the nonparametric regression setting. For\nbinary classification, we derive convergence rates for CNN classifiers with\nhinge loss and logistic loss. It is also shown that the obtained rates are\nminimax optimal in several settings.\n","authors":["Yunfei Yang","Han Feng","Ding-Xuan Zhou"],"pdf_url":"https://arxiv.org/pdf/2403.16459v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16377v1","updated":"2024-03-25T02:47:29Z","published":"2024-03-25T02:47:29Z","title":"Real-time Adaptation for Condition Monitoring Signal Prediction using\n  Label-aware Neural Processes","summary":"  Building a predictive model that rapidly adapts to real-time condition\nmonitoring (CM) signals is critical for engineering systems/units.\nUnfortunately, many current methods suffer from a trade-off between\nrepresentation power and agility in online settings. For instance, parametric\nmethods that assume an underlying functional form for CM signals facilitate\nefficient online prediction updates. However, this simplification leads to\nvulnerability to model specifications and an inability to capture complex\nsignals. On the other hand, approaches based on over-parameterized or\nnon-parametric models can excel at explaining complex nonlinear signals, but\nreal-time updates for such models pose a challenging task. In this paper, we\npropose a neural process-based approach that addresses this trade-off. It\nencodes available observations within a CM signal into a representation space\nand then reconstructs the signal's history and evolution for prediction. Once\ntrained, the model can encode an arbitrary number of observations without\nrequiring retraining, enabling on-the-spot real-time predictions along with\nquantified uncertainty and can be readily updated as more online data is\ngathered. Furthermore, our model is designed to incorporate qualitative\ninformation (i.e., labels) from individual units. This integration not only\nenhances individualized predictions for each unit but also enables joint\ninference for both signals and their associated labels. Numerical studies on\nboth synthetic and real-world data in reliability engineering highlight the\nadvantageous features of our model in real-time adaptation, enhanced signal\nprediction with uncertainty quantification, and joint prediction for labels and\nsignals.\n","authors":["Seokhyun Chung","Raed Al Kontar"],"pdf_url":"https://arxiv.org/pdf/2403.16377v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16369v1","updated":"2024-03-25T02:17:54Z","published":"2024-03-25T02:17:54Z","title":"Learning Action-based Representations Using Invariance","summary":"  Robust reinforcement learning agents using high-dimensional observations must\nbe able to identify relevant state features amidst many exogeneous distractors.\nA representation that captures controllability identifies these state elements\nby determining what affects agent control. While methods such as inverse\ndynamics and mutual information capture controllability for a limited number of\ntimesteps, capturing long-horizon elements remains a challenging problem.\nMyopic controllability can capture the moment right before an agent crashes\ninto a wall, but not the control-relevance of the wall while the agent is still\nsome distance away. To address this we introduce action-bisimulation encoding,\na method inspired by the bisimulation invariance pseudometric, that extends\nsingle-step controllability with a recursive invariance constraint. By doing\nthis, action-bisimulation learns a multi-step controllability metric that\nsmoothly discounts distant state features that are relevant for control. We\ndemonstrate that action-bisimulation pretraining on reward-free, uniformly\nrandom data improves sample efficiency in several environments, including a\nphotorealistic 3D simulation domain, Habitat. Additionally, we provide\ntheoretical analysis and qualitative results demonstrating the information\ncaptured by action-bisimulation.\n","authors":["Max Rudolph","Caleb Chuck","Kevin Black","Misha Lvovsky","Scott Niekum","Amy Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.16369v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16336v1","updated":"2024-03-25T00:21:34Z","published":"2024-03-25T00:21:34Z","title":"Predictive Inference in Multi-environment Scenarios","summary":"  We address the challenge of constructing valid confidence intervals and sets\nin problems of prediction across multiple environments. We investigate two\ntypes of coverage suitable for these problems, extending the jackknife and\nsplit-conformal methods to show how to obtain distribution-free coverage in\nsuch non-traditional, hierarchical data-generating scenarios. Our contributions\nalso include extensions for settings with non-real-valued responses and a\ntheory of consistency for predictive inference in these general problems. We\ndemonstrate a novel resizing method to adapt to problem difficulty, which\napplies both to existing approaches for predictive inference with hierarchical\ndata and the methods we develop; this reduces prediction set sizes using\nlimited information from the test environment, a key to the methods' practical\nperformance, which we evaluate through neurochemical sensing and species\nclassification datasets.\n","authors":["John C. Duchi","Suyash Gupta","Kuanhao Jiang","Pragya Sur"],"pdf_url":"https://arxiv.org/pdf/2403.16336v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.08774v2","updated":"2024-03-25T00:18:35Z","published":"2023-10-12T23:46:08Z","title":"PhyloGFN: Phylogenetic inference with generative flow networks","summary":"  Phylogenetics is a branch of computational biology that studies the\nevolutionary relationships among biological entities. Its long history and\nnumerous applications notwithstanding, inference of phylogenetic trees from\nsequence data remains challenging: the high complexity of tree space poses a\nsignificant obstacle for the current combinatorial and probabilistic\ntechniques. In this paper, we adopt the framework of generative flow networks\n(GFlowNets) to tackle two core problems in phylogenetics: parsimony-based and\nBayesian phylogenetic inference. Because GFlowNets are well-suited for sampling\ncomplex combinatorial structures, they are a natural choice for exploring and\nsampling from the multimodal posterior distribution over tree topologies and\nevolutionary distances. We demonstrate that our amortized posterior sampler,\nPhyloGFN, produces diverse and high-quality evolutionary hypotheses on real\nbenchmark datasets. PhyloGFN is competitive with prior works in marginal\nlikelihood estimation and achieves a closer fit to the target distribution than\nstate-of-the-art variational inference methods. Our code is available at\nhttps://github.com/zmy1116/phylogfn.\n","authors":["Mingyang Zhou","Zichao Yan","Elliot Layne","Nikolay Malkin","Dinghuai Zhang","Moksh Jain","Mathieu Blanchette","Yoshua Bengio"],"pdf_url":"https://arxiv.org/pdf/2310.08774v2.pdf","comment":null}]},"2024-03-24T00:00:00Z":{"Computer Science and Game Theory":[{"id":"http://arxiv.org/abs/2403.16223v1","updated":"2024-03-24T16:33:01Z","published":"2024-03-24T16:33:01Z","title":"A Coupled Optimization Framework for Correlated Equilibria in\n  Normal-Form Game","summary":"  In competitive multi-player interactions, simultaneous optimality is a key\nrequirement for establishing strategic equilibria. This property is explicit\nwhen the game-theoretic equilibrium is the simultaneously optimal solution of\ncoupled optimization problems. However, no such optimization problems exist for\nthe correlated equilibrium, a strategic equilibrium where the players can\ncorrelate their actions. We address the lack of a coupled optimization\nframework for the correlated equilibrium by introducing an {unnormalized game}\n-- an extension of normal-form games in which the player strategies are lifted\nto unnormalized measures over the joint actions. We show that the set of fully\nmixed generalized Nash equilibria of this unnormalized game is a subset of the\ncorrelated equilibrium of the normal-form game. Furthermore, we introduce an\nentropy regularization to the unnormalized game and prove that the\nentropy-regularized generalized Nash equilibrium is a sub-optimal correlated\nequilibrium of the normal form game where the degree of sub-optimality depends\non the magnitude of regularization. We prove that the entropy-regularized\nunnormalized game has a closed-form solution, and empirically verify its\ncomputational efficacy at approximating the correlated equilibrium of\nnormal-form games.\n","authors":["Sarah H. Q. Li","Yue Yu","Florian Dörfler","John Lygeros"],"pdf_url":"https://arxiv.org/pdf/2403.16223v1.pdf","comment":"8 pages, 2 figures"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2403.16327v1","updated":"2024-03-24T23:22:02Z","published":"2024-03-24T23:22:02Z","title":"Artificial Neural Microcircuits as Building Blocks: Concept and\n  Challenges","summary":"  Artificial Neural Networks (ANNs) are one of the most widely employed forms\nof bio-inspired computation. However the current trend is for ANNs to be\nstructurally homogeneous. Furthermore, this structural homogeneity requires the\napplication of complex training and learning tools that produce application\nspecific ANNs, susceptible to pitfalls such as overfitting. In this paper, an\nnew approach is explored, inspired by the role played in biology by Neural\nMicrocircuits, the so called ``fundamental processing elements'' of organic\nnervous systems. How large neural networks, particularly Spiking Neural\nNetworks (SNNs) can be assembled using Artificial Neural Microcircuits (ANMs),\nintended as off-the-shelf components, is articulated; the results of initial\nwork to produce a catalogue of such Microcircuits though the use of Novelty\nSearch is shown; followed by efforts to expand upon this initial work,\nincluding a discussion of challenges uncovered during these efforts and\nexplorations of methods by which they might be overcome.\n","authors":["Andrew Walter","Shimeng Wu","Andy M. Tyrrell","Liam McDaid","Malachy McElholm","Nidhin Thandassery Sumithran","Jim Harkin","Martin A. Trefzer"],"pdf_url":"https://arxiv.org/pdf/2403.16327v1.pdf","comment":"12 pages, 31 figures, 3 tables, submitted to A-Life Journal for\n  review"},{"id":"http://arxiv.org/abs/2403.16247v1","updated":"2024-03-24T17:39:36Z","published":"2024-03-24T17:39:36Z","title":"Improving Sequence-to-Sequence Models for Abstractive Text Summarization\n  Using Meta Heuristic Approaches","summary":"  As human society transitions into the information age, reduction in our\nattention span is a contingency, and people who spend time reading lengthy news\narticles are decreasing rapidly and the need for succinct information is higher\nthan ever before. Therefore, it is essential to provide a quick overview of\nimportant news by concisely summarizing the top news article and the most\nintuitive headline. When humans try to make summaries, they extract the\nessential information from the source and add useful phrases and grammatical\nannotations from the original extract. Humans have a unique ability to create\nabstractions. However, automatic summarization is a complicated problem to\nsolve. The use of sequence-to-sequence (seq2seq) models for neural abstractive\ntext summarization has been ascending as far as prevalence. Numerous innovative\nstrategies have been proposed to develop the current seq2seq models further,\npermitting them to handle different issues like saliency, familiarity, and\nhuman lucidness and create excellent synopses. In this article, we aimed toward\nenhancing the present architectures and models for abstractive text\nsummarization. The modifications have been aimed at fine-tuning\nhyper-parameters, attempting specific encoder-decoder combinations. We examined\nmany experiments on an extensively used CNN/DailyMail dataset to check the\neffectiveness of various models.\n","authors":["Aditya Saxena","Ashutosh Ranjan"],"pdf_url":"https://arxiv.org/pdf/2403.16247v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15974v1","updated":"2024-03-24T00:46:40Z","published":"2024-03-24T00:46:40Z","title":"CBGT-Net: A Neuromimetic Architecture for Robust Classification of\n  Streaming Data","summary":"  This paper describes CBGT-Net, a neural network model inspired by the\ncortico-basal ganglia-thalamic (CBGT) circuits found in mammalian brains.\nUnlike traditional neural network models, which either generate an output for\neach provided input, or an output after a fixed sequence of inputs, the\nCBGT-Net learns to produce an output after a sufficient criteria for evidence\nis achieved from a stream of observed data. For each observation, the CBGT-Net\ngenerates a vector that explicitly represents the amount of evidence the\nobservation provides for each potential decision, accumulates the evidence over\ntime, and generates a decision when the accumulated evidence exceeds a\npre-defined threshold. We evaluate the proposed model on two image\nclassification tasks, where models need to predict image categories based on a\nstream of small patches extracted from the image. We show that the CBGT-Net\nprovides improved accuracy and robustness compared to models trained to\nclassify from a single patch, and models leveraging an LSTM layer to classify\nfrom a fixed sequence length of patches.\n","authors":["Shreya Sharma","Dana Hughes","Katia Sycara"],"pdf_url":"https://arxiv.org/pdf/2403.15974v1.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2402.11858v2","updated":"2024-03-24T21:33:21Z","published":"2024-02-19T06:00:35Z","title":"Stochastic Hessian Fittings on Lie Groups","summary":"  This paper studies the fitting of Hessian or its inverse for stochastic\noptimizations using a Hessian fitting criterion from the preconditioned\nstochastic gradient descent (PSGD) method, which is intimately related to many\ncommonly used second order and adaptive gradient optimizers, e.g., BFGS,\nGaussian-Newton and natural gradient descent, AdaGrad, etc. Our analyses reveal\nthe efficiency and reliability differences among a wide range of preconditioner\nfitting methods, from closed-form to iterative solutions, using Hessian-vector\nproducts or stochastic gradients only, with Hessian fittings in the Euclidean\nspace, the manifold of symmetric positive definite (SPL) matrices, or a variety\nof Lie groups. The most intriguing discovery is that the Hessian fitting itself\nas an optimization problem is strongly convex under mild conditions on a\nspecific yet general enough Lie group. This discovery turns Hessian fitting\ninto a well behaved optimization problem, and facilitates the designs of highly\nefficient and elegant Lie group sparse preconditioner fitting methods for large\nscale stochastic optimizations.\n","authors":["Xi-Lin Li"],"pdf_url":"https://arxiv.org/pdf/2402.11858v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16260v1","updated":"2024-03-24T18:43:04Z","published":"2024-03-24T18:43:04Z","title":"Out-of-Distribution Detection via Deep Multi-Comprehension Ensemble","summary":"  Recent research underscores the pivotal role of the Out-of-Distribution (OOD)\nfeature representation field scale in determining the efficacy of models in OOD\ndetection. Consequently, the adoption of model ensembles has emerged as a\nprominent strategy to augment this feature representation field, capitalizing\non anticipated model diversity.\n  However, our introduction of novel qualitative and quantitative model\nensemble evaluation methods, specifically Loss Basin/Barrier Visualization and\nthe Self-Coupling Index, reveals a critical drawback in existing ensemble\nmethods. We find that these methods incorporate weights that are\naffine-transformable, exhibiting limited variability and thus failing to\nachieve the desired diversity in feature representation.\n  To address this limitation, we elevate the dimensions of traditional model\nensembles, incorporating various factors such as different weight\ninitializations, data holdout, etc., into distinct supervision tasks. This\ninnovative approach, termed Multi-Comprehension (MC) Ensemble, leverages\ndiverse training tasks to generate distinct comprehensions of the data and\nlabels, thereby extending the feature representation field.\n  Our experimental results demonstrate the superior performance of the MC\nEnsemble strategy in OOD detection compared to both the naive Deep Ensemble\nmethod and a standalone model of comparable size. This underscores the\neffectiveness of our proposed approach in enhancing the model's capability to\ndetect instances outside its training distribution.\n","authors":["Chenhui Xu","Fuxun Yu","Zirui Xu","Nathan Inkawhich","Xiang Chen"],"pdf_url":"https://arxiv.org/pdf/2403.16260v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09961v2","updated":"2024-03-24T18:11:41Z","published":"2022-12-20T02:28:27Z","title":"Uncertainty Quantification of MLE for Entity Ranking with Covariates","summary":"  This paper concerns with statistical estimation and inference for the ranking\nproblems based on pairwise comparisons with additional covariate information\nsuch as the attributes of the compared items. Despite extensive studies, few\nprior literatures investigate this problem under the more realistic setting\nwhere covariate information exists. To tackle this issue, we propose a novel\nmodel, Covariate-Assisted Ranking Estimation (CARE) model, that extends the\nwell-known Bradley-Terry-Luce (BTL) model, by incorporating the covariate\ninformation. Specifically, instead of assuming every compared item has a fixed\nlatent score $\\{\\theta_i^*\\}_{i=1}^n$, we assume the underlying scores are\ngiven by $\\{\\alpha_i^*+{x}_i^\\top\\beta^*\\}_{i=1}^n$, where $\\alpha_i^*$ and\n${x}_i^\\top\\beta^*$ represent latent baseline and covariate score of the $i$-th\nitem, respectively. We impose natural identifiability conditions and derive the\n$\\ell_{\\infty}$- and $\\ell_2$-optimal rates for the maximum likelihood\nestimator of $\\{\\alpha_i^*\\}_{i=1}^{n}$ and $\\beta^*$ under a sparse comparison\ngraph, using a novel `leave-one-out' technique (Chen et al., 2019) . To conduct\nstatistical inferences, we further derive asymptotic distributions for the MLE\nof $\\{\\alpha_i^*\\}_{i=1}^n$ and $\\beta^*$ with minimal sample complexity. This\nallows us to answer the question whether some covariates have any explanation\npower for latent scores and to threshold some sparse parameters to improve the\nranking performance. We improve the approximation method used in (Gao et al.,\n2021) for the BLT model and generalize it to the CARE model. Moreover, we\nvalidate our theoretical results through large-scale numerical studies and an\napplication to the mutual fund stock holding dataset.\n","authors":["Jianqing Fan","Jikai Hou","Mengxin Yu"],"pdf_url":"https://arxiv.org/pdf/2212.09961v2.pdf","comment":"81 pages, 3 figures"},{"id":"http://arxiv.org/abs/2303.16971v3","updated":"2024-03-24T17:10:42Z","published":"2023-03-29T19:10:24Z","title":"Sparse joint shift in multinomial classification","summary":"  Sparse joint shift (SJS) was recently proposed as a tractable model for\ngeneral dataset shift which may cause changes to the marginal distributions of\nfeatures and labels as well as the posterior probabilities and the\nclass-conditional feature distributions. Fitting SJS for a target dataset\nwithout label observations may produce valid predictions of labels and\nestimates of class prior probabilities. We present new results on the\ntransmission of SJS from sets of features to larger sets of features, a\nconditional correction formula for the class posterior probabilities under the\ntarget distribution, identifiability of SJS, and the relationship between SJS\nand covariate shift. In addition, we point out inconsistencies in the\nalgorithms which were proposed for estimating the characteristics of SJS, as\nthey could hamper the search for optimal solutions, and suggest potential\nimprovements.\n","authors":["Dirk Tasche"],"pdf_url":"https://arxiv.org/pdf/2303.16971v3.pdf","comment":"27 pages"},{"id":"http://arxiv.org/abs/2312.09146v3","updated":"2024-03-24T16:32:13Z","published":"2023-12-14T17:17:16Z","title":"Featurizing Koopman Mode Decomposition","summary":"  This article introduces an advanced Koopman mode decomposition (KMD)\ntechnique -- coined Featurized Koopman Mode Decomposition (FKMD) -- that uses\ntime embedding and Mahalanobis scaling to enhance analysis and prediction of\nhigh dimensional dynamical systems. The time embedding expands the observation\nspace to better capture underlying manifold structure, while the Mahalanobis\nscaling, applied to kernel or random Fourier features, adjusts observations\nbased on the system's dynamics. This aids in featurizing KMD in cases where\ngood features are not a priori known. We find that the Mahalanobis scaling from\nFKMD can be used for effective dimensionality reduction of alanine dipeptide\ndata. We also show that FKMD improves predictions for a high-dimensional Lorenz\nattractor and a cell signaling problem from cancer research.\n","authors":["David Aristoff","Jeremy Copperman","Nathan Mankovich","Alexander Davies"],"pdf_url":"https://arxiv.org/pdf/2312.09146v3.pdf","comment":"10 pages, 5 figures"},{"id":"http://arxiv.org/abs/2306.14693v2","updated":"2024-03-24T15:43:32Z","published":"2023-06-26T13:38:49Z","title":"Conformal link prediction for false discovery rate control","summary":"  Most link prediction methods return estimates of the connection probability\nof missing edges in a graph. Such output can be used to rank the missing edges\nfrom most to least likely to be a true edge, but does not directly provide a\nclassification into true and non-existent. In this work, we consider the\nproblem of identifying a set of true edges with a control of the false\ndiscovery rate (FDR). We propose a novel method based on high-level ideas from\nthe literature on conformal inference. The graph structure induces intricate\ndependence in the data, which we carefully take into account, as this makes the\nsetup different from the usual setup in conformal inference, where data\nexchangeability is assumed. The FDR control is empirically demonstrated for\nboth simulated and real data.\n","authors":["Ariane Marandon"],"pdf_url":"https://arxiv.org/pdf/2306.14693v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16163v1","updated":"2024-03-24T14:08:24Z","published":"2024-03-24T14:08:24Z","title":"An Analytic Solution to Covariance Propagation in Neural Networks","summary":"  Uncertainty quantification of neural networks is critical to measuring the\nreliability and robustness of deep learning systems. However, this often\ninvolves costly or inaccurate sampling methods and approximations. This paper\npresents a sample-free moment propagation technique that propagates mean\nvectors and covariance matrices across a network to accurately characterize the\ninput-output distributions of neural networks. A key enabler of our technique\nis an analytic solution for the covariance of random variables passed through\nnonlinear activation functions, such as Heaviside, ReLU, and GELU. The wide\napplicability and merits of the proposed technique are shown in experiments\nanalyzing the input-output distributions of trained neural networks and\ntraining Bayesian neural networks.\n","authors":["Oren Wright","Yorie Nakahira","José M. F. Moura"],"pdf_url":"https://arxiv.org/pdf/2403.16163v1.pdf","comment":"Accepted to AISTATS 2024"},{"id":"http://arxiv.org/abs/2402.15585v2","updated":"2024-03-24T12:36:03Z","published":"2024-02-23T19:52:09Z","title":"Inference for Regression with Variables Generated from Unstructured Data","summary":"  The leading strategy for analyzing unstructured data uses two steps. First,\nlatent variables of economic interest are estimated with an upstream\ninformation retrieval model. Second, the estimates are treated as \"data\" in a\ndownstream econometric model. We establish theoretical arguments for why this\ntwo-step strategy leads to biased inference in empirically plausible settings.\nMore constructively, we propose a one-step strategy for valid inference that\nuses the upstream and downstream models jointly. The one-step strategy (i)\nsubstantially reduces bias in simulations; (ii) has quantitatively important\neffects in a leading application using CEO time-use data; and (iii) can be\nreadily adapted by applied researchers.\n","authors":["Laura Battaglia","Timothy Christensen","Stephen Hansen","Szymon Sacher"],"pdf_url":"https://arxiv.org/pdf/2402.15585v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.11782v2","updated":"2024-03-24T10:12:42Z","published":"2024-03-18T13:40:48Z","title":"A tutorial on learning from preferences and choices with Gaussian\n  Processes","summary":"  Preference modelling lies at the intersection of economics, decision theory,\nmachine learning and statistics. By understanding individuals' preferences and\nhow they make choices, we can build products that closely match their\nexpectations, paving the way for more efficient and personalised applications\nacross a wide range of domains. The objective of this tutorial is to present a\ncohesive and comprehensive framework for preference learning with Gaussian\nProcesses (GPs), demonstrating how to seamlessly incorporate rationality\nprinciples (from economics and decision theory) into the learning process. By\nsuitably tailoring the likelihood function, this framework enables the\nconstruction of preference learning models that encompass random utility\nmodels, limits of discernment, and scenarios with multiple conflicting\nutilities for both object- and label-preference. This tutorial builds upon\nestablished research while simultaneously introducing some novel GP-based\nmodels to address specific gaps in the existing literature.\n","authors":["Alessio Benavoli","Dario Azzimonti"],"pdf_url":"https://arxiv.org/pdf/2403.11782v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16059v1","updated":"2024-03-24T08:06:34Z","published":"2024-03-24T08:06:34Z","title":"Manifold Regularization Classification Model Based On Improved Diffusion\n  Map","summary":"  Manifold regularization model is a semi-supervised learning model that\nleverages the geometric structure of a dataset, comprising a small number of\nlabeled samples and a large number of unlabeled samples, to generate\nclassifiers. However, the original manifold norm limits the performance of\nmodels to local regions. To address this limitation, this paper proposes an\napproach to improve manifold regularization based on a label propagation model.\nWe initially enhance the probability transition matrix of the diffusion map\nalgorithm, which can be used to estimate the Neumann heat kernel, enabling it\nto accurately depict the label propagation process on the manifold. Using this\nmatrix, we establish a label propagation function on the dataset to describe\nthe distribution of labels at different time steps. Subsequently, we extend the\nlabel propagation function to the entire data manifold. We prove that the\nextended label propagation function converges to a stable distribution after a\nsufficiently long time and can be considered as a classifier. Building upon\nthis concept, we propose a viable improvement to the manifold regularization\nmodel and validate its superiority through experiments.\n","authors":["Hongfu Guo","Wencheng Zou","Zeyu Zhang","Shuishan Zhang","Ruitong Wang","Jintao Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.16059v1.pdf","comment":"20 pages, 24figures"},{"id":"http://arxiv.org/abs/2208.07243v4","updated":"2024-03-24T07:48:18Z","published":"2022-08-15T14:57:26Z","title":"Exponential Concentration in Stochastic Approximation","summary":"  We analyze the behavior of stochastic approximation algorithms where\niterates, in expectation, progress towards an objective at each step. When\nprogress is proportional to the step size of the algorithm, we prove\nexponential concentration bounds. These tail-bounds contrast asymptotic\nnormality results, which are more frequently associated with stochastic\napproximation. The methods that we develop rely on a geometric ergodicity\nproof. This extends a result on Markov chains due to Hajek (1982) to the area\nof stochastic approximation algorithms. We apply our results to several\ndifferent Stochastic Approximation algorithms, specifically Projected\nStochastic Gradient Descent, Kiefer-Wolfowitz and Stochastic Frank-Wolfe\nalgorithms. When applicable, our results prove faster $O(1/t)$ and linear\nconvergence rates for Projected Stochastic Gradient Descent with a\nnon-vanishing gradient.\n","authors":["Kody Law","Neil Walton","Shangda Yang"],"pdf_url":"https://arxiv.org/pdf/2208.07243v4.pdf","comment":"35 pages, 11 Figures"},{"id":"http://arxiv.org/abs/2309.05153v3","updated":"2024-03-24T07:31:23Z","published":"2023-09-10T22:05:24Z","title":"Learning Energy-Based Models by Cooperative Diffusion Recovery\n  Likelihood","summary":"  Training energy-based models (EBMs) on high-dimensional data can be both\nchallenging and time-consuming, and there exists a noticeable gap in sample\nquality between EBMs and other generative frameworks like GANs and diffusion\nmodels. To close this gap, inspired by the recent efforts of learning EBMs by\nmaximizing diffusion recovery likelihood (DRL), we propose cooperative\ndiffusion recovery likelihood (CDRL), an effective approach to tractably learn\nand sample from a series of EBMs defined on increasingly noisy versions of a\ndataset, paired with an initializer model for each EBM. At each noise level,\nthe two models are jointly estimated within a cooperative training framework:\nsamples from the initializer serve as starting points that are refined by a few\nMCMC sampling steps from the EBM. The EBM is then optimized by maximizing\nrecovery likelihood, while the initializer model is optimized by learning from\nthe difference between the refined samples and the initial samples. In\naddition, we made several practical designs for EBM training to further improve\nthe sample quality. Combining these advances, our approach significantly boost\nthe generation performance compared to existing EBM methods on CIFAR-10 and\nImageNet datasets. We also demonstrate the effectiveness of our models for\nseveral downstream tasks, including classifier-free guided generation,\ncompositional generation, image inpainting and out-of-distribution detection.\n","authors":["Yaxuan Zhu","Jianwen Xie","Yingnian Wu","Ruiqi Gao"],"pdf_url":"https://arxiv.org/pdf/2309.05153v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16031v1","updated":"2024-03-24T06:14:50Z","published":"2024-03-24T06:14:50Z","title":"Learning Directed Acyclic Graphs from Partial Orderings","summary":"  Directed acyclic graphs (DAGs) are commonly used to model causal\nrelationships among random variables. In general, learning the DAG structure is\nboth computationally and statistically challenging. Moreover, without\nadditional information, the direction of edges may not be estimable from\nobservational data. In contrast, given a complete causal ordering of the\nvariables, the problem can be solved efficiently, even in high dimensions. In\nthis paper, we consider the intermediate problem of learning DAGs when a\npartial causal ordering of variables is available. We propose a general\nestimation framework for leveraging the partial ordering and present efficient\nestimation algorithms for low- and high-dimensional problems. The advantages of\nthe proposed framework are illustrated via numerical studies.\n","authors":["Ali Shojaie","Wenyu Chen"],"pdf_url":"https://arxiv.org/pdf/2403.16031v1.pdf","comment":"29 pages, 5 figures"},{"id":"http://arxiv.org/abs/2403.03868v2","updated":"2024-03-24T04:07:37Z","published":"2024-03-06T17:18:24Z","title":"Confidence on the Focal: Conformal Prediction with Selection-Conditional\n  Coverage","summary":"  Conformal prediction builds marginally valid prediction intervals that cover\nthe unknown outcome of a randomly drawn new test point with a prescribed\nprobability. However, a common scenario in practice is that, after seeing the\ndata, practitioners decide which test unit(s) to focus on in a data-driven\nmanner and seek for uncertainty quantification of the focal unit(s). In such\ncases, marginally valid conformal prediction intervals may not provide valid\ncoverage for the focal unit(s) due to selection bias. This paper presents a\ngeneral framework for constructing a prediction set with finite-sample exact\ncoverage conditional on the unit being selected by a given procedure. The\ngeneral form of our method works for arbitrary selection rules that are\ninvariant to the permutation of the calibration units, and generalizes Mondrian\nConformal Prediction to multiple test units and non-equivariant classifiers. We\nthen work out the computationally efficient implementation of our framework for\na number of realistic selection rules, including top-K selection,\noptimization-based selection, selection based on conformal p-values, and\nselection based on properties of preliminary conformal prediction sets. The\nperformance of our methods is demonstrated via applications in drug discovery\nand health risk prediction.\n","authors":["Ying Jin","Zhimei Ren"],"pdf_url":"https://arxiv.org/pdf/2403.03868v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15999v1","updated":"2024-03-24T03:57:21Z","published":"2024-03-24T03:57:21Z","title":"Near-Optimal differentially private low-rank trace regression with\n  guaranteed private initialization","summary":"  We study differentially private (DP) estimation of a rank-$r$ matrix $M \\in\n\\mathbb{R}^{d_1\\times d_2}$ under the trace regression model with Gaussian\nmeasurement matrices. Theoretically, the sensitivity of non-private spectral\ninitialization is precisely characterized, and the\ndifferential-privacy-constrained minimax lower bound for estimating $M$ under\nthe Schatten-$q$ norm is established. Methodologically, the paper introduces a\ncomputationally efficient algorithm for DP-initialization with a sample size of\n$n \\geq \\widetilde O (r^2 (d_1\\vee d_2))$. Under certain regularity conditions,\nthe DP-initialization falls within a local ball surrounding $M$. We also\npropose a differentially private algorithm for estimating $M$ based on\nRiemannian optimization (DP-RGrad), which achieves a near-optimal convergence\nrate with the DP-initialization and sample size of $n \\geq \\widetilde O(r (d_1\n+ d_2))$. Finally, the paper discusses the non-trivial gap between the minimax\nlower bound and the upper bound of low-rank matrix estimation under the trace\nregression model. It is shown that the estimator given by DP-RGrad attains the\noptimal convergence rate in a weaker notion of differential privacy. Our\npowerful technique for analyzing the sensitivity of initialization requires no\neigengap condition between $r$ non-zero singular values.\n","authors":["Mengyue Zha"],"pdf_url":"https://arxiv.org/pdf/2403.15999v1.pdf","comment":null}]},"2024-03-23T00:00:00Z":{"Computer Science and Game Theory":[{"id":"http://arxiv.org/abs/2403.15848v1","updated":"2024-03-23T13:51:31Z","published":"2024-03-23T13:51:31Z","title":"On the Stability of Learning in Network Games with Many Players","summary":"  Multi-agent learning algorithms have been shown to display complex, unstable\nbehaviours in a wide array of games. In fact, previous works indicate that\nconvergent behaviours are less likely to occur as the total number of agents\nincreases. This seemingly prohibits convergence to stable strategies, such as\nNash Equilibria, in games with many players.\n  To make progress towards addressing this challenge we study the Q-Learning\nDynamics, a classical model for exploration and exploitation in multi-agent\nlearning. In particular, we study the behaviour of Q-Learning on games where\ninteractions between agents are constrained by a network. We determine a number\nof sufficient conditions, depending on the game and network structure, which\nguarantee that agent strategies converge to a unique stable strategy, called\nthe Quantal Response Equilibrium (QRE). Crucially, these sufficient conditions\nare independent of the total number of agents, allowing for provable\nconvergence in arbitrarily large games.\n  Next, we compare the learned QRE to the underlying NE of the game, by showing\nthat any QRE is an $\\epsilon$-approximate Nash Equilibrium. We first provide\ntight bounds on $\\epsilon$ and show how these bounds lead naturally to a\ncentralised scheme for choosing exploration rates, which enables independent\nlearners to learn stable approximate Nash Equilibrium strategies. We validate\nthe method through experiments and demonstrate its effectiveness even in the\npresence of numerous agents and actions. Through these results, we show that\nindependent learning dynamics may converge to approximate Nash Equilibria, even\nin the presence of many agents.\n","authors":["Aamal Hussain","Dan Leonte","Francesco Belardinelli","Georgios Piliouras"],"pdf_url":"https://arxiv.org/pdf/2403.15848v1.pdf","comment":"AAMAS 2024. arXiv admin note: text overlap with arXiv:2307.13922"},{"id":"http://arxiv.org/abs/2311.03326v2","updated":"2024-03-23T11:05:53Z","published":"2023-11-06T18:22:18Z","title":"Non-convex potential games for finding global solutions to sensor\n  network localization","summary":"  Sensor network localization (SNL) problems require determining the physical\ncoordinates of all sensors in a network. This process relies on the global\ncoordinates of anchors and the available measurements between non-anchor and\nanchor nodes. Attributed to the intrinsic non-convexity, obtaining a globally\noptimal solution to SNL is challenging, as well as implementing corresponding\nalgorithms. In this paper, we formulate a non-convex multi-player potential\ngame for a generic SNL problem to investigate the identification condition of\nthe global Nash equilibrium (NE) therein, where the global NE represents the\nglobal solution of SNL. We employ canonical duality theory to transform the\nnon-convex game into a complementary dual problem. Then we develop a\nconjugation-based algorithm to compute the stationary points of the\ncomplementary dual problem. On this basis, we show an identification condition\nof the global NE: the stationary point of the proposed algorithm satisfies a\nduality relation. Finally, simulation results are provided to validate the\neffectiveness of the theoretical results.\n","authors":["Gehui Xu","Guanpu Chen","Yiguang Hong","Baris Fidan","Thomas Parisini","Karl H. Johansson"],"pdf_url":"https://arxiv.org/pdf/2311.03326v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.06860v6","updated":"2024-03-23T08:35:25Z","published":"2022-03-14T05:10:07Z","title":"Cooperative networks and f-Shapley value","summary":"  Lloyd Shapley's cooperative value allocation theory stands as a central\nconcept in game theory, extensively utilized across various domains to\ndistribute resources, evaluate individual contributions, and ensure fairness.\nThe Shapley value formula and his four axioms that characterize it form the\nfoundation of the theory.\n  Traditionally, the Shapley value is assigned under the assumption that all\nplayers in a cooperative game will ultimately form the grand coalition. In this\npaper, we reinterpret the Shapley value as an expectation of a certain\nstochastic path integral, with each path representing a general coalition\nformation process. As a result, the value allocation is naturally extended to\nall partial coalition states. In addition, we provide a set of five properties\nthat extend the Shapley axioms and characterize the stochastic path integral.\nFinally, by integrating Hodge calculus, stochastic processes, and path\nintegration of edge flows on graphs, we expand the cooperative value allocation\ntheory beyond the standard coalition game structure to encompass a broader\nrange of cooperative network configurations.\n","authors":["Tongseok Lim"],"pdf_url":"https://arxiv.org/pdf/2203.06860v6.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2403.04810v2","updated":"2024-03-23T07:03:34Z","published":"2024-03-06T19:09:11Z","title":"Restricted Bayesian Neural Network","summary":"  Modern deep learning tools are remarkably effective in addressing intricate\nproblems. However, their operation as black-box models introduces increased\nuncertainty in predictions. Additionally, they contend with various challenges,\nincluding the need for substantial storage space in large networks, issues of\noverfitting, underfitting, vanishing gradients, and more. This study explores\nthe concept of Bayesian Neural Networks, presenting a novel architecture\ndesigned to significantly alleviate the storage space complexity of a network.\nFurthermore, we introduce an algorithm adept at efficiently handling\nuncertainties, ensuring robust convergence values without becoming trapped in\nlocal optima, particularly when the objective function lacks perfect convexity.\n","authors":["Sourav Ganguly"],"pdf_url":"https://arxiv.org/pdf/2403.04810v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.09469v2","updated":"2024-03-23T04:41:23Z","published":"2023-09-18T04:03:05Z","title":"Spiking-LEAF: A Learnable Auditory front-end for Spiking Neural Networks","summary":"  Brain-inspired spiking neural networks (SNNs) have demonstrated great\npotential for temporal signal processing. However, their performance in speech\nprocessing remains limited due to the lack of an effective auditory front-end.\nTo address this limitation, we introduce Spiking-LEAF, a learnable auditory\nfront-end meticulously designed for SNN-based speech processing. Spiking-LEAF\ncombines a learnable filter bank with a novel two-compartment spiking neuron\nmodel called IHC-LIF. The IHC-LIF neurons draw inspiration from the structure\nof inner hair cells (IHC) and they leverage segregated dendritic and somatic\ncompartments to effectively capture multi-scale temporal dynamics of speech\nsignals. Additionally, the IHC-LIF neurons incorporate the lateral feedback\nmechanism along with spike regularization loss to enhance spike encoding\nefficiency. On keyword spotting and speaker identification tasks, the proposed\nSpiking-LEAF outperforms both SOTA spiking auditory front-ends and conventional\nreal-valued acoustic features in terms of classification accuracy, noise\nrobustness, and encoding efficiency.\n","authors":["Zeyang Song","Jibin Wu","Malu Zhang","Mike Zheng Shou","Haizhou Li"],"pdf_url":"https://arxiv.org/pdf/2309.09469v2.pdf","comment":"Accepted by ICASSP2024"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2403.15908v1","updated":"2024-03-23T18:42:22Z","published":"2024-03-23T18:42:22Z","title":"Deep Gaussian Covariance Network with Trajectory Sampling for\n  Data-Efficient Policy Search","summary":"  Probabilistic world models increase data efficiency of model-based\nreinforcement learning (MBRL) by guiding the policy with their epistemic\nuncertainty to improve exploration and acquire new samples. Moreover, the\nuncertainty-aware learning procedures in probabilistic approaches lead to\nrobust policies that are less sensitive to noisy observations compared to\nuncertainty unaware solutions. We propose to combine trajectory sampling and\ndeep Gaussian covariance network (DGCN) for a data-efficient solution to MBRL\nproblems in an optimal control setting. We compare trajectory sampling with\ndensity-based approximation for uncertainty propagation using three different\nprobabilistic world models; Gaussian processes, Bayesian neural networks, and\nDGCNs. We provide empirical evidence using four different well-known test\nenvironments, that our method improves the sample-efficiency over other\ncombinations of uncertainty propagation methods and probabilistic models.\nDuring our tests, we place particular emphasis on the robustness of the learned\npolicies with respect to noisy initial states.\n","authors":["Can Bogoclu","Robert Vosshall","Kevin Cremanns","Dirk Roos"],"pdf_url":"https://arxiv.org/pdf/2403.15908v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15881v1","updated":"2024-03-23T16:21:22Z","published":"2024-03-23T16:21:22Z","title":"Fast and Unified Path Gradient Estimators for Normalizing Flows","summary":"  Recent work shows that path gradient estimators for normalizing flows have\nlower variance compared to standard estimators for variational inference,\nresulting in improved training. However, they are often prohibitively more\nexpensive from a computational point of view and cannot be applied to maximum\nlikelihood training in a scalable manner, which severely hinders their\nwidespread adoption. In this work, we overcome these crucial limitations.\nSpecifically, we propose a fast path gradient estimator which improves\ncomputational efficiency significantly and works for all normalizing flow\narchitectures of practical relevance. We then show that this estimator can also\nbe applied to maximum likelihood training for which it has a regularizing\neffect as it can take the form of a given target energy function into account.\nWe empirically establish its superior performance and reduced variance for\nseveral natural sciences applications.\n","authors":["Lorenz Vaitl","Ludwig Winkler","Lorenz Richter","Pan Kessel"],"pdf_url":"https://arxiv.org/pdf/2403.15881v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15877v1","updated":"2024-03-23T15:55:52Z","published":"2024-03-23T15:55:52Z","title":"Integrated path stability selection","summary":"  Stability selection is a widely used method for improving the performance of\nfeature selection algorithms. However, stability selection has been found to be\nhighly conservative, resulting in low sensitivity. Further, the theoretical\nbound on the expected number of false positives, E(FP), is relatively loose,\nmaking it difficult to know how many false positives to expect in practice. In\nthis paper, we introduce a novel method for stability selection based on\nintegrating the stability paths rather than maximizing over them. This yields a\ntighter bound on E(FP), resulting in a feature selection criterion that has\nhigher sensitivity in practice and is better calibrated in terms of matching\nthe target E(FP). Our proposed method requires the same amount of computation\nas the original stability selection algorithm, and only requires the user to\nspecify one input parameter, a target value for E(FP). We provide theoretical\nbounds on performance, and demonstrate the method on simulations and real data\nfrom cancer gene expression studies.\n","authors":["Omar Melikechi","Jeffrey W. Miller"],"pdf_url":"https://arxiv.org/pdf/2403.15877v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17978v1","updated":"2024-03-23T15:49:13Z","published":"2024-03-23T15:49:13Z","title":"Holographic Global Convolutional Networks for Long-Range Prediction\n  Tasks in Malware Detection","summary":"  Malware detection is an interesting and valuable domain to work in because it\nhas significant real-world impact and unique machine-learning challenges. We\ninvestigate existing long-range techniques and benchmarks and find that they're\nnot very suitable in this problem area. In this paper, we introduce Holographic\nGlobal Convolutional Networks (HGConv) that utilize the properties of\nHolographic Reduced Representations (HRR) to encode and decode features from\nsequence elements. Unlike other global convolutional methods, our method does\nnot require any intricate kernel computation or crafted kernel design. HGConv\nkernels are defined as simple parameters learned through backpropagation. The\nproposed method has achieved new SOTA results on Microsoft Malware\nClassification Challenge, Drebin, and EMBER malware benchmarks. With log-linear\ncomplexity in sequence length, the empirical results demonstrate substantially\nfaster run-time by HGConv compared to other methods achieving far more\nefficient scaling even with sequence length $\\geq 100,000$.\n","authors":["Mohammad Mahmudul Alam","Edward Raff","Stella Biderman","Tim Oates","James Holt"],"pdf_url":"https://arxiv.org/pdf/2403.17978v1.pdf","comment":"To appear in Proceedings of the 27th International Conference on\n  Artificial Intelligence and Statistics (AISTATS) 2024, Valencia, Spain"},{"id":"http://arxiv.org/abs/2009.13961v4","updated":"2024-03-23T15:01:03Z","published":"2020-09-29T12:25:05Z","title":"Online Action Learning in High Dimensions: A Conservative Perspective","summary":"  Sequential learning problems are common in several fields of research and\npractical applications. Examples include dynamic pricing and assortment, design\nof auctions and incentives and permeate a large number of sequential treatment\nexperiments. In this paper, we extend one of the most popular learning\nsolutions, the $\\epsilon_t$-greedy heuristics, to high-dimensional contexts\nconsidering a conservative directive. We do this by allocating part of the time\nthe original rule uses to adopt completely new actions to a more focused search\nin a restrictive set of promising actions. The resulting rule might be useful\nfor practical applications that still values surprises, although at a\ndecreasing rate, while also has restrictions on the adoption of unusual\nactions. With high probability, we find reasonable bounds for the cumulative\nregret of a conservative high-dimensional decaying $\\epsilon_t$-greedy rule.\nAlso, we provide a lower bound for the cardinality of the set of viable actions\nthat implies in an improved regret bound for the conservative version when\ncompared to its non-conservative counterpart. Additionally, we show that\nend-users have sufficient flexibility when establishing how much safety they\nwant, since it can be tuned without impacting theoretical properties. We\nillustrate our proposal both in a simulation exercise and using a real dataset.\n","authors":["Claudio Cardoso Flores","Marcelo Cunha Medeiros"],"pdf_url":"https://arxiv.org/pdf/2009.13961v4.pdf","comment":"We found an error in the proof of the main theorem which cannot be\n  fixed without completely changing the results in the paper"},{"id":"http://arxiv.org/abs/2303.10599v2","updated":"2024-03-23T13:26:31Z","published":"2023-03-19T08:29:49Z","title":"Convergence Analysis of Stochastic Gradient Descent with MCMC Estimators","summary":"  Understanding stochastic gradient descent (SGD) and its variants is essential\nfor machine learning. However, most of the preceding analyses are conducted\nunder amenable conditions such as unbiased gradient estimator and bounded\nobjective functions, which does not encompass many sophisticated applications,\nsuch as variational Monte Carlo, entropy-regularized reinforcement learning and\nvariational inference. In this paper, we consider the SGD algorithm that employ\nthe Markov Chain Monte Carlo (MCMC) estimator to compute the gradient, called\nMCMC-SGD. Since MCMC reduces the sampling complexity significantly, it is an\nasymptotically convergent biased estimator in practice. Moreover, by\nincorporating a general class of unbounded functions, it is much more difficult\nto analyze the MCMC sampling error. Therefore, we assume that the function is\nsub-exponential and use the Bernstein inequality for non-stationary Markov\nchains to derive error bounds of the MCMC estimator. Consequently, MCMC-SGD is\nproven to have a first order convergence rate $O(\\log K/\\sqrt{n K})$ with $K$\niterations and a sample size $n$. It partially explains how MCMC influences the\nbehavior of SGD. Furthermore, we verify the correlated negative curvature\ncondition under reasonable assumptions. It is shown that MCMC-SGD escapes from\nsaddle points and reaches $(\\epsilon,\\epsilon^{1/4})$ approximate second order\nstationary points or $\\epsilon^{1/2}$-variance points at least\n$O(\\epsilon^{-11/2}\\log^{2}(1/\\epsilon) )$ steps with high probability. Our\nanalysis unveils the convergence pattern of MCMC-SGD across a broad class of\nstochastic optimization problems, and interprets the convergence phenomena\nobserved in practical applications.\n","authors":["Tianyou Li","Fan Chen","Huajie Chen","Zaiwen Wen"],"pdf_url":"https://arxiv.org/pdf/2303.10599v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15822v1","updated":"2024-03-23T12:19:49Z","published":"2024-03-23T12:19:49Z","title":"Computational Sentence-level Metrics Predicting Human Sentence\n  Comprehension","summary":"  The majority of research in computational psycholinguistics has concentrated\non the processing of words. This study introduces innovative methods for\ncomputing sentence-level metrics using multilingual large language models. The\nmetrics developed sentence surprisal and sentence relevance and then are tested\nand compared to validate whether they can predict how humans comprehend\nsentences as a whole across languages. These metrics offer significant\ninterpretability and achieve high accuracy in predicting human sentence reading\nspeeds. Our results indicate that these computational sentence-level metrics\nare exceptionally effective at predicting and elucidating the processing\ndifficulties encountered by readers in comprehending sentences as a whole\nacross a variety of languages. Their impressive performance and generalization\ncapabilities provide a promising avenue for future research in integrating LLMs\nand cognitive science.\n","authors":["Kun Sun","Rong Wang"],"pdf_url":"https://arxiv.org/pdf/2403.15822v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.03967v2","updated":"2024-03-23T11:22:00Z","published":"2024-03-06T15:41:21Z","title":"Effect of Ambient-Intrinsic Dimension Gap on Adversarial Vulnerability","summary":"  The existence of adversarial attacks on machine learning models imperceptible\nto a human is still quite a mystery from a theoretical perspective. In this\nwork, we introduce two notions of adversarial attacks: natural or on-manifold\nattacks, which are perceptible by a human/oracle, and unnatural or off-manifold\nattacks, which are not. We argue that the existence of the off-manifold attacks\nis a natural consequence of the dimension gap between the intrinsic and ambient\ndimensions of the data. For 2-layer ReLU networks, we prove that even though\nthe dimension gap does not affect generalization performance on samples drawn\nfrom the observed data space, it makes the clean-trained model more vulnerable\nto adversarial perturbations in the off-manifold direction of the data space.\nOur main results provide an explicit relationship between the\n$\\ell_2,\\ell_{\\infty}$ attack strength of the on/off-manifold attack and the\ndimension gap.\n","authors":["Rajdeep Haldar","Yue Xing","Qifan Song"],"pdf_url":"https://arxiv.org/pdf/2403.03967v2.pdf","comment":"AISTATS 2024"},{"id":"http://arxiv.org/abs/2403.15790v1","updated":"2024-03-23T10:37:22Z","published":"2024-03-23T10:37:22Z","title":"Boarding for ISS: Imbalanced Self-Supervised: Discovery of a Scaled\n  Autoencoder for Mixed Tabular Datasets","summary":"  The field of imbalanced self-supervised learning, especially in the context\nof tabular data, has not been extensively studied. Existing research has\npredominantly focused on image datasets. This paper aims to fill this gap by\nexamining the specific challenges posed by data imbalance in self-supervised\nlearning in the domain of tabular data, with a primary focus on autoencoders.\nAutoencoders are widely employed for learning and constructing a new\nrepresentation of a dataset, particularly for dimensionality reduction. They\nare also often used for generative model learning, as seen in variational\nautoencoders. When dealing with mixed tabular data, qualitative variables are\noften encoded using a one-hot encoder with a standard loss function (MSE or\nCross Entropy). In this paper, we analyze the drawbacks of this approach,\nespecially when categorical variables are imbalanced. We propose a novel metric\nto balance learning: a Multi-Supervised Balanced MSE. This approach reduces the\nreconstruction error by balancing the influence of variables. Finally, we\nempirically demonstrate that this new metric, compared to the standard MSE: i)\noutperforms when the dataset is imbalanced, especially when the learning\nprocess is insufficient, and ii) provides similar results in the opposite case.\n","authors":["Samuel Stocksieker","Denys Pommeret","Arthur Charpentier"],"pdf_url":"https://arxiv.org/pdf/2403.15790v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15778v1","updated":"2024-03-23T09:24:29Z","published":"2024-03-23T09:24:29Z","title":"Supervised Learning via Ensembles of Diverse Functional Representations:\n  the Functional Voting Classifier","summary":"  Many conventional statistical and machine learning methods face challenges\nwhen applied directly to high dimensional temporal observations. In recent\ndecades, Functional Data Analysis (FDA) has gained widespread popularity as a\nframework for modeling and analyzing data that are, by their nature, functions\nin the domain of time. Although supervised classification has been extensively\nexplored in recent decades within the FDA literature, ensemble learning of\nfunctional classifiers has only recently emerged as a topic of significant\ninterest. Thus, the latter subject presents unexplored facets and challenges\nfrom various statistical perspectives. The focal point of this paper lies in\nthe realm of ensemble learning for functional data and aims to show how\ndifferent functional data representations can be used to train ensemble members\nand how base model predictions can be combined through majority voting. The\nso-called Functional Voting Classifier (FVC) is proposed to demonstrate how\ndifferent functional representations leading to augmented diversity can\nincrease predictive accuracy. Many real-world datasets from several domains are\nused to display that the FVC can significantly enhance performance compared to\nindividual models. The framework presented provides a foundation for voting\nensembles with functional data and can stimulate a highly encouraging line of\nresearch in the FDA context.\n","authors":["Donato Riccio","Fabrizio Maturo","Elvira Romano"],"pdf_url":"https://arxiv.org/pdf/2403.15778v1.pdf","comment":"35 pages, 20 figures"},{"id":"http://arxiv.org/abs/2403.15711v1","updated":"2024-03-23T04:13:55Z","published":"2024-03-23T04:13:55Z","title":"Identifiable Latent Neural Causal Models","summary":"  Causal representation learning seeks to uncover latent, high-level causal\nrepresentations from low-level observed data. It is particularly good at\npredictions under unseen distribution shifts, because these shifts can\ngenerally be interpreted as consequences of interventions. Hence leveraging\n{seen} distribution shifts becomes a natural strategy to help identifying\ncausal representations, which in turn benefits predictions where distributions\nare previously {unseen}. Determining the types (or conditions) of such\ndistribution shifts that do contribute to the identifiability of causal\nrepresentations is critical. This work establishes a {sufficient} and\n{necessary} condition characterizing the types of distribution shifts for\nidentifiability in the context of latent additive noise models. Furthermore, we\npresent partial identifiability results when only a portion of distribution\nshifts meets the condition. In addition, we extend our findings to latent\npost-nonlinear causal models. We translate our findings into a practical\nalgorithm, allowing for the acquisition of reliable latent causal\nrepresentations. Our algorithm, guided by our underlying theory, has\ndemonstrated outstanding performance across a diverse range of synthetic and\nreal-world datasets. The empirical observations align closely with the\ntheoretical findings, affirming the robustness and effectiveness of our\napproach.\n","authors":["Yuhang Liu","Zhen Zhang","Dong Gong","Mingming Gong","Biwei Huang","Anton van den Hengel","Kun Zhang","Javen Qinfeng Shi"],"pdf_url":"https://arxiv.org/pdf/2403.15711v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15707v1","updated":"2024-03-23T03:57:28Z","published":"2024-03-23T03:57:28Z","title":"Role of Locality and Weight Sharing in Image-Based Tasks: A Sample\n  Complexity Separation between CNNs, LCNs, and FCNs","summary":"  Vision tasks are characterized by the properties of locality and translation\ninvariance. The superior performance of convolutional neural networks (CNNs) on\nthese tasks is widely attributed to the inductive bias of locality and weight\nsharing baked into their architecture. Existing attempts to quantify the\nstatistical benefits of these biases in CNNs over locally connected\nconvolutional neural networks (LCNs) and fully connected neural networks (FCNs)\nfall into one of the following categories: either they disregard the optimizer\nand only provide uniform convergence upper bounds with no separating lower\nbounds, or they consider simplistic tasks that do not truly mirror the locality\nand translation invariance as found in real-world vision tasks. To address\nthese deficiencies, we introduce the Dynamic Signal Distribution (DSD)\nclassification task that models an image as consisting of $k$ patches, each of\ndimension $d$, and the label is determined by a $d$-sparse signal vector that\ncan freely appear in any one of the $k$ patches. On this task, for any\northogonally equivariant algorithm like gradient descent, we prove that CNNs\nrequire $\\tilde{O}(k+d)$ samples, whereas LCNs require $\\Omega(kd)$ samples,\nestablishing the statistical advantages of weight sharing in translation\ninvariant tasks. Furthermore, LCNs need $\\tilde{O}(k(k+d))$ samples, compared\nto $\\Omega(k^2d)$ samples for FCNs, showcasing the benefits of locality in\nlocal tasks. Additionally, we develop information theoretic tools for analyzing\nrandomized algorithms, which may be of interest for statistical research.\n","authors":["Aakash Lahoti","Stefani Karp","Ezra Winston","Aarti Singh","Yuanzhi Li"],"pdf_url":"https://arxiv.org/pdf/2403.15707v1.pdf","comment":"40 pages, 4 figures, Accepted to ICLR 2024, Spotlight"}]},"2024-03-22T00:00:00Z":{"Computer Science and Game Theory":[{"id":"http://arxiv.org/abs/2403.15636v1","updated":"2024-03-22T22:27:28Z","published":"2024-03-22T22:27:28Z","title":"On the Variational Interpretation of Mirror Play in Monotone Games","summary":"  Mirror play (MP) is a well-accepted primal-dual multi-agent learning\nalgorithm where all agents simultaneously implement mirror descent in a\ndistributed fashion. The advantage of MP over vanilla gradient play lies in its\nusage of mirror maps that better exploit the geometry of decision domains.\nDespite extensive literature dedicated to the asymptotic convergence of MP to\nequilibrium, the understanding of the finite-time behavior of MP before\nreaching equilibrium is still rudimentary. To facilitate the study of MP's\nnon-equilibrium performance, this work establishes an equivalence between MP's\nfinite-time primal-dual path (mirror path) in monotone games and the\nclosed-loop Nash equilibrium path of a finite-horizon differential game,\nreferred to as mirror differential game (MDG). Our construction of MDG rests on\nthe Brezis-Ekeland variational principle, and the stage cost functional for MDG\nis Fenchel coupling between MP's iterates and associated gradient updates. The\nvariational interpretation of mirror path in static games as the equilibrium\npath in MDG holds in deterministic and stochastic cases. Such a variational\ninterpretation translates the non-equilibrium studies of learning dynamics into\na more tractable equilibrium analysis of dynamic games, as demonstrated in a\ncase study on the Cournot game, where MP dynamics corresponds to a linear\nquadratic game.\n","authors":["Yunian Pan","Tao Li","Quanyan Zhu"],"pdf_url":"https://arxiv.org/pdf/2403.15636v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15616v1","updated":"2024-03-22T21:06:48Z","published":"2024-03-22T21:06:48Z","title":"Balancing Fairness and Efficiency in Energy Resource Allocations","summary":"  Bringing fairness to energy resource allocation remains a challenge, due to\nthe complexity of system structures and economic interdependencies among users\nand system operators' decision-making. The rise of distributed energy resources\nhas introduced more diverse heterogeneous user groups, surpassing the\ncapabilities of traditional efficiency-oriented allocation schemes. Without\nexplicitly bringing fairness to user-system interaction, this disparity often\nleads to disproportionate payments for certain user groups due to their utility\nformats or group sizes.\n  Our paper addresses this challenge by formalizing the problem of fair energy\nresource allocation and introducing the framework for aggregators. This\nframework enables optimal fairness-efficiency trade-offs by selecting\nappropriate objectives in a principled way. By jointly optimizing over the\ntotal resources to allocate and individual allocations, our approach reveals\noptimized allocation schemes that lie on the Pareto front, balancing fairness\nand efficiency in resource allocation strategies.\n","authors":["Jiayi Li","Matthew Motoki","Baosen Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.15616v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15307v1","updated":"2024-03-22T15:58:39Z","published":"2024-03-22T15:58:39Z","title":"Strategic Network Creation for Enabling Greedy Routing","summary":"  In this paper, we present the first game-theoretic network creation model\nthat incorporates greedy routing, i.e., the agents in our model are embedded in\nsome metric space and strive for creating a network where all-pairs greedy\nrouting is enabled. In contrast to graph-theoretic shortest paths, our agents\nroute their traffic along greedy paths, which are sequences of nodes where the\ndistance in the metric space to the respective target node gets strictly\nsmaller by each hop. Besides enabling greedy routing, the agents also optimize\ntheir connection quality within the created network by constructing greedy\npaths with low stretch. This ensures that greedy routing is always possible in\nequilibrium networks, while realistically modeling the agents' incentives for\nlocal structural changes to the network. With this we augment the elegant\nnetwork creation model by Moscibroda, Schmidt, and Wattenhofer (PODC'06) with\nthe feature of greedy routing.\n  For our model, we analyze the existence of (approximate)-equilibria and the\ncomputational hardness in different underlying metric spaces. E.g., we\ncharacterize the set of equilibria in 1-2-metrics and tree metrics, we show\nthat in both metrics Nash equilibria always exist, and we prove that the\nwell-known $\\Theta$-graph construction yields constant-approximate Nash\nequilibria in Euclidean space. The latter justifies distributed network\nconstruction via $\\Theta$-graphs from a new point-of-view, since it shows that\nthis powerful technique not only guarantees networks having a low stretch but\nalso networks that are almost stable.\n","authors":["Julian Berger","Tobias Friedrich","Pascal Lenzner","Paraskevi Machaira","Janosch Ruff"],"pdf_url":"https://arxiv.org/pdf/2403.15307v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15293v1","updated":"2024-03-22T15:40:11Z","published":"2024-03-22T15:40:11Z","title":"Human behaviour through a LENS: How Linguistic content triggers Emotions\n  and Norms and determines Strategy choices","summary":"  Over the last two decades, a growing body of experimental research has\nprovided evidence that linguistic frames influence human behaviour in economic\ngames, beyond the economic consequences of the available actions. This article\nproposes a novel framework that transcends the traditional confines of\noutcome-based preference models. According to the LENS model, the Linguistic\ndescription of the decision problem triggers Emotional responses and suggests\npotential Norms of behaviour, which then interact to shape an individual's\nStrategic choice. The article reviews experimental evidence that supports each\npath of the LENS model. Furthermore, it identifies and discusses several\ncritical research questions that arise from this model, pointing towards\navenues for future inquiry.\n","authors":["Valerio Capraro"],"pdf_url":"https://arxiv.org/pdf/2403.15293v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15524v1","updated":"2024-03-22T14:13:11Z","published":"2024-03-22T14:13:11Z","title":"PPA-Game: Characterizing and Learning Competitive Dynamics Among Online\n  Content Creators","summary":"  We introduce the Proportional Payoff Allocation Game (PPA-Game) to model how\nagents, akin to content creators on platforms like YouTube and TikTok, compete\nfor divisible resources and consumers' attention. Payoffs are allocated to\nagents based on heterogeneous weights, reflecting the diversity in content\nquality among creators. Our analysis reveals that although a pure Nash\nequilibrium (PNE) is not guaranteed in every scenario, it is commonly observed,\nwith its absence being rare in our simulations. Beyond analyzing static\npayoffs, we further discuss the agents' online learning about resource payoffs\nby integrating a multi-player multi-armed bandit framework. We propose an\nonline algorithm facilitating each agent's maximization of cumulative payoffs\nover $T$ rounds. Theoretically, we establish that the regret of any agent is\nbounded by $O(\\log^{1 + \\eta} T)$ for any $\\eta > 0$. Empirical results further\nvalidate the effectiveness of our approach.\n","authors":["Renzhe Xu","Haotian Wang","Xingxuan Zhang","Bo Li","Peng Cui"],"pdf_url":"https://arxiv.org/pdf/2403.15524v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.12520v2","updated":"2024-03-22T01:18:08Z","published":"2023-08-24T03:14:45Z","title":"A-PSRO: A Unified Strategy Learning Method with Advantage Function for\n  Normal-form Games","summary":"  Solving Nash equilibrium is the key challenge in normal-form games with large\nstrategy spaces, where open-ended learning frameworks offer an efficient\napproach. In this work, we propose an innovative unified open-ended learning\nframework A-PSRO, i.e., Advantage Policy Space Response Oracle, as a\ncomprehensive framework for both zero-sum and general-sum games. In particular,\nwe introduce the advantage function as an enhanced evaluation metric for\nstrategies, enabling a unified learning objective for agents engaged in\nnormal-form games. We prove that the advantage function exhibits favorable\nproperties and is connected with the Nash equilibrium, which can be used as an\nobjective to guide agents to learn strategies efficiently. Our experiments\nreveal that A-PSRO achieves a considerable decrease in exploitability in\nzero-sum games and an escalation in rewards in general-sum games, significantly\noutperforming previous PSRO algorithms.\n","authors":["Yudong Hu","Haoran Li","Congying Han","Tiande Guo","Mingqiang Li","Bonan Li"],"pdf_url":"https://arxiv.org/pdf/2308.12520v2.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2302.06746v2","updated":"2024-03-22T19:53:37Z","published":"2023-02-13T23:18:47Z","title":"Workload-Balanced Pruning for Sparse Spiking Neural Networks","summary":"  Pruning for Spiking Neural Networks (SNNs) has emerged as a fundamental\nmethodology for deploying deep SNNs on resource-constrained edge devices.\nThough the existing pruning methods can provide extremely high weight sparsity\nfor deep SNNs, the high weight sparsity brings a workload imbalance problem.\nSpecifically, the workload imbalance happens when a different number of\nnon-zero weights are assigned to hardware units running in parallel. This\nresults in low hardware utilization and thus imposes longer latency and higher\nenergy costs. In preliminary experiments, we show that sparse SNNs (~98% weight\nsparsity) can suffer as low as ~59% utilization. To alleviate the workload\nimbalance problem, we propose u-Ticket, where we monitor and adjust the weight\nconnections of the SNN during Lottery Ticket Hypothesis (LTH) based pruning,\nthus guaranteeing the final ticket gets optimal utilization when deployed onto\nthe hardware. Experiments indicate that our u-Ticket can guarantee up to 100%\nhardware utilization, thus reducing up to 76.9% latency and 63.8% energy cost\ncompared to the non-utilization-aware LTH method.\n","authors":["Ruokai Yin","Youngeun Kim","Yuhang Li","Abhishek Moitra","Nitin Satpute","Anna Hambitzer","Priyadarshini Panda"],"pdf_url":"https://arxiv.org/pdf/2302.06746v2.pdf","comment":"11 pages. Accepted to IEEE Transactions on Emerging Topics in\n  Computational Intelligence (2024)"},{"id":"http://arxiv.org/abs/2309.16512v4","updated":"2024-03-22T17:26:53Z","published":"2023-09-28T15:19:30Z","title":"From Complexity to Clarity: Analytical Expressions of Deep Neural\n  Network Weights via Clifford's Geometric Algebra and Convexity","summary":"  In this paper, we introduce a novel analysis of neural networks based on\ngeometric (Clifford) algebra and convex optimization. We show that optimal\nweights of deep ReLU neural networks are given by the wedge product of training\nsamples when trained with standard regularized loss. Furthermore, the training\nproblem reduces to convex optimization over wedge product features, which\nencode the geometric structure of the training dataset. This structure is given\nin terms of signed volumes of triangles and parallelotopes generated by data\nvectors. The convex problem finds a small subset of samples via $\\ell_1$\nregularization to discover only relevant wedge product features. Our analysis\nprovides a novel perspective on the inner workings of deep neural networks and\nsheds light on the role of the hidden layers.\n","authors":["Mert Pilanci"],"pdf_url":"https://arxiv.org/pdf/2309.16512v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15525v1","updated":"2024-03-22T14:15:28Z","published":"2024-03-22T14:15:28Z","title":"Latent Neural Cellular Automata for Resource-Efficient Image Restoration","summary":"  Neural cellular automata represent an evolution of the traditional cellular\nautomata model, enhanced by the integration of a deep learning-based transition\nfunction. This shift from a manual to a data-driven approach significantly\nincreases the adaptability of these models, enabling their application in\ndiverse domains, including content generation and artificial life. However,\ntheir widespread application has been hampered by significant computational\nrequirements. In this work, we introduce the Latent Neural Cellular Automata\n(LNCA) model, a novel architecture designed to address the resource limitations\nof neural cellular automata. Our approach shifts the computation from the\nconventional input space to a specially designed latent space, relying on a\npre-trained autoencoder. We apply our model in the context of image\nrestoration, which aims to reconstruct high-quality images from their degraded\nversions. This modification not only reduces the model's resource consumption\nbut also maintains a flexible framework suitable for various applications. Our\nmodel achieves a significant reduction in computational requirements while\nmaintaining high reconstruction fidelity. This increase in efficiency allows\nfor inputs up to 16 times larger than current state-of-the-art neural cellular\nautomata models, using the same resources.\n","authors":["Andrea Menta","Alberto Archetti","Matteo Matteucci"],"pdf_url":"https://arxiv.org/pdf/2403.15525v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14413v2","updated":"2024-03-22T13:15:20Z","published":"2024-03-21T13:59:19Z","title":"Model Uncertainty in Evolutionary Optimization and Bayesian\n  Optimization: A Comparative Analysis","summary":"  Black-box optimization problems, which are common in many real-world\napplications, require optimization through input-output interactions without\naccess to internal workings. This often leads to significant computational\nresources being consumed for simulations. Bayesian Optimization (BO) and\nSurrogate-Assisted Evolutionary Algorithm (SAEA) are two widely used\ngradient-free optimization techniques employed to address such challenges. Both\napproaches follow a similar iterative procedure that relies on surrogate models\nto guide the search process. This paper aims to elucidate the similarities and\ndifferences in the utilization of model uncertainty between these two methods,\nas well as the impact of model inaccuracies on algorithmic performance. A novel\nmodel-assisted strategy is introduced, which utilizes unevaluated solutions to\ngenerate offspring, leveraging the population-based search capabilities of\nevolutionary algorithm to enhance the effectiveness of model-assisted\noptimization. Experimental results demonstrate that the proposed approach\noutperforms mainstream Bayesian optimization algorithms in terms of accuracy\nand efficiency.\n","authors":["Hao Hao","Xiaoqun Zhang","Aimin Zhou"],"pdf_url":"https://arxiv.org/pdf/2403.14413v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14303v2","updated":"2024-03-22T10:54:09Z","published":"2023-11-24T06:27:08Z","title":"RFI Detection with Spiking Neural Networks","summary":"  Detecting and mitigating Radio Frequency Interference (RFI) is critical for\nenabling and maximising the scientific output of radio telescopes. The\nemergence of machine learning methods has led to their application in radio\nastronomy, and in RFI detection. Spiking Neural Networks (SNNs), inspired by\nbiological systems, are well-suited for processing spatio-temporal data. This\nstudy introduces the first exploratory application of SNNs to an astronomical\ndata-processing task, specifically RFI detection. We adapt the\nnearest-latent-neighbours (NLN) algorithm and auto-encoder architecture\nproposed by previous authors to SNN execution by direct ANN2SNN conversion,\nenabling simplified downstream RFI detection by sampling the naturally varying\nlatent space from the internal spiking neurons. Our subsequent evaluation aims\nto determine whether SNNs are viable for future RFI detection schemes. We\nevaluate detection performance with the simulated HERA telescope and\nhand-labelled LOFAR observation dataset the original authors provided. We\nadditionally evaluate detection performance with a new MeerKAT-inspired\nsimulation dataset that provides a technical challenge for machine-learnt RFI\ndetection methods. This dataset focuses on satellite-based RFI, an increasingly\nimportant class of RFI and is an additional contribution. Our approach remains\ncompetitive with existing methods in AUROC, AUPRC and F1 scores for the HERA\ndataset but exhibits difficulty in the LOFAR and Tabascal datasets. Our method\nmaintains this accuracy while completely removing the compute and\nmemory-intense latent sampling step found in NLN. This work demonstrates the\nviability of SNNs as a promising avenue for machine-learning-based RFI\ndetection in radio telescopes by establishing a minimal performance baseline on\ntraditional and nascent satellite-based RFI sources and is the first work to\nour knowledge to apply SNNs in astronomy.\n","authors":["Nicholas J. Pritchard","Andreas Wicenec","Mohammed Bennamoun","Richard Dodson"],"pdf_url":"https://arxiv.org/pdf/2311.14303v2.pdf","comment":"11 pages, 5 figures, 5 tables. Accepted for publication in PASA"},{"id":"http://arxiv.org/abs/2204.01368v3","updated":"2024-03-22T09:42:26Z","published":"2022-04-04T10:28:11Z","title":"Training Fully Connected Neural Networks is $\\exists\\mathbb{R}$-Complete","summary":"  We consider the problem of finding weights and biases for a two-layer fully\nconnected neural network to fit a given set of data points as well as possible,\nalso known as EmpiricalRiskMinimization. Our main result is that the associated\ndecision problem is $\\exists\\mathbb{R}$-complete, that is, polynomial-time\nequivalent to determining whether a multivariate polynomial with integer\ncoefficients has any real roots. Furthermore, we prove that algebraic numbers\nof arbitrarily large degree are required as weights to be able to train some\ninstances to optimality, even if all data points are rational. Our result\nalready applies to fully connected instances with two inputs, two outputs, and\none hidden layer of ReLU neurons. Thereby, we strengthen a result by\nAbrahamsen, Kleist and Miltzow [NeurIPS 2021]. A consequence of this is that a\ncombinatorial search algorithm like the one by Arora, Basu, Mianjy and\nMukherjee [ICLR 2018] is impossible for networks with more than one output\ndimension, unless $\\mathsf{NP}=\\exists\\mathbb{R}$.\n","authors":["Daniel Bertschinger","Christoph Hertrich","Paul Jungeblut","Tillmann Miltzow","Simon Weber"],"pdf_url":"https://arxiv.org/pdf/2204.01368v3.pdf","comment":"39 pages, 17 figures. Changes in version 2: Added algebraic\n  universality result, improved interpretation of results Changes in version 3:\n  Improved exposition by formalizing properties of gadgets"},{"id":"http://arxiv.org/abs/2403.14999v1","updated":"2024-03-22T07:21:09Z","published":"2024-03-22T07:21:09Z","title":"Magic for the Age of Quantized DNNs","summary":"  Recently, the number of parameters in DNNs has explosively increased, as\nexemplified by LLMs (Large Language Models), making inference on small-scale\ncomputers more difficult. Model compression technology is, therefore, essential\nfor integration into products. In this paper, we propose a method of\nquantization-aware training. We introduce a novel normalization (Layer-Batch\nNormalization) that is independent of the mini-batch size and does not require\nany additional computation cost during inference. Then, we quantize the weights\nby the scaled round-clip function with the weight standardization. We also\nquantize activation functions using the same function and apply surrogate\ngradients to train the model with both quantized weights and the quantized\nactivation functions. We call this method Magic for the age of Quantised DNNs\n(MaQD). Experimental results show that our quantization method can be achieved\nwith minimal accuracy degradation.\n","authors":["Yoshihide Sawada","Ryuji Saiin","Kazuma Suetake"],"pdf_url":"https://arxiv.org/pdf/2403.14999v1.pdf","comment":"14 pages, 5 figures, 4 tables"},{"id":"http://arxiv.org/abs/2403.14913v1","updated":"2024-03-22T02:22:03Z","published":"2024-03-22T02:22:03Z","title":"Optimisation of photodetectors design: comparison between Montecarlo and\n  Genetic Algorithms","summary":"  We present Montecarlo and Genetic Algorithm optimisations applied to the\ndesign of photodetectors based on a transimpedance amplifier and a photodiode.\nThe circuit performance is evaluated with a merit function and the systematic\nsearch method is used as a reference. The design parameters are the feedback\nnetwork components and the photodiode bias voltage. To evaluate the\noptimisations, we define the relative difference between its merit and the\noptimum merit obtained by the systematic search. In both algorithms, the\nrelative difference decreases with the number of evaluations, following a power\nlaw. The power-law exponent for the Genetic Algorithm is larger than that of\nMontecarlo (0.74 vs. 0.50). We conclude that both algorithms are advantageous\ncompared to the systematic search method, and that the Genetic Algorithm shows\na better performance than Montecarlo.\n","authors":["Patricia M. E. Vázquez","Ligia Ciocci Brazzano","Francisco E. Veiras","Patricio A. Sorichetti"],"pdf_url":"https://arxiv.org/pdf/2403.14913v1.pdf","comment":"10 pages, 14 figures"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2401.11565v2","updated":"2024-03-22T21:33:47Z","published":"2024-01-21T18:57:38Z","title":"Thompson Sampling for Stochastic Bandits with Noisy Contexts: An\n  Information-Theoretic Regret Analysis","summary":"  We explore a stochastic contextual linear bandit problem where the agent\nobserves a noisy, corrupted version of the true context through a noise channel\nwith an unknown noise parameter. Our objective is to design an action policy\nthat can approximate\" that of an oracle, which has access to the reward model,\nthe channel parameter, and the predictive distribution of the true context from\nthe observed noisy context. In a Bayesian framework, we introduce a Thompson\nsampling algorithm for Gaussian bandits with Gaussian context noise. Adopting\nan information-theoretic analysis, we demonstrate the Bayesian regret of our\nalgorithm concerning the oracle's action policy. We also extend this problem to\na scenario where the agent observes the true context with some delay after\nreceiving the reward and show that delayed true contexts lead to lower Bayesian\nregret. Finally, we empirically demonstrate the performance of the proposed\nalgorithms against baselines.\n","authors":["Sharu Theresa Jose","Shana Moothedath"],"pdf_url":"https://arxiv.org/pdf/2401.11565v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.06721v3","updated":"2024-03-22T19:40:59Z","published":"2023-06-11T16:46:00Z","title":"Differentially Private Conditional Independence Testing","summary":"  Conditional independence (CI) tests are widely used in statistical data\nanalysis, e.g., they are the building block of many algorithms for causal graph\ndiscovery. The goal of a CI test is to accept or reject the null hypothesis\nthat $X \\perp \\!\\!\\! \\perp Y \\mid Z$, where $X \\in \\mathbb{R}, Y \\in\n\\mathbb{R}, Z \\in \\mathbb{R}^d$. In this work, we investigate conditional\nindependence testing under the constraint of differential privacy. We design\ntwo private CI testing procedures: one based on the generalized covariance\nmeasure of Shah and Peters (2020) and another based on the conditional\nrandomization test of Cand\\`es et al. (2016) (under the model-X assumption). We\nprovide theoretical guarantees on the performance of our tests and validate\nthem empirically. These are the first private CI tests with rigorous\ntheoretical guarantees that work for the general case when $Z$ is continuous.\n","authors":["Iden Kalemaj","Shiva Prasad Kasiviswanathan","Aaditya Ramdas"],"pdf_url":"https://arxiv.org/pdf/2306.06721v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.02710v2","updated":"2024-03-22T18:49:46Z","published":"2023-10-04T10:27:17Z","title":"Local Search GFlowNets","summary":"  Generative Flow Networks (GFlowNets) are amortized sampling methods that\nlearn a distribution over discrete objects proportional to their rewards.\nGFlowNets exhibit a remarkable ability to generate diverse samples, yet\noccasionally struggle to consistently produce samples with high rewards due to\nover-exploration on wide sample space. This paper proposes to train GFlowNets\nwith local search, which focuses on exploiting high-rewarded sample space to\nresolve this issue. Our main idea is to explore the local neighborhood via\nbacktracking and reconstruction guided by backward and forward policies,\nrespectively. This allows biasing the samples toward high-reward solutions,\nwhich is not possible for a typical GFlowNet solution generation scheme, which\nuses the forward policy to generate the solution from scratch. Extensive\nexperiments demonstrate a remarkable performance improvement in several\nbiochemical tasks. Source code is available:\n\\url{https://github.com/dbsxodud-11/ls_gfn}.\n","authors":["Minsu Kim","Taeyoung Yun","Emmanuel Bengio","Dinghuai Zhang","Yoshua Bengio","Sungsoo Ahn","Jinkyoo Park"],"pdf_url":"https://arxiv.org/pdf/2310.02710v2.pdf","comment":"ICLR 2024 (Spotlight paper), 18 pages, 17 figures"},{"id":"http://arxiv.org/abs/2306.03111v2","updated":"2024-03-22T18:43:38Z","published":"2023-06-05T08:23:46Z","title":"Bootstrapped Training of Score-Conditioned Generator for Offline Design\n  of Biological Sequences","summary":"  We study the problem of optimizing biological sequences, e.g., proteins, DNA,\nand RNA, to maximize a black-box score function that is only evaluated in an\noffline dataset. We propose a novel solution, bootstrapped training of\nscore-conditioned generator (BootGen) algorithm. Our algorithm repeats a\ntwo-stage process. In the first stage, our algorithm trains the biological\nsequence generator with rank-based weights to enhance the accuracy of sequence\ngeneration based on high scores. The subsequent stage involves bootstrapping,\nwhich augments the training dataset with self-generated data labeled by a proxy\nscore function. Our key idea is to align the score-based generation with a\nproxy score function, which distills the knowledge of the proxy score function\nto the generator. After training, we aggregate samples from multiple\nbootstrapped generators and proxies to produce a diverse design. Extensive\nexperiments show that our method outperforms competitive baselines on\nbiological sequential design tasks. We provide reproducible source code:\n\\href{https://github.com/kaist-silab/bootgen}{https://github.com/kaist-silab/bootgen}.\n","authors":["Minsu Kim","Federico Berto","Sungsoo Ahn","Jinkyoo Park"],"pdf_url":"https://arxiv.org/pdf/2306.03111v2.pdf","comment":"NeurIPS 2023, 19 pages, 5 figures"},{"id":"http://arxiv.org/abs/2309.16512v4","updated":"2024-03-22T17:26:53Z","published":"2023-09-28T15:19:30Z","title":"From Complexity to Clarity: Analytical Expressions of Deep Neural\n  Network Weights via Clifford's Geometric Algebra and Convexity","summary":"  In this paper, we introduce a novel analysis of neural networks based on\ngeometric (Clifford) algebra and convex optimization. We show that optimal\nweights of deep ReLU neural networks are given by the wedge product of training\nsamples when trained with standard regularized loss. Furthermore, the training\nproblem reduces to convex optimization over wedge product features, which\nencode the geometric structure of the training dataset. This structure is given\nin terms of signed volumes of triangles and parallelotopes generated by data\nvectors. The convex problem finds a small subset of samples via $\\ell_1$\nregularization to discover only relevant wedge product features. Our analysis\nprovides a novel perspective on the inner workings of deep neural networks and\nsheds light on the role of the hidden layers.\n","authors":["Mert Pilanci"],"pdf_url":"https://arxiv.org/pdf/2309.16512v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.02695v2","updated":"2024-03-22T17:00:40Z","published":"2023-11-05T16:05:00Z","title":"Identifying Linearly-Mixed Causal Representations from Multi-Node\n  Interventions","summary":"  The task of inferring high-level causal variables from low-level\nobservations, commonly referred to as causal representation learning, is\nfundamentally underconstrained. As such, recent works to address this problem\nfocus on various assumptions that lead to identifiability of the underlying\nlatent causal variables. A large corpus of these preceding approaches consider\nmulti-environment data collected under different interventions on the causal\nmodel. What is common to virtually all of these works is the restrictive\nassumption that in each environment, only a single variable is intervened on.\nIn this work, we relax this assumption and provide the first identifiability\nresult for causal representation learning that allows for multiple variables to\nbe targeted by an intervention within one environment. Our approach hinges on a\ngeneral assumption on the coverage and diversity of interventions across\nenvironments, which also includes the shared assumption of single-node\ninterventions of previous works. The main idea behind our approach is to\nexploit the trace that interventions leave on the variance of the ground truth\ncausal variables and regularizing for a specific notion of sparsity with\nrespect to this trace. In addition to and inspired by our theoretical\ncontributions, we present a practical algorithm to learn causal representations\nfrom multi-node interventional data and provide empirical evidence that\nvalidates our identifiability results.\n","authors":["Simon Bing","Urmi Ninad","Jonas Wahl","Jakob Runge"],"pdf_url":"https://arxiv.org/pdf/2311.02695v2.pdf","comment":"Accepted for publication at CLeaR 2024"},{"id":"http://arxiv.org/abs/2403.15312v1","updated":"2024-03-22T16:04:26Z","published":"2024-03-22T16:04:26Z","title":"A Wasserstein perspective of Vanilla GANs","summary":"  The empirical success of Generative Adversarial Networks (GANs) caused an\nincreasing interest in theoretical research. The statistical literature is\nmainly focused on Wasserstein GANs and generalizations thereof, which\nespecially allow for good dimension reduction properties. Statistical results\nfor Vanilla GANs, the original optimization problem, are still rather limited\nand require assumptions such as smooth activation functions and equal\ndimensions of the latent space and the ambient space. To bridge this gap, we\ndraw a connection from Vanilla GANs to the Wasserstein distance. By doing so,\nexisting results for Wasserstein GANs can be extended to Vanilla GANs. In\nparticular, we obtain an oracle inequality for Vanilla GANs in Wasserstein\ndistance. The assumptions of this oracle inequality are designed to be\nsatisfied by network architectures commonly used in practice, such as\nfeedforward ReLU networks. By providing a quantitative result for the\napproximation of a Lipschitz function by a feedforward ReLU network with\nbounded H\\\"older norm, we conclude a rate of convergence for Vanilla GANs as\nwell as Wasserstein GANs as estimators of the unknown probability distribution.\n","authors":["Lea Kunkel","Mathias Trabs"],"pdf_url":"https://arxiv.org/pdf/2403.15312v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15527v1","updated":"2024-03-22T15:40:06Z","published":"2024-03-22T15:40:06Z","title":"Conformal online model aggregation","summary":"  Conformal prediction equips machine learning models with a reasonable notion\nof uncertainty quantification without making strong distributional assumptions.\nIt wraps around any black-box prediction model and converts point predictions\ninto set predictions that have a predefined marginal coverage guarantee.\nHowever, conformal prediction only works if we fix the underlying machine\nlearning model in advance. A relatively unaddressed issue in conformal\nprediction is that of model selection and/or aggregation: for a given problem,\nwhich of the plethora of prediction methods (random forests, neural nets,\nregularized linear models, etc.) should we conformalize? This paper proposes a\nnew approach towards conformal model aggregation in online settings that is\nbased on combining the prediction sets from several algorithms by voting, where\nweights on the models are adapted over time based on past performance.\n","authors":["Matteo Gasparin","Aaditya Ramdas"],"pdf_url":"https://arxiv.org/pdf/2403.15527v1.pdf","comment":"15 pages, 8 figures. arXiv admin note: substantial text overlap with\n  arXiv:2401.09379"},{"id":"http://arxiv.org/abs/2403.15263v1","updated":"2024-03-22T15:02:24Z","published":"2024-03-22T15:02:24Z","title":"Federated Bayesian Deep Learning: The Application of Statistical\n  Aggregation Methods to Bayesian Models","summary":"  Federated learning (FL) is an approach to training machine learning models\nthat takes advantage of multiple distributed datasets while maintaining data\nprivacy and reducing communication costs associated with sharing local\ndatasets. Aggregation strategies have been developed to pool or fuse the\nweights and biases of distributed deterministic models; however, modern\ndeterministic deep learning (DL) models are often poorly calibrated and lack\nthe ability to communicate a measure of epistemic uncertainty in prediction,\nwhich is desirable for remote sensing platforms and safety-critical\napplications. Conversely, Bayesian DL models are often well calibrated and\ncapable of quantifying and communicating a measure of epistemic uncertainty\nalong with a competitive prediction accuracy. Unfortunately, because the\nweights and biases in Bayesian DL models are defined by a probability\ndistribution, simple application of the aggregation methods associated with FL\nschemes for deterministic models is either impossible or results in sub-optimal\nperformance. In this work, we use independent and identically distributed (IID)\nand non-IID partitions of the CIFAR-10 dataset and a fully variational\nResNet-20 architecture to analyze six different aggregation strategies for\nBayesian DL models. Additionally, we analyze the traditional federated\naveraging approach applied to an approximate Bayesian Monte Carlo dropout model\nas a lightweight alternative to more complex variational inference methods in\nFL. We show that aggregation strategy is a key hyperparameter in the design of\na Bayesian FL system with downstream effects on accuracy, calibration,\nuncertainty quantification, training stability, and client compute\nrequirements.\n","authors":["John Fischer","Marko Orescanin","Justin Loomis","Patrick McClure"],"pdf_url":"https://arxiv.org/pdf/2403.15263v1.pdf","comment":"22 pages, 9 figures"},{"id":"http://arxiv.org/abs/2403.15175v1","updated":"2024-03-22T12:59:03Z","published":"2024-03-22T12:59:03Z","title":"Double Cross-fit Doubly Robust Estimators: Beyond Series Regression","summary":"  Doubly robust estimators with cross-fitting have gained popularity in causal\ninference due to their favorable structure-agnostic error guarantees. However,\nwhen additional structure, such as H\\\"{o}lder smoothness, is available then\nmore accurate \"double cross-fit doubly robust\" (DCDR) estimators can be\nconstructed by splitting the training data and undersmoothing nuisance function\nestimators on independent samples. We study a DCDR estimator of the Expected\nConditional Covariance, a functional of interest in causal inference and\nconditional independence testing, and derive a series of increasingly powerful\nresults with progressively stronger assumptions. We first provide a\nstructure-agnostic error analysis for the DCDR estimator with no assumptions on\nthe nuisance functions or their estimators. Then, assuming the nuisance\nfunctions are H\\\"{o}lder smooth, but without assuming knowledge of the true\nsmoothness level or the covariate density, we establish that DCDR estimators\nwith several linear smoothers are semiparametric efficient under minimal\nconditions and achieve fast convergence rates in the non-$\\sqrt{n}$ regime.\nWhen the covariate density and smoothnesses are known, we propose a minimax\nrate-optimal DCDR estimator based on undersmoothed kernel regression. Moreover,\nwe show an undersmoothed DCDR estimator satisfies a slower-than-$\\sqrt{n}$\ncentral limit theorem, and that inference is possible even in the\nnon-$\\sqrt{n}$ regime. Finally, we support our theoretical results with\nsimulations, providing intuition for double cross-fitting and undersmoothing,\ndemonstrating where our estimator achieves semiparametric efficiency while the\nusual \"single cross-fit\" estimator fails, and illustrating asymptotic normality\nfor the undersmoothed DCDR estimator.\n","authors":["Alec McClean","Sivaraman Balakrishnan","Edward H. Kennedy","Larry Wasserman"],"pdf_url":"https://arxiv.org/pdf/2403.15175v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.13185v2","updated":"2024-03-22T12:20:30Z","published":"2023-06-22T20:03:05Z","title":"An Agnostic View on the Cost of Overfitting in (Kernel) Ridge Regression","summary":"  We study the cost of overfitting in noisy kernel ridge regression (KRR),\nwhich we define as the ratio between the test error of the interpolating\nridgeless model and the test error of the optimally-tuned model. We take an\n\"agnostic\" view in the following sense: we consider the cost as a function of\nsample size for any target function, even if the sample size is not large\nenough for consistency or the target is outside the RKHS. We analyze the cost\nof overfitting under a Gaussian universality ansatz using recently derived\n(non-rigorous) risk estimates in terms of the task eigenstructure. Our analysis\nprovides a more refined characterization of benign, tempered and catastrophic\noverfitting (cf. Mallinar et al. 2022).\n","authors":["Lijia Zhou","James B. Simon","Gal Vardi","Nathan Srebro"],"pdf_url":"https://arxiv.org/pdf/2306.13185v2.pdf","comment":"This is the ICLR CR version"},{"id":"http://arxiv.org/abs/2312.16427v3","updated":"2024-03-22T12:05:02Z","published":"2023-12-27T06:23:29Z","title":"Learning to Embed Time Series Patches Independently","summary":"  Masked time series modeling has recently gained much attention as a\nself-supervised representation learning strategy for time series. Inspired by\nmasked image modeling in computer vision, recent works first patchify and\npartially mask out time series, and then train Transformers to capture the\ndependencies between patches by predicting masked patches from unmasked\npatches. However, we argue that capturing such patch dependencies might not be\nan optimal strategy for time series representation learning; rather, learning\nto embed patches independently results in better time series representations.\nSpecifically, we propose to use 1) the simple patch reconstruction task, which\nautoencode each patch without looking at other patches, and 2) the simple\npatch-wise MLP that embeds each patch independently. In addition, we introduce\ncomplementary contrastive learning to hierarchically capture adjacent time\nseries information efficiently. Our proposed method improves time series\nforecasting and classification performance compared to state-of-the-art\nTransformer-based models, while it is more efficient in terms of the number of\nparameters and training/inference time. Code is available at this repository:\nhttps://github.com/seunghan96/pits.\n","authors":["Seunghan Lee","Taeyoung Park","Kibok Lee"],"pdf_url":"https://arxiv.org/pdf/2312.16427v3.pdf","comment":"ICLR 2024"},{"id":"http://arxiv.org/abs/2312.16424v3","updated":"2024-03-22T12:02:42Z","published":"2023-12-27T06:15:00Z","title":"Soft Contrastive Learning for Time Series","summary":"  Contrastive learning has shown to be effective to learn representations from\ntime series in a self-supervised way. However, contrasting similar time series\ninstances or values from adjacent timestamps within a time series leads to\nignore their inherent correlations, which results in deteriorating the quality\nof learned representations. To address this issue, we propose SoftCLT, a simple\nyet effective soft contrastive learning strategy for time series. This is\nachieved by introducing instance-wise and temporal contrastive loss with soft\nassignments ranging from zero to one. Specifically, we define soft assignments\nfor 1) instance-wise contrastive loss by the distance between time series on\nthe data space, and 2) temporal contrastive loss by the difference of\ntimestamps. SoftCLT is a plug-and-play method for time series contrastive\nlearning that improves the quality of learned representations without bells and\nwhistles. In experiments, we demonstrate that SoftCLT consistently improves the\nperformance in various downstream tasks including classification,\nsemi-supervised learning, transfer learning, and anomaly detection, showing\nstate-of-the-art performance. Code is available at this repository:\nhttps://github.com/seunghan96/softclt.\n","authors":["Seunghan Lee","Taeyoung Park","Kibok Lee"],"pdf_url":"https://arxiv.org/pdf/2312.16424v3.pdf","comment":"ICLR 2024 Spotlight"},{"id":"http://arxiv.org/abs/2403.15123v1","updated":"2024-03-22T11:25:38Z","published":"2024-03-22T11:25:38Z","title":"Quantification using Permutation-Invariant Networks based on Histograms","summary":"  Quantification, also known as class prevalence estimation, is the supervised\nlearning task in which a model is trained to predict the prevalence of each\nclass in a given bag of examples. This paper investigates the application of\ndeep neural networks to tasks of quantification in scenarios where it is\npossible to apply a symmetric supervised approach that eliminates the need for\nclassification as an intermediary step, directly addressing the quantification\nproblem. Additionally, it discusses existing permutation-invariant layers\ndesigned for set processing and assesses their suitability for quantification.\nIn light of our analysis, we propose HistNetQ, a novel neural architecture that\nrelies on a permutation-invariant representation based on histograms that is\nspecially suited for quantification problems. Our experiments carried out in\nthe only quantification competition held to date, show that HistNetQ\noutperforms other deep neural architectures devised for set processing, as well\nas the state-of-the-art quantification methods. Furthermore, HistNetQ offers\ntwo significant advantages over traditional quantification methods: i) it does\nnot require the labels of the training examples but only the prevalence values\nof a collection of training bags, making it applicable to new scenarios; and\nii) it is able to optimize any custom quantification-oriented loss function.\n","authors":["Olaya Pérez-Mon","Alejandro Moreo","Juan José del Coz","Pablo González"],"pdf_url":"https://arxiv.org/pdf/2403.15123v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.06015v4","updated":"2024-03-22T10:59:43Z","published":"2022-10-12T08:39:35Z","title":"EC-NAS: Energy Consumption Aware Tabular Benchmarks for Neural\n  Architecture Search","summary":"  Energy consumption from the selection, training, and deployment of deep\nlearning models has seen a significant uptick recently. This work aims to\nfacilitate the design of energy-efficient deep learning models that require\nless computational resources and prioritize environmental sustainability by\nfocusing on the energy consumption. Neural architecture search (NAS) benefits\nfrom tabular benchmarks, which evaluate NAS strategies cost-effectively through\nprecomputed performance statistics. We advocate for including energy efficiency\nas an additional performance criterion in NAS. To this end, we introduce an\nenhanced tabular benchmark encompassing data on energy consumption for varied\narchitectures. The benchmark, designated as EC-NAS, has been made available in\nan open-source format to advance research in energy-conscious NAS. EC-NAS\nincorporates a surrogate model to predict energy consumption, aiding in\ndiminishing the energy expenditure of the dataset creation. Our findings\nemphasize the potential of EC-NAS by leveraging multi-objective optimization\nalgorithms, revealing a balance between energy usage and accuracy. This\nsuggests the feasibility of identifying energy-lean architectures with little\nor no compromise in performance.\n","authors":["Pedram Bakhtiarifard","Christian Igel","Raghavendra Selvan"],"pdf_url":"https://arxiv.org/pdf/2210.06015v4.pdf","comment":"Accepted to be presented at the International Conference on\n  Acoustics, Speech and Signal Processing (ICASSP-2024). Source code at\n  https://github.com/saintslab/EC-NAS-Bench"},{"id":"http://arxiv.org/abs/2403.15108v1","updated":"2024-03-22T10:51:55Z","published":"2024-03-22T10:51:55Z","title":"Active Learning for Regression based on Wasserstein distance and\n  GroupSort Neural Networks","summary":"  This paper addresses a new active learning strategy for regression problems.\nThe presented Wasserstein active regression model is based on the principles of\ndistribution-matching to measure the representativeness of the labeled dataset.\nThe Wasserstein distance is computed using GroupSort Neural Networks. The use\nof such networks provides theoretical foundations giving a way to quantify\nerrors with explicit bounds for their size and depth. This solution is combined\nwith another uncertainty-based approach that is more outlier-tolerant to\ncomplete the query strategy. Finally, this method is compared with other\nclassical and recent solutions. The study empirically shows the pertinence of\nsuch a representativity-uncertainty approach, which provides good estimation\nall along the query procedure. Moreover, the Wasserstein active regression\noften achieves more precise estimations and tends to improve accuracy faster\nthan other models.\n","authors":["Benjamin Bobbia","Matthias Picard"],"pdf_url":"https://arxiv.org/pdf/2403.15108v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15038v1","updated":"2024-03-22T08:42:41Z","published":"2024-03-22T08:42:41Z","title":"Estimation of multiple mean vectors in high dimension","summary":"  We endeavour to estimate numerous multi-dimensional means of various\nprobability distributions on a common space based on independent samples. Our\napproach involves forming estimators through convex combinations of empirical\nmeans derived from these samples. We introduce two strategies to find\nappropriate data-dependent convex combination weights: a first one employing a\ntesting procedure to identify neighbouring means with low variance, which\nresults in a closed-form plug-in formula for the weights, and a second one\ndetermining weights via minimization of an upper confidence bound on the\nquadratic risk.Through theoretical analysis, we evaluate the improvement in\nquadratic risk offered by our methods compared to the empirical means. Our\nanalysis focuses on a dimensional asymptotics perspective, showing that our\nmethods asymptotically approach an oracle (minimax) improvement as the\neffective dimension of the data increases.We demonstrate the efficacy of our\nmethods in estimating multiple kernel mean embeddings through experiments on\nboth simulated and real-world datasets.\n","authors":["Gilles Blanchard","Jean-Baptiste Fermanian","Hannah Marienwald"],"pdf_url":"https://arxiv.org/pdf/2403.15038v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.11838v6","updated":"2024-03-22T08:42:14Z","published":"2023-08-23T00:10:29Z","title":"A Benchmark Study on Calibration","summary":"  Deep neural networks are increasingly utilized in various machine learning\ntasks. However, as these models grow in complexity, they often face calibration\nissues, despite enhanced prediction accuracy. Many studies have endeavored to\nimprove calibration performance through the use of specific loss functions,\ndata preprocessing and training frameworks. Yet, investigations into\ncalibration properties have been somewhat overlooked. Our study leverages the\nNeural Architecture Search (NAS) search space, offering an exhaustive model\narchitecture space for thorough calibration properties exploration. We\nspecifically create a model calibration dataset. This dataset evaluates 90\nbin-based and 12 additional calibration measurements across 117,702 unique\nneural networks within the widely employed NATS-Bench search space. Our\nanalysis aims to answer several longstanding questions in the field, using our\nproposed dataset: (i) Can model calibration be generalized across different\ndatasets? (ii) Can robustness be used as a calibration measurement? (iii) How\nreliable are calibration metrics? (iv) Does a post-hoc calibration method\naffect all models uniformly? (v) How does calibration interact with accuracy?\n(vi) What is the impact of bin size on calibration measurement? (vii) Which\narchitectural designs are beneficial for calibration? Additionally, our study\nbridges an existing gap by exploring calibration within NAS. By providing this\ndataset, we enable further research into NAS calibration. As far as we are\naware, our research represents the first large-scale investigation into\ncalibration properties and the premier study of calibration issues within NAS.\nThe project page can be found at https://www.taolinwei.com/calibration-study\n","authors":["Linwei Tao","Younan Zhu","Haolan Guo","Minjing Dong","Chang Xu"],"pdf_url":"https://arxiv.org/pdf/2308.11838v6.pdf","comment":"ICLR 2024 poster"},{"id":"http://arxiv.org/abs/2403.15025v1","updated":"2024-03-22T08:13:33Z","published":"2024-03-22T08:13:33Z","title":"Robust Conformal Prediction under Distribution Shift via\n  Physics-Informed Structural Causal Model","summary":"  Uncertainty is critical to reliable decision-making with machine learning.\nConformal prediction (CP) handles uncertainty by predicting a set on a test\ninput, hoping the set to cover the true label with at least $(1-\\alpha)$\nconfidence. This coverage can be guaranteed on test data even if the marginal\ndistributions $P_X$ differ between calibration and test datasets. However, as\nit is common in practice, when the conditional distribution $P_{Y|X}$ is\ndifferent on calibration and test data, the coverage is not guaranteed and it\nis essential to measure and minimize the coverage loss under distributional\nshift at \\textit{all} possible confidence levels. To address these issues, we\nupper bound the coverage difference at all levels using the cumulative density\nfunctions of calibration and test conformal scores and Wasserstein distance.\nInspired by the invariance of physics across data distributions, we propose a\nphysics-informed structural causal model (PI-SCM) to reduce the upper bound. We\nvalidated that PI-SCM can improve coverage robustness along confidence level\nand test domain on a traffic speed prediction task and an epidemic spread task\nwith multiple real-world datasets.\n","authors":["Rui Xu","Yue Sun","Chao Chen","Parv Venkitasubramaniam","Sihong Xie"],"pdf_url":"https://arxiv.org/pdf/2403.15025v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15012v1","updated":"2024-03-22T07:56:31Z","published":"2024-03-22T07:56:31Z","title":"Empirical investigation of multi-source cross-validation in clinical\n  machine learning","summary":"  Traditionally, machine learning-based clinical prediction models have been\ntrained and evaluated on patient data from a single source, such as a hospital.\nCross-validation methods can be used to estimate the accuracy of such models on\nnew patients originating from the same source, by repeated random splitting of\nthe data. However, such estimates tend to be highly overoptimistic when\ncompared to accuracy obtained from deploying models to sources not represented\nin the dataset, such as a new hospital. The increasing availability of\nmulti-source medical datasets provides new opportunities for obtaining more\ncomprehensive and realistic evaluations of expected accuracy through\nsource-level cross-validation designs.\n  In this study, we present a systematic empirical evaluation of standard\nK-fold cross-validation and leave-source-out cross-validation methods in a\nmulti-source setting. We consider the task of electrocardiogram based\ncardiovascular disease classification, combining and harmonizing the openly\navailable PhysioNet CinC Challenge 2021 and the Shandong Provincial Hospital\ndatasets for our study.\n  Our results show that K-fold cross-validation, both on single-source and\nmulti-source data, systemically overestimates prediction performance when the\nend goal is to generalize to new sources. Leave-source-out cross-validation\nprovides more reliable performance estimates, having close to zero bias though\nlarger variability. The evaluation highlights the dangers of obtaining\nmisleading cross-validation results on medical data and demonstrates how these\nissues can be mitigated when having access to multi-source data.\n","authors":["Tuija Leinonen","David Wong","Ali Wahab","Ramesh Nadarajah","Matti Kaisti","Antti Airola"],"pdf_url":"https://arxiv.org/pdf/2403.15012v1.pdf","comment":"14 pages, 3 figures"},{"id":"http://arxiv.org/abs/1808.07840v2","updated":"2024-03-22T07:27:29Z","published":"2018-08-23T16:55:53Z","title":"Learning to Importance Sample in Primary Sample Space","summary":"  Importance sampling is one of the most widely used variance reduction\nstrategies in Monte Carlo rendering. In this paper, we propose a novel\nimportance sampling technique that uses a neural network to learn how to sample\nfrom a desired density represented by a set of samples. Our approach considers\nan existing Monte Carlo rendering algorithm as a black box. During a\nscene-dependent training phase, we learn to generate samples with a desired\ndensity in the primary sample space of the rendering algorithm using maximum\nlikelihood estimation. We leverage a recent neural network architecture that\nwas designed to represent real-valued non-volume preserving ('Real NVP')\ntransformations in high dimensional spaces. We use Real NVP to non-linearly\nwarp primary sample space and obtain desired densities. In addition, Real NVP\nefficiently computes the determinant of the Jacobian of the warp, which is\nrequired to implement the change of integration variables implied by the warp.\nA main advantage of our approach is that it is agnostic of underlying light\ntransport effects, and can be combined with many existing rendering techniques\nby treating them as a black box. We show that our approach leads to effective\nvariance reduction in several practical scenarios.\n","authors":["Quan Zheng","Matthias Zwicker"],"pdf_url":"https://arxiv.org/pdf/1808.07840v2.pdf","comment":"11 pages, 14 figure; authors' version, the definitive version of\n  record is available at https://onlinelibrary.wiley.com/doi/10.1111/cgf.13628"},{"id":"http://arxiv.org/abs/2402.15213v2","updated":"2024-03-22T07:26:48Z","published":"2024-02-23T09:19:26Z","title":"Statistical Agnostic Regression: a machine learning method to validate\n  regression models","summary":"  Regression analysis is a central topic in statistical modeling, aiming to\nestimate the relationships between a dependent variable, commonly referred to\nas the response variable, and one or more independent variables, i.e.,\nexplanatory variables. Linear regression is by far the most popular method for\nperforming this task in several fields of research, such as prediction,\nforecasting, or causal inference. Beyond various classical methods to solve\nlinear regression problems, such as Ordinary Least Squares, Ridge, or Lasso\nregressions - which are often the foundation for more advanced machine learning\n(ML) techniques - the latter have been successfully applied in this scenario\nwithout a formal definition of statistical significance. At most, permutation\nor classical analyses based on empirical measures (e.g., residuals or accuracy)\nhave been conducted to reflect the greater ability of ML estimations for\ndetection. In this paper, we introduce a method, named Statistical Agnostic\nRegression (SAR), for evaluating the statistical significance of an ML-based\nlinear regression based on concentration inequalities of the actual risk using\nthe analysis of the worst case. To achieve this goal, similar to the\nclassification problem, we define a threshold to establish that there is\nsufficient evidence with a probability of at least 1-eta to conclude that there\nis a linear relationship in the population between the explanatory (feature)\nand the response (label) variables. Simulations in only two dimensions\ndemonstrate the ability of the proposed agnostic test to provide a similar\nanalysis of variance given by the classical $F$ test for the slope parameter.\n","authors":["Juan M Gorriz","J. Ramirez","F. Segovia","F. J. Martinez-Murcia","C. Jiménez-Mesa","J. Suckling"],"pdf_url":"https://arxiv.org/pdf/2402.15213v2.pdf","comment":"17 pages, 15 figures"},{"id":"http://arxiv.org/abs/2309.06985v2","updated":"2024-03-22T06:37:39Z","published":"2023-09-13T14:20:22Z","title":"CARE: Large Precision Matrix Estimation for Compositional Data","summary":"  High-dimensional compositional data are prevalent in many applications. The\nsimplex constraint poses intrinsic challenges to inferring the conditional\ndependence relationships among the components forming a composition, as encoded\nby a large precision matrix. We introduce a precise specification of the\ncompositional precision matrix and relate it to its basis counterpart, which is\nshown to be asymptotically identifiable under suitable sparsity assumptions. By\nexploiting this connection, we propose a composition adaptive regularized\nestimation (CARE) method for estimating the sparse basis precision matrix. We\nderive rates of convergence for the estimator and provide theoretical\nguarantees on support recovery and data-driven parameter tuning. Our theory\nreveals an intriguing trade-off between identification and estimation, thereby\nhighlighting the blessing of dimensionality in compositional data analysis. In\nparticular, in sufficiently high dimensions, the CARE estimator achieves\nminimax optimality and performs as well as if the basis were observed. We\nfurther discuss how our framework can be extended to handle data containing\nzeros, including sampling zeros and structural zeros. The advantages of CARE\nover existing methods are illustrated by simulation studies and an application\nto inferring microbial ecological networks in the human gut.\n","authors":["Shucong Zhang","Huiyuan Wang","Wei Lin"],"pdf_url":"https://arxiv.org/pdf/2309.06985v2.pdf","comment":"67 pages, 7 figures, to appear in Journal of the American Statistical\n  Association (http://www.tandfonline.com/r/JASA)"},{"id":"http://arxiv.org/abs/2312.09016v2","updated":"2024-03-22T04:12:08Z","published":"2023-12-14T15:06:48Z","title":"Symmetry Breaking and Equivariant Neural Networks","summary":"  Using symmetry as an inductive bias in deep learning has been proven to be a\nprincipled approach for sample-efficient model design. However, the\nrelationship between symmetry and the imperative for equivariance in neural\nnetworks is not always obvious. Here, we analyze a key limitation that arises\nin equivariant functions: their incapacity to break symmetry at the level of\nindividual data samples. In response, we introduce a novel notion of 'relaxed\nequivariance' that circumvents this limitation. We further demonstrate how to\nincorporate this relaxation into equivariant multilayer perceptrons (E-MLPs),\noffering an alternative to the noise-injection method. The relevance of\nsymmetry breaking is then discussed in various application domains: physics,\ngraph representation learning, combinatorial optimization and equivariant\ndecoding.\n","authors":["Sékou-Oumar Kaba","Siamak Ravanbakhsh"],"pdf_url":"https://arxiv.org/pdf/2312.09016v2.pdf","comment":"14 pages, 2 figures, Symmetry and Geometry in Neural Representations"},{"id":"http://arxiv.org/abs/2403.14926v1","updated":"2024-03-22T03:01:42Z","published":"2024-03-22T03:01:42Z","title":"Contrastive Learning on Multimodal Analysis of Electronic Health Records","summary":"  Electronic health record (EHR) systems contain a wealth of multimodal\nclinical data including structured data like clinical codes and unstructured\ndata such as clinical notes. However, many existing EHR-focused studies has\ntraditionally either concentrated on an individual modality or merged different\nmodalities in a rather rudimentary fashion. This approach often results in the\nperception of structured and unstructured data as separate entities, neglecting\nthe inherent synergy between them. Specifically, the two important modalities\ncontain clinically relevant, inextricably linked and complementary health\ninformation. A more complete picture of a patient's medical history is captured\nby the joint analysis of the two modalities of data. Despite the great success\nof multimodal contrastive learning on vision-language, its potential remains\nunder-explored in the realm of multimodal EHR, particularly in terms of its\ntheoretical understanding. To accommodate the statistical analysis of\nmultimodal EHR data, in this paper, we propose a novel multimodal feature\nembedding generative model and design a multimodal contrastive loss to obtain\nthe multimodal EHR feature representation. Our theoretical analysis\ndemonstrates the effectiveness of multimodal learning compared to\nsingle-modality learning and connects the solution of the loss function to the\nsingular value decomposition of a pointwise mutual information matrix. This\nconnection paves the way for a privacy-preserving algorithm tailored for\nmultimodal EHR feature representation learning. Simulation studies show that\nthe proposed algorithm performs well under a variety of configurations. We\nfurther validate the clinical utility of the proposed algorithm in real-world\nEHR data.\n","authors":["Tianxi Cai","Feiqing Huang","Ryumei Nakada","Linjun Zhang","Doudou Zhou"],"pdf_url":"https://arxiv.org/pdf/2403.14926v1.pdf","comment":"34 pages"},{"id":"http://arxiv.org/abs/2403.14917v1","updated":"2024-03-22T02:41:57Z","published":"2024-03-22T02:41:57Z","title":"Mean-field Analysis on Two-layer Neural Networks from a Kernel\n  Perspective","summary":"  In this paper, we study the feature learning ability of two-layer neural\nnetworks in the mean-field regime through the lens of kernel methods. To focus\non the dynamics of the kernel induced by the first layer, we utilize a\ntwo-timescale limit, where the second layer moves much faster than the first\nlayer. In this limit, the learning problem is reduced to the minimization\nproblem over the intrinsic kernel. Then, we show the global convergence of the\nmean-field Langevin dynamics and derive time and particle discretization error.\nWe also demonstrate that two-layer neural networks can learn a union of\nmultiple reproducing kernel Hilbert spaces more efficiently than any kernel\nmethods, and neural networks acquire data-dependent kernel which aligns with\nthe target function. In addition, we develop a label noise procedure, which\nconverges to the global optimum and show that the degrees of freedom appears as\nan implicit regularization.\n","authors":["Shokichi Takakura","Taiji Suzuki"],"pdf_url":"https://arxiv.org/pdf/2403.14917v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.06370v4","updated":"2024-03-22T02:30:02Z","published":"2022-12-13T05:03:16Z","title":"Dual Accuracy-Quality-Driven Neural Network for Prediction Interval\n  Generation","summary":"  Accurate uncertainty quantification is necessary to enhance the reliability\nof deep learning models in real-world applications. In the case of regression\ntasks, prediction intervals (PIs) should be provided along with the\ndeterministic predictions of deep learning models. Such PIs are useful or\n\"high-quality\" as long as they are sufficiently narrow and capture most of the\nprobability density. In this paper, we present a method to learn prediction\nintervals for regression-based neural networks automatically in addition to the\nconventional target predictions. In particular, we train two companion neural\nnetworks: one that uses one output, the target estimate, and another that uses\ntwo outputs, the upper and lower bounds of the corresponding PI. Our main\ncontribution is the design of a novel loss function for the PI-generation\nnetwork that takes into account the output of the target-estimation network and\nhas two optimization objectives: minimizing the mean prediction interval width\nand ensuring the PI integrity using constraints that maximize the prediction\ninterval probability coverage implicitly. Furthermore, we introduce a\nself-adaptive coefficient that balances both objectives within the loss\nfunction, which alleviates the task of fine-tuning. Experiments using a\nsynthetic dataset, eight benchmark datasets, and a real-world crop yield\nprediction dataset showed that our method was able to maintain a nominal\nprobability coverage and produce significantly narrower PIs without detriment\nto its target estimation accuracy when compared to those PIs generated by three\nstate-of-the-art neural-network-based methods. In other words, our method was\nshown to produce higher-quality PIs.\n","authors":["Giorgio Morales","John W. Sheppard"],"pdf_url":"https://arxiv.org/pdf/2212.06370v4.pdf","comment":"Accepted at the IEEE Transactions on Neural Networks and Learning\n  Systems"},{"id":"http://arxiv.org/abs/2401.14591v6","updated":"2024-03-22T01:51:51Z","published":"2024-01-26T01:36:48Z","title":"Ricci flow-guided autoencoders in learning time-dependent dynamics","summary":"  We present a manifold-based autoencoder method for learning nonlinear\ndynamics in time, notably partial differential equations (PDEs), in which the\nmanifold latent space evolves according to Ricci flow. This can be accomplished\nby simulating Ricci flow in a physics-informed setting, and manifold quantities\ncan be matched so that Ricci flow is empirically achieved. With our\nmethodology, the manifold is learned as part of the training procedure, so\nideal geometries may be discerned, while the evolution simultaneously induces a\nmore accommodating latent representation over static methods. We present our\nmethod on a range of numerical experiments consisting of PDEs that encompass\ndesirable characteristics such as periodicity and randomness, remarking error\non in-distribution and extrapolation scenarios.\n","authors":["Andrew Gracyk"],"pdf_url":"https://arxiv.org/pdf/2401.14591v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14899v1","updated":"2024-03-22T01:06:36Z","published":"2024-03-22T01:06:36Z","title":"Statistical Inference For Noisy Matrix Completion Incorporating\n  Auxiliary Information","summary":"  This paper investigates statistical inference for noisy matrix completion in\na semi-supervised model when auxiliary covariates are available. The model\nconsists of two parts. One part is a low-rank matrix induced by unobserved\nlatent factors; the other part models the effects of the observed covariates\nthrough a coefficient matrix which is composed of high-dimensional column\nvectors. We model the observational pattern of the responses through a logistic\nregression of the covariates, and allow its probability to go to zero as the\nsample size increases. We apply an iterative least squares (LS) estimation\napproach in our considered context. The iterative LS methods in general enjoy a\nlow computational cost, but deriving the statistical properties of the\nresulting estimators is a challenging task. We show that our method only needs\na few iterations, and the resulting entry-wise estimators of the low-rank\nmatrix and the coefficient matrix are guaranteed to have asymptotic normal\ndistributions. As a result, individual inference can be conducted for each\nentry of the unknown matrices. We also propose a simultaneous testing procedure\nwith multiplier bootstrap for the high-dimensional coefficient matrix. This\nsimultaneous inferential tool can help us further investigate the effects of\ncovariates for the prediction of missing entries.\n","authors":["Shujie Ma","Po-Yao Niu","Yichong Zhang","Yinchu Zhu"],"pdf_url":"https://arxiv.org/pdf/2403.14899v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10270v2","updated":"2024-03-22T00:08:51Z","published":"2023-11-17T01:30:43Z","title":"Multiscale Hodge Scattering Networks for Data Analysis","summary":"  We propose new scattering networks for signals measured on simplicial\ncomplexes, which we call \\emph{Multiscale Hodge Scattering Networks} (MHSNs).\nOur construction is based on multiscale basis dictionaries on simplicial\ncomplexes, i.e., the $\\kappa$-GHWT and $\\kappa$-HGLET, which we recently\ndeveloped for simplices of dimension $\\kappa \\in \\mathbb{N}$ in a given\nsimplicial complex by generalizing the node-based Generalized Haar-Walsh\nTransform (GHWT) and Hierarchical Graph Laplacian Eigen Transform (HGLET). The\n$\\kappa$-GHWT and the $\\kappa$-HGLET both form redundant sets (i.e.,\ndictionaries) of multiscale basis vectors and the corresponding expansion\ncoefficients of a given signal. Our MHSNs use a layered structure analogous to\na convolutional neural network (CNN) to cascade the moments of the modulus of\nthe dictionary coefficients. The resulting features are invariant to reordering\nof the simplices (i.e., node permutation of the underlying graphs).\nImportantly, the use of multiscale basis dictionaries in our MHSNs admits a\nnatural pooling operation that is akin to local pooling in CNNs, and which may\nbe performed either locally or per-scale. These pooling operations are harder\nto define in both traditional scattering networks based on Morlet wavelets, and\ngeometric scattering networks based on Diffusion Wavelets. As a result, we are\nable to extract a rich set of descriptive yet robust features that can be used\nalong with very simple machine learning methods (i.e., logistic regression or\nsupport vector machines) to achieve high-accuracy classification systems with\nfar fewer parameters to train than most modern graph neural networks. Finally,\nwe demonstrate the usefulness of our MHSNs in three distinct types of problems:\nsignal classification, domain (i.e., graph/simplex) classification, and\nmolecular dynamics prediction.\n","authors":["Naoki Saito","Stefan C. Schonsheck","Eugene Shvarts"],"pdf_url":"https://arxiv.org/pdf/2311.10270v2.pdf","comment":"20 Pages, Comments Welcome"}]},"2024-03-21T00:00:00Z":{"Computer Science and Game Theory":[{"id":"http://arxiv.org/abs/2307.09470v2","updated":"2024-03-21T19:12:08Z","published":"2023-07-13T19:05:11Z","title":"Multi-Player Zero-Sum Markov Games with Networked Separable Interactions","summary":"  We study a new class of Markov games, \\emph(multi-player) zero-sum Markov\nGames} with \\emph{Networked separable interactions} (zero-sum NMGs), to model\nthe local interaction structure in non-cooperative multi-agent sequential\ndecision-making. We define a zero-sum NMG as a model where {the payoffs of the\nauxiliary games associated with each state are zero-sum and} have some\nseparable (i.e., polymatrix) structure across the neighbors over some\ninteraction network. We first identify the necessary and sufficient conditions\nunder which an MG can be presented as a zero-sum NMG, and show that the set of\nMarkov coarse correlated equilibrium (CCE) collapses to the set of Markov Nash\nequilibrium (NE) in these games, in that the product of per-state\nmarginalization of the former for all players yields the latter. Furthermore,\nwe show that finding approximate Markov \\emph{stationary} CCE in\ninfinite-horizon discounted zero-sum NMGs is \\texttt{PPAD}-hard, unless the\nunderlying network has a ``star topology''. Then, we propose\nfictitious-play-type dynamics, the classical learning dynamics in normal-form\ngames, for zero-sum NMGs, and establish convergence guarantees to Markov\nstationary NE under a star-shaped network structure. Finally, in light of the\nhardness result, we focus on computing a Markov \\emph{non-stationary} NE and\nprovide finite-iteration guarantees for a series of value-iteration-based\nalgorithms. We also provide numerical experiments to corroborate our\ntheoretical results.\n","authors":["Chanwoo Park","Kaiqing Zhang","Asuman Ozdaglar"],"pdf_url":"https://arxiv.org/pdf/2307.09470v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.12258v5","updated":"2024-03-21T17:29:37Z","published":"2024-01-21T16:59:45Z","title":"Emergent Dominance Hierarchies in Reinforcement Learning Agents","summary":"  Modern Reinforcement Learning (RL) algorithms are able to outperform humans\nin a wide variety of tasks. Multi-agent reinforcement learning (MARL) settings\npresent additional challenges, and successful cooperation in mixed-motive\ngroups of agents depends on a delicate balancing act between individual and\ngroup objectives. Social conventions and norms, often inspired by human\ninstitutions, are used as tools for striking this balance.\n  In this paper, we examine a fundamental, well-studied social convention that\nunderlies cooperation in both animal and human societies: dominance\nhierarchies.\n  We adapt the ethological theory of dominance hierarchies to artificial\nagents, borrowing the established terminology and definitions with as few\namendments as possible. We demonstrate that populations of RL agents, operating\nwithout explicit programming or intrinsic rewards, can invent, learn, enforce,\nand transmit a dominance hierarchy to new populations. The dominance\nhierarchies that emerge have a similar structure to those studied in chickens,\nmice, fish, and other species.\n","authors":["Ram Rachum","Yonatan Nakar","Bill Tomlinson","Nitay Alon","Reuth Mirsky"],"pdf_url":"https://arxiv.org/pdf/2401.12258v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14443v1","updated":"2024-03-21T14:48:37Z","published":"2024-03-21T14:48:37Z","title":"Language Models Can Reduce Asymmetry in Information Markets","summary":"  This work addresses the buyer's inspection paradox for information markets.\nThe paradox is that buyers need to access information to determine its value,\nwhile sellers need to limit access to prevent theft. To study this, we\nintroduce an open-source simulated digital marketplace where intelligent\nagents, powered by language models, buy and sell information on behalf of\nexternal participants. The central mechanism enabling this marketplace is the\nagents' dual capabilities: they not only have the capacity to assess the\nquality of privileged information but also come equipped with the ability to\nforget. This ability to induce amnesia allows vendors to grant temporary access\nto proprietary information, significantly reducing the risk of unauthorized\nretention while enabling agents to accurately gauge the information's relevance\nto specific queries or tasks. To perform well, agents must make rational\ndecisions, strategically explore the marketplace through generated sub-queries,\nand synthesize answers from purchased information. Concretely, our experiments\n(a) uncover biases in language models leading to irrational behavior and\nevaluate techniques to mitigate these biases, (b) investigate how price affects\ndemand in the context of informational goods, and (c) show that inspection and\nhigher budgets both lead to higher quality outcomes.\n","authors":["Nasim Rahaman","Martin Weiss","Manuel Wüthrich","Yoshua Bengio","Li Erran Li","Chris Pal","Bernhard Schölkopf"],"pdf_url":"https://arxiv.org/pdf/2403.14443v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.03501v2","updated":"2024-03-21T10:48:26Z","published":"2023-10-05T12:25:48Z","title":"Designing Digital Voting Systems for Citizens: Achieving Fairness and\n  Legitimacy in Participatory Budgeting","summary":"  Participatory Budgeting (PB) has evolved into a key democratic instrument for\nresource allocation in cities. Enabled by digital platforms, cities now have\nthe opportunity to let citizens directly propose and vote on urban projects,\nusing different voting input and aggregation rules. However, the choices cities\nmake in terms of the rules of their PB have often not been informed by academic\nstudies on voter behaviour and preferences. Therefore, this work presents the\nresults of behavioural experiments where participants were asked to vote in a\nfictional PB setting. We identified approaches to designing PB voting that\nminimise cognitive load and enhance the perceived fairness and legitimacy of\nthe digital process from the citizens' perspective. In our study, participants\npreferred voting input formats that are more expressive (like rankings and\ndistributing points) over simpler formats (like approval voting). Participants\nalso indicated a desire for the budget to be fairly distributed across city\ndistricts and project categories. Participants found the Method of Equal Shares\nvoting rule to be fairer than the conventional Greedy voting rule. These\nfindings offer actionable insights for digital governance, contributing to the\ndevelopment of fairer and more transparent digital systems and collective\ndecision-making processes for citizens.\n","authors":["Joshua C. Yang","Carina I. Hausladen","Dominik Peters","Evangelos Pournaras","Regula Hänggli Fricker","Dirk Helbing"],"pdf_url":"https://arxiv.org/pdf/2310.03501v2.pdf","comment":"Under review in ACM Digital Government: Research and Practice"},{"id":"http://arxiv.org/abs/2307.09478v2","updated":"2024-03-21T10:28:38Z","published":"2023-07-14T09:16:24Z","title":"The Role of Transparency in Repeated First-Price Auctions with Unknown\n  Valuations","summary":"  We study the problem of regret minimization for a single bidder in a sequence\nof first-price auctions where the bidder discovers the item's value only if the\nauction is won. Our main contribution is a complete characterization, up to\nlogarithmic factors, of the minimax regret in terms of the auction's\n\\emph{transparency}, which controls the amount of information on competing bids\ndisclosed by the auctioneer at the end of each auction. Our results hold under\ndifferent assumptions (stochastic, adversarial, and their smoothed variants) on\nthe environment generating the bidder's valuations and competing bids. These\nminimax rates reveal how the interplay between transparency and the nature of\nthe environment affects how fast one can learn to bid optimally in first-price\nauctions.\n","authors":["Nicolò Cesa-Bianchi","Tommaso Cesari","Roberto Colomboni","Federico Fusco","Stefano Leonardi"],"pdf_url":"https://arxiv.org/pdf/2307.09478v2.pdf","comment":"Accepted at STOC 2024"},{"id":"http://arxiv.org/abs/2310.12928v2","updated":"2024-03-21T10:19:36Z","published":"2023-10-19T17:24:48Z","title":"Resolving social dilemmas with minimal reward transfer","summary":"  Multi-agent cooperation is an important topic, and is particularly\nchallenging in mixed-motive situations where it does not pay to be nice to\nothers. Consequently, self-interested agents often avoid collective behaviour,\nresulting in suboptimal outcomes for the group. In response, in this paper we\nintroduce a metric to quantify the disparity between what is rational for\nindividual agents and what is rational for the group, which we call the general\nself-interest level. This metric represents the maximum proportion of\nindividual rewards that all agents can retain while ensuring that achieving\nsocial welfare optimum becomes a dominant strategy. By aligning the individual\nand group incentives, rational agents acting to maximise their own reward will\nsimultaneously maximise the collective reward. As agents transfer their rewards\nto motivate others to consider their welfare, we diverge from traditional\nconcepts of altruism or prosocial behaviours. The general self-interest level\nis a property of a game that is useful for assessing the propensity of players\nto cooperate and understanding how features of a game impact this. We\nillustrate the effectiveness of our method on several novel games\nrepresentations of social dilemmas with arbitrary numbers of players.\n","authors":["Richard Willis","Yali Du","Joel Z Leibo","Michael Luck"],"pdf_url":"https://arxiv.org/pdf/2310.12928v2.pdf","comment":"34 pages, 13 tables, submitted to the Journal of Autonomous Agents\n  and Multi-Agent Systems: Special Issue on Citizen-Centric AI Systems"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2403.14838v1","updated":"2024-03-21T21:17:17Z","published":"2024-03-21T21:17:17Z","title":"An Analysis of the Preferences of Distribution Indicators in\n  Evolutionary Multi-Objective Optimization","summary":"  The distribution of objective vectors in a Pareto Front Approximation (PFA)\nis crucial for representing the associated manifold accurately. Distribution\nIndicators (DIs) assess the distribution of a PFA numerically, utilizing\nconcepts like distance calculation, Biodiversity, Entropy, Potential Energy, or\nClustering. Despite the diversity of DIs, their strengths and weaknesses across\nassessment scenarios are not well-understood. This paper introduces a taxonomy\nfor classifying DIs, followed by a preference analysis of nine DIs, each\nrepresenting a category in the taxonomy. Experimental results, considering\nvarious PFAs under controlled scenarios (loss of coverage, loss of uniformity,\npathological distributions), reveal that some DIs can be misleading and need\ncautious use. Additionally, DIs based on Biodiversity and Potential Energy show\npromise for PFA evaluation and comparison of Multi-Objective Evolutionary\nAlgorithms.\n","authors":["Jesús Guillermo Falcón-Cardona","Mahboubeh Nezhadmoghaddam","Emilio Bernal-Zubieta"],"pdf_url":"https://arxiv.org/pdf/2403.14838v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14484v1","updated":"2024-03-21T15:31:28Z","published":"2024-03-21T15:31:28Z","title":"HyperGALE: ASD Classification via Hypergraph Gated Attention with\n  Learnable Hyperedges","summary":"  Autism Spectrum Disorder (ASD) is a neurodevelopmental condition\ncharacterized by varied social cognitive challenges and repetitive behavioral\npatterns. Identifying reliable brain imaging-based biomarkers for ASD has been\na persistent challenge due to the spectrum's diverse symptomatology. Existing\nbaselines in the field have made significant strides in this direction, yet\nthere remains room for improvement in both performance and interpretability. We\npropose \\emph{HyperGALE}, which builds upon the hypergraph by incorporating\nlearned hyperedges and gated attention mechanisms. This approach has led to\nsubstantial improvements in the model's ability to interpret complex brain\ngraph data, offering deeper insights into ASD biomarker characterization.\nEvaluated on the extensive ABIDE II dataset, \\emph{HyperGALE} not only improves\ninterpretability but also demonstrates statistically significant enhancements\nin key performance metrics compared to both previous baselines and the\nfoundational hypergraph model. The advancement \\emph{HyperGALE} brings to ASD\nresearch highlights the potential of sophisticated graph-based techniques in\nneurodevelopmental studies. The source code and implementation instructions are\navailable at GitHub:https://github.com/mehular0ra/HyperGALE.\n","authors":["Mehul Arora","Chirag Shantilal Jain","Lalith Bharadwaj Baru","Kamalaker Dadi","Bapi Raju Surampudi"],"pdf_url":"https://arxiv.org/pdf/2403.14484v1.pdf","comment":"Accepted to IJCNN 2024"},{"id":"http://arxiv.org/abs/2403.14405v1","updated":"2024-03-21T13:54:03Z","published":"2024-03-21T13:54:03Z","title":"A reinforcement learning guided hybrid evolutionary algorithm for the\n  latency location routing problem","summary":"  The latency location routing problem integrates the facility location problem\nand the multi-depot cumulative capacitated vehicle routing problem. This\nproblem involves making simultaneous decisions about depot locations and\nvehicle routes to serve customers while aiming to minimize the sum of waiting\n(arriving) times for all customers. To address this computationally challenging\nproblem, we propose a reinforcement learning guided hybrid evolutionary\nalgorithm following the framework of the memetic algorithm. The proposed\nalgorithm relies on a diversity-enhanced multi-parent edge assembly crossover\nto build promising offspring and a reinforcement learning guided variable\nneighborhood descent to determine the exploration order of multiple\nneighborhoods. Additionally, strategic oscillation is used to achieve a\nbalanced exploration of both feasible and infeasible solutions. The\ncompetitiveness of the algorithm against state-of-the-art methods is\ndemonstrated by experimental results on the three sets of 76 popular instances,\nincluding 51 improved best solutions (new upper bounds) for the 59 instances\nwith unknown optima and equal best results for the remaining instances. We also\nconduct additional experiments to shed light on the key components of the\nalgorithm.\n","authors":["Yuji Zou","Jin-Kao Hao","Qinghua Wu"],"pdf_url":"https://arxiv.org/pdf/2403.14405v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14302v1","updated":"2024-03-21T11:16:42Z","published":"2024-03-21T11:16:42Z","title":"SpikingResformer: Bridging ResNet and Vision Transformer in Spiking\n  Neural Networks","summary":"  The remarkable success of Vision Transformers in Artificial Neural Networks\n(ANNs) has led to a growing interest in incorporating the self-attention\nmechanism and transformer-based architecture into Spiking Neural Networks\n(SNNs). While existing methods propose spiking self-attention mechanisms that\nare compatible with SNNs, they lack reasonable scaling methods, and the overall\narchitectures proposed by these methods suffer from a bottleneck in effectively\nextracting local features. To address these challenges, we propose a novel\nspiking self-attention mechanism named Dual Spike Self-Attention (DSSA) with a\nreasonable scaling method. Based on DSSA, we propose a novel spiking Vision\nTransformer architecture called SpikingResformer, which combines the\nResNet-based multi-stage architecture with our proposed DSSA to improve both\nperformance and energy efficiency while reducing parameters. Experimental\nresults show that SpikingResformer achieves higher accuracy with fewer\nparameters and lower energy consumption than other spiking Vision Transformer\ncounterparts. Notably, our SpikingResformer-L achieves 79.40% top-1 accuracy on\nImageNet with 4 time-steps, which is the state-of-the-art result in the SNN\nfield.\n","authors":["Xinyu Shi","Zecheng Hao","Zhaofei Yu"],"pdf_url":"https://arxiv.org/pdf/2403.14302v1.pdf","comment":"To be published in the 2024 IEEE/CVF Conference on Computer Vision\n  and Pattern Recognition (CVPR)"},{"id":"http://arxiv.org/abs/2403.14273v1","updated":"2024-03-21T10:26:47Z","published":"2024-03-21T10:26:47Z","title":"Reactor Optimization Benchmark by Reinforcement Learning","summary":"  Neutronic calculations for reactors are a daunting task when using Monte\nCarlo (MC) methods. As high-performance computing has advanced, the simulation\nof a reactor is nowadays more readily done, but design and optimization with\nmultiple parameters is still a computational challenge. MC transport\nsimulations, coupled with machine learning techniques, offer promising avenues\nfor enhancing the efficiency and effectiveness of nuclear reactor optimization.\nThis paper introduces a novel benchmark problem within the OpenNeoMC framework\ndesigned specifically for reinforcement learning. The benchmark involves\noptimizing a unit cell of a research reactor with two varying parameters (fuel\ndensity and water spacing) to maximize neutron flux while maintaining reactor\ncriticality. The test case features distinct local optima, representing\ndifferent physical regimes, thus posing a challenge for learning algorithms.\nThrough extensive simulations utilizing evolutionary and neuroevolutionary\nalgorithms, we demonstrate the effectiveness of reinforcement learning in\nnavigating complex optimization landscapes with strict constraints.\nFurthermore, we propose acceleration techniques within the OpenNeoMC framework,\nincluding model updating and cross-section usage by RAM utilization, to\nexpedite simulation times. Our findings emphasize the importance of machine\nlearning integration in reactor optimization and contribute to advancing\nmethodologies for addressing intricate optimization challenges in nuclear\nengineering. The sources of this work are available at our GitHub repository:\nhttps://github.com/Scientific-Computing-Lab-NRCN/RLOpenNeoMC\n","authors":["Deborah Schwarcz","Nadav Schneider","Gal Oren","Uri Steinitz"],"pdf_url":"https://arxiv.org/pdf/2403.14273v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.15141v3","updated":"2024-03-21T10:15:19Z","published":"2023-05-24T13:36:06Z","title":"From Tempered to Benign Overfitting in ReLU Neural Networks","summary":"  Overparameterized neural networks (NNs) are observed to generalize well even\nwhen trained to perfectly fit noisy data. This phenomenon motivated a large\nbody of work on \"benign overfitting\", where interpolating predictors achieve\nnear-optimal performance. Recently, it was conjectured and empirically observed\nthat the behavior of NNs is often better described as \"tempered overfitting\",\nwhere the performance is non-optimal yet also non-trivial, and degrades as a\nfunction of the noise level. However, a theoretical justification of this claim\nfor non-linear NNs has been lacking so far. In this work, we provide several\nresults that aim at bridging these complementing views. We study a simple\nclassification setting with 2-layer ReLU NNs, and prove that under various\nassumptions, the type of overfitting transitions from tempered in the extreme\ncase of one-dimensional data, to benign in high dimensions. Thus, we show that\nthe input dimension has a crucial role on the type of overfitting in this\nsetting, which we also validate empirically for intermediate dimensions.\nOverall, our results shed light on the intricate connections between the\ndimension, sample size, architecture and training algorithm on the one hand,\nand the type of resulting overfitting on the other hand.\n","authors":["Guy Kornowski","Gilad Yehudai","Ohad Shamir"],"pdf_url":"https://arxiv.org/pdf/2305.15141v3.pdf","comment":"NeurIPS 2023; fixed bug"},{"id":"http://arxiv.org/abs/2308.03574v2","updated":"2024-03-21T09:13:17Z","published":"2023-08-07T13:25:48Z","title":"Generalized Early Stopping in Evolutionary Direct Policy Search","summary":"  Lengthy evaluation times are common in many optimization problems such as\ndirect policy search tasks, especially when they involve conducting evaluations\nin the physical world, e.g. in robotics applications. Often when evaluating\nsolution over a fixed time period it becomes clear that the objective value\nwill not increase with additional computation time (for example when a two\nwheeled robot continuously spins on the spot). In such cases, it makes sense to\nstop the evaluation early to save computation time. However, most approaches to\nstop the evaluation are problem specific and need to be specifically designed\nfor the task at hand. Therefore, we propose an early stopping method for direct\npolicy search. The proposed method only looks at the objective value at each\ntime step and requires no problem specific knowledge. We test the introduced\nstopping criterion in five direct policy search environments drawn from games,\nrobotics and classic control domains, and show that it can save up to 75% of\nthe computation time. We also compare it with problem specific stopping\ncriteria and show that it performs comparably, while being more generally\napplicable.\n","authors":["Etor Arza","Leni K. Le Goff","Emma Hart"],"pdf_url":"https://arxiv.org/pdf/2308.03574v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14224v1","updated":"2024-03-21T08:30:44Z","published":"2024-03-21T08:30:44Z","title":"Stitching for Neuroevolution: Recombining Deep Neural Networks without\n  Breaking Them","summary":"  Traditional approaches to neuroevolution often start from scratch. This\nbecomes prohibitively expensive in terms of computational and data requirements\nwhen targeting modern, deep neural networks. Using a warm start could be highly\nadvantageous, e.g., using previously trained networks, potentially from\ndifferent sources. This moreover enables leveraging the benefits of transfer\nlearning (in particular vastly reduced training effort). However, recombining\ntrained networks is non-trivial because architectures and feature\nrepresentations typically differ. Consequently, a straightforward exchange of\nlayers tends to lead to a performance breakdown. We overcome this by matching\nthe layers of parent networks based on their connectivity, identifying\npotential crossover points. To correct for differing feature representations\nbetween these layers we employ stitching, which merges the networks by\nintroducing new layers at crossover points. To train the merged network, only\nstitching layers need to be considered. New networks can then be created by\nselecting a subnetwork by choosing which stitching layers to (not) use.\nAssessing their performance is efficient as only their evaluation on data is\nrequired. We experimentally show that our approach enables finding networks\nthat represent novel trade-offs between performance and computational cost,\nwith some even dominating the original networks.\n","authors":["Arthur Guijt","Dirk Thierens","Tanja Alderliesten","Peter A. N. Bosman"],"pdf_url":"https://arxiv.org/pdf/2403.14224v1.pdf","comment":"10 pages, submitted to GECCO 2024"},{"id":"http://arxiv.org/abs/2403.13795v2","updated":"2024-03-21T08:14:36Z","published":"2023-11-22T14:18:30Z","title":"PyVRP: a high-performance VRP solver package","summary":"  We introduce PyVRP, a Python package that implements hybrid genetic search in\na state-of-the-art vehicle routing problem (VRP) solver. The package is\ndesigned for the VRP with time windows (VRPTW), but can be easily extended to\nsupport other VRP variants. PyVRP combines the flexibility of Python with the\nperformance of C++, by implementing (only) performance critical parts of the\nalgorithm in C++, while being fully customisable at the Python level. PyVRP is\na polished implementation of the algorithm that ranked 1st in the 2021 DIMACS\nVRPTW challenge and, after improvements, ranked 1st on the static variant of\nthe EURO meets NeurIPS 2022 vehicle routing competition. The code follows good\nsoftware engineering practices, and is well-documented and unit tested. PyVRP\nis freely available under the liberal MIT license. Through numerical\nexperiments we show that PyVRP achieves state-of-the-art results on the VRPTW\nand capacitated VRP. We hope that PyVRP enables researchers and practitioners\nto easily and quickly build on a state-of-the-art VRP solver.\n","authors":["Niels A. Wouda","Leon Lan","Wouter Kool"],"pdf_url":"https://arxiv.org/pdf/2403.13795v2.pdf","comment":"Pre-print of accepted paper in INFORMS Journal on Computing. 24\n  pages, 1 figure, 2 listings"},{"id":"http://arxiv.org/abs/2403.14146v1","updated":"2024-03-21T05:42:17Z","published":"2024-03-21T05:42:17Z","title":"Evolving Benchmark Functions to Compare Evolutionary Algorithms via\n  Genetic Programming","summary":"  In this study, we use Genetic Programming (GP) to compose new optimization\nbenchmark functions. Optimization benchmarks have the important role of showing\nthe differences between evolutionary algorithms, making it possible for further\nanalysis and comparisons. We show that the benchmarks generated by GP are able\nto differentiate algorithms better than human-made benchmark functions. The\nfitness measure of the GP is the Wasserstein distance of the solutions found by\na pair of optimizers. Additionally, we use MAP-Elites to both enhance the\nsearch power of the GP and also illustrate how the difference between\noptimizers changes by various landscape features. Our approach provides a novel\nway to automate the design of benchmark functions and to compare evolutionary\nalgorithms.\n","authors":["Yifan He","Claus Aranha"],"pdf_url":"https://arxiv.org/pdf/2403.14146v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14139v1","updated":"2024-03-21T05:17:22Z","published":"2024-03-21T05:17:22Z","title":"Genetic Programming for Explainable Manifold Learning","summary":"  Manifold learning techniques play a pivotal role in machine learning by\nrevealing lower-dimensional embeddings within high-dimensional data, thus\nenhancing both the efficiency and interpretability of data analysis by\ntransforming the data into a lower-dimensional representation. However, a\nnotable challenge with current manifold learning methods is their lack of\nexplicit functional mappings, crucial for explainability in many real-world\napplications. Genetic programming, known for its interpretable functional\ntree-based models, has emerged as a promising approach to address this\nchallenge. Previous research leveraged multi-objective GP to balance manifold\nquality against embedding dimensionality, producing functional mappings across\na range of embedding sizes. Yet, these mapping trees often became complex,\nhindering explainability. In response, in this paper, we introduce Genetic\nProgramming for Explainable Manifold Learning (GP-EMaL), a novel approach that\ndirectly penalises tree complexity. Our new method is able to maintain high\nmanifold quality while significantly enhancing explainability and also allows\ncustomisation of complexity measures, such as symmetry balancing, scaling, and\nnode complexity, catering to diverse application needs. Our experimental\nanalysis demonstrates that GP-EMaL is able to match the performance of the\nexisting approach in most cases, while using simpler, smaller, and more\ninterpretable tree structures. This advancement marks a significant step\ntowards achieving interpretable manifold learning.\n","authors":["Ben Cravens","Andrew Lensen","Paula Maddigan","Bing Xue"],"pdf_url":"https://arxiv.org/pdf/2403.14139v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15480v1","updated":"2024-03-21T03:11:53Z","published":"2024-03-21T03:11:53Z","title":"SpikeGraphormer: A High-Performance Graph Transformer with Spiking Graph\n  Attention","summary":"  Recently, Graph Transformers have emerged as a promising solution to\nalleviate the inherent limitations of Graph Neural Networks (GNNs) and enhance\ngraph representation performance. Unfortunately, Graph Transformers are\ncomputationally expensive due to the quadratic complexity inherent in\nself-attention when applied over large-scale graphs, especially for node tasks.\nIn contrast, spiking neural networks (SNNs), with event-driven and binary\nspikes properties, can perform energy-efficient computation. In this work, we\npropose a novel insight into integrating SNNs with Graph Transformers and\ndesign a Spiking Graph Attention (SGA) module. The matrix multiplication is\nreplaced by sparse addition and mask operations. The linear complexity enables\nall-pair node interactions on large-scale graphs with limited GPU memory. To\nour knowledge, our work is the first attempt to introduce SNNs into Graph\nTransformers. Furthermore, we design SpikeGraphormer, a Dual-branch\narchitecture, combining a sparse GNN branch with our SGA-driven Graph\nTransformer branch, which can simultaneously perform all-pair node interactions\nand capture local neighborhoods. SpikeGraphormer consistently outperforms\nexisting state-of-the-art approaches across various datasets and makes\nsubstantial improvements in training time, inference time, and GPU memory cost\n(10 ~ 20x lower than vanilla self-attention). It also performs well in\ncross-domain applications (image and text classification). We release our code\nat https://github.com/PHD-lanyu/SpikeGraphormer.\n","authors":["Yundong Sun","Dongjie Zhu","Yansong Wang","Zhaoshuo Tian","Ning Cao","Gregory O'Hared"],"pdf_url":"https://arxiv.org/pdf/2403.15480v1.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2403.14830v1","updated":"2024-03-21T20:43:44Z","published":"2024-03-21T20:43:44Z","title":"Deep Clustering Evaluation: How to Validate Internal Clustering\n  Validation Measures","summary":"  Deep clustering, a method for partitioning complex, high-dimensional data\nusing deep neural networks, presents unique evaluation challenges. Traditional\nclustering validation measures, designed for low-dimensional spaces, are\nproblematic for deep clustering, which involves projecting data into\nlower-dimensional embeddings before partitioning. Two key issues are\nidentified: 1) the curse of dimensionality when applying these measures to raw\ndata, and 2) the unreliable comparison of clustering results across different\nembedding spaces stemming from variations in training procedures and parameter\nsettings in different clustering models. This paper addresses these challenges\nin evaluating clustering quality in deep learning. We present a theoretical\nframework to highlight ineffectiveness arising from using internal validation\nmeasures on raw and embedded data and propose a systematic approach to applying\nclustering validity indices in deep clustering contexts. Experiments show that\nthis framework aligns better with external validation measures, effectively\nreducing the misguidance from the improper use of clustering validity indices\nin deep learning.\n","authors":["Zeya Wang","Chenglong Ye"],"pdf_url":"https://arxiv.org/pdf/2403.14830v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14829v1","updated":"2024-03-21T20:43:34Z","published":"2024-03-21T20:43:34Z","title":"Hyperbolic Secant representation of the logistic function: Application\n  to probabilistic Multiple Instance Learning for CT intracranial hemorrhage\n  detection","summary":"  Multiple Instance Learning (MIL) is a weakly supervised paradigm that has\nbeen successfully applied to many different scientific areas and is\nparticularly well suited to medical imaging. Probabilistic MIL methods, and\nmore specifically Gaussian Processes (GPs), have achieved excellent results due\nto their high expressiveness and uncertainty quantification capabilities. One\nof the most successful GP-based MIL methods, VGPMIL, resorts to a variational\nbound to handle the intractability of the logistic function. Here, we formulate\nVGPMIL using P\\'olya-Gamma random variables. This approach yields the same\nvariational posterior approximations as the original VGPMIL, which is a\nconsequence of the two representations that the Hyperbolic Secant distribution\nadmits. This leads us to propose a general GP-based MIL method that takes\ndifferent forms by simply leveraging distributions other than the Hyperbolic\nSecant one. Using the Gamma distribution we arrive at a new approach that\nobtains competitive or superior predictive performance and efficiency. This is\nvalidated in a comprehensive experimental study including one synthetic MIL\ndataset, two well-known MIL benchmarks, and a real-world medical problem. We\nexpect that this work provides useful ideas beyond MIL that can foster further\nresearch in the field.\n","authors":["F. M. Castro-Macías","P. Morales-Álvarez","Y. Wu","R. Molina","A. K. Katsaggelos"],"pdf_url":"https://arxiv.org/pdf/2403.14829v1.pdf","comment":"48 pages, 12 figures, published in Artificial Intelligence Journal"},{"id":"http://arxiv.org/abs/2403.14822v1","updated":"2024-03-21T20:29:43Z","published":"2024-03-21T20:29:43Z","title":"Non-Convex Robust Hypothesis Testing using Sinkhorn Uncertainty Sets","summary":"  We present a new framework to address the non-convex robust hypothesis\ntesting problem, wherein the goal is to seek the optimal detector that\nminimizes the maximum of worst-case type-I and type-II risk functions. The\ndistributional uncertainty sets are constructed to center around the empirical\ndistribution derived from samples based on Sinkhorn discrepancy. Given that the\nobjective involves non-convex, non-smooth probabilistic functions that are\noften intractable to optimize, existing methods resort to approximations rather\nthan exact solutions. To tackle the challenge, we introduce an exact\nmixed-integer exponential conic reformulation of the problem, which can be\nsolved into a global optimum with a moderate amount of input data.\nSubsequently, we propose a convex approximation, demonstrating its superiority\nover current state-of-the-art methodologies in literature. Furthermore, we\nestablish connections between robust hypothesis testing and regularized\nformulations of non-robust risk functions, offering insightful interpretations.\nOur numerical study highlights the satisfactory testing performance and\ncomputational efficiency of the proposed framework.\n","authors":["Jie Wang","Rui Gao","Yao Xie"],"pdf_url":"https://arxiv.org/pdf/2403.14822v1.pdf","comment":"26 pages, 2 figures"},{"id":"http://arxiv.org/abs/2403.14813v1","updated":"2024-03-21T19:59:07Z","published":"2024-03-21T19:59:07Z","title":"Curvature Augmented Manifold Embedding and Learning","summary":"  A new dimensional reduction (DR) and data visualization method,\nCurvature-Augmented Manifold Embedding and Learning (CAMEL), is proposed. The\nkey novel contribution is to formulate the DR problem as a mechanistic/physics\nmodel, where the force field among nodes (data points) is used to find an\nn-dimensional manifold representation of the data sets. Compared with many\nexisting attractive-repulsive force-based methods, one unique contribution of\nthe proposed method is to include a non-pairwise force. A new force field model\nis introduced and discussed, inspired by the multi-body potential in\nlattice-particle physics and Riemann curvature in topology. A\ncurvature-augmented force is included in CAMEL. Following this, CAMEL\nformulation for unsupervised learning, supervised learning, semi-supervised\nlearning/metric learning, and inverse learning are provided. Next, CAMEL is\napplied to many benchmark datasets by comparing existing models, such as tSNE,\nUMAP, TRIMAP, and PacMap. Both visual comparison and metrics-based evaluation\nare performed. 14 open literature and self-proposed metrics are employed for a\ncomprehensive comparison. Conclusions and future work are suggested based on\nthe current investigation. Related code and demonstration are available on\nhttps://github.com/ymlasu/CAMEL for interested readers to reproduce the results\nand other applications.\n","authors":["Yongming Liu"],"pdf_url":"https://arxiv.org/pdf/2403.14813v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14593v1","updated":"2024-03-21T17:48:38Z","published":"2024-03-21T17:48:38Z","title":"Rethinking Adversarial Inverse Reinforcement Learning: From the Angles\n  of Policy Imitation and Transferable Reward Recovery","summary":"  Adversarial inverse reinforcement learning (AIRL) stands as a cornerstone\napproach in imitation learning. This paper rethinks the two different angles of\nAIRL: policy imitation and transferable reward recovery. We begin with\nsubstituting the built-in algorithm in AIRL with soft actor-critic (SAC) during\nthe policy optimization process to enhance sample efficiency, thanks to the\noff-policy formulation of SAC and identifiable Markov decision process (MDP)\nmodels with respect to AIRL. It indeed exhibits a significant improvement in\npolicy imitation but accidentally brings drawbacks to transferable reward\nrecovery. To learn this issue, we illustrate that the SAC algorithm itself is\nnot feasible to disentangle the reward function comprehensively during the AIRL\ntraining process, and propose a hybrid framework, PPO-AIRL + SAC, for\nsatisfactory transfer effect. Additionally, we analyze the capability of\nenvironments to extract disentangled rewards from an algebraic theory\nperspective.\n","authors":["Yangchun Zhang","Yirui Zhou"],"pdf_url":"https://arxiv.org/pdf/2403.14593v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14573v1","updated":"2024-03-21T17:20:23Z","published":"2024-03-21T17:20:23Z","title":"A Transfer Learning Causal Approach to Evaluate Racial/Ethnic and\n  Geographic Variation in Outcomes Following Congenital Heart Surgery","summary":"  Congenital heart defects (CHD) are the most prevalent birth defects in the\nUnited States and surgical outcomes vary considerably across the country. The\noutcomes of treatment for CHD differ for specific patient subgroups, with\nnon-Hispanic Black and Hispanic populations experiencing higher rates of\nmortality and morbidity. A valid comparison of outcomes within racial/ethnic\nsubgroups is difficult given large differences in case-mix and small subgroup\nsizes. We propose a causal inference framework for outcome assessment and\nleverage advances in transfer learning to incorporate data from both target and\nsource populations to help estimate causal effects while accounting for\ndifferent sources of risk factor and outcome differences across populations.\nUsing the Society of Thoracic Surgeons' Congenital Heart Surgery Database\n(STS-CHSD), we focus on a national cohort of patients undergoing the Norwood\noperation from 2016-2022 to assess operative mortality and morbidity outcomes\nacross U.S. geographic regions by race/ethnicity. We find racial and ethnic\noutcome differences after controlling for potential confounding factors. While\ngeography does not have a causal effect on outcomes for non-Hispanic Caucasian\npatients, non-Hispanic Black patients experience wide variability in outcomes\nwith estimated 30-day mortality ranging from 5.9% (standard error 2.2%) to\n21.6% (4.4%) across U.S. regions.\n","authors":["Larry Han","Yi Zhang","Meena Nathan","John E. Mayer, Jr.","Sara K. Pasquali","Katya Zelevinsky","Rui Duan","Sharon-Lise T. Normand"],"pdf_url":"https://arxiv.org/pdf/2403.14573v1.pdf","comment":"26 pages"},{"id":"http://arxiv.org/abs/2312.09234v3","updated":"2024-03-21T16:26:09Z","published":"2023-12-14T18:57:16Z","title":"Let's do the time-warp-attend: Learning topological invariants of\n  dynamical systems","summary":"  Dynamical systems across the sciences, from electrical circuits to ecological\nnetworks, undergo qualitative and often catastrophic changes in behavior,\ncalled bifurcations, when their underlying parameters cross a threshold.\nExisting methods predict oncoming catastrophes in individual systems but are\nprimarily time-series-based and struggle both to categorize qualitative\ndynamical regimes across diverse systems and to generalize to real data. To\naddress this challenge, we propose a data-driven, physically-informed\ndeep-learning framework for classifying dynamical regimes and characterizing\nbifurcation boundaries based on the extraction of topologically invariant\nfeatures. We focus on the paradigmatic case of the supercritical Hopf\nbifurcation, which is used to model periodic dynamics across a wide range of\napplications. Our convolutional attention method is trained with data\naugmentations that encourage the learning of topological invariants which can\nbe used to detect bifurcation boundaries in unseen systems and to design models\nof biological systems like oscillatory gene regulatory networks. We further\ndemonstrate our method's use in analyzing real data by recovering distinct\nproliferation and differentiation dynamics along pancreatic endocrinogenesis\ntrajectory in gene expression space based on single-cell data. Our method\nprovides valuable insights into the qualitative, long-term behavior of a wide\nrange of dynamical systems, and can detect bifurcations or catastrophic\ntransitions in large-scale physical and biological systems.\n","authors":["Noa Moriel","Matthew Ricci","Mor Nitzan"],"pdf_url":"https://arxiv.org/pdf/2312.09234v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.12032v2","updated":"2024-03-21T14:36:26Z","published":"2023-10-18T15:16:24Z","title":"Exact and general decoupled solutions of the LMC Multitask Gaussian\n  Process model","summary":"  The Linear Model of Co-regionalization (LMC) is a very general model of\nmultitask gaussian process for regression or classification. While its\nexpressivity and conceptual simplicity are appealing, naive implementations\nhave cubic complexity in the number of datapoints and number of tasks, making\napproximations mandatory for most applications. However, recent work has shown\nthat under some conditions the latent processes of the model can be decoupled,\nleading to a complexity that is only linear in the number of said processes. We\nhere extend these results, showing from the most general assumptions that the\nonly condition necessary to an efficient exact computation of the LMC is a mild\nhypothesis on the noise model. We introduce a full parametrization of the\nresulting \\emph{projected LMC} model, and an expression of the marginal\nlikelihood enabling efficient optimization. We perform a parametric study on\nsynthetic data to show the excellent performance of our approach, compared to\nan unrestricted exact LMC and approximations of the latter. Overall, the\nprojected LMC appears as a credible and simpler alternative to state-of-the art\nmodels, which greatly facilitates some computations such as leave-one-out\ncross-validation and fantasization.\n","authors":["Olivier Truffinet","Karim Ammar","Jean-Philippe Argaud","Bertrand Bouriquet"],"pdf_url":"https://arxiv.org/pdf/2310.12032v2.pdf","comment":"29 pages, 10 figures, submitted to UAI"},{"id":"http://arxiv.org/abs/2209.10053v5","updated":"2024-03-21T14:12:15Z","published":"2022-09-21T00:44:20Z","title":"Instance-dependent uniform tail bounds for empirical processes","summary":"  We formulate a uniform tail bound for empirical processes indexed by a class\nof functions, in terms of the individual deviations of the functions rather\nthan the worst-case deviation in the considered class. The tail bound is\nestablished by introducing an initial \"deflation\" step to the standard generic\nchaining argument. The resulting tail bound is the sum of the complexity of the\n\"deflated function class\" in terms of a generalization of Talagrand's $\\gamma$\nfunctional, and the deviation of the function instance, both of which are\nformulated based on the natural seminorm induced by the corresponding\nCram\\'{e}r functions. We also provide certain approximations for the mentioned\nseminorm when the function class lies in a given (exponential type) Orlicz\nspace, that can be used to make the complexity term and the deviation term more\nexplicit.\n","authors":["Sohail Bahmani"],"pdf_url":"https://arxiv.org/pdf/2209.10053v5.pdf","comment":"25 pages. Revised and extended one of the examples for a more clear,\n  detailed, and accurate description"},{"id":"http://arxiv.org/abs/2403.14385v1","updated":"2024-03-21T13:21:33Z","published":"2024-03-21T13:21:33Z","title":"Estimating Causal Effects with Double Machine Learning -- A Method\n  Evaluation","summary":"  The estimation of causal effects with observational data continues to be a\nvery active research area. In recent years, researchers have developed new\nframeworks which use machine learning to relax classical assumptions necessary\nfor the estimation of causal effects. In this paper, we review one of the most\nprominent methods - \"double/debiased machine learning\" (DML) - and empirically\nevaluate it by comparing its performance on simulated data relative to more\ntraditional statistical methods, before applying it to real-world data. Our\nfindings indicate that the application of a suitably flexible machine learning\nalgorithm within DML improves the adjustment for various nonlinear confounding\nrelationships. This advantage enables a departure from traditional functional\nform assumptions typically necessary in causal effect estimation. However, we\ndemonstrate that the method continues to critically depend on standard\nassumptions about causal structure and identification. When estimating the\neffects of air pollution on housing prices in our application, we find that DML\nestimates are consistently larger than estimates of less flexible methods. From\nour overall results, we provide actionable recommendations for specific choices\nresearchers must make when applying DML in practice.\n","authors":["Jonathan Fuhr","Philipp Berens","Dominik Papies"],"pdf_url":"https://arxiv.org/pdf/2403.14385v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.10326v2","updated":"2024-03-21T12:54:04Z","published":"2024-02-15T21:01:29Z","title":"Mathematical Opportunities in Digital Twins (MATH-DT)","summary":"  The report describes the discussions from the Workshop on Mathematical\nOpportunities in Digital Twins (MATH-DT) from December 11-13, 2023, George\nMason University.\n  It illustrates that foundational Mathematical advances are required for\nDigital Twins (DTs) that are different from traditional approaches. A\ntraditional model, in biology, physics, engineering or medicine, starts with a\ngeneric physical law (e.g., equations) and is often a simplification of\nreality. A DT starts with a specific ecosystem, object or person (e.g.,\npersonalized care) representing reality, requiring multi -scale, -physics\nmodeling and coupling. Thus, these processes begin at opposite ends of the\nsimulation and modeling pipeline, requiring different reliability criteria and\nuncertainty assessments. Additionally, unlike existing approaches, a DT assists\nhumans to make decisions for the physical system, which (via sensors) in turn\nfeeds data into the DT, and operates for the life of the physical system.\n  While some of the foundational mathematical research can be done without a\nspecific application context, one must also keep specific applications in mind\nfor DTs. E.g., modeling a bridge or a biological system (a patient), or a\nsocio-technical system (a city) is very different. The models range from\ndifferential equations (deterministic/uncertain) in engineering, to stochastic\nin biology, including agent-based. These are multi-scale hybrid models or large\nscale (multi-objective) optimization problems under uncertainty. There are no\nuniversal models or approaches. For e.g., Kalman filters for forecasting might\nwork in engineering, but can fail in biomedical domain. Ad hoc studies, with\nlimited systematic work, have shown that AI/ML methods can fail for simple\nengineering systems and can work well for biomedical problems.\n  A list of `Mathematical Opportunities and Challenges' concludes the report.\n","authors":["Harbir Antil"],"pdf_url":"https://arxiv.org/pdf/2402.10326v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.03054v3","updated":"2024-03-21T12:43:34Z","published":"2023-10-04T11:40:02Z","title":"Posterior Sampling Based on Gradient Flows of the MMD with Negative\n  Distance Kernel","summary":"  We propose conditional flows of the maximum mean discrepancy (MMD) with the\nnegative distance kernel for posterior sampling and conditional generative\nmodeling. This MMD, which is also known as energy distance, has several\nadvantageous properties like efficient computation via slicing and sorting. We\napproximate the joint distribution of the ground truth and the observations\nusing discrete Wasserstein gradient flows and establish an error bound for the\nposterior distributions. Further, we prove that our particle flow is indeed a\nWasserstein gradient flow of an appropriate functional. The power of our method\nis demonstrated by numerical examples including conditional image generation\nand inverse problems like superresolution, inpainting and computed tomography\nin low-dose and limited-angle settings.\n","authors":["Paul Hagemann","Johannes Hertrich","Fabian Altekrüger","Robert Beinert","Jannis Chemseddine","Gabriele Steidl"],"pdf_url":"https://arxiv.org/pdf/2310.03054v3.pdf","comment":"Published as a conference paper at ICLR 2024"},{"id":"http://arxiv.org/abs/2303.10712v2","updated":"2024-03-21T12:19:24Z","published":"2023-03-19T16:43:17Z","title":"Mixture of segmentation for heterogeneous functional data","summary":"  In this paper we consider functional data with heterogeneity in time and in\npopulation. We propose a mixture model with segmentation of time to represent\nthis heterogeneity while keeping the functional structure. Maximum likelihood\nestimator is considered, proved to be identifiable and consistent. In practice,\nan EM algorithm is used, combined with dynamic programming for the maximization\nstep, to approximate the maximum likelihood estimator. The method is\nillustrated on a simulated dataset, and used on a real dataset of electricity\nconsumption.\n","authors":["Vincent Brault","Émilie Devijver","Charlotte Laclau"],"pdf_url":"https://arxiv.org/pdf/2303.10712v2.pdf","comment":"45 pages, 13 figures"},{"id":"http://arxiv.org/abs/2305.15141v3","updated":"2024-03-21T10:15:19Z","published":"2023-05-24T13:36:06Z","title":"From Tempered to Benign Overfitting in ReLU Neural Networks","summary":"  Overparameterized neural networks (NNs) are observed to generalize well even\nwhen trained to perfectly fit noisy data. This phenomenon motivated a large\nbody of work on \"benign overfitting\", where interpolating predictors achieve\nnear-optimal performance. Recently, it was conjectured and empirically observed\nthat the behavior of NNs is often better described as \"tempered overfitting\",\nwhere the performance is non-optimal yet also non-trivial, and degrades as a\nfunction of the noise level. However, a theoretical justification of this claim\nfor non-linear NNs has been lacking so far. In this work, we provide several\nresults that aim at bridging these complementing views. We study a simple\nclassification setting with 2-layer ReLU NNs, and prove that under various\nassumptions, the type of overfitting transitions from tempered in the extreme\ncase of one-dimensional data, to benign in high dimensions. Thus, we show that\nthe input dimension has a crucial role on the type of overfitting in this\nsetting, which we also validate empirically for intermediate dimensions.\nOverall, our results shed light on the intricate connections between the\ndimension, sample size, architecture and training algorithm on the one hand,\nand the type of resulting overfitting on the other hand.\n","authors":["Guy Kornowski","Gilad Yehudai","Ohad Shamir"],"pdf_url":"https://arxiv.org/pdf/2305.15141v3.pdf","comment":"NeurIPS 2023; fixed bug"},{"id":"http://arxiv.org/abs/2308.03574v2","updated":"2024-03-21T09:13:17Z","published":"2023-08-07T13:25:48Z","title":"Generalized Early Stopping in Evolutionary Direct Policy Search","summary":"  Lengthy evaluation times are common in many optimization problems such as\ndirect policy search tasks, especially when they involve conducting evaluations\nin the physical world, e.g. in robotics applications. Often when evaluating\nsolution over a fixed time period it becomes clear that the objective value\nwill not increase with additional computation time (for example when a two\nwheeled robot continuously spins on the spot). In such cases, it makes sense to\nstop the evaluation early to save computation time. However, most approaches to\nstop the evaluation are problem specific and need to be specifically designed\nfor the task at hand. Therefore, we propose an early stopping method for direct\npolicy search. The proposed method only looks at the objective value at each\ntime step and requires no problem specific knowledge. We test the introduced\nstopping criterion in five direct policy search environments drawn from games,\nrobotics and classic control domains, and show that it can save up to 75% of\nthe computation time. We also compare it with problem specific stopping\ncriteria and show that it performs comparably, while being more generally\napplicable.\n","authors":["Etor Arza","Leni K. Le Goff","Emma Hart"],"pdf_url":"https://arxiv.org/pdf/2308.03574v2.pdf","comment":null},{"id":"http://arxiv.org/abs/1902.06931v5","updated":"2024-03-21T09:01:19Z","published":"2019-02-19T07:27:19Z","title":"On the consistency of supervised learning with missing values","summary":"  In many application settings, the data have missing entries which make\nanalysis challenging. An abundant literature addresses missing values in an\ninferential framework: estimating parameters and their variance from incomplete\ntables. Here, we consider supervised-learning settings: predicting a target\nwhen missing values appear in both training and testing data. We show the\nconsistency of two approaches in prediction. A striking result is that the\nwidely-used method of imputing with a constant, such as the mean prior to\nlearning is consistent when missing values are not informative. This contrasts\nwith inferential settings where mean imputation is pointed at for distorting\nthe distribution of the data. That such a simple approach can be consistent is\nimportant in practice. We also show that a predictor suited for complete\nobservations can predict optimally on incomplete data, through multiple\nimputation. Finally, to compare imputation with learning directly with a model\nthat accounts for missing values, we analyze further decision trees. These can\nnaturally tackle empirical risk minimization with missing values, due to their\nability to handle the half-discrete nature of incomplete variables. After\ncomparing theoretically and empirically different missing values strategies in\ntrees, we recommend using the \"missing incorporated in attribute\" method as it\ncan handle both non-informative and informative missing values.\n","authors":["Julie Josse","Jacob M. Chen","Nicolas Prost","Erwan Scornet","Gaël Varoquaux"],"pdf_url":"https://arxiv.org/pdf/1902.06931v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14228v1","updated":"2024-03-21T08:39:13Z","published":"2024-03-21T08:39:13Z","title":"Recovering Latent Confounders from High-dimensional Proxy Variables","summary":"  Detecting latent confounders from proxy variables is an essential problem in\ncausal effect estimation. Previous approaches are limited to low-dimensional\nproxies, sorted proxies, and binary treatments. We remove these assumptions and\npresent a novel Proxy Confounder Factorization (PCF) framework for continuous\ntreatment effect estimation when latent confounders manifest through\nhigh-dimensional, mixed proxy variables. For specific sample sizes, our\ntwo-step PCF implementation, using Independent Component Analysis (ICA-PCF),\nand the end-to-end implementation, using Gradient Descent (GD-PCF), achieve\nhigh correlation with the latent confounder and low absolute error in causal\neffect estimation with synthetic datasets in the high sample size regime. Even\nwhen faced with climate data, ICA-PCF recovers four components that explain\n$75.9\\%$ of the variance in the North Atlantic Oscillation, a known confounder\nof precipitation patterns in Europe. Code for our PCF implementations and\nexperiments can be found here: https://github.com/IPL-UV/confound_it. The\nproposed methodology constitutes a stepping stone towards discovering latent\nconfounders and can be applied to many problems in disciplines dealing with\nhigh-dimensional observed proxies, e.g., spatiotemporal fields.\n","authors":["Nathan Mankovich","Homer Durand","Emiliano Diaz","Gherardo Varando","Gustau Camps-Valls"],"pdf_url":"https://arxiv.org/pdf/2403.14228v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.14225v1","updated":"2024-03-21T08:31:36Z","published":"2024-03-21T08:31:36Z","title":"Posterior concentrations of fully-connected Bayesian neural networks\n  with general priors on the weights","summary":"  Bayesian approaches for training deep neural networks (BNNs) have received\nsignificant interest and have been effectively utilized in a wide range of\napplications. There have been several studies on the properties of posterior\nconcentrations of BNNs. However, most of these studies only demonstrate results\nin BNN models with sparse or heavy-tailed priors. Surprisingly, no theoretical\nresults currently exist for BNNs using Gaussian priors, which are the most\ncommonly used one. The lack of theory arises from the absence of approximation\nresults of Deep Neural Networks (DNNs) that are non-sparse and have bounded\nparameters. In this paper, we present a new approximation theory for non-sparse\nDNNs with bounded parameters. Additionally, based on the approximation theory,\nwe show that BNNs with non-sparse general priors can achieve near-minimax\noptimal posterior concentration rates to the true model.\n","authors":["Insung Kong","Yongdai Kim"],"pdf_url":"https://arxiv.org/pdf/2403.14225v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.02712v2","updated":"2024-03-21T07:20:35Z","published":"2023-10-04T10:28:38Z","title":"ED-NeRF: Efficient Text-Guided Editing of 3D Scene with Latent Space\n  NeRF","summary":"  Recently, there has been a significant advancement in text-to-image diffusion\nmodels, leading to groundbreaking performance in 2D image generation. These\nadvancements have been extended to 3D models, enabling the generation of novel\n3D objects from textual descriptions. This has evolved into NeRF editing\nmethods, which allow the manipulation of existing 3D objects through textual\nconditioning. However, existing NeRF editing techniques have faced limitations\nin their performance due to slow training speeds and the use of loss functions\nthat do not adequately consider editing. To address this, here we present a\nnovel 3D NeRF editing approach dubbed ED-NeRF by successfully embedding\nreal-world scenes into the latent space of the latent diffusion model (LDM)\nthrough a unique refinement layer. This approach enables us to obtain a NeRF\nbackbone that is not only faster but also more amenable to editing compared to\ntraditional image space NeRF editing. Furthermore, we propose an improved loss\nfunction tailored for editing by migrating the delta denoising score (DDS)\ndistillation loss, originally used in 2D image editing to the three-dimensional\ndomain. This novel loss function surpasses the well-known score distillation\nsampling (SDS) loss in terms of suitability for editing purposes. Our\nexperimental results demonstrate that ED-NeRF achieves faster editing speed\nwhile producing improved output quality compared to state-of-the-art 3D editing\nmodels.\n","authors":["Jangho Park","Gihyun Kwon","Jong Chul Ye"],"pdf_url":"https://arxiv.org/pdf/2310.02712v2.pdf","comment":"ICLR 2024; Project Page: https://jhq1234.github.io/ed-nerf.github.io/"},{"id":"http://arxiv.org/abs/2403.14183v1","updated":"2024-03-21T07:15:37Z","published":"2024-03-21T07:15:37Z","title":"OTSeg: Multi-prompt Sinkhorn Attention for Zero-Shot Semantic\n  Segmentation","summary":"  The recent success of CLIP has demonstrated promising results in zero-shot\nsemantic segmentation by transferring muiltimodal knowledge to pixel-level\nclassification. However, leveraging pre-trained CLIP knowledge to closely align\ntext embeddings with pixel embeddings still has limitations in existing\napproaches. To address this issue, we propose OTSeg, a novel multimodal\nattention mechanism aimed at enhancing the potential of multiple text prompts\nfor matching associated pixel embeddings. We first propose Multi-Prompts\nSinkhorn (MPS) based on the Optimal Transport (OT) algorithm, which leads\nmultiple text prompts to selectively focus on various semantic features within\nimage pixels. Moreover, inspired by the success of Sinkformers in unimodal\nsettings, we introduce the extension of MPS, called Multi-Prompts Sinkhorn\nAttention (MPSA), which effectively replaces cross-attention mechanisms within\nTransformer framework in multimodal settings. Through extensive experiments, we\ndemonstrate that OTSeg achieves state-of-the-art (SOTA) performance with\nsignificant gains on Zero-Shot Semantic Segmentation (ZS3) tasks across three\nbenchmark datasets.\n","authors":["Kwanyoung Kim","Yujin Oh","Jong Chul Ye"],"pdf_url":"https://arxiv.org/pdf/2403.14183v1.pdf","comment":"22 pages, 7 figures"}]},"2024-03-20T00:00:00Z":{"Computer Science and Game Theory":[{"id":"http://arxiv.org/abs/2403.14011v1","updated":"2024-03-20T22:21:22Z","published":"2024-03-20T22:21:22Z","title":"A Unified Toll Lane Framework for Autonomous and High-Occupancy Vehicles\n  in Interactive Mixed Autonomy","summary":"  In this study, we introduce a toll lane framework that optimizes the mixed\nflow of autonomous and high-occupancy vehicles on freeways, where human-driven\nand autonomous vehicles of varying commuter occupancy share a segment.\nAutonomous vehicles, with their ability to maintain shorter headways, boost\ntraffic throughput. Our framework designates a toll lane for autonomous\nvehicles with high occupancy to use free of charge, while others pay a toll. We\nexplore the lane choice equilibria when all vehicles minimize travel costs, and\ncharacterize the equilibria by ranking vehicles by their mobility enhancement\npotential, a concept we term the mobility degree. Through numerical examples,\nwe demonstrate the framework's utility in addressing design challenges such as\nsetting optimal tolls, determining occupancy thresholds, and designing lane\npolicies, showing how it facilitates the integration of high-occupancy and\nautonomous vehicles. We also propose an algorithm for assigning rational tolls\nto decrease total commuter delay and examine the effects of toll\nnon-compliance. Our findings suggest that self-interest-driven behavior\nmitigates moderate non-compliance impacts, highlighting the framework's\nresilience. This work presents a pioneering comprehensive analysis of a toll\nlane framework that emphasizes the coexistence of autonomous and high-occupancy\nvehicles, offering insights for traffic management improvements and the\nintegration of autonomous vehicles into existing transportation\ninfrastructures.\n","authors":["Ruolin Li","Philip N. Brown","Roberto Horowitz"],"pdf_url":"https://arxiv.org/pdf/2403.14011v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.08851v3","updated":"2024-03-20T17:07:59Z","published":"2024-02-13T23:37:53Z","title":"Cardinal-Utility Matching Markets: The Quest for Envy-Freeness,\n  Pareto-Optimality, and Efficient Computability","summary":"  Unlike ordinal-utility matching markets, which are well-developed from the\nviewpoint of both theory and practice, recent insights from a computer science\nperspective have left cardinal-utility matching markets in a quandary. The\ncelebrated pricing-based mechanism for one-sided cardinal-utility matching\nmarkets due to Hylland and Zeckhauser, which had long eluded efficient\nalgorithms, was finally shown to be PPAD-complete.\n  This led us to ask the question: is there an alternative, polynomial time,\nmechanism for one-sided cardinal-utility matching markets which achieves the\ndesirable properties of HZ, i.e.\\ (ex-ante) envy-freeness (EF) and\nPareto-optimality (PO)? In this paper we show:\n  1. The problem of finding an EF+PO lottery in a one-sided cardinal-utility\nmatching market is PPAD-complete.\n  2. A $(2 + \\epsilon)$-approximately envy-free and (exactly) Pareto-optimal\nlottery can be found in polynomial time using Nash bargaining. Moreover, the\nresulting mechanism is $(2 + \\epsilon)$-approximately incentive compatible.\n  We also present several results on two-sided cardinal-utility matching\nmarkets, including non-existence of EF+PO lotteries as well as existence of\njustified-envy-free and weak Pareto-optimal lotteries.\n","authors":["Thorben Tröbst","Vijay V. Vazirani"],"pdf_url":"https://arxiv.org/pdf/2402.08851v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.14339v3","updated":"2024-03-20T04:34:54Z","published":"2023-08-28T06:32:04Z","title":"Entropy-Based Strategies for Multi-Bracket Pools","summary":"  Much work in the parimutuel betting literature has discussed estimating event\noutcome probabilities or developing optimal wagering strategies, particularly\nfor horse race betting. Some betting pools, however, involve betting not just\non a single event, but on a tuple of events. For example, pick six betting in\nhorse racing, March Madness bracket challenges, and predicting a randomly drawn\nbitstring each involve making a series of individual forecasts. Although\ntraditional optimal wagering strategies work well when the size of the tuple is\nvery small (e.g., betting on the winner of a horse race), they are intractable\nfor more general betting pools in higher dimensions (e.g., March Madness\nbracket challenges). Hence we pose the multi-brackets problem: supposing we\nwish to predict a tuple of events and that we know the true probabilities of\neach potential outcome of each event, what is the best way to tractably\ngenerate a set of $n$ predicted tuples? The most general version of this\nproblem is extremely difficult, so we begin with a simpler setting. In\nparticular, we generate $n$ independent predicted tuples according to a\ndistribution having optimal entropy. This entropy-based approach is tractable,\nscalable, and performs well.\n","authors":["Ryan S. Brill","Abraham J. Wyner","Ian J. Barnett"],"pdf_url":"https://arxiv.org/pdf/2308.14339v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13275v1","updated":"2024-03-20T03:19:51Z","published":"2024-03-20T03:19:51Z","title":"Analysing Guarantees in Australian Senate Outcomes","summary":"  Single Transferable Vote (STV) is used to elect candidates to the 76 seat\nAustralian Senate across six states and two territories. These eight STV\ncontests are counted using a combination of ballot scanners, manual data entry\nand tabulation software. On election night, some properties of the set of cast\nballots are determined by hand. This includes the first preference tallies of\neach party. This technical report considers whether there are some properties,\nsuch as individual candidates' first preference tallies, that, if assumed to be\naccurate, imply a portion of the election outcome. The paper also presents an\ninteresting example showing that the rules of STV tabulation used for the\nAustralian Senate can allow bizarre behaviour, such as votes increasing in\nvalue over time.\n","authors":["Michelle Blom"],"pdf_url":"https://arxiv.org/pdf/2403.13275v1.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2403.14019v1","updated":"2024-03-20T22:40:53Z","published":"2024-03-20T22:40:53Z","title":"Searching Search Spaces: Meta-evolving a Geometric Encoding for Neural\n  Networks","summary":"  In evolutionary policy search, neural networks are usually represented using\na direct mapping: each gene encodes one network weight. Indirect encoding\nmethods, where each gene can encode for multiple weights, shorten the genome to\nreduce the dimensions of the search space and better exploit permutations and\nsymmetries. The Geometric Encoding for Neural network Evolution (GENE)\nintroduced an indirect encoding where the weight of a connection is computed as\nthe (pseudo-)distance between the two linked neurons, leading to a genome size\ngrowing linearly with the number of genes instead of quadratically in direct\nencoding. However GENE still relies on hand-crafted distance functions with no\nprior optimization. Here we show that better performing distance functions can\nbe found for GENE using Cartesian Genetic Programming (CGP) in a meta-evolution\napproach, hence optimizing the encoding to create a search space that is easier\nto exploit. We show that GENE with a learned function can outperform both\ndirect encoding and the hand-crafted distances, generalizing on unseen\nproblems, and we study how the encoding impacts neural network properties.\n","authors":["Tarek Kunze","Paul Templier","Dennis G Wilson"],"pdf_url":"https://arxiv.org/pdf/2403.14019v1.pdf","comment":"9 pages, 8 figures"},{"id":"http://arxiv.org/abs/2403.13950v1","updated":"2024-03-20T19:42:11Z","published":"2024-03-20T19:42:11Z","title":"Evo* 2023 -- Late-Breaking Abstracts Volume","summary":"  Volume with the Late-Breaking Abstracts submitted to the Evo* 2023\nConference, held in Brno (Czech Republic), from 12 to 14 of April. These papers\npresent ongoing research and preliminary results investigating on the\napplication of different approaches of Bioinspired Methods (mainly Evolutionary\nComputation) to different problems, most of them real world ones.\n","authors":["A. M. Mora","A. I. Esparcia-Alcázar"],"pdf_url":"https://arxiv.org/pdf/2403.13950v1.pdf","comment":"LBAs accepted in Evo* 2023. Part of the Conference Proceedings"},{"id":"http://arxiv.org/abs/2403.13649v1","updated":"2024-03-20T14:57:02Z","published":"2024-03-20T14:57:02Z","title":"Network bottlenecks and task structure control the evolution of\n  interpretable learning rules in a foraging agent","summary":"  Developing reliable mechanisms for continuous local learning is a central\nchallenge faced by biological and artificial systems. Yet, how the\nenvironmental factors and structural constraints on the learning network\ninfluence the optimal plasticity mechanisms remains obscure even for simple\nsettings. To elucidate these dependencies, we study meta-learning via\nevolutionary optimization of simple reward-modulated plasticity rules in\nembodied agents solving a foraging task. We show that unconstrained\nmeta-learning leads to the emergence of diverse plasticity rules. However,\nregularization and bottlenecks to the model help reduce this variability,\nresulting in interpretable rules. Our findings indicate that the meta-learning\nof plasticity rules is very sensitive to various parameters, with this\nsensitivity possibly reflected in the learning rules found in biological\nnetworks. When included in models, these dependencies can be used to discover\npotential objective functions and details of biological learning via\ncomparisons with experimental observations.\n","authors":["Emmanouil Giannakakis","Sina Khajehabdollahi","Anna Levina"],"pdf_url":"https://arxiv.org/pdf/2403.13649v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.02696v2","updated":"2024-03-20T12:58:14Z","published":"2023-12-05T11:55:47Z","title":"Analyzing and Improving the Training Dynamics of Diffusion Models","summary":"  Diffusion models currently dominate the field of data-driven image synthesis\nwith their unparalleled scaling to large datasets. In this paper, we identify\nand rectify several causes for uneven and ineffective training in the popular\nADM diffusion model architecture, without altering its high-level structure.\nObserving uncontrolled magnitude changes and imbalances in both the network\nactivations and weights over the course of training, we redesign the network\nlayers to preserve activation, weight, and update magnitudes on expectation. We\nfind that systematic application of this philosophy eliminates the observed\ndrifts and imbalances, resulting in considerably better networks at equal\ncomputational complexity. Our modifications improve the previous record FID of\n2.41 in ImageNet-512 synthesis to 1.81, achieved using fast deterministic\nsampling.\n  As an independent contribution, we present a method for setting the\nexponential moving average (EMA) parameters post-hoc, i.e., after completing\nthe training run. This allows precise tuning of EMA length without the cost of\nperforming several training runs, and reveals its surprising interactions with\nnetwork architecture, training time, and guidance.\n","authors":["Tero Karras","Miika Aittala","Jaakko Lehtinen","Janne Hellsten","Timo Aila","Samuli Laine"],"pdf_url":"https://arxiv.org/pdf/2312.02696v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.17159v2","updated":"2024-03-20T02:21:23Z","published":"2022-10-31T09:10:06Z","title":"PAGE: Prototype-Based Model-Level Explanations for Graph Neural Networks","summary":"  Aside from graph neural networks (GNNs) attracting significant attention as a\npowerful framework revolutionizing graph representation learning, there has\nbeen an increasing demand for explaining GNN models. Although various\nexplanation methods for GNNs have been developed, most studies have focused on\ninstance-level explanations, which produce explanations tailored to a given\ngraph instance. In our study, we propose Prototype-bAsed GNN-Explainer (PAGE),\na novel model-level GNN explanation method that explains what the underlying\nGNN model has learned for graph classification by discovering\nhuman-interpretable prototype graphs. Our method produces explanations for a\ngiven class, thus being capable of offering more concise and comprehensive\nexplanations than those of instance-level explanations. First, PAGE selects\nembeddings of class-discriminative input graphs on the graph-level embedding\nspace after clustering them. Then, PAGE discovers a common subgraph pattern by\niteratively searching for high matching node tuples using node-level embeddings\nvia a prototype scoring function, thereby yielding a prototype graph as our\nexplanation. Using six graph classification datasets, we demonstrate that PAGE\nqualitatively and quantitatively outperforms the state-of-the-art model-level\nexplanation method. We also carry out systematic experimental studies by\ndemonstrating the relationship between PAGE and instance-level explanation\nmethods, the robustness of PAGE to input data scarce environments, and the\ncomputational efficiency of the proposed prototype scoring function in PAGE.\n","authors":["Yong-Min Shin","Sun-Woo Kim","Won-Yong Shin"],"pdf_url":"https://arxiv.org/pdf/2210.17159v2.pdf","comment":"18 pages, 12 figures, 5 tables; to appear in the IEEE Transactions on\n  Pattern Analysis and Machine Intelligence (Please cite our journal version\n  that will appear in an upcoming issue. Its two-page extended summary was\n  presented in the AAAI-22 Student Abstract and Poster Program.)"},{"id":"http://arxiv.org/abs/2403.08153v2","updated":"2024-03-20T00:18:40Z","published":"2024-03-13T00:30:47Z","title":"The Runtime of Random Local Search on the Generalized Needle Problem","summary":"  In their recent work, C. Doerr and Krejca (Transactions on Evolutionary\nComputation, 2023) proved upper bounds on the expected runtime of the\nrandomized local search heuristic on generalized Needle functions. Based on\nthese upper bounds, they deduce in a not fully rigorous manner a drastic\ninfluence of the needle radius $k$ on the runtime.\n  In this short article, we add the missing lower bound necessary to determine\nthe influence of parameter $k$ on the runtime. To this aim, we derive an exact\ndescription of the expected runtime, which also significantly improves the\nupper bound given by C. Doerr and Krejca. We also describe asymptotic estimates\nof the expected runtime.\n","authors":["Benjamin Doerr","Andrew James Kelley"],"pdf_url":"https://arxiv.org/pdf/2403.08153v2.pdf","comment":"18 pages"}]},"2024-03-19T00:00:00Z":{"Computer Science and Game Theory":[{"id":"http://arxiv.org/abs/2403.13083v1","updated":"2024-03-19T18:27:38Z","published":"2024-03-19T18:27:38Z","title":"Uber Stable: Formulating the Rideshare System as a Stable Matching\n  Problem","summary":"  Peer-to-peer ride-sharing platforms like Uber, Lyft, and DiDi have\nrevolutionized the transportation industry and labor market. At its essence,\nthese systems tackle the bipartite matching problem between two populations:\nriders and drivers. This research paper comprises two main components: an\ninitial literature review of existing ride-sharing platforms and efforts to\nenhance driver satisfaction, and the development of a novel algorithm\nimplemented through simulation testing to allow us to make our own\nobservations. The core algorithm utilized is the Gale-Shapley deferred\nacceptance algorithm, applied to a static matching problem over multiple time\nperiods. In this simulation, we construct a preference-aware task assignment\nmodel, considering both overall revenue maximization and individual preference\nsatisfaction. Specifically, the algorithm design incorporates factors such as\npassenger willingness-to-pay, driver preferences, and location attractiveness,\nwith an overarching goal of achieving equitable income distribution for drivers\nwhile maintaining overall system efficiency.\n  Through simulation, the paper compares the performance of the proposed\nalgorithm with random matching and closest neighbor algorithms, looking at\nmetrics such as total revenue, revenue per ride, and standard deviation to\nidentify trends and impacts of shifting priorities. Additionally, the DA\nalgorithm is compared to the Boston algorithm, and the paper explores the\neffect of prioritizing proximity to passengers versus distance from city\ncenter. Ultimately, the research underscores the importance of continued\nexploration in areas such as dynamic pricing models and additional modeling for\nunconventional driving times to further enhance the findings on the\neffectiveness and fairness of ride-sharing platforms.\n","authors":["Rhea Acharya","Jessica Chen","Helen Xiao"],"pdf_url":"https://arxiv.org/pdf/2403.13083v1.pdf","comment":"6 pages, 10 figures"},{"id":"http://arxiv.org/abs/2305.11261v2","updated":"2024-03-19T18:25:15Z","published":"2023-05-18T18:55:54Z","title":"Game Theory with Simulation of Other Players","summary":"  Game-theoretic interactions with AI agents could differ from traditional\nhuman-human interactions in various ways. One such difference is that it may be\npossible to simulate an AI agent (for example because its source code is\nknown), which allows others to accurately predict the agent's actions. This\ncould lower the bar for trust and cooperation. In this paper, we formalize\ngames in which one player can simulate another at a cost. We first derive some\nbasic properties of such games and then prove a number of results for them,\nincluding: (1) introducing simulation into generic-payoff normal-form games\nmakes them easier to solve; (2) if the only obstacle to cooperation is a lack\nof trust in the possibly-simulated agent, simulation enables equilibria that\nimprove the outcome for both agents; and however (3) there are settings where\nintroducing simulation results in strictly worse outcomes for both players.\n","authors":["Vojtech Kovarik","Caspar Oesterheld","Vincent Conitzer"],"pdf_url":"https://arxiv.org/pdf/2305.11261v2.pdf","comment":"The latest version fixes some typos in the proof of Theorem 5"},{"id":"http://arxiv.org/abs/2403.12807v1","updated":"2024-03-19T15:07:12Z","published":"2024-03-19T15:07:12Z","title":"Freshness-aware Block Propagation Optimization in 6G-based Web 3.0: An\n  Evolutionary Game Approach","summary":"  Driven by the aspiration to establish a decentralized digital economy, Web\n3.0 is emerging as the fundamental technology for digital transformation.\nIncorporating the promising sixth-generation (6G) technology with large\nbandwidth and space-air-ground integrated coverage, 6G-based Web 3.0 holds\ngreat potential in empowering users with enhanced data control and facilitating\nsecure peer-to-peer transactions, especially in consumer electronics, through\nthe utilization of blockchain technologies. However, 6G-based Web 3.0 is still\nin its infancy, such as ensuring block freshness and optimizing block\npropagation to improve blockchain performance. In this paper, we develop a\nfreshness-aware block propagation optimization framework for 6G-based Web 3.0.\nWe first propose a novel metric called Age of Block Information (AoBI) based on\nthe concept of age of information to quantify block freshness. To make block\npropagation optimization tractable, we classify miners into five different\nstates and propose a block propagation model for public blockchains inspired by\nepidemic models. Moreover, considering that the miners are bounded rational, we\npropose an incentive mechanism based on the evolutionary game for block\npropagation to improve block propagation efficiency. Numerical results\ndemonstrate that compared with other block propagation mechanisms, the proposed\nscheme has a higher block forwarding probability, which improves block\npropagation efficiency.\n","authors":["Jinbo Wen","Jiawen Kang","Zehui Xiong","Hongyang Du","Zhaohui Yang","Dusit Niyato","Meng Shen","Yutao Jiao","Yang Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.12807v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.02761v2","updated":"2024-03-19T14:41:35Z","published":"2023-11-05T20:43:08Z","title":"One-Shot Strategic Classification Under Unknown Costs","summary":"  The goal of strategic classification is to learn decision rules which are\nrobust to strategic input manipulation. Earlier works assume that these\nresponses are known; while some recent works handle unknown responses, they\nexclusively study online settings with repeated model deployments. But there\nare many domains$\\unicode{x2014}$particularly in public policy, a common\nmotivating use case$\\unicode{x2014}$where multiple deployments are infeasible,\nor where even one bad round is unacceptable. To address this gap, we initiate\nthe formal study of one-shot strategic classification under unknown responses,\nwhich requires committing to a single classifier once. Focusing on uncertainty\nin the users' cost function, we begin by proving that for a broad class of\ncosts, even a small mis-estimation of the true cost can entail trivial accuracy\nin the worst case. In light of this, we frame the task as a minimax problem,\nwith the goal of identifying the classifier with the smallest worst-case risk\nover an uncertainty set of possible costs. We design efficient algorithms for\nboth the full-batch and stochastic settings, which we prove converge (offline)\nto the minimax solution at the dimension-independent rate of\n$\\tilde{\\mathcal{O}}(T^{-\\frac{1}{2}})$. Our theoretical analysis reveals\nimportant structure stemming from strategic responses, particularly the value\nof dual norm regularization with respect to the cost function.\n","authors":["Elan Rosenfeld","Nir Rosenfeld"],"pdf_url":"https://arxiv.org/pdf/2311.02761v2.pdf","comment":"Fixed a bug in Algorithm 1, significantly strengthened Theorem 4.2,\n  and added Figure 1 to help visualize the lower bound in Theorem 3.2"},{"id":"http://arxiv.org/abs/2402.19292v2","updated":"2024-03-19T07:05:45Z","published":"2024-02-29T15:55:10Z","title":"Fundamental Limits of Throughput and Availability: Applications to\n  prophet inequalities & transaction fee mechanism design","summary":"  This paper studies the fundamental limits of availability and throughput for\nindependent and heterogeneous demands of a limited resource. Availability is\nthe probability that the demands are below the capacity of the resource.\nThroughput is the expected fraction of the resource that is utilized by the\ndemands. We offer a concentration inequality generator that gives lower bounds\non feasible availability and throughput pairs with a given capacity and\nindependent but not necessarily identical distributions of up-to-unit demands.\nWe show that availability and throughput cannot both be poor. These bounds are\nanalogous to tail inequalities on sums of independent random variables, but\nhold throughout the support of the demand distribution. This analysis gives\nanalytically tractable bounds supporting the unit-demand characterization of\nChawla, Devanur, and Lykouris (2023) and generalizes to up-to-unit demands. Our\nbounds also provide an approach towards improved multi-unit prophet\ninequalities (Hajiaghayi, Kleinberg, and Sandholm, 2007). They have\napplications to transaction fee mechanism design (for blockchains) where high\navailability limits the probability of profitable user-miner coalitions (Chung\nand Shi, 2023).\n","authors":["Aadityan Ganesh","Jason Hartline","Atanu R Sinha","Matthew vonAllmen"],"pdf_url":"https://arxiv.org/pdf/2402.19292v2.pdf","comment":"34 pages, 7 figures; updated author information to include\n  institutions and email addresses"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2403.13187v1","updated":"2024-03-19T22:56:53Z","published":"2024-03-19T22:56:53Z","title":"Evolutionary Optimization of Model Merging Recipes","summary":"  We present a novel application of evolutionary algorithms to automate the\ncreation of powerful foundation models. While model merging has emerged as a\npromising approach for LLM development due to its cost-effectiveness, it\ncurrently relies on human intuition and domain knowledge, limiting its\npotential. Here, we propose an evolutionary approach that overcomes this\nlimitation by automatically discovering effective combinations of diverse\nopen-source models, harnessing their collective intelligence without requiring\nextensive additional training data or compute. Our approach operates in both\nparameter space and data flow space, allowing for optimization beyond just the\nweights of the individual models. This approach even facilitates cross-domain\nmerging, generating models like a Japanese LLM with Math reasoning\ncapabilities. Surprisingly, our Japanese Math LLM achieved state-of-the-art\nperformance on a variety of established Japanese LLM benchmarks, even\nsurpassing models with significantly more parameters, despite not being\nexplicitly trained for such tasks. Furthermore, a culturally-aware Japanese VLM\ngenerated through our approach demonstrates its effectiveness in describing\nJapanese culture-specific content, outperforming previous Japanese VLMs. This\nwork not only contributes new state-of-the-art models back to the open-source\ncommunity, but also introduces a new paradigm for automated model composition,\npaving the way for exploring alternative, efficient approaches to foundation\nmodel development.\n","authors":["Takuya Akiba","Makoto Shing","Yujin Tang","Qi Sun","David Ha"],"pdf_url":"https://arxiv.org/pdf/2403.13187v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13105v1","updated":"2024-03-19T19:11:00Z","published":"2024-03-19T19:11:00Z","title":"Using evolutionary computation to optimize task performance of\n  unclocked, recurrent Boolean circuits in FPGAs","summary":"  It has been shown that unclocked, recurrent networks of Boolean gates in\nFPGAs can be used for low-SWaP reservoir computing. In such systems, topology\nand node functionality of the network are randomly initialized. To create a\nnetwork that solves a task, weights are applied to output nodes and learning is\nachieved by adjusting those weights with conventional machine learning methods.\nHowever, performance is often limited compared to networks where all parameters\nare learned. Herein, we explore an alternative learning approach for unclocked,\nrecurrent networks in FPGAs. We use evolutionary computation to evolve the\nBoolean functions of network nodes. In one type of implementation the output\nnodes are used directly to perform a task and all learning is via evolution of\nthe network's node functions. In a second type of implementation a back-end\nclassifier is used as in traditional reservoir computing. In that case, both\nevolution of node functions and adjustment of output node weights contribute to\nlearning. We demonstrate the practicality of node function evolution, obtaining\nan accuracy improvement of ~30% on an image classification task while\nprocessing at a rate of over three million samples per second. We additionally\ndemonstrate evolvability of network memory and dynamic output signals.\n","authors":["Raphael Norman-Tenazas","David Kleinberg","Erik C. Johnson","Daniel P. Lathrop","Matthew J. Roos"],"pdf_url":"https://arxiv.org/pdf/2403.13105v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.07473v3","updated":"2024-03-19T17:25:14Z","published":"2022-05-16T06:53:14Z","title":"Towards Lossless ANN-SNN Conversion under Ultra-Low Latency with\n  Dual-Phase Optimization","summary":"  Spiking neural networks (SNNs) operating with asynchronous discrete events\nshow higher energy efficiency with sparse computation. A popular approach for\nimplementing deep SNNs is ANN-SNN conversion combining both efficient training\nof ANNs and efficient inference of SNNs. However, the accuracy loss is usually\nnon-negligible, especially under a few time steps, which restricts the\napplications of SNN on latency-sensitive edge devices greatly. In this paper,\nwe first identify that such performance degradation stems from the\nmisrepresentation of the negative or overflow residual membrane potential in\nSNNs. Inspired by this, we decompose the conversion error into three parts:\nquantization error, clipping error, and residual membrane potential\nrepresentation error. With such insights, we propose a two-stage conversion\nalgorithm to minimize those errors respectively. Besides, We show each stage\nachieves significant performance gains in a complementary manner. By evaluating\non challenging datasets including CIFAR-10, CIFAR- 100 and ImageNet, the\nproposed method demonstrates the state-of-the-art performance in terms of\naccuracy, latency and energy preservation. Furthermore, our method is evaluated\nusing a more challenging object detection task, revealing notable gains in\nregression performance under ultra-low latency when compared to existing\nspike-based detection algorithms. Codes are available at\nhttps://github.com/Windere/snn-cvt-dual-phase.\n","authors":["Ziming Wang","Shuang Lian","Yuhao Zhang","Xiaoxin Cui","Rui Yan","Huajin Tang"],"pdf_url":"https://arxiv.org/pdf/2205.07473v3.pdf","comment":"Accepted by IEEE Transactions on Neural Networks and Learning Systems\n  (TNNLS)"},{"id":"http://arxiv.org/abs/2403.12739v1","updated":"2024-03-19T13:56:34Z","published":"2024-03-19T13:56:34Z","title":"Path Planning in a dynamic environment using Spherical Particle Swarm\n  Optimization","summary":"  Efficiently planning an Unmanned Aerial Vehicle (UAV) path is crucial,\nespecially in dynamic settings where potential threats are prevalent. A Dynamic\nPath Planner (DPP) for UAV using the Spherical Vector-based Particle Swarm\nOptimisation (SPSO) technique is proposed in this study. The UAV is supposed to\ngo from a starting point to an end point through an optimal path according to\nsome flight criteria. Path length, Safety, Attitude and Path Smoothness are all\ntaken into account upon deciding how an optimal path should be. The path is\nconstructed as a set of way-points that stands as re-planning checkpoints. At\neach path way-point, threats are allowed some constrained random motion, where\ntheir exact positions are updated and fed to the SPSO-solver. Four test\nscenarios are carried out using real digital elevation models. Each test gives\ndifferent priorities to path length and safety, in order to show how well the\nSPSO-DPP is capable of generating a safe yet efficient path segments. Finally,\na comparison is made to reveal the persistent overall superior performance of\nthe SPSO, in a dynamic environment, over both the Particle Swarm Optimisation\n(PSO) and the Genetic Algorithm (GA). The methods are compared directly, by\naveraging costs over multiple runs, and by considering different challenging\nlevels of obstacle motion. SPSO outperformed both PSO and GA, showcasing cost\nreductions ranging from 330\\% to 675\\% compared to both algorithms.\n","authors":["Mohssen E. Elshaar","Mohammed R. Elbalshy","A. Hussien","Mohammed Abido"],"pdf_url":"https://arxiv.org/pdf/2403.12739v1.pdf","comment":"Accepted as conference paper in IEEE WCCI 2024"},{"id":"http://arxiv.org/abs/2310.13391v2","updated":"2024-03-19T09:58:29Z","published":"2023-10-20T10:03:14Z","title":"Learning Successor Features with Distributed Hebbian Temporal Memory","summary":"  This paper presents a novel approach to address the challenge of online\ntemporal memory learning for decision-making under uncertainty in\nnon-stationary, partially observable environments. The proposed algorithm,\nDistributed Hebbian Temporal Memory (DHTM), is based on factor graph formalism\nand a multicomponent neuron model. DHTM aims to capture sequential data\nrelationships and make cumulative predictions about future observations,\nforming Successor Features (SF). Inspired by neurophysiological models of the\nneocortex, the algorithm utilizes distributed representations, sparse\ntransition matrices, and local Hebbian-like learning rules to overcome the\ninstability and slow learning process of traditional temporal memory algorithms\nlike RNN and HMM. Experimental results demonstrate that DHTM outperforms LSTM\nand a biologically inspired HMM-like algorithm, CSCG, in the case of\nnon-stationary datasets. Our findings suggest that DHTM is a promising approach\nfor addressing the challenges of online sequence learning and planning in\ndynamic environments.\n","authors":["Evgenii Dzhivelikian","Petr Kuderov","Aleksandr I. Panov"],"pdf_url":"https://arxiv.org/pdf/2310.13391v2.pdf","comment":"20 pages, 9 figures"},{"id":"http://arxiv.org/abs/2403.12574v1","updated":"2024-03-19T09:34:11Z","published":"2024-03-19T09:34:11Z","title":"EAS-SNN: End-to-End Adaptive Sampling and Representation for Event-based\n  Detection with Recurrent Spiking Neural Networks","summary":"  Event cameras, with their high dynamic range and temporal resolution, are\nideally suited for object detection, especially under scenarios with motion\nblur and challenging lighting conditions. However, while most existing\napproaches prioritize optimizing spatiotemporal representations with advanced\ndetection backbones and early aggregation functions, the crucial issue of\nadaptive event sampling remains largely unaddressed. Spiking Neural Networks\n(SNNs), which operate on an event-driven paradigm through sparse spike\ncommunication, emerge as a natural fit for addressing this challenge. In this\nstudy, we discover that the neural dynamics of spiking neurons align closely\nwith the behavior of an ideal temporal event sampler. Motivated by this\ninsight, we propose a novel adaptive sampling module that leverages recurrent\nconvolutional SNNs enhanced with temporal memory, facilitating a fully\nend-to-end learnable framework for event-based detection. Additionally, we\nintroduce Residual Potential Dropout (RPD) and Spike-Aware Training (SAT) to\nregulate potential distribution and address performance degradation encountered\nin spike-based sampling modules. Through rigorous testing on neuromorphic\ndatasets for event-based detection, our approach demonstrably surpasses\nexisting state-of-the-art spike-based methods, achieving superior performance\nwith significantly fewer parameters and time steps. For instance, our method\nachieves a 4.4\\% mAP improvement on the Gen1 dataset, while requiring 38\\%\nfewer parameters and three time steps. Moreover, the applicability and\neffectiveness of our adaptive sampling methodology extend beyond SNNs, as\ndemonstrated through further validation on conventional non-spiking detection\nmodels.\n","authors":["Ziming Wang","Ziling Wang","Huaning Li","Lang Qin","Runhao Jiang","De Ma","Huajin Tang"],"pdf_url":"https://arxiv.org/pdf/2403.12574v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.12490v1","updated":"2024-03-19T06:55:59Z","published":"2024-03-19T06:55:59Z","title":"Genetically programmable optical random neural networks","summary":"  Today, machine learning tools, particularly artificial neural networks, have\nbecome crucial for diverse applications. However, current digital computing\ntools to train and deploy artificial neural networks often struggle with\nmassive data sizes and high power consumptions. Optical computing provides\ninherent parallelism and perform fundamental operations with passive optical\ncomponents. However, most of the optical computing platforms suffer from\nrelatively low accuracies for machine learning tasks due to fixed connections\nwhile avoiding complex and sensitive techniques. Here, we demonstrate a\ngenetically programmable yet simple optical neural network to achieve high\nperformances with optical random projection. By genetically programming the\norientation of the scattering medium which acts as a random projection kernel\nand only using 1% of the search space, our novel technique finds an optimum\nkernel and improves its initial test accuracies 7-22% for various machine\nlearning tasks. Our optical computing method presents a promising approach to\nachieve high performance in optical neural networks with a simple and scalable\ndesign.\n","authors":["Bora Çarpınlıoğlu","Bahrem Serhat Daniş","Uğur Teğin"],"pdf_url":"https://arxiv.org/pdf/2403.12490v1.pdf","comment":"Manuscript: 11 pages, 5 Figures. Supplementary material: 8 pages, 6\n  Figures, 2 Tables"},{"id":"http://arxiv.org/abs/2403.12462v1","updated":"2024-03-19T05:37:26Z","published":"2024-03-19T05:37:26Z","title":"Topological Representations of Heterogeneous Learning Dynamics of\n  Recurrent Spiking Neural Networks","summary":"  Spiking Neural Networks (SNNs) have become an essential paradigm in\nneuroscience and artificial intelligence, providing brain-inspired computation.\nRecent advances in literature have studied the network representations of deep\nneural networks. However, there has been little work that studies\nrepresentations learned by SNNs, especially using unsupervised local learning\nmethods like spike-timing dependent plasticity (STDP). Recent work by\n\\cite{barannikov2021representation} has introduced a novel method to compare\ntopological mappings of learned representations called Representation Topology\nDivergence (RTD). Though useful, this method is engineered particularly for\nfeedforward deep neural networks and cannot be used for recurrent networks like\nRecurrent SNNs (RSNNs). This paper introduces a novel methodology to use RTD to\nmeasure the difference between distributed representations of RSNN models with\ndifferent learning methods. We propose a novel reformulation of RSNNs using\nfeedforward autoencoder networks with skip connections to help us compute the\nRTD for recurrent networks. Thus, we investigate the learning capabilities of\nRSNN trained using STDP and the role of heterogeneity in the synaptic dynamics\nin learning such representations. We demonstrate that heterogeneous STDP in\nRSNNs yield distinct representations than their homogeneous and surrogate\ngradient-based supervised learning counterparts. Our results provide insights\ninto the potential of heterogeneous SNN models, aiding the development of more\nefficient and biologically plausible hybrid artificial intelligence systems.\n","authors":["Biswadeep Chakraborty","Saibal Mukhopadhyay"],"pdf_url":"https://arxiv.org/pdf/2403.12462v1.pdf","comment":"Accepted in IEEE World Congress on Computational Intelligence (IEEE\n  WCCI) 2024"},{"id":"http://arxiv.org/abs/2403.12389v1","updated":"2024-03-19T02:57:10Z","published":"2024-03-19T02:57:10Z","title":"Learning-guided iterated local search for the minmax multiple traveling\n  salesman problem","summary":"  The minmax multiple traveling salesman problem involves minimizing the\nlongest tour among a set of tours. The problem is of great practical interest\nbecause it can be used to formulate several real-life applications. To solve\nthis computationally challenging problem, we propose a leaning-driven iterated\nlocal search approach that combines an aggressive local search procedure with a\nprobabilistic acceptance criterion to find high-quality local optimal solutions\nand a multi-armed bandit algorithm to select various removal and insertion\noperators to escape local optimal traps. Extensive experiments on 77 commonly\nused benchmark instances show that our algorithm achieves excellent results in\nterms of solution quality and running time. In particular, it achieves 32 new\nbest-known results and matches the best-known results for 35 other instances.\nAdditional experiments shed light on the understanding of the composing\nelements of the algorithm.\n","authors":["Pengfei He","Jin-Kao Hao","Jinhui Xia"],"pdf_url":"https://arxiv.org/pdf/2403.12389v1.pdf","comment":null}]},"2024-03-18T00:00:00Z":{"Computer Science and Game Theory":[{"id":"http://arxiv.org/abs/2403.12204v1","updated":"2024-03-18T19:40:16Z","published":"2024-03-18T19:40:16Z","title":"Information Compression in Dynamic Information Disclosure Games","summary":"  We consider a two-player dynamic information design problem between a\nprincipal and a receiver -- a game is played between the two agents on top of a\nMarkovian system controlled by the receiver's actions, where the principal\nobtains and strategically shares some information about the underlying system\nwith the receiver in order to influence their actions. In our setting, both\nplayers have long-term objectives, and the principal sequentially commits to\ntheir strategies instead of committing at the beginning. Further, the principal\ncannot directly observe the system state, but at every turn they can choose\nrandomized experiments to observe the system partially. The principal can share\ndetails about the experiments to the receiver. For our analysis we impose the\ntruthful disclosure rule: the principal is required to truthfully announce the\ndetails and the result of each experiment to the receiver immediately after the\nexperiment result is revealed. Based on the received information, the receiver\ntakes an action when its their turn, with the action influencing the state of\nthe underlying system. We show that there exist Perfect Bayesian equilibria in\nthis game where both agents play Canonical Belief Based (CBB) strategies using\na compressed version of their information, rather than full information, to\nchoose experiments (for the principal) or actions (for the receiver). We also\nprovide a backward inductive procedure to solve for an equilibrium in CBB\nstrategies.\n","authors":["Dengwang Tang","Vijay G. Subramanian"],"pdf_url":"https://arxiv.org/pdf/2403.12204v1.pdf","comment":"14 pages, 5 figures"},{"id":"http://arxiv.org/abs/2403.12195v1","updated":"2024-03-18T19:09:20Z","published":"2024-03-18T19:09:20Z","title":"PackIt! Gamified Rectangle Packing","summary":"  We present and analyze PackIt!, a turn-based game consisting of packing\nrectangles on an $n \\times n$ grid. PackIt! can be easily played on paper,\neither as a competitive two-player game or in \\emph{solitaire} fashion. On the\n$t$-th turn, a rectangle of area $t$ or $t+1$ must be placed in the grid. In\nthe two-player format of PackIt! whichever player places a rectangle last wins,\nwhereas the goal in the solitaire variant is to perfectly pack the $n \\times n$\ngrid. We analyze conditions for the existence of a perfect packing over $n\n\\times n$, then present an automated reasoning approach that allows finding\nperfect games of PackIt! up to $n = 50$ which includes a novel SAT-encoding\ntechnique of independent interest, and conclude by proving an NP-hardness\nresult.\n","authors":["Thomas Garrison","Marijn J. H. Heule","Bernardo Subercaseaux"],"pdf_url":"https://arxiv.org/pdf/2403.12195v1.pdf","comment":"28 pages, 10 figures, Submitted to Fun with Algorithms"},{"id":"http://arxiv.org/abs/2403.12183v1","updated":"2024-03-18T18:55:46Z","published":"2024-03-18T18:55:46Z","title":"Fragile Stable Matchings","summary":"  We show how fragile stable matchings are in a decentralized one-to-one\nmatching setting. The classical work of Roth and Vande Vate (1990) suggests\nsimple decentralized dynamics in which randomly-chosen blocking pairs match\nsuccessively. Such decentralized interactions guarantee convergence to a stable\nmatching. Our first theorem shows that, under mild conditions, any unstable\nmatching -- including a small perturbation of a stable matching -- can\nculminate in any stable matching through these dynamics. Our second theorem\nhighlights another aspect of fragility: stabilization may take a long time.\nEven in markets with a unique stable matching, where the dynamics always\nconverge to the same matching, decentralized interactions can require an\nexponentially long duration to converge. A small perturbation of a stable\nmatching may lead the market away from stability and involve a sizable\nproportion of mismatched participants for extended periods. Our results hold\nfor a broad class of dynamics.\n","authors":["Kirill Rudov"],"pdf_url":"https://arxiv.org/pdf/2403.12183v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.12181v1","updated":"2024-03-18T18:52:04Z","published":"2024-03-18T18:52:04Z","title":"MAC Advice for Facility Location Mechanism Design","summary":"  Algorithms with predictions have attracted much attention in the last years\nacross various domains, including variants of facility location, as a way to\nsurpass traditional worst-case analyses. We study the $k$-facility location\nmechanism design problem, where the $n$ agents are strategic and might\nmisreport their location.\n  Unlike previous models, where predictions are for the $k$ optimal facility\nlocations, we receive $n$ predictions for the locations of each of the agents.\nHowever, these predictions are only \"mostly\" and \"approximately\" correct (or\nMAC for short) -- i.e., some $\\delta$-fraction of the predicted locations are\nallowed to be arbitrarily incorrect, and the remainder of the predictions are\nallowed to be correct up to an $\\varepsilon$-error. We make no assumption on\nthe independence of the errors. Can such predictions allow us to beat the\ncurrent best bounds for strategyproof facility location?\n  We show that the $1$-median (geometric median) of a set of points is\nnaturally robust under corruptions, which leads to an algorithm for\nsingle-facility location with MAC predictions. We extend the robustness result\nto a \"balanced\" variant of the $k$ facilities case. Without balancedness, we\nshow that robustness completely breaks down, even for the setting of $k=2$\nfacilities on a line. For this \"unbalanced\" setting, we devise a truthful\nrandom mechanism that outperforms the best known result of Lu et al. [2010],\nwhich does not use predictions. En route, we introduce the problem of \"second\"\nfacility location (when the first facility's location is already fixed). Our\nfindings on the robustness of the $1$-median and more generally $k$-medians may\nbe of independent interest, as quantitative versions of classic breakdown-point\nresults in robust statistics.\n","authors":["Zohar Barak","Anupam Gupta","Inbal Talgam-Cohen"],"pdf_url":"https://arxiv.org/pdf/2403.12181v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.11811v1","updated":"2024-03-18T14:09:47Z","published":"2024-03-18T14:09:47Z","title":"A Simple 2-Approximation Algorithm For Minimum Manhattan Network Problem","summary":"  Given a n points in two dimensional space, a Manhattan Network G is a network\nthat connects all n points with either horizontal or vertical edges, with the\nproperty that for any two point in G should be connected by a Manhattan path\nand distance between this two points is equal to Manhattan Distance. The\nMinimum Manhattan Network problem is to find a Manhattan network with minimum\nnetwork length, i.e., summation of all line segment in network should be\nminimize. In this paper, we proposed a 2-approximation algorithm with time\ncomplexity O(|E|lgN) where |E| is the number of edges and N is the number of\nnodes. Using randomly generated datasets, we compare our result with the\noptimal one.\n","authors":["Md. Musfiqur Rahman Sanim","Safrunnesa Saira","Fatin Faiaz Ahsan","Rajon Bardhan","S. M. Ferdous"],"pdf_url":"https://arxiv.org/pdf/2403.11811v1.pdf","comment":"ARSSS International Conference, Dhaka, Bangladesh"},{"id":"http://arxiv.org/abs/2307.06212v3","updated":"2024-03-18T10:16:49Z","published":"2023-07-12T15:00:16Z","title":"Contract-Based Distributed Synthesis in Two-Objective Parity Games","summary":"  We present a novel method to compute $\\textit{assume-guarantee contracts}$ in\nnon-zerosum two-player games over finite graphs where each player has a\ndifferent $ \\omega $-regular winning condition. Given a game graph $G$ and two\nparity winning conditions $\\Phi_0$ and $\\Phi_1$ over $G$, we compute\n$\\textit{contracted strategy-masks}$ ($\\texttt{csm}$) $(\\Psi_{i},\\Phi_{i})$ for\neach Player $i$. Within a $\\texttt{csm}$, $\\Phi_{i}$ is a $\\textit{permissive\nstrategy template}$ which collects an infinite number of winning strategies for\nPlayer $i$ under the assumption that Player $1-i$ chooses any strategy from the\n$\\textit{permissive assumption template}$ $\\Psi_{i}$. The main feature of\n$\\texttt{csm}$'s is their power to $\\textit{fully decentralize all remaining\nstrategy choices}$ -- if the two player's $\\texttt{csm}$'s are compatible, they\nprovide a pair of new local specifications $\\Phi_0^\\bullet$ and\n$\\Phi_1^\\bullet$ such that Player $i$ can locally and fully independently\nchoose any strategy satisfying $\\Phi_i^\\bullet$ and the resulting strategy\nprofile is ensured to be winning in the original two-objective game\n$(G,\\Phi_0,\\Phi_1)$.\n  In addition, the new specifications $\\Phi_i^\\bullet$ are $\\textit{maximally\ncooperative}$, i.e., allow for the distributed synthesis of any cooperative\nsolution. Further, our algorithmic computation of $\\texttt{csm}$'s is complete\nand ensured to terminate.\n  We illustrate how the unique features of our synthesis framework effectively\naddress multiple challenges in the context of \\enquote{correct-by-design}\nlogical control software synthesis for cyber-physical systems and provide\nempirical evidence that our approach possess desirable structural and\ncomputational properties compared to state-of-the-art techniques.\n","authors":["Ashwani Anand","Satya Prakash Nayak","Anne-Kathrin Schmuck"],"pdf_url":"https://arxiv.org/pdf/2307.06212v3.pdf","comment":"HSCC 2024"},{"id":"http://arxiv.org/abs/2403.11633v1","updated":"2024-03-18T10:13:51Z","published":"2024-03-18T10:13:51Z","title":"Cooperative Agri-Food Export under Minimum Quantity Commitments","summary":"  International trade can be a profitable business for agri-food communities.\nHowever, access to international markets can be costly and thus unattainable\nfor small and medium sized enterprises (SMEs). This problem is exacerbated\nunder trade policies which require minimum quantity commitments (MQCs) on\nexport volumes, e.g., licensing tariff rate quota (TRQ) mechanisms.\n  We show how cooperative exporting among agri-food SMEs can tackle the\nbarriers posed by the MQCs, and give market access to a broader range of SMEs.\nWe formulate a class of cooperative games associated with these situations and\nfind a gain-sharing mechanism that result in allocations in their corresponding\ncores. Thus, grand coalitions of cooperative exporting SMEs can form in stable\nmanners.\n  This allocation rule shares the export surplus only among the \"essential\" SME\nexporters, that is, the players who are sufficiently cost efficient. Thus, less\ncost efficient \"complimentary\" SMEs whose capacities are needed to maintain\nMQCs receive no benefit from collaborative exporting and their participation\nhave to be altruistic. We propose two modifications to our original allocation\nrule to share a portion of export surplus among the complementary SMEs through\ntaxing the essential SMEs: the first through egalitarian, and the second\nthrough revenue-based rates. We compare the performance of these allocations\nwith the numerical examples and discuss their practical implications.\n","authors":["Luis A. Guardiola","Behzad Hezarkhani","Ana Meca"],"pdf_url":"https://arxiv.org/pdf/2403.11633v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.00726v2","updated":"2024-03-18T09:51:27Z","published":"2022-08-01T10:22:48Z","title":"Fair Division of Multi-layered Cakes","summary":"  We consider multi-layered cake cutting in order to fairly allocate numerous\ndivisible resources (layers of cake) among a group of agents under two\nconstraints: contiguity and feasibility. We first introduce a new computational\nmodel in a multi-layered cake named ``a pair of knives''. Then, we show the\nexistence of an exact multi-allocation for two agents and two layers using the\nnew computational model. We demonstrate the computation procedure of a feasible\nand contiguous proportional multi-allocation over a three-layered cake for more\nthan three agents. Finally, we develop a technique for computing proportional\nallocations for any number $n\\geq 2^a3$ of agents and $2^a3$ layers, where $a$\nis any positive integer.\n","authors":["Mohammad Azharuddin Sanpui"],"pdf_url":"https://arxiv.org/pdf/2208.00726v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.11486v1","updated":"2024-03-18T05:32:31Z","published":"2024-03-18T05:32:31Z","title":"Expanding the Resolution Boundary of Outcome-Based Imperfect-Recall\n  Abstraction in Games with Ordered Signals","summary":"  In the development of advanced Texas Hold'em AI systems, abstraction\ntechnology has garnered widespread attention due to its significant effect in\nsimplifying game complexity. This study adopts a more specific model, the games\nof ordered signal, to describe Texas Hold'em-style games and optimizes this\nmodel to streamline its mathematical representation and broaden its\napplicability. By transitioning from a broad imperfect information game model\nto a game with ordered signals model, we have separated the previously\nintertwined infoset abstraction and action abstraction into independent signal\nabstraction and action abstraction. Importantly, this signal abstraction\nprovides a mathematical framework for the hand abstraction task, which is\nemphatically discussed in this paper. Additionally, a novel common refinement\nprinciple is introduced, revealing the limit performance of hand abstraction\nalgorithms. We introduce potential outcome isomorphism (POI) and pinpoint that\nit suffers from the issue of excessive abstraction. Futher, We demonstrate that\nPOI serves as a common refinement for leading outcome-based hand abstraction\nalgorithms, such as E[HS] and PA\\&PAEMD. Consequently, excessive abstraction\nalso inherently affects these algorithms, leading to suboptimal performance.\nOur investigation reveals the omission of historical data as a primary\ncontributor to excessive abstraction. To remedy this, we propose the K-Recall\nOutcome Isomorphism (KROI) to incorporate the missing information. Compared\nwith POI, KROI more accurately mirrors lossless isomorphism (LI), the ground\ntruth, offering enhanced signal abstraction resolution. Experimental results in\nthe Numeral211 Hold'em indicate that strategies developed through KROI\napproximate the exploitability of those developed through LI more closely than\nthose trained through POI.\n","authors":["Yanchang Fu","Junge Zhang","Dongdong Bai","Lingyun Zhao","Jialu Song","Kaiqi Huang"],"pdf_url":"https://arxiv.org/pdf/2403.11486v1.pdf","comment":"35 pages, 7 figures"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2403.12307v1","updated":"2024-03-18T23:16:17Z","published":"2024-03-18T23:16:17Z","title":"Molecular Classification Using Hyperdimensional Graph Classification","summary":"  Our work introduces an innovative approach to graph learning by leveraging\nHyperdimensional Computing. Graphs serve as a widely embraced method for\nconveying information, and their utilization in learning has gained significant\nattention. This is notable in the field of chemoinformatics, where learning\nfrom graph representations plays a pivotal role. An important application\nwithin this domain involves the identification of cancerous cells across\ndiverse molecular structures.\n  We propose an HDC-based model that demonstrates comparable Area Under the\nCurve results when compared to state-of-the-art models like Graph Neural\nNetworks (GNNs) or the Weisfieler-Lehman graph kernel (WL). Moreover, it\noutperforms previously proposed hyperdimensional computing graph learning\nmethods. Furthermore, it achieves noteworthy speed enhancements, boasting a 40x\nacceleration in the training phase and a 15x improvement in inference time\ncompared to GNN and WL models. This not only underscores the efficacy of the\nHDC-based method, but also highlights its potential for expedited and\nresource-efficient graph learning.\n","authors":["Pere Verges","Igor Nunes","Mike Heddes","Tony Givargis","Alexandru Nicolau"],"pdf_url":"https://arxiv.org/pdf/2403.12307v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.01046v2","updated":"2024-03-18T22:11:45Z","published":"2024-03-02T00:33:45Z","title":"A Library of Mirrors: Deep Neural Nets in Low Dimensions are Convex\n  Lasso Models with Reflection Features","summary":"  We prove that training neural networks on 1-D data is equivalent to solving a\nconvex Lasso problem with a fixed, explicitly defined dictionary matrix of\nfeatures. The specific dictionary depends on the activation and depth. We\nconsider 2-layer networks with piecewise linear activations, deep narrow ReLU\nnetworks with up to 4 layers, and rectangular and tree networks with sign\nactivation and arbitrary depth. Interestingly in ReLU networks, a fourth layer\ncreates features that represent reflections of training data about themselves.\nThe Lasso representation sheds insight to globally optimal networks and the\nsolution landscape.\n","authors":["Emi Zeger","Yifei Wang","Aaron Mishkin","Tolga Ergen","Emmanuel Candès","Mert Pilanci"],"pdf_url":"https://arxiv.org/pdf/2403.01046v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.12116v1","updated":"2024-03-18T16:14:28Z","published":"2024-03-18T16:14:28Z","title":"Unsupervised End-to-End Training with a Self-Defined Bio-Inspired Target","summary":"  Current unsupervised learning methods depend on end-to-end training via deep\nlearning techniques such as self-supervised learning, with high computational\nrequirements, or employ layer-by-layer training using bio-inspired approaches\nlike Hebbian learning, using local learning rules incompatible with supervised\nlearning. Both approaches are problematic for edge AI hardware that relies on\nsparse computational resources and would strongly benefit from alternating\nbetween unsupervised and supervised learning phases - thus leveraging widely\navailable unlabeled data from the environment as well as labeled training\ndatasets. To solve this challenge, in this work, we introduce a 'self-defined\ntarget' that uses Winner-Take-All (WTA) selectivity at the network's final\nlayer, complemented by regularization through biologically inspired homeostasis\nmechanism. This approach, framework-agnostic and compatible with both global\n(Backpropagation) and local (Equilibrium propagation) learning rules, achieves\na 97.6% test accuracy on the MNIST dataset. Furthermore, we demonstrate that\nincorporating a hidden layer enhances classification accuracy and the quality\nof learned features across all training methods, showcasing the advantages of\nend-to-end unsupervised training. Extending to semi-supervised learning, our\nmethod dynamically adjusts the target according to data availability, reaching\na 96.6% accuracy with just 600 labeled MNIST samples. This result highlights\nour 'unsupervised target' strategy's efficacy and flexibility in scenarios\nranging from abundant to no labeled data availability.\n","authors":["Dongshu Liu","Jérémie Laydevant","Adrien Pontlevy","Damien Querlioz","Julie Grollier"],"pdf_url":"https://arxiv.org/pdf/2403.12116v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.11563v1","updated":"2024-03-18T08:33:56Z","published":"2024-03-18T08:33:56Z","title":"Advancing Neuromorphic Computing: Mixed-Signal Design Techniques\n  Leveraging Brain Code Units and Fundamental Code Units","summary":"  This paper introduces a groundbreaking digital neuromorphic architecture that\ninnovatively integrates Brain Code Unit (BCU) and Fundamental Code Unit (FCU)\nusing mixedsignal design methodologies. Leveraging open-source datasets and the\nlatest advances in materials science, our research focuses on enhancing the\ncomputational efficiency, accuracy, and adaptability of neuromorphic systems.\nThe core of our approach lies in harmonizing the precision and scalability of\ndigital systems with the robustness and energy efficiency of analog processing.\nThrough experimentation, we demonstrate the effectiveness of our system across\nvarious metrics. The BCU achieved an accuracy of 88.0% and a power efficiency\nof 20.0 GOP/s/W, while the FCU recorded an accuracy of 86.5% and a power\nefficiency of 18.5 GOP/s/W. Our mixed-signal design approach significantly\nimproved latency and throughput, achieving a latency as low as 0.75 ms and\nthroughput up to 213 TOP/s. These results firmly establish the potential of our\narchitecture in neuromorphic computing, providing a solid foundation for future\ndevelopments in this domain. Our study underscores the feasibility of\nmixedsignal neuromorphic systems and their promise in advancing the field,\nparticularly in applications requiring high efficiency and adaptability\n","authors":["Murat Isik","Sols Miziev","Wiktoria Pawlak","Newton Howard"],"pdf_url":"https://arxiv.org/pdf/2403.11563v1.pdf","comment":"Accepted at 2024 International Joint Conference on Neural Networks"},{"id":"http://arxiv.org/abs/2403.11446v1","updated":"2024-03-18T03:44:55Z","published":"2024-03-18T03:44:55Z","title":"LLM Guided Evolution -- The Automation of Models Advancing Models","summary":"  In the realm of machine learning, traditional model development and automated\napproaches like AutoML typically rely on layers of abstraction, such as\ntree-based or Cartesian genetic programming. Our study introduces \"Guided\nEvolution\" (GE), a novel framework that diverges from these methods by\nutilizing Large Language Models (LLMs) to directly modify code. GE leverages\nLLMs for a more intelligent, supervised evolutionary process, guiding mutations\nand crossovers. Our unique \"Evolution of Thought\" (EoT) technique further\nenhances GE by enabling LLMs to reflect on and learn from the outcomes of\nprevious mutations. This results in a self-sustaining feedback loop that\naugments decision-making in model evolution. GE maintains genetic diversity,\ncrucial for evolutionary algorithms, by leveraging LLMs' capability to generate\ndiverse responses from expertly crafted prompts and modulate model temperature.\nThis not only accelerates the evolution process but also injects expert like\ncreativity and insight into the process. Our application of GE in evolving the\nExquisiteNetV2 model demonstrates its efficacy: the LLM-driven GE autonomously\nproduced variants with improved accuracy, increasing from 92.52% to 93.34%,\nwithout compromising model compactness. This underscores the potential of LLMs\nto accelerate the traditional model design pipeline, enabling models to\nautonomously evolve and enhance their own designs.\n","authors":["Clint Morris","Michael Jurado","Jason Zutty"],"pdf_url":"https://arxiv.org/pdf/2403.11446v1.pdf","comment":null}]},"2024-03-17T00:00:00Z":{"Computer Science and Game Theory":[{"id":"http://arxiv.org/abs/2403.11345v1","updated":"2024-03-17T21:11:55Z","published":"2024-03-17T21:11:55Z","title":"Independent RL for Cooperative-Competitive Agents: A Mean-Field\n  Perspective","summary":"  We address in this paper Reinforcement Learning (RL) among agents that are\ngrouped into teams such that there is cooperation within each team but\ngeneral-sum (non-zero sum) competition across different teams. To develop an RL\nmethod that provably achieves a Nash equilibrium, we focus on a\nlinear-quadratic structure. Moreover, to tackle the non-stationarity induced by\nmulti-agent interactions in the finite population setting, we consider the case\nwhere the number of agents within each team is infinite, i.e., the mean-field\nsetting. This results in a General-Sum LQ Mean-Field Type Game (GS-MFTGs). We\ncharacterize the Nash equilibrium (NE) of the GS-MFTG, under a standard\ninvertibility condition. This MFTG NE is then shown to be $\\mathcal{O}(1/M)$-NE\nfor the finite population game where $M$ is a lower bound on the number of\nagents in each team. These structural results motivate an algorithm called\nMulti-player Receding-horizon Natural Policy Gradient (MRPG), where each team\nminimizes its cumulative cost independently in a receding-horizon manner.\nDespite the non-convexity of the problem, we establish that the resulting\nalgorithm converges to a global NE through a novel problem decomposition into\nsub-problems using backward recursive discrete-time Hamilton-Jacobi-Isaacs\n(HJI) equations, in which independent natural policy gradient is shown to\nexhibit linear convergence under time-independent diagonal dominance.\nExperiments illuminate the merits of this approach in practice.\n","authors":["Muhammad Aneeq uz Zaman","Alec Koppel","Mathieu Laurière","Tamer Başar"],"pdf_url":"https://arxiv.org/pdf/2403.11345v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.14510v3","updated":"2024-03-17T21:10:24Z","published":"2023-12-22T08:18:25Z","title":"Strategic Bidding Wars in On-chain Auctions","summary":"  The Ethereum block-building process has changed significantly since the\nemergence of Proposer-Builder Separation. Validators access blocks through a\nmarketplace, where block builders bid for the right to construct the block and\nearn MEV (Maximal Extractable Value) rewards in an on-chain competition, known\nas the MEV-boost auction. While more than 90% of blocks are currently built via\nMEV-Boost, trade-offs between builders' strategic behaviors and auction design\nremain poorly understood. In this paper we address this gap. We introduce a\ngame-theoretic model for MEV-Boost auctions and use simulations to study\ndifferent builders' bidding strategies observed in practice. We study various\nstrategic interactions and auction setups and evaluate how the interplay\nbetween critical elements such as access to MEV opportunities and improved\nconnectivity to relays impact bidding performance. Our results demonstrate the\nimportance of latency on the effectiveness of builders' strategies and the\noverall auction outcome from the proposer's perspective.\n","authors":["Fei Wu","Thomas Thiery","Stefanos Leonardos","Carmine Ventre"],"pdf_url":"https://arxiv.org/pdf/2312.14510v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.11307v1","updated":"2024-03-17T19:05:40Z","published":"2024-03-17T19:05:40Z","title":"An upper bound of the mutation probability in the genetic algorithm for\n  general 0-1 knapsack problem","summary":"  As an important part of genetic algorithms (GAs), mutation operators is\nwidely used in evolutionary algorithms to solve $\\mathcal{NP}$-hard problems\nbecause it can increase the population diversity of individual. Due to\nlimitations in mathematical tools, the mutation probability of the mutation\noperator is primarily empirically set in practical applications.\n  In this paper, we propose a novel reduction method for the 0-1 knapsack\nproblem(0-1 KP) and an improved mutation operator (IMO) based on the assumption\n$\\mathcal{NP}\\neq\\mathcal{P}$, along with the utilization of linear relaxation\ntechniques and a recent result by Dey et al. (Math. Prog., pp 569-587, 2022).\nWe employ this method to calculate an upper bound of the mutation probability\nin general instances of the 0-1 KP, and construct an instance where the\nmutation probability does not tend towards 0 as the problem size increases.\nFinally, we prove that the probability of the IMO hitting the optimal solution\nwithin only a single iteration in large-scale instances is superior to that of\nthe traditional mutation operator.\n","authors":["Yang Yang"],"pdf_url":"https://arxiv.org/pdf/2403.11307v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.11267v1","updated":"2024-03-17T16:43:15Z","published":"2024-03-17T16:43:15Z","title":"Barely Random Algorithms for Metrical Task Systems","summary":"  We consider metrical task systems on general metric spaces with $n$ points,\nand show that any fully randomized algorithm can be turned into a randomized\nalgorithm that uses only $2\\log n$ random bits, and achieves the same\ncompetitive ratio up to a factor $2$. This provides the first order-optimal\nbarely random algorithms for metrical task systems, i.e. which use a number of\nrandom bits that does not depend on the number of requests addressed to the\nsystem. We put forward an equivalent view that we call collective metrical task\nsystems where $k$ agents in a metrical task system team up, and suffer the\naverage cost paid by each agent. Our results imply that such team can be\n$O(\\log n^2)$-competitive, as soon as $k\\geq n^2$ (in comparison, a single\nagent is $\\Omega(n)$-competitive at best). We discuss implications on various\naspects of online decision making such as: distributed systems, transaction\ncosts, and advice complexity, suggesting broad applicability.\n","authors":["Romain Cosson","Laurent Massoulié"],"pdf_url":"https://arxiv.org/pdf/2403.11267v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.11054v1","updated":"2024-03-17T01:51:09Z","published":"2024-03-17T01:51:09Z","title":"A Novel Mutual Insurance Model for Hedging Against Cyber Risks in Power\n  Systems Deploying Smart Technologies","summary":"  In this paper, a novel cyber-insurance model design is proposed based on\nsystem risk evaluation with smart technology applications. The cyber insurance\npolicy for power systems is tailored via cyber risk modeling, reliability\nimpact analysis, and insurance premium calculation. A stochastic Epidemic\nNetwork Model is developed to evaluate the cyber risk by propagating\ncyberattacks among graphical vulnerabilities. Smart technologies deployed in\nrisk modeling include smart monitoring and job thread assignment. Smart\nmonitoring boosts the substation availability against cyberattacks with\npreventive and corrective measures. The job thread assignment solution reduces\nthe execution failures by distributing the control and monitoring tasks to\nmultiple threads. Reliability assessment is deployed to estimate load losses\nconvertible to monetary losses. These monetary losses would be shared through a\nmutual insurance plan. To ensure a fair distribution of indemnity, a new\nShapley mutual insurance principle is devised. Effectiveness of the proposed\nShapley mutual insurance design is validated via case studies. The Shapley\npremium is compared with existent premium designs. It is shown that the Shapley\npremium has high indemnity levels closer to those of Tail Conditional\nExpectation premium. Meanwhile, the Shapley premium is nearly as affordable as\nthe coalitional premium and keeps a relatively low insolvency probability.\n","authors":["Pikkin Lau","Lingfeng Wang","Wei Wei","Zhaoxi Liu","Chee-Wooi Ten"],"pdf_url":"https://arxiv.org/pdf/2403.11054v1.pdf","comment":"Power system reliability, cyber-insurance, power system security,\n  cyber-physical systems, cyber risk modeling, actuarial design, tail risk"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2403.11307v1","updated":"2024-03-17T19:05:40Z","published":"2024-03-17T19:05:40Z","title":"An upper bound of the mutation probability in the genetic algorithm for\n  general 0-1 knapsack problem","summary":"  As an important part of genetic algorithms (GAs), mutation operators is\nwidely used in evolutionary algorithms to solve $\\mathcal{NP}$-hard problems\nbecause it can increase the population diversity of individual. Due to\nlimitations in mathematical tools, the mutation probability of the mutation\noperator is primarily empirically set in practical applications.\n  In this paper, we propose a novel reduction method for the 0-1 knapsack\nproblem(0-1 KP) and an improved mutation operator (IMO) based on the assumption\n$\\mathcal{NP}\\neq\\mathcal{P}$, along with the utilization of linear relaxation\ntechniques and a recent result by Dey et al. (Math. Prog., pp 569-587, 2022).\nWe employ this method to calculate an upper bound of the mutation probability\nin general instances of the 0-1 KP, and construct an instance where the\nmutation probability does not tend towards 0 as the problem size increases.\nFinally, we prove that the probability of the IMO hitting the optimal solution\nwithin only a single iteration in large-scale instances is superior to that of\nthe traditional mutation operator.\n","authors":["Yang Yang"],"pdf_url":"https://arxiv.org/pdf/2403.11307v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.16922v3","updated":"2024-03-17T15:36:53Z","published":"2023-06-14T13:34:13Z","title":"The Expressive Leaky Memory Neuron: an Efficient and Expressive\n  Phenomenological Neuron Model Can Solve Long-Horizon Tasks","summary":"  Biological cortical neurons are remarkably sophisticated computational\ndevices, temporally integrating their vast synaptic input over an intricate\ndendritic tree, subject to complex, nonlinearly interacting internal biological\nprocesses. A recent study proposed to characterize this complexity by fitting\naccurate surrogate models to replicate the input-output relationship of a\ndetailed biophysical cortical pyramidal neuron model and discovered it needed\ntemporal convolutional networks (TCN) with millions of parameters. Requiring\nthese many parameters, however, could stem from a misalignment between the\ninductive biases of the TCN and cortical neuron's computations. In light of\nthis, and to explore the computational implications of leaky memory units and\nnonlinear dendritic processing, we introduce the Expressive Leaky Memory (ELM)\nneuron model, a biologically inspired phenomenological model of a cortical\nneuron. Remarkably, by exploiting such slowly decaying memory-like hidden\nstates and two-layered nonlinear integration of synaptic input, our ELM neuron\ncan accurately match the aforementioned input-output relationship with under\nten thousand trainable parameters. To further assess the computational\nramifications of our neuron design, we evaluate it on various tasks with\ndemanding temporal structures, including the Long Range Arena (LRA) datasets,\nas well as a novel neuromorphic dataset based on the Spiking Heidelberg Digits\ndataset (SHD-Adding). Leveraging a larger number of memory units with\nsufficiently long timescales, and correspondingly sophisticated synaptic\nintegration, the ELM neuron displays substantial long-range processing\ncapabilities, reliably outperforming the classic Transformer or Chrono-LSTM\narchitectures on LRA, and even solving the Pathfinder-X task with over 70%\naccuracy (16k context length).\n","authors":["Aaron Spieler","Nasim Rahaman","Georg Martius","Bernhard Schölkopf","Anna Levina"],"pdf_url":"https://arxiv.org/pdf/2306.16922v3.pdf","comment":"25 pages, 14 figures, 13 tables, additional experiments and\n  clarifications, accepted to ICLR 2024"},{"id":"http://arxiv.org/abs/2311.12867v2","updated":"2024-03-17T14:05:24Z","published":"2023-11-08T14:45:25Z","title":"Amplitude-Ensemble Quantum-Inspired Tabu Search Algorithm for Solving\n  0/1 Knapsack Problems","summary":"  In this paper, an improved version of QTS (Quantum-inspired Tabu Search) has\nbeen proposed, which enhances the utilization of population information, called\n\"amplitude-ensemble\" QTS (AE-QTS). This makes AE-QTS more similar to the real\nquantum search algorithm, Grover Search Algorithm, in abstract concept, while\nkeeping the simplicity of the algorithm. Later, we demonstrate the AE-QTS on\nthe classical combinatorial optimization 0/1 knapsack problem. Experimental\nresults show that the AE-QTS outperforms other algorithms, including the QTS,\nby at least an average of 20% in all cases and even by 30% in some cases. Even\nas the problem complexity increases, the quality of the solutions found by our\nmethod remains superior to that of the QTS. These results prove that our method\nhas better search performance.\n","authors":["Kuo-Chun Tseng","Wei-Chieh Lai","I-Chia Chen","Yun-Hsiang Hsiao","Jr-Yu Chiue","Wei-Chun Huang"],"pdf_url":"https://arxiv.org/pdf/2311.12867v2.pdf","comment":"7 pages, 7 figures"},{"id":"http://arxiv.org/abs/2403.11173v1","updated":"2024-03-17T11:19:45Z","published":"2024-03-17T11:19:45Z","title":"Multi-Objective Evolutionary Neural Architecture Search for Recurrent\n  Neural Networks","summary":"  Artificial neural network (NN) architecture design is a nontrivial and\ntime-consuming task that often requires a high level of human expertise. Neural\narchitecture search (NAS) serves to automate the design of NN architectures and\nhas proven to be successful in automatically finding NN architectures that\noutperform those manually designed by human experts. NN architecture\nperformance can be quantified based on multiple objectives, which include model\naccuracy and some NN architecture complexity objectives, among others. The\nmajority of modern NAS methods that consider multiple objectives for NN\narchitecture performance evaluation are concerned with automated feed forward\nNN architecture design, which leaves multi-objective automated recurrent neural\nnetwork (RNN) architecture design unexplored. RNNs are important for modeling\nsequential datasets, and prominent within the natural language processing\ndomain. It is often the case in real world implementations of machine learning\nand NNs that a reasonable trade-off is accepted for marginally reduced model\naccuracy in favour of lower computational resources demanded by the model. This\npaper proposes a multi-objective evolutionary algorithm-based RNN architecture\nsearch method. The proposed method relies on approximate network morphisms for\nRNN architecture complexity optimisation during evolution. The results show\nthat the proposed method is capable of finding novel RNN architectures with\ncomparable performance to state-of-the-art manually designed RNN architectures,\nbut with reduced computational demand.\n","authors":["Reinhard Booysen","Anna Sergeevna Bosman"],"pdf_url":"https://arxiv.org/pdf/2403.11173v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.11159v1","updated":"2024-03-17T09:50:20Z","published":"2024-03-17T09:50:20Z","title":"Deep Neural Crossover","summary":"  We present a novel multi-parent crossover operator in genetic algorithms\n(GAs) called ``Deep Neural Crossover'' (DNC). Unlike conventional GA crossover\noperators that rely on a random selection of parental genes, DNC leverages the\ncapabilities of deep reinforcement learning (DRL) and an encoder-decoder\narchitecture to select the genes. Specifically, we use DRL to learn a policy\nfor selecting promising genes. The policy is stochastic, to maintain the\nstochastic nature of GAs, representing a distribution for selecting genes with\na higher probability of improving fitness. Our architecture features a\nrecurrent neural network (RNN) to encode the parental genomes into latent\nmemory states, and a decoder RNN that utilizes an attention-based pointing\nmechanism to generate a distribution over the next selected gene in the\noffspring. To improve the training time, we present a pre-training approach,\nwherein the architecture is initially trained on a single problem within a\nspecific domain and then applied to solving other problems of the same domain.\nWe compare DNC to known operators from the literature over two benchmark\ndomains -- bin packing and graph coloring. We compare with both two- and\nthree-parent crossover, outperforming all baselines. DNC is domain-independent\nand can be easily applied to other problem domains.\n","authors":["Eliad Shem-Tov","Achiya Elyasaf"],"pdf_url":"https://arxiv.org/pdf/2403.11159v1.pdf","comment":"7 pages, 3 figures, 4 tables. Submitted to the Genetic and\n  Evolutionary Computation Conference (GECCO 2024)"},{"id":"http://arxiv.org/abs/2403.11100v1","updated":"2024-03-17T06:08:08Z","published":"2024-03-17T06:08:08Z","title":"Graph Expansion in Pruned Recurrent Neural Network Layers Preserve\n  Performance","summary":"  Expansion property of a graph refers to its strong connectivity as well as\nsparseness. It has been reported that deep neural networks can be pruned to a\nhigh degree of sparsity while maintaining their performance. Such pruning is\nessential for performing real time sequence learning tasks using recurrent\nneural networks in resource constrained platforms. We prune recurrent networks\nsuch as RNNs and LSTMs, maintaining a large spectral gap of the underlying\ngraphs and ensuring their layerwise expansion properties. We also study the\ntime unfolded recurrent network graphs in terms of the properties of their\nbipartite layers. Experimental results for the benchmark sequence MNIST,\nCIFAR-10, and Google speech command data show that expander graph properties\nare key to preserving classification accuracy of RNN and LSTM.\n","authors":["Suryam Arnav Kalra","Arindam Biswas","Pabitra Mitra","Biswajit Basu"],"pdf_url":"https://arxiv.org/pdf/2403.11100v1.pdf","comment":"Accepted as tiny paper in ICLR 2024"}]},"2024-03-16T00:00:00Z":{"Computer Science and Game Theory":[{"id":"http://arxiv.org/abs/2403.11022v1","updated":"2024-03-16T21:54:13Z","published":"2024-03-16T21:54:13Z","title":"Auctions with Dynamic Scoring","summary":"  We study the design of auctions with dynamic scoring, which allocate a single\nitem according to a given scoring rule. We are motivated by online advertising\nauctions when users interact with a platform over the course of a session. The\nplatform ranks ads based on a combination of bids and quality scores, and\nupdates the quality scores throughout the session based on the user's online\nactivity. The platform must decide when to show an ad during the session. By\ndelaying the auction, the auctioneer acquires information about an ad's\nquality, improving her chances of selecting a high quality ad. However\ninformation is costly, because delay reduces market thickness and in turn\nrevenue. When should the auctioneer allocate the impression to balance these\nforces?\n  We develop a theoretical model to study the effect of market design on the\ntrade-off between market thickness and information. In particular, we focus on\nfirst- and second-price auctions. The auctioneer can commit to the auction\nformat, but not to its timing: her decision can thus be cast as a real options\nproblem. We show that under optimal stopping the first-price auction allocates\nefficiently but with delay. Instead, the second-price auction generates more\nrevenue by avoiding delay. The auctioneer benefits from introducing reserve\nprices, more so in a first-price auction.\n","authors":["Martino Banchio","Aranyak Mehta","Andres Perlroth"],"pdf_url":"https://arxiv.org/pdf/2403.11022v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.10980v1","updated":"2024-03-16T17:23:20Z","published":"2024-03-16T17:23:20Z","title":"Inverse learning of black-box aggregator for robust Nash equilibrium","summary":"  In this note, we investigate the robustness of Nash equilibria (NE) in\nmulti-player aggregative games with coupling constraints. There are many\nalgorithms for computing an NE of an aggregative game given a known aggregator.\nWhen the coupling parameters are affected by uncertainty, robust NE need to be\ncomputed. We consider a scenario where players' weight in the aggregator is\nunknown, making the aggregator kind of \"a black box\". We pursue a suitable\nlearning approach to estimate the unknown aggregator by proposing an inverse\nvariational inequality-based relationship. We then utilize the counterpart to\nreconstruct the game and obtain first-order conditions for robust NE in the\nworst case. Furthermore, we characterize the generalization property of the\nlearning methodology via an upper bound on the violation probability.\nSimulation experiments show the effectiveness of the proposed inverse learning\napproach.\n","authors":["Guanpu Chen","Gehui Xu","Fengxiang He","Dacheng Tao","Thomas Parisini","Karl Henrik Johansson"],"pdf_url":"https://arxiv.org/pdf/2403.10980v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.15935v2","updated":"2024-03-16T02:55:59Z","published":"2023-10-24T15:32:54Z","title":"Mediator Interpretation and Faster Learning Algorithms for Linear\n  Correlated Equilibria in General Extensive-Form Games","summary":"  A recent paper by Farina & Pipis (2023) established the existence of\nuncoupled no-linear-swap regret dynamics with polynomial-time iterations in\nextensive-form games. The equilibrium points reached by these dynamics, known\nas linear correlated equilibria, are currently the tightest known relaxation of\ncorrelated equilibrium that can be learned in polynomial time in any finite\nextensive-form game. However, their properties remain vastly unexplored, and\ntheir computation is onerous. In this paper, we provide several contributions\nshedding light on the fundamental nature of linear-swap regret. First, we show\na connection between linear deviations and a generalization of communication\ndeviations in which the player can make queries to a \"mediator\" who replies\nwith action recommendations, and, critically, the player is not constrained to\nmatch the timing of the game as would be the case for communication deviations.\nWe coin this latter set the untimed communication (UTC) deviations. We show\nthat the UTC deviations coincide precisely with the linear deviations, and\ntherefore that any player minimizing UTC regret also minimizes linear-swap\nregret. We then leverage this connection to develop state-of-the-art no-regret\nalgorithms for computing linear correlated equilibria, both in theory and in\npractice. In theory, our algorithms achieve polynomially better per-iteration\nruntimes; in practice, our algorithms represent the state of the art by several\norders of magnitude.\n","authors":["Brian Hu Zhang","Gabriele Farina","Tuomas Sandholm"],"pdf_url":"https://arxiv.org/pdf/2310.15935v2.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2403.11041v1","updated":"2024-03-16T23:24:03Z","published":"2024-03-16T23:24:03Z","title":"FAGH: Accelerating Federated Learning with Approximated Global Hessian","summary":"  In federated learning (FL), the significant communication overhead due to the\nslow convergence speed of training the global model poses a great challenge.\nSpecifically, a large number of communication rounds are required to achieve\nthe convergence in FL. One potential solution is to employ the Newton-based\noptimization method for training, known for its quadratic convergence rate.\nHowever, the existing Newton-based FL training methods suffer from either\nmemory inefficiency or high computational costs for local clients or the\nserver. To address this issue, we propose an FL with approximated global\nHessian (FAGH) method to accelerate FL training. FAGH leverages the first\nmoment of the approximated global Hessian and the first moment of the global\ngradient to train the global model. By harnessing the approximated global\nHessian curvature, FAGH accelerates the convergence of global model training,\nleading to the reduced number of communication rounds and thus the shortened\ntraining time. Experimental results verify FAGH's effectiveness in decreasing\nthe number of communication rounds and the time required to achieve the\npre-specified objectives of the global model performance in terms of training\nand test losses as well as test accuracy. Notably, FAGH outperforms several\nstate-of-the-art FL training methods.\n","authors":["Mrinmay Sen","A. K. Qin","Krishna Mohan C"],"pdf_url":"https://arxiv.org/pdf/2403.11041v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.11035v1","updated":"2024-03-16T22:49:47Z","published":"2024-03-16T22:49:47Z","title":"Multiplane Quantitative Phase Imaging Using a Wavelength-Multiplexed\n  Diffractive Optical Processor","summary":"  Quantitative phase imaging (QPI) is a label-free technique that provides\noptical path length information for transparent specimens, finding utility in\nbiology, materials science, and engineering. Here, we present quantitative\nphase imaging of a 3D stack of phase-only objects using a\nwavelength-multiplexed diffractive optical processor. Utilizing multiple\nspatially engineered diffractive layers trained through deep learning, this\ndiffractive processor can transform the phase distributions of multiple 2D\nobjects at various axial positions into intensity patterns, each encoded at a\nunique wavelength channel. These wavelength-multiplexed patterns are projected\nonto a single field-of-view (FOV) at the output plane of the diffractive\nprocessor, enabling the capture of quantitative phase distributions of input\nobjects located at different axial planes using an intensity-only image sensor.\nBased on numerical simulations, we show that our diffractive processor could\nsimultaneously achieve all-optical quantitative phase imaging across several\ndistinct axial planes at the input by scanning the illumination wavelength. A\nproof-of-concept experiment with a 3D-fabricated diffractive processor further\nvalidated our approach, showcasing successful imaging of two distinct phase\nobjects at different axial positions by scanning the illumination wavelength in\nthe terahertz spectrum. Diffractive network-based multiplane QPI designs can\nopen up new avenues for compact on-chip phase imaging and sensing devices.\n","authors":["Che-Yung Shen","Jingxi Li","Tianyi Gan","Yuhang Li","Langxing Bai","Mona Jarrahi","Aydogan Ozcan"],"pdf_url":"https://arxiv.org/pdf/2403.11035v1.pdf","comment":"27 Pages, 9 Figures"},{"id":"http://arxiv.org/abs/2311.12424v3","updated":"2024-03-16T21:10:38Z","published":"2023-11-21T08:32:38Z","title":"Looped Transformers are Better at Learning Learning Algorithms","summary":"  Transformers have demonstrated effectiveness in in-context solving\ndata-fitting problems from various (latent) models, as reported by Garg et al.\nHowever, the absence of an inherent iterative structure in the transformer\narchitecture presents a challenge in emulating the iterative algorithms, which\nare commonly employed in traditional machine learning methods. To address this,\nwe propose the utilization of looped transformer architecture and its\nassociated training methodology, with the aim of incorporating iterative\ncharacteristics into the transformer architectures. Experimental results\nsuggest that the looped transformer achieves performance comparable to the\nstandard transformer in solving various data-fitting problems, while utilizing\nless than 10% of the parameter count.\n","authors":["Liu Yang","Kangwook Lee","Robert Nowak","Dimitris Papailiopoulos"],"pdf_url":"https://arxiv.org/pdf/2311.12424v3.pdf","comment":"Accepted for publication at ICLR 2024"},{"id":"http://arxiv.org/abs/2206.15238v2","updated":"2024-03-16T17:08:42Z","published":"2022-06-30T12:35:36Z","title":"Runtime Analysis of Competitive co-Evolutionary Algorithms for Maximin\n  Optimisation of a Bilinear Function","summary":"  Co-evolutionary algorithms have a wide range of applications, such as in\nhardware design, evolution of strategies for board games, and patching software\nbugs. However, these algorithms are poorly understood and applications are\noften limited by pathological behaviour, such as loss of gradient, relative\nover-generalisation, and mediocre objective stasis. It is an open challenge to\ndevelop a theory that can predict when co-evolutionary algorithms find\nsolutions efficiently and reliable.\n  This paper provides a first step in developing runtime analysis for\npopulation-based competitive co-evolutionary algorithms. We provide a\nmathematical framework for describing and reasoning about the performance of\nco-evolutionary processes. An example application of the framework shows a\nscenario where a simple co-evolutionary algorithm obtains a solution in\npolynomial expected time. Finally, we describe settings where the\nco-evolutionary algorithm needs exponential time with overwhelmingly high\nprobability to obtain a solution.\n","authors":["Per Kristian Lehre"],"pdf_url":"https://arxiv.org/pdf/2206.15238v2.pdf","comment":"To appear in Algorithmica"},{"id":"http://arxiv.org/abs/2403.01827v2","updated":"2024-03-16T15:43:04Z","published":"2024-03-04T08:22:29Z","title":"Analysis and Fully Memristor-based Reservoir Computing for Temporal Data\n  Classification","summary":"  Reservoir computing (RC) offers a neuromorphic framework that is particularly\neffective for processing spatiotemporal signals. Known for its temporal\nprocessing prowess, RC significantly lowers training costs compared to\nconventional recurrent neural networks. A key component in its hardware\ndeployment is the ability to generate dynamic reservoir states. Our research\nintroduces a novel dual-memory RC system, integrating a short-term memory via a\nWOx-based memristor, capable of achieving 16 distinct states encoded over 4\nbits, and a long-term memory component using a TiOx-based memristor within the\nreadout layer. We thoroughly examine both memristor types and leverage the RC\nsystem to process temporal data sets. The performance of the proposed RC system\nis validated through two benchmark tasks: isolated spoken digit recognition\nwith incomplete inputs and Mackey-Glass time series prediction. The system\ndelivered an impressive 98.84% accuracy in digit recognition and sustained a\nlow normalized root mean square error (NRMSE) of 0.036 in the time series\nprediction task, underscoring its capability. This study illuminates the\nadeptness of memristor-based RC systems in managing intricate temporal\nchallenges, laying the groundwork for further innovations in neuromorphic\ncomputing.\n","authors":["Ankur Singh","Sanghyeon Choi","Gunuk Wang","Maryaradhiya Daimari","Byung-Geun Lee"],"pdf_url":"https://arxiv.org/pdf/2403.01827v2.pdf","comment":"22 pages, 20 figures, Journal, Typo corrected and updated reference"},{"id":"http://arxiv.org/abs/2310.09692v2","updated":"2024-03-16T05:45:59Z","published":"2023-10-15T01:05:35Z","title":"Spike-based Neuromorphic Computing for Next-Generation Computer Vision","summary":"  Neuromorphic Computing promises orders of magnitude improvement in energy\nefficiency compared to traditional von Neumann computing paradigm. The goal is\nto develop an adaptive, fault-tolerant, low-footprint, fast, low-energy\nintelligent system by learning and emulating brain functionality which can be\nrealized through innovation in different abstraction layers including material,\ndevice, circuit, architecture and algorithm. As the energy consumption in\ncomplex vision tasks keep increasing exponentially due to larger data set and\nresource-constrained edge devices become increasingly ubiquitous, spike-based\nneuromorphic computing approaches can be viable alternative to deep\nconvolutional neural network that is dominating the vision field today. In this\nbook chapter, we introduce neuromorphic computing, outline a few representative\nexamples from different layers of the design stack (devices, circuits and\nalgorithms) and conclude with a few exciting applications and future research\ndirections that seem promising for computer vision in the near future.\n","authors":["Md Sakib Hasan","Catherine D. Schuman","Zhongyang Zhang","Tauhidur Rahman","Garrett S. Rose"],"pdf_url":"https://arxiv.org/pdf/2310.09692v2.pdf","comment":"Pending to be published as a book chapter in the book 'Computer\n  Vision: Challenges, Trends, and Opportunities' from CRC Press"},{"id":"http://arxiv.org/abs/2304.09444v4","updated":"2024-03-16T02:36:37Z","published":"2023-04-19T06:25:04Z","title":"Rank-Based Learning and Local Model Based Evolutionary Algorithm for\n  High-Dimensional Expensive Multi-Objective Problems","summary":"  Surrogate-assisted evolutionary algorithms have been widely developed to\nsolve complex and computationally expensive multi-objective optimization\nproblems in recent years. However, when dealing with high-dimensional\noptimization problems, the performance of these surrogate-assisted\nmulti-objective evolutionary algorithms deteriorate drastically. In this work,\na novel Classifier-assisted rank-based learning and Local Model based\nmulti-objective Evolutionary Algorithm (CLMEA) is proposed for high-dimensional\nexpensive multi-objective optimization problems. The proposed algorithm\nconsists of three parts: classifier-assisted rank-based learning,\nhypervolume-based non-dominated search, and local search in the relatively\nsparse objective space. Specifically, a probabilistic neural network is built\nas classifier to divide the offspring into a number of ranks. The offspring in\ndifferent ranks uses rank-based learning strategy to generate more promising\nand informative candidates for real function evaluations. Then, radial basis\nfunction networks are built as surrogates to approximate the objective\nfunctions. After searching non-dominated solutions assisted by the surrogate\nmodel, the candidates with higher hypervolume improvement are selected for real\nevaluations. Subsequently, in order to maintain the diversity of solutions, the\nmost uncertain sample point from the non-dominated solutions measured by the\ncrowding distance is selected as the guided parent to further infill in the\nuncertain region of the front. The experimental results of benchmark problems\nand a real-world application on geothermal reservoir heat extraction\noptimization demonstrate that the proposed algorithm shows superior performance\ncompared with the state-of-the-art surrogate-assisted multi-objective\nevolutionary algorithms. The source code for this work is available at\nhttps://github.com/JellyChen7/CLMEA.\n","authors":["Guodong Chen","Jiu Jimmy Jiao","Xiaoming Xue","Zhongzheng Wang"],"pdf_url":"https://arxiv.org/pdf/2304.09444v4.pdf","comment":null}]},"2024-03-15T00:00:00Z":{"Computer Science and Game Theory":[{"id":"http://arxiv.org/abs/2111.03174v2","updated":"2024-03-15T20:51:20Z","published":"2021-11-04T21:56:23Z","title":"Single-Sample Prophet Inequalities via Greedy-Ordered Selection","summary":"  We study single-sample prophet inequalities (SSPIs), i.e., prophet\ninequalities where only a single sample from each prior distribution is\navailable. Besides a direct, and optimal, SSPI for the basic single choice\nproblem [Rubinstein et al., 2020], most existing SSPI results were obtained via\nan elegant, but inherently lossy, reduction to order-oblivious secretary (OOS)\npolicies [Azar et al., 2014]. Motivated by this discrepancy, we develop an\nintuitive and versatile greedy-based technique that yields SSPIs directly\nrather than through the reduction to OOSs. Our results can be seen as\ngeneralizing and unifying a number of existing results in the area of prophet\nand secretary problems. Our algorithms significantly improve on the competitive\nguarantees for a number of interesting scenarios (including general matching\nwith edge arrivals, bipartite matching with vertex arrivals, and certain\nmatroids), and capture new settings (such as budget additive combinatorial\nauctions). Complementing our algorithmic results, we also consider mechanism\ndesign variants. Finally, we analyze the power and limitations of different\nSSPI approaches by providing a partial converse to the reduction from SSPI to\nOOS given by Azar et al.\n","authors":["Constantine Caramanis","Paul Dütting","Matthew Faw","Federico Fusco","Philip Lazos","Stefano Leonardi","Orestis Papadigenopoulos","Emmanouil Pountourakis","Rebecca Reiffenhäuser"],"pdf_url":"https://arxiv.org/pdf/2111.03174v2.pdf","comment":"Merges and extends arXiv:2103.13089 [cs.GT] and arXiv:2104.02050\n  [cs.DS]"},{"id":"http://arxiv.org/abs/2205.08104v4","updated":"2024-03-15T16:55:46Z","published":"2022-05-17T05:59:52Z","title":"Restricting Entries to All-Pay Contests","summary":"  We study an all-pay contest where players with low abilities are filtered\nprior to the round of competing for prizes. These are often practiced due to\nlimited resources or to enhance the competitiveness of the contest. We consider\na setting where the designer admits a certain number of top players into the\ncontest. The players admitted into the contest update their beliefs about their\nopponents based on the signal that their abilities are among the top. We find\nthat their posterior beliefs, even with IID priors, are correlated and depend\non players' private abilities, representing a unique feature of this game. We\nexplicitly characterize the symmetric and unique Bayesian equilibrium strategy.\nWe find that each admitted player's equilibrium effort is in general not\nmonotone with the number of admitted players. Despite this non-monotonicity,\nsurprisingly, all players exert their highest efforts when all players are\nadmitted. This result holds generally -- it is true under any ranking-based\nprize structure, ability distribution, and cost function. We also discuss a\ntwo-stage extension where players with top first-stage efforts can proceed to\nthe second stage competing for prizes.\n","authors":["Fupeng Sun","Yanwei Sun","Chiwei Yan","Li Jin"],"pdf_url":"https://arxiv.org/pdf/2205.08104v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.10451v1","updated":"2024-03-15T16:36:15Z","published":"2024-03-15T16:36:15Z","title":"Subgame Optimal and Prior-Independent Online Algorithms","summary":"  This paper takes a game theoretic approach to the design and analysis of\nonline algorithms and illustrates the approach on the finite-horizon ski-rental\nproblem. This approach allows beyond worst-case analysis of online algorithms.\nFirst, we define \"subgame optimality\" which is stronger than worst case\noptimality in that it requires the algorithm to take advantage of an adversary\nnot playing a worst case input. Algorithms only focusing on the worst case can\nbe far from subgame optimal. Second, we consider prior-independent design and\nanalysis of online algorithms, where rather than choosing a worst case input,\nthe adversary chooses a worst case independent and identical distribution over\ninputs. Prior-independent online algorithms are generally analytically\nintractable; instead we give a fully polynomial time approximation scheme to\ncompute them. Highlighting the potential improvement from these paradigms for\nthe finite-horizon ski-rental problem, we empirically compare worst-case,\nsubgame optimal, and prior-independent algorithms in the prior-independent\nframework.\n","authors":["Jason Hartline","Aleck Johnsen","Anant Shah"],"pdf_url":"https://arxiv.org/pdf/2403.10451v1.pdf","comment":"22 main pages, 1 figure"},{"id":"http://arxiv.org/abs/2403.10384v1","updated":"2024-03-15T15:14:24Z","published":"2024-03-15T15:14:24Z","title":"Coordination in Noncooperative Multiplayer Matrix Games via Reduced Rank\n  Correlated Equilibria","summary":"  Coordination in multiplayer games enables players to avoid the lose-lose\noutcome that often arises at Nash equilibria. However, designing a coordination\nmechanism typically requires the consideration of the joint actions of all\nplayers, which becomes intractable in large-scale games. We develop a novel\ncoordination mechanism, termed reduced rank correlated equilibria, which\nreduces the number of joint actions to be considered and thereby mitigates\ncomputational complexity. The idea is to approximate the set of all joint\nactions with the actions used in a set of pre-computed Nash equilibria via a\nconvex hull operation. In a game with n players and each player having m\nactions, the proposed mechanism reduces the number of joint actions considered\nfrom O(m^n) to O(mn). We demonstrate the application of the proposed mechanism\nto an air traffic queue management problem. Compared with the correlated\nequilibrium-a popular benchmark coordination mechanism-the proposed approach is\ncapable of solving a queue management problem involving four thousand times\nmore joint actions. In the meantime, it yields a solution that shows a 58.5% to\n99.5% improvement in the fairness indicator and a 1.8% to 50.4% reduction in\naverage delay cost compared to the Nash solution, which does not involve\ncoordination.\n","authors":["Jaehan Im","Yue Yu","David Fridovich-Keil","Ufuk Topcu"],"pdf_url":"https://arxiv.org/pdf/2403.10384v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.13838v5","updated":"2024-03-15T15:04:05Z","published":"2023-08-26T10:09:46Z","title":"Price-Discrimination Game for Distributed Resource Management in\n  Federated Learning","summary":"  In vanilla federated learning (FL) such as FedAvg, the parameter server (PS)\nand multiple distributed clients can form a typical buyer's market, where the\nnumber of PS/buyers of FL services is far less than the number of\nclients/sellers. In order to improve the performance of FL and reduce the cost\nof motivating clients to participate in FL, this paper proposes to\ndifferentiate the pricing for services provided by different clients rather\nthan simply providing the same service pricing for different clients. The price\nis differentiated based on the performance improvements brought to FL and their\nheterogeneity in computing and communication capabilities. To this end, a\nprice-discrimination game (PDG) is formulated to comprehensively address the\ndistributed resource management problems in FL, including multi-objective\ntrade-off, client selection, and incentive mechanism. As the PDG is a\nmixed-integer nonlinear programming (MINLP) problem, a distributed\nsemi-heuristic algorithm with low computational complexity and low\ncommunication overhead is designed to solve it. The simulation result verifies\nthe effectiveness of the proposed approach.\n","authors":["Han Zhang","Halvin Yang","Guopeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2308.13838v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.10310v1","updated":"2024-03-15T13:55:54Z","published":"2024-03-15T13:55:54Z","title":"Scaling Game-Theoretic Security Reasoning","summary":"  We present the CheckMate tool for automated verification of game-theoretic\nsecurity properties, with application to blockchain protocols. CheckMate\napplies automated reasoning techniques to determine whether a game-theoretic\nprotocol model is game-theoretically secure, that is, Byzantine fault tolerant\nand incentive compatible. We describe CheckMate's input format and its various\ncomponents, modes, and output. CheckMate is evaluated on 14 benchmarks,\nincluding models of decentralized protocols, board games, and game-theoretic\nexamples.\n","authors":["Sophie Rain","Lea Salome Brugger","Anja Petkovic Komel","Laura Kovacs","Michael Rawson"],"pdf_url":"https://arxiv.org/pdf/2403.10310v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2008.01680v3","updated":"2024-03-15T09:54:10Z","published":"2020-08-04T16:29:40Z","title":"Stable Matching Games","summary":"  Gale and Shapley introduced a matching problem between two sets of agents\nwhere each agent on one side has an exogenous preference ordering over the\nagents on the other side. They defined a matching as stable if no unmatched\npair can both improve their utility by forming a new pair. They proved,\nalgorithmically, the existence of a stable matching. Shapley and Shubik,\nDemange and Gale, and many others extended the model by allowing monetary\ntransfers. We offer a further extension by assuming that matched couples obtain\ntheir payoff endogenously as the outcome of a strategic game they have to play\nin a usual non-cooperative sense (without commitment) or in a semi-cooperative\nway (with commitment, as the outcome of a bilateral binding contract in which\neach player is responsible for her part of the contract). Depending on whether\nthe players can commit or not, we define in each case a solution concept that\ncombines Gale-Shapley pairwise stability with a (generalized) Nash equilibrium\nstability. In each case we give necessary and sufficient conditions for the set\nof solutions to be non-empty and provide an algorithm to compute a solution.\n","authors":["Felipe Garrido-Lucero","Rida Laraki"],"pdf_url":"https://arxiv.org/pdf/2008.01680v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.09991v1","updated":"2024-03-15T03:24:31Z","published":"2024-03-15T03:24:31Z","title":"DDPS: Dynamic Differential Pricing-based Edge Offloading System with\n  Energy Harvesting Devices","summary":"  Mobile edge computing (MEC) paves the way to alleviate the burden of energy\nand computation of mobile users (MUs) by offloading tasks to the network edge.\nTo enhance the MEC server utilization by optimizing its resource allocation, a\nwell-designed pricing strategy is indispensable. In this paper, we consider the\nedge offloading scenario with energy harvesting devices, and propose a dynamic\ndifferential pricing system (DDPS), which determines the price per unit time\naccording to the usage of computing resources to improve the edge server\nutilization. Firstly, we propose an offloading decision algorithm to decide\nwhether to conduct the offloading operation and how much data to be offloaded\nif conducted, the algorithm determines offloading operation by balancing the\nenergy harvested with the energy consumed. Secondly, for the offloading case,\nwe formulate the game between the MUs and the server as a Stackelberg game, and\npropose a differential pricing algorithm to determine the optimal computing\nresources required by MUs. Furthermore, the proposed algorithm also reallocates\ncomputing resources for delay-sensitive devices while server resources are\nsurplus after the initial allocation, aiming to make full use of the server\ncomputing resources. Extensive simulations are conducted to demonstrate the\neffectiveness of the proposed DDPS scheme.\n","authors":["Hai Xue","Yun Xia","Neal N. Xiong","Di Zhang","Songwen Pei"],"pdf_url":"https://arxiv.org/pdf/2403.09991v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.08082v3","updated":"2024-03-15T01:01:13Z","published":"2024-03-12T21:16:25Z","title":"Data Monetization Pathways and Complex Dynamic Game Equilibrium Analysis\n  in the Energy Industry","summary":"  As the most critical production factor in the era of the digital economy,\ndata will have a significant impact on social production and development.\nEnergy enterprises possess data that is interconnected with multiple\nindustries, characterized by diverse needs, sensitivity, and long-term nature.\nThe path to monetizing energy enterprises' data is challenging yet crucial.\nThis paper explores the game-theoretic aspects of the data monetization process\nin energy enterprises by considering the relationships between enterprises and\ntrading platforms. We construct a class of game decision models and study their\nequilibrium strategies. Our analysis shows that enterprises and platforms can\nadjust respective benefits by regulating the wholesale price of data and the\nintensity of data value mining to form a benign equilibrium state. Furthermore,\nby integrating nonlinear dynamical theory, we discuss the dynamic\ncharacteristics present in multi-period repeated game processes. We find that\ndecision-makers should keep the adjustment parameters and initial states within\nreasonable ranges in multi-period dynamic decision-making to avoid market\nfailure. Finally, based on the theoretical and numerical analysis, we provide\ndecision insights and recommendations for enterprise decision-making to\nfacilitate data monetization through strategic interactions with trading\nplatforms.\n","authors":["Zongxian Wang","Jie Song"],"pdf_url":"https://arxiv.org/pdf/2403.08082v3.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2311.00136v4","updated":"2024-03-15T22:07:06Z","published":"2023-10-31T20:17:32Z","title":"Neuroformer: Multimodal and Multitask Generative Pretraining for Brain\n  Data","summary":"  State-of-the-art systems neuroscience experiments yield large-scale\nmultimodal data, and these data sets require new tools for analysis. Inspired\nby the success of large pretrained models in vision and language domains, we\nreframe the analysis of large-scale, cellular-resolution neuronal spiking data\ninto an autoregressive spatiotemporal generation problem. Neuroformer is a\nmultimodal, multitask generative pretrained transformer (GPT) model that is\nspecifically designed to handle the intricacies of data in systems\nneuroscience. It scales linearly with feature size, can process an arbitrary\nnumber of modalities, and is adaptable to downstream tasks, such as predicting\nbehavior. We first trained Neuroformer on simulated datasets, and found that it\nboth accurately predicted simulated neuronal circuit activity, and also\nintrinsically inferred the underlying neural circuit connectivity, including\ndirection. When pretrained to decode neural responses, the model predicted the\nbehavior of a mouse with only few-shot fine-tuning, suggesting that the model\nbegins learning how to do so directly from the neural representations\nthemselves, without any explicit supervision. We used an ablation study to show\nthat joint training on neuronal responses and behavior boosted performance,\nhighlighting the model's ability to associate behavioral and neural\nrepresentations in an unsupervised manner. These findings show that Neuroformer\ncan analyze neural datasets and their emergent properties, informing the\ndevelopment of models and hypotheses associated with the brain.\n","authors":["Antonis Antoniades","Yiyi Yu","Joseph Canzano","William Wang","Spencer LaVere Smith"],"pdf_url":"https://arxiv.org/pdf/2311.00136v4.pdf","comment":"9 pages for main paper. 22 pages in total. 13 figures, 1 table"},{"id":"http://arxiv.org/abs/2305.14392v2","updated":"2024-03-15T21:28:59Z","published":"2023-05-22T22:59:05Z","title":"FEDORA: Flying Event Dataset fOr Reactive behAvior","summary":"  The ability of resource-constrained biological systems such as fruitflies to\nperform complex and high-speed maneuvers in cluttered environments has been one\nof the prime sources of inspiration for developing vision-based autonomous\nsystems. To emulate this capability, the perception pipeline of such systems\nmust integrate information cues from tasks including optical flow and depth\nestimation, object detection and tracking, and segmentation, among others.\nHowever, the conventional approach of employing slow, synchronous inputs from\nstandard frame-based cameras constrains these perception capabilities,\nparticularly during high-speed maneuvers. Recently, event-based sensors have\nemerged as low latency and low energy alternatives to standard frame-based\ncameras for capturing high-speed motion, effectively speeding up perception and\nhence navigation. For coherence, all the perception tasks must be trained on\nthe same input data. However, present-day datasets are curated mainly for a\nsingle or a handful of tasks and are limited in the rate of the provided ground\ntruths. To address these limitations, we present Flying Event Dataset fOr\nReactive behAviour (FEDORA) - a fully synthetic dataset for perception tasks,\nwith raw data from frame-based cameras, event-based cameras, and Inertial\nMeasurement Units (IMU), along with ground truths for depth, pose, and optical\nflow at a rate much higher than existing datasets.\n","authors":["Amogh Joshi","Adarsh Kosta","Wachirawit Ponghiran","Manish Nagaraj","Kaushik Roy"],"pdf_url":"https://arxiv.org/pdf/2305.14392v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.10684v1","updated":"2024-03-15T21:08:37Z","published":"2024-03-15T21:08:37Z","title":"Improved discrete particle swarm optimization using Bee Algorithm and\n  multi-parent crossover method (Case study: Allocation problem and benchmark\n  functions)","summary":"  Compared to other techniques, particle swarm optimization is more frequently\nutilized because of its ease of use and low variability. However, it is\ncomplicated to find the best possible solution in the search space in\nlarge-scale optimization problems. Moreover, changing algorithm variables does\nnot influence algorithm convergence much. The PSO algorithm can be combined\nwith other algorithms. It can use their advantages and operators to solve this\nproblem. Therefore, this paper proposes the onlooker multi-parent crossover\ndiscrete particle swarm optimization (OMPCDPSO). To improve the efficiency of\nthe DPSO algorithm, we utilized multi-parent crossover on the best solutions.\nWe performed an independent and intensive neighborhood search using the\nonlooker bees of the bee algorithm. The algorithm uses onlooker bees and\ncrossover. They do local search (exploitation) and global search (exploration).\nEach of these searches is among the best solutions (employed bees). The\nproposed algorithm was tested on the allocation problem, which is an NP-hard\noptimization problem. Also, we used two types of simulated data. They were used\nto test the scalability and complexity of the better algorithm. Also, fourteen\n2D test functions and thirteen 30D test functions were used. They also used\ntwenty IEEE CEC2005 benchmark functions to test the efficiency of OMPCDPSO.\nAlso, to test OMPCDPSO's performance, we compared it to four new binary\noptimization algorithms and three classic ones. The results show that the\nOMPCDPSO version had high capability. It performed better than other\nalgorithms. The developed algorithm in this research (OMCDPSO) in 36 test\nfunctions out of 47 (76.60%) is better than other algorithms. The Onlooker bees\nand multi-parent operators significantly impact the algorithm's performance.\n","authors":["Hamed Zibaei","Mohammad Saadi Mesgari"],"pdf_url":"https://arxiv.org/pdf/2403.10684v1.pdf","comment":"34 pages, 8 figures, 15 tables"},{"id":"http://arxiv.org/abs/2308.08218v2","updated":"2024-03-15T13:50:58Z","published":"2023-08-16T08:45:53Z","title":"Expressivity of Spiking Neural Networks","summary":"  The synergy between spiking neural networks and neuromorphic hardware holds\npromise for the development of energy-efficient AI applications. Inspired by\nthis potential, we revisit the foundational aspects to study the capabilities\nof spiking neural networks where information is encoded in the firing time of\nneurons. Under the Spike Response Model as a mathematical model of a spiking\nneuron with a linear response function, we compare the expressive power of\nartificial and spiking neural networks, where we initially show that they\nrealize piecewise linear mappings. In contrast to ReLU networks, we prove that\nspiking neural networks can realize both continuous and discontinuous\nfunctions. Moreover, we provide complexity bounds on the size of spiking neural\nnetworks to emulate multi-layer (ReLU) neural networks. Restricting to the\ncontinuous setting, we also establish complexity bounds in the reverse\ndirection for one-layer spiking neural networks.\n","authors":["Manjot Singh","Adalbert Fono","Gitta Kutyniok"],"pdf_url":"https://arxiv.org/pdf/2308.08218v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.10112v1","updated":"2024-03-15T08:55:56Z","published":"2024-03-15T08:55:56Z","title":"Single- and Multi-Agent Private Active Sensing: A Deep Neuroevolution\n  Approach","summary":"  In this paper, we focus on one centralized and one decentralized problem of\nactive hypothesis testing in the presence of an eavesdropper. For the\ncentralized problem including a single legitimate agent, we present a new\nframework based on NeuroEvolution (NE), whereas, for the decentralized problem,\nwe develop a novel NE-based method for solving collaborative multi-agent tasks,\nwhich interestingly maintains all computational benefits of single-agent NE.\nThe superiority of the proposed EAHT approaches over conventional active\nhypothesis testing policies, as well as learning-based methods, is validated\nthrough numerical investigations in an example use case of anomaly detection\nover wireless sensor networks.\n","authors":["George Stamatelis","Angelos-Nikolaos Kanatas","Ioannis Asprogerakas","George C. Alexandropoulos"],"pdf_url":"https://arxiv.org/pdf/2403.10112v1.pdf","comment":"7 pages, 5 figures, accepted at IEEE ICC 2024 (to be presented)"},{"id":"http://arxiv.org/abs/2403.10100v1","updated":"2024-03-15T08:45:32Z","published":"2024-03-15T08:45:32Z","title":"Efficient Multiplayer Battle Game Optimizer for Adversarial Robust\n  Neural Architecture Search","summary":"  This paper introduces a novel metaheuristic algorithm, known as the efficient\nmultiplayer battle game optimizer (EMBGO), specifically designed for addressing\ncomplex numerical optimization tasks. The motivation behind this research stems\nfrom the need to rectify identified shortcomings in the original MBGO,\nparticularly in search operators during the movement phase, as revealed through\nablation experiments. EMBGO mitigates these limitations by integrating the\nmovement and battle phases to simplify the original optimization framework and\nimprove search efficiency. Besides, two efficient search operators:\ndifferential mutation and L\\'evy flight are introduced to increase the\ndiversity of the population. To evaluate the performance of EMBGO\ncomprehensively and fairly, numerical experiments are conducted on benchmark\nfunctions such as CEC2017, CEC2020, and CEC2022, as well as engineering\nproblems. Twelve well-established MA approaches serve as competitor algorithms\nfor comparison. Furthermore, we apply the proposed EMBGO to the complex\nadversarial robust neural architecture search (ARNAS) tasks and explore its\nrobustness and scalability. The experimental results and statistical analyses\nconfirm the efficiency and effectiveness of EMBGO across various optimization\ntasks. As a potential optimization technique, EMBGO holds promise for diverse\napplications in real-world problems and deep learning scenarios. The source\ncode of EMBGO is made available in\n\\url{https://github.com/RuiZhong961230/EMBGO}.\n","authors":["Rui Zhong","Yuefeng Xu","Chao Zhang","Jun Yu"],"pdf_url":"https://arxiv.org/pdf/2403.10100v1.pdf","comment":"33 pages"},{"id":"http://arxiv.org/abs/2210.05397v3","updated":"2024-03-15T06:51:04Z","published":"2022-10-11T12:16:06Z","title":"Analyzing the Expected Hitting Time of Evolutionary Computation-based\n  Neural Architecture Search Algorithms","summary":"  Evolutionary computation-based neural architecture search (ENAS) is a popular\ntechnique for automating architecture design of deep neural networks. Despite\nits groundbreaking applications, there is no theoretical study for ENAS. The\nexpected hitting time (EHT) is one of the most important theoretical issues,\nsince it implies the average computational time complexity. This paper proposes\na general method by integrating theory and experiment for estimating the EHT of\nENAS algorithms, which includes common configuration, search space partition,\ntransition probability estimation, population distribution fitting, and hitting\ntime analysis. By exploiting the proposed method, we consider the\n($\\lambda$+$\\lambda$)-ENAS algorithms with different mutation operators and\nestimate the lower bounds of the EHT. Furthermore, we study the EHT on the\nNAS-Bench-101 problem, and the results demonstrate the validity of the proposed\nmethod. To the best of our knowledge, this work is the first attempt to\nestablish a theoretical foundation for ENAS algorithms.\n","authors":["Zeqiong Lv","Chao Qian","Gary G. Yen","Yanan Sun"],"pdf_url":"https://arxiv.org/pdf/2210.05397v3.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"},{"id":"http://arxiv.org/abs/2309.08045v2","updated":"2024-03-15T02:29:44Z","published":"2023-09-03T22:48:10Z","title":"Traveling Waves Encode the Recent Past and Enhance Sequence Learning","summary":"  Traveling waves of neural activity have been observed throughout the brain at\na diversity of regions and scales; however, their precise computational role is\nstill debated. One physically inspired hypothesis suggests that the cortical\nsheet may act like a wave-propagating system capable of invertibly storing a\nshort-term memory of sequential stimuli through induced waves traveling across\nthe cortical surface, and indeed many experimental results from neuroscience\ncorrelate wave activity with memory tasks. To date, however, the computational\nimplications of this idea have remained hypothetical due to the lack of a\nsimple recurrent neural network architecture capable of exhibiting such waves.\nIn this work, we introduce a model to fill this gap, which we denote the\nWave-RNN (wRNN), and demonstrate how such an architecture indeed efficiently\nencodes the recent past through a suite of synthetic memory tasks where wRNNs\nlearn faster and reach significantly lower error than wave-free counterparts.\nWe further explore the implications of this memory storage system on more\ncomplex sequence modeling tasks such as sequential image classification and\nfind that wave-based models not only again outperform comparable wave-free RNNs\nwhile using significantly fewer parameters, but additionally perform comparably\nto more complex gated architectures such as LSTMs and GRUs.\n","authors":["T. Anderson Keller","Lyle Muller","Terrence Sejnowski","Max Welling"],"pdf_url":"https://arxiv.org/pdf/2309.08045v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.06862v8","updated":"2024-03-15T02:05:21Z","published":"2022-09-09T00:40:14Z","title":"Deep learning in a bilateral brain with hemispheric specialization","summary":"  The brains of all bilaterally symmetric animals on Earth are divided into\nleft and right hemispheres. The anatomy and functionality of the hemispheres\nhave a large degree of overlap, but there are asymmetries and they specialise\nto possess different attributes. Other authors have used computational models\nto mimic hemispheric asymmetries with a focus on reproducing human data on\nsemantic and visual processing tasks. We took a different approach and aimed to\nunderstand how dual hemispheres in a bilateral architecture interact to perform\nwell in a given task. We propose a bilateral artificial neural network that\nimitates lateralisation observed in nature: that the left hemisphere\nspecialises in specificity and the right in generality. We used different\ntraining objectives to achieve the desired specialisation and tested it on an\nimage classification task with two different CNN backbones -- ResNet and VGG.\nOur analysis found that the hemispheres represent complementary features that\nare exploited by a network head which implements a type of weighted attention.\nThe bilateral architecture outperformed a range of baselines of similar\nrepresentational capacity that don't exploit differential specialisation, with\nthe exception of a conventional ensemble of unilateral networks trained on a\ndual training objective for specifics and generalities. The results demonstrate\nthe efficacy of bilateralism, contribute to the discussion of bilateralism in\nbiological brains and the principle may serves as an inductive bias for new AI\nsystems.\n","authors":["Chandramouli Rajagopalan","David Rawlinson","Elkhonon Goldberg","Gideon Kowadlo"],"pdf_url":"https://arxiv.org/pdf/2209.06862v8.pdf","comment":"14 pages, 11 figures"}]},"2024-03-14T00:00:00Z":{"Computer Science and Game Theory":[{"id":"http://arxiv.org/abs/2403.10570v1","updated":"2024-03-14T20:17:57Z","published":"2024-03-14T20:17:57Z","title":"Symbiotic Game and Foundation Models for Cyber Deception Operations in\n  Strategic Cyber Warfare","summary":"  We are currently facing unprecedented cyber warfare with the rapid evolution\nof tactics, increasing asymmetry of intelligence, and the growing accessibility\nof hacking tools. In this landscape, cyber deception emerges as a critical\ncomponent of our defense strategy against increasingly sophisticated attacks.\nThis chapter aims to highlight the pivotal role of game-theoretic models and\nfoundation models (FMs) in analyzing, designing, and implementing cyber\ndeception tactics. Game models (GMs) serve as a foundational framework for\nmodeling diverse adversarial interactions, allowing us to encapsulate both\nadversarial knowledge and domain-specific insights. Meanwhile, FMs serve as the\nbuilding blocks for creating tailored machine learning models suited to given\napplications. By leveraging the synergy between GMs and FMs, we can advance\nproactive and automated cyber defense mechanisms by not only securing our\nnetworks against attacks but also enhancing their resilience against\nwell-planned operations. This chapter discusses the games at the tactical,\noperational, and strategic levels of warfare, delves into the symbiotic\nrelationship between these methodologies, and explores relevant applications\nwhere such a framework can make a substantial impact in cybersecurity. The\nchapter discusses the promising direction of the multi-agent neurosymbolic\nconjectural learning (MANSCOL), which allows the defender to predict\nadversarial behaviors, design adaptive defensive deception tactics, and\nsynthesize knowledge for the operational level synthesis and adaptation. FMs\nserve as pivotal tools across various functions for MANSCOL, including\nreinforcement learning, knowledge assimilation, formation of conjectures, and\ncontextual representation. This chapter concludes with a discussion of the\nchallenges associated with FMs and their application in the domain of\ncybersecurity.\n","authors":["Tao Li","Quanyan Zhu"],"pdf_url":"https://arxiv.org/pdf/2403.10570v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.09794v1","updated":"2024-03-14T18:26:31Z","published":"2024-03-14T18:26:31Z","title":"The Query Complexity of Contracts","summary":"  Algorithmic contract design is a new frontier in the intersection of\neconomics and computation, with combinatorial contracts being a core problem in\nthis domain. A central model within combinatorial contracts explores a setting\nwhere a principal delegates the execution of a task, which can either succeed\nor fail, to an agent. The agent can choose any subset among a given set of\ncostly actions, where every subset is associated with a success probability.\nThe principal incentivizes the agent through a contract that specifies the\npayment upon success of the task.\n  A natural setting of interest is one with submodular success probabilities.\nIt is known that finding the optimal contract for the principal is\n$\\mathsf{NP}$-hard, but the hardness result is derived from the hardness of\ndemand queries. A major open problem is whether the hardness arises solely from\nthe hardness of demand queries, or if the complexity lies within the optimal\ncontract problem itself. In other words: does the problem retain its hardness,\neven when provided access to a demand oracle? We resolve this question in the\naffirmative, showing that any algorithm that computes the optimal contract for\nsubmodular success probabilities requires an exponential number of demand\nqueries, thus settling the query complexity problem.\n","authors":["Paul Dütting","Michal Feldman","Yoav Gal-Tzur","Aviad Rubinstein"],"pdf_url":"https://arxiv.org/pdf/2403.09794v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.15423v3","updated":"2024-03-14T17:53:08Z","published":"2023-09-27T06:20:28Z","title":"Prosumers Participation in Markets: A Scalar-Parameterized Function\n  Bidding Approach","summary":"  In uniform-price markets, suppliers compete to supply a resource to\nconsumers, resulting in a single market price determined by their competition.\nFor sufficient flexibility, producers and consumers prefer to commit to a\nfunction as their strategies, indicating their preferred quantity at any given\nmarket price. Producers and consumers may wish to act as both, i.e., prosumers.\nIn this paper, we examine the behavior of profit-maximizing prosumers in a\nuniform-price market for resource allocation with the objective of maximizing\nthe social welfare. We propose a scalar-parameterized function bidding\nmechanism for the prosumers, in which we establish the existence and uniqueness\nof Nash equilibrium. Furthermore, we provide an efficient way to compute the\nNash equilibrium through the computation of the market allocation at the Nash\nequilibrium. Finally, we present a case study to illustrate the welfare loss\nunder different variations of market parameters, such as the market's supply\ncapacity and inelastic demand.\n","authors":["Abdullah Alawad","Muhammad Aneeq uz Zaman","Khaled Alshehri","Tamer Başar"],"pdf_url":"https://arxiv.org/pdf/2309.15423v3.pdf","comment":"Corrected typos in the figures"},{"id":"http://arxiv.org/abs/2403.09545v1","updated":"2024-03-14T16:32:29Z","published":"2024-03-14T16:32:29Z","title":"Sequential Contracts","summary":"  We study the principal-agent setting, where a principal delegates the\nexecution of a costly project to an agent. In the classical model, the agent\nchooses an action among a set of available actions. Every action is associated\nwith some cost, and leads to a stochastic outcome for the project. The agent's\naction is hidden from the principal, who only observes the outcome. The\nprincipal incentivizes the agent through a payment scheme (a contract) that\nmaps outcomes to payments, with the objective of finding the optimal contract -\nthe contract maximizing the principal's expected utility.\n  In this work, we introduce a sequential variant of the model, capturing many\nreal-life settings, where the agent engages in multiple attempts, incurring the\nsum of costs of the actions taken and being compensated for the best realized\noutcome. We study the contract design problem in this new setting. We first\nobserve that the agent's problem - finding the sequential set of actions that\nmaximizes his utility for a given contract - is equivalent to the well-known\nPandora's Box problem. With this insight at hand, we provide algorithms and\nhardness results for the (principal's) contract design problem, under both\nindependent and correlated actions. For independent actions, we show that the\noptimal linear contract can be computed in polynomial time. Furthermore, this\nresult extends to the optimal arbitrary contract when the number of outcomes is\na constant. For correlated actions we find that approximating the optimal\ncontract within any constant ratio is NP-hard.\n","authors":["Tomer Ezra","Michal Feldman","Maya Schlesinger"],"pdf_url":"https://arxiv.org/pdf/2403.09545v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.06689v2","updated":"2024-03-14T16:02:45Z","published":"2023-10-10T15:05:21Z","title":"Approximating Nash Equilibria in Normal-Form Games via Stochastic\n  Optimization","summary":"  We propose the first loss function for approximate Nash equilibria of\nnormal-form games that is amenable to unbiased Monte Carlo estimation. This\nconstruction allows us to deploy standard non-convex stochastic optimization\ntechniques for approximating Nash equilibria, resulting in novel algorithms\nwith provable guarantees. We complement our theoretical analysis with\nexperiments demonstrating that stochastic gradient descent can outperform\nprevious state-of-the-art approaches.\n","authors":["Ian Gemp","Luke Marris","Georgios Piliouras"],"pdf_url":"https://arxiv.org/pdf/2310.06689v2.pdf","comment":"Published at ICLR 2024"},{"id":"http://arxiv.org/abs/2403.09510v1","updated":"2024-03-14T15:56:39Z","published":"2024-03-14T15:56:39Z","title":"Trust AI Regulation? Discerning users are vital to build trust and\n  effective AI regulation","summary":"  There is general agreement that some form of regulation is necessary both for\nAI creators to be incentivised to develop trustworthy systems, and for users to\nactually trust those systems. But there is much debate about what form these\nregulations should take and how they should be implemented. Most work in this\narea has been qualitative, and has not been able to make formal predictions.\nHere, we propose that evolutionary game theory can be used to quantitatively\nmodel the dilemmas faced by users, AI creators, and regulators, and provide\ninsights into the possible effects of different regulatory regimes. We show\nthat creating trustworthy AI and user trust requires regulators to be\nincentivised to regulate effectively. We demonstrate the effectiveness of two\nmechanisms that can achieve this. The first is where governments can recognise\nand reward regulators that do a good job. In that case, if the AI system is not\ntoo risky for users then some level of trustworthy development and user trust\nevolves. We then consider an alternative solution, where users can condition\ntheir trust decision on the effectiveness of the regulators. This leads to\neffective regulation, and consequently the development of trustworthy AI and\nuser trust, provided that the cost of implementing regulations is not too high.\nOur findings highlight the importance of considering the effect of different\nregulatory regimes from an evolutionary game theoretic perspective.\n","authors":["Zainab Alalawi","Paolo Bova","Theodor Cimpeanu","Alessandro Di Stefano","Manh Hong Duong","Elias Fernandez Domingos","The Anh Han","Marcus Krellner","Bianca Ogbo","Simon T. Powers","Filippo Zimmaro"],"pdf_url":"https://arxiv.org/pdf/2403.09510v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.09129v1","updated":"2024-03-14T06:29:17Z","published":"2024-03-14T06:29:17Z","title":"All-pay Auction Based Profit Maximization in End-to-End Computation\n  Offloading System","summary":"  Pricing is an important issue in mobile edge computing. How to appropriately\ndetermine the bid of end user (EU) is an incentive factor for edge cloud (EC)\nto offer service. In this letter, we propose an equilibrium pricing scheme\nbased on the all-pay auction model in end-to-end collaboration environment,\nwherein all EUs can acquire the service at a lower price than the own value of\nthe required resource. In addition, we propose a set allocation algorithm to\ndivide all the bidders into different sets according to the price, and the EUs\nin each set get the service, which averts the case of getting no service due to\nthe low price. Extensive simulation results demonstrate that the proposed\nscheme can effectively maximize the total profit of the edge offloading system,\nand guarantee all EUs can access the service.\n","authors":["Hai Xue","Yun Xia","Di Zhang","Honghua Wei","Xiaolong Xu"],"pdf_url":"https://arxiv.org/pdf/2403.09129v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.17757v3","updated":"2024-03-14T02:55:25Z","published":"2023-05-28T15:43:59Z","title":"Diversity-seeking Jump Games in Networks","summary":"  Recently, strategic games inspired by Schelling's influential model of\nresidential segregation have been studied in the TCS and AI literature. In\nthese games, agents of k different types occupy the nodes of a network topology\naiming to maximize their utility, which is a function of the fraction of\nsame-type agents they are adjacent to in the network. As such, the agents\nexhibit similarity seeking strategic behavior. In this paper, we introduce a\nclass of strategic jump games in which the agents are diversity-seeking: The\nutility of an agent is defined as the fraction of its neighbors that are of\ndifferent type than itself. We show that in general it is computationally hard\nto determine the existence of an equilibrium in such games. However, when the\nnetwork is a tree, diversity-seeking jump games always admit an equilibrium\nassignment. For regular graphs and spider graphs with a single empty node, we\nprove a stronger result: The game is potential, that is, the improving response\ndynamics always converge to an equilibrium from any initial placement of the\nagents. We also show (nearly tight) bounds on the price of anarchy and price of\nstability in terms of the social welfare (the total utility of the agents).\n","authors":["Lata Narayanan","Yasaman Sabbagh","Alexandros A. Voudouris"],"pdf_url":"https://arxiv.org/pdf/2305.17757v3.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2403.09762v1","updated":"2024-03-14T15:58:13Z","published":"2024-03-14T15:58:13Z","title":"Emotional Intelligence Through Artificial Intelligence : NLP and Deep\n  Learning in the Analysis of Healthcare Texts","summary":"  This manuscript presents a methodical examination of the utilization of\nArtificial Intelligence in the assessment of emotions in texts related to\nhealthcare, with a particular focus on the incorporation of Natural Language\nProcessing and deep learning technologies. We scrutinize numerous research\nstudies that employ AI to augment sentiment analysis, categorize emotions, and\nforecast patient outcomes based on textual information derived from clinical\nnarratives, patient feedback on medications, and online health discussions. The\nreview demonstrates noteworthy progress in the precision of algorithms used for\nsentiment classification, the prognostic capabilities of AI models for\nneurodegenerative diseases, and the creation of AI-powered systems that offer\nsupport in clinical decision-making. Remarkably, the utilization of AI\napplications has exhibited an enhancement in personalized therapy plans by\nintegrating patient sentiment and contributing to the early identification of\nmental health disorders. There persist challenges, which encompass ensuring the\nethical application of AI, safeguarding patient confidentiality, and addressing\npotential biases in algorithmic procedures. Nevertheless, the potential of AI\nto revolutionize healthcare practices is unmistakable, offering a future where\nhealthcare is not only more knowledgeable and efficient but also more\nempathetic and centered around the needs of patients. This investigation\nunderscores the transformative influence of AI on healthcare, delivering a\ncomprehensive comprehension of its role in examining emotional content in\nhealthcare texts and highlighting the trajectory towards a more compassionate\napproach to patient care. The findings advocate for a harmonious synergy\nbetween AI's analytical capabilities and the human aspects of healthcare.\n","authors":["Prashant Kumar Nag","Amit Bhagat","R. Vishnu Priya","Deepak kumar Khare"],"pdf_url":"https://arxiv.org/pdf/2403.09762v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.19078v2","updated":"2024-03-14T14:47:54Z","published":"2024-02-29T12:03:05Z","title":"Smooth Tchebycheff Scalarization for Multi-Objective Optimization","summary":"  Multi-objective optimization problems can be found in many real-world\napplications, where the objectives often conflict each other and cannot be\noptimized by a single solution. In the past few decades, numerous methods have\nbeen proposed to find Pareto solutions that represent different optimal\ntrade-offs among the objectives for a given problem. However, these existing\nmethods could have high computational complexity or may not have good\ntheoretical properties for solving a general differentiable multi-objective\noptimization problem. In this work, by leveraging the smooth optimization\ntechnique, we propose a novel and lightweight smooth Tchebycheff scalarization\napproach for gradient-based multi-objective optimization. It has good\ntheoretical properties for finding all Pareto solutions with valid trade-off\npreferences, while enjoying significantly lower computational complexity\ncompared to other methods. Experimental results on various real-world\napplication problems fully demonstrate the effectiveness of our proposed\nmethod.\n","authors":["Xi Lin","Xiaoyuan Zhang","Zhiyuan Yang","Fei Liu","Zhenkun Wang","Qingfu Zhang"],"pdf_url":"https://arxiv.org/pdf/2402.19078v2.pdf","comment":"fix some typos"},{"id":"http://arxiv.org/abs/2403.07917v2","updated":"2024-03-14T13:00:37Z","published":"2024-02-27T15:59:15Z","title":"A Neural-Evolutionary Algorithm for Autonomous Transit Network Design","summary":"  Planning a public transit network is a challenging optimization problem, but\nessential in order to realize the benefits of autonomous buses. We propose a\nnovel algorithm for planning networks of routes for autonomous buses. We first\ntrain a graph neural net model as a policy for constructing route networks, and\nthen use the policy as one of several mutation operators in a evolutionary\nalgorithm. We evaluate this algorithm on a standard set of benchmarks for\ntransit network design, and find that it outperforms the learned policy alone\nby up to 20% and a plain evolutionary algorithm approach by up to 53% on\nrealistic benchmark instances.\n","authors":["Andrew Holliday","Gregory Dudek"],"pdf_url":"https://arxiv.org/pdf/2403.07917v2.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible. arXiv admin note: text overlap with arXiv:2306.00720"},{"id":"http://arxiv.org/abs/2403.08265v2","updated":"2024-03-14T05:18:08Z","published":"2024-03-13T05:32:13Z","title":"Random Search as a Baseline for Sparse Neural Network Architecture\n  Search","summary":"  Sparse neural networks have shown similar or better generalization\nperformance than their dense counterparts while having higher parameter\nefficiency. This has motivated a number of works to learn or search for high\nperforming sparse networks. While reports of task performance or efficiency\ngains are impressive, standard baselines are lacking leading to poor\ncomparability and unreliable reproducibility across methods. In this work, we\npropose Random Search as a baseline algorithm for finding good sparse\nconfigurations and study its performance. We apply Random Search on the node\nspace of an overparameterized network with the goal of finding better\ninitialized sparse sub-networks that are positioned more advantageously in the\nloss landscape. We record the post-training performances of the found sparse\nnetworks and at various levels of sparsity, and compare against both their\nfully connected parent networks and random sparse configurations at the same\nsparsity levels. First, we demonstrate performance at different levels of\nsparsity and highlight that a significant level of performance can still be\npreserved even when the network is highly sparse. Second, we observe that for\nthis sparse architecture search task, initialized sparse networks found by\nRandom Search neither perform better nor converge more efficiently than their\nrandom counterparts. Thus we conclude that Random Search may be viewed as a\nreasonable neutral baseline for sparsity search methods.\n","authors":["Rezsa Farahani"],"pdf_url":"https://arxiv.org/pdf/2403.08265v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.09053v1","updated":"2024-03-14T02:42:19Z","published":"2024-03-14T02:42:19Z","title":"Towards a theory of model distillation","summary":"  Distillation is the task of replacing a complicated machine learning model\nwith a simpler model that approximates the original [BCNM06,HVD15]. Despite\nmany practical applications, basic questions about the extent to which models\ncan be distilled, and the runtime and amount of data needed to distill, remain\nlargely open.\n  To study these questions, we initiate a general theory of distillation,\ndefining PAC-distillation in an analogous way to PAC-learning [Val84]. As\napplications of this theory: (1) we propose new algorithms to extract the\nknowledge stored in the trained weights of neural networks -- we show how to\nefficiently distill neural networks into succinct, explicit decision tree\nrepresentations when possible by using the ``linear representation\nhypothesis''; and (2) we prove that distillation can be much cheaper than\nlearning from scratch, and make progress on characterizing its complexity.\n","authors":["Enric Boix-Adsera"],"pdf_url":"https://arxiv.org/pdf/2403.09053v1.pdf","comment":"47 pages, 5 figures. Please reach out with comments! Feedback is\n  welcome"},{"id":"http://arxiv.org/abs/2403.09026v1","updated":"2024-03-14T01:39:12Z","published":"2024-03-14T01:39:12Z","title":"FlexNN: A Dataflow-aware Flexible Deep Learning Accelerator for\n  Energy-Efficient Edge Devices","summary":"  This paper introduces FlexNN, a Flexible Neural Network accelerator, which\nadopts agile design principles to enable versatile dataflows, enhancing energy\nefficiency. Unlike conventional convolutional neural network accelerator\narchitectures that adhere to fixed dataflows (such as input, weight, output, or\nrow stationary) for transferring activations and weights between storage and\ncompute units, our design revolutionizes by enabling adaptable dataflows of any\ntype through software configurable descriptors. Considering that data movement\ncosts considerably outweigh compute costs from an energy perspective, the\nflexibility in dataflow allows us to optimize the movement per layer for\nminimal data transfer and energy consumption, a capability unattainable in\nfixed dataflow architectures. To further enhance throughput and reduce energy\nconsumption in the FlexNN architecture, we propose a novel sparsity-based\nacceleration logic that utilizes fine-grained sparsity in both the activation\nand weight tensors to bypass redundant computations, thus optimizing the\nconvolution engine within the hardware accelerator. Extensive experimental\nresults underscore a significant enhancement in the performance and energy\nefficiency of FlexNN relative to existing DNN accelerators.\n","authors":["Arnab Raha","Deepak A. Mathaikutty","Soumendu K. Ghosh","Shamik Kundu"],"pdf_url":"https://arxiv.org/pdf/2403.09026v1.pdf","comment":"Version 0. Work started in 2019"}]},"2024-03-13T00:00:00Z":{"Computer Science and Game Theory":[{"id":"http://arxiv.org/abs/2310.02779v2","updated":"2024-03-13T22:57:44Z","published":"2023-10-04T12:50:29Z","title":"Expected flow networks in stochastic environments and two-player\n  zero-sum games","summary":"  Generative flow networks (GFlowNets) are sequential sampling models trained\nto match a given distribution. GFlowNets have been successfully applied to\nvarious structured object generation tasks, sampling a diverse set of\nhigh-reward objects quickly. We propose expected flow networks (EFlowNets),\nwhich extend GFlowNets to stochastic environments. We show that EFlowNets\noutperform other GFlowNet formulations in stochastic tasks such as protein\ndesign. We then extend the concept of EFlowNets to adversarial environments,\nproposing adversarial flow networks (AFlowNets) for two-player zero-sum games.\nWe show that AFlowNets learn to find above 80% of optimal moves in Connect-4\nvia self-play and outperform AlphaZero in tournaments.\n","authors":["Marco Jiralerspong","Bilun Sun","Danilo Vucetic","Tianyu Zhang","Yoshua Bengio","Gauthier Gidel","Nikolay Malkin"],"pdf_url":"https://arxiv.org/pdf/2310.02779v2.pdf","comment":"ICLR 2024; code: https://github.com/GFNOrg/AdversarialFlowNetworks"},{"id":"http://arxiv.org/abs/2403.08948v1","updated":"2024-03-13T20:27:35Z","published":"2024-03-13T20:27:35Z","title":"Model-free Resilient Controller Design based on Incentive Feedback\n  Stackelberg Game and Q-learning","summary":"  In the swift evolution of Cyber-Physical Systems (CPSs) within intelligent\nenvironments, especially in the industrial domain shaped by Industry 4.0, the\nsurge in development brings forth unprecedented security challenges. This paper\nexplores the intricate security issues of Industrial CPSs (ICPSs), with a\nspecific focus on the unique threats presented by intelligent attackers capable\nof directly compromising the controller, thereby posing a direct risk to\nphysical security. Within the framework of hierarchical control and incentive\nfeedback Stackelberg game, we design a resilient leading controller (leader)\nthat is adaptive to a compromised following controller (follower) such that the\ncompromised follower acts cooperatively with the leader, aligning its\nstrategies with the leader's objective to achieve a team-optimal solution.\nFirst, we provide sufficient conditions for the existence of an incentive\nStackelberg solution when system dynamics are known. Then, we propose a\nQ-learning-based Approximate Dynamic Programming (ADP) approach, and\ncorresponding algorithms for the online resolution of the incentive Stackelberg\nsolution without requiring prior knowledge of system dynamics. Last but not\nleast, we prove the convergence of our approach to the optimum.\n","authors":["Jiajun Shen","Fengjun Li","Morteza Hashemi","Huazhen Fang"],"pdf_url":"https://arxiv.org/pdf/2403.08948v1.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2403.08944v1","updated":"2024-03-13T20:21:20Z","published":"2024-03-13T20:21:20Z","title":"Language-based game theory in the age of artificial intelligence","summary":"  Understanding human behaviour in decision problems and strategic interactions\nhas wide-ranging applications in economics, psychology, and artificial\nintelligence. Game theory offers a robust foundation for this understanding,\nbased on the idea that individuals aim to maximize a utility function. However,\nthe exact factors influencing strategy choices remain elusive. While\ntraditional models try to explain human behaviour as a function of the outcomes\nof available actions, recent experimental research reveals that linguistic\ncontent significantly impacts decision-making, thus prompting a paradigm shift\nfrom outcome-based to language-based utility functions. This shift is more\nurgent than ever, given the advancement of generative AI, which has the\npotential to support humans in making critical decisions through language-based\ninteractions. We propose sentiment analysis as a fundamental tool for this\nshift and take an initial step by analyzing 61 experimental instructions from\nthe dictator game, an economic game capturing the balance between self-interest\nand the interest of others, which is at the core of many social interactions.\nOur meta-analysis shows that sentiment analysis can explain human behaviour\nbeyond economic outcomes. We discuss future research directions. We hope this\nwork sets the stage for a novel game theoretical approach that emphasizes the\nimportance of language in human decisions.\n","authors":["Valerio Capraro","Roberto Di Paolo","Matjaz Perc","Veronica Pizziol"],"pdf_url":"https://arxiv.org/pdf/2403.08944v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.08906v1","updated":"2024-03-13T18:54:27Z","published":"2024-03-13T18:54:27Z","title":"Strategizing against Q-learners: A Control-theoretical Approach","summary":"  In this paper, we explore the susceptibility of the Q-learning algorithm (a\nclassical and widely used reinforcement learning method) to strategic\nmanipulation of sophisticated opponents in games. We quantify how much a\nstrategically sophisticated agent can exploit a naive Q-learner if she knows\nthe opponent's Q-learning algorithm. To this end, we formulate the strategic\nactor's problem as a Markov decision process (with a continuum state space\nencompassing all possible Q-values) as if the Q-learning algorithm is the\nunderlying dynamical system. We also present a quantization-based approximation\nscheme to tackle the continuum state space and analyze its performance both\nanalytically and numerically.\n","authors":["Yuksel Arslantas","Ege Yuceel","Muhammed O. Sayin"],"pdf_url":"https://arxiv.org/pdf/2403.08906v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.08741v1","updated":"2024-03-13T17:44:16Z","published":"2024-03-13T17:44:16Z","title":"Learning How to Strategically Disclose Information","summary":"  Strategic information disclosure, in its simplest form, considers a game\nbetween an information provider (sender) who has access to some private\ninformation that an information receiver is interested in. While the receiver\ntakes an action that affects the utilities of both players, the sender can\ndesign information (or modify beliefs) of the receiver through signal\ncommitment, hence posing a Stackelberg game. However, obtaining a Stackelberg\nequilibrium for this game traditionally requires the sender to have access to\nthe receiver's objective. In this work, we consider an online version of\ninformation design where a sender interacts with a receiver of an unknown type\nwho is adversarially chosen at each round. Restricting attention to Gaussian\nprior and quadratic costs for the sender and the receiver, we show that\n$\\mathcal{O}(\\sqrt{T})$ regret is achievable with full information feedback,\nwhere $T$ is the total number of interactions between the sender and the\nreceiver. Further, we propose a novel parametrization that allows the sender to\nachieve $\\mathcal{O}(\\sqrt{T})$ regret for a general convex utility function.\nWe then consider the Bayesian Persuasion problem with an additional cost term\nin the objective function, which penalizes signaling policies that are more\ninformative and obtain $\\mathcal{O}(\\log(T))$ regret. Finally, we establish a\nsublinear regret bound for the partial information feedback setting and provide\nsimulations to support our theoretical results.\n","authors":["Raj Kiriti Velicheti","Melih Bastopcu","S. Rasoul Etesami","Tamer Başar"],"pdf_url":"https://arxiv.org/pdf/2403.08741v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.08610v1","updated":"2024-03-13T15:22:18Z","published":"2024-03-13T15:22:18Z","title":"An Algorithmic Theory of Simplicity in Mechanism Design","summary":"  A growing body of work in economics and computation focuses on the trade-off\nbetween implementability and simplicity in mechanism design. The goal is to\ndevelop a theory that not only allows to design an incentive structure easy to\ngrasp for imperfectly rational agents, but also understand the ensuing\nlimitations on the class of mechanisms that enforce it. In this context, the\nconcept of OSP mechanisms has assumed a prominent role since they provably\naccount for the absence of contingent reasoning skills, a specific cognitive\nlimitation. For single-dimensional agents, it is known that OSP mechanisms need\nto use certain greedy algorithms.\n  In this work, we introduce a notion that interpolates between OSP and SOSP, a\nmore stringent notion where agents only plan a subset of their own future\nmoves. We provide an algorithmic characterization of this novel class of\nmechanisms for single-dimensional domains and binary allocation problems, that\nprecisely measures the interplay between simplicity and implementability. We\nbuild on this to show how mechanisms based on reverse greedy algorithms\n(a.k.a., deferred acceptance auctions) are algorithmically more robust to\nimperfectly rationality than those adopting greedy algorithms.\n","authors":["Diodato Ferraioli","Carmine Ventre"],"pdf_url":"https://arxiv.org/pdf/2403.08610v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15429v1","updated":"2024-03-13T12:19:59Z","published":"2024-03-13T12:19:59Z","title":"Single-token vs Two-token Blockchain Tokenomics","summary":"  We consider long-term equilibria that arise in the tokenomics design of\nproof-of-stake (PoS) blockchain systems that comprise of users and validators,\nboth striving to maximize their own utilities. Validators are system\nmaintainers who get rewarded with tokens for performing the work necessary for\nthe system to function properly, while users compete and pay with such tokens\nfor getting a desired system service level.\n  We study how the system service provision and suitable rewards schemes\ntogether can lead to equilibria with desirable characteristics (1) viability:\nthe system keeps parties engaged, (2) decentralization: multiple validators are\nparticipating, (3) stability: the price path of the underlying token used to\ntransact with the system does not change widely over time, and (4) feasibility:\nthe mechanism is easy to implement as a smart contract, i.e., it does not\nrequire fiat reserves on-chain for buy back of tokens or to perform bookkeeping\nof exponentially growing token holdings. Furthermore, we consider both the\ncommon single-token PoS model and a less widely used two-token approach (that\nroughly, utilizes one token for the users to pay the transaction fees and a\ndifferent token for the validators to participate in the PoS protocol and get\nrewarded). Our approach demonstrates, for the first time to our knowledge,\nconcrete advantages of the two-token approach in terms of the ability of the\nmechanism to reach equilibrium.\n","authors":["Aggelos Kiayias","Philip Lazos","Paolo Penna"],"pdf_url":"https://arxiv.org/pdf/2403.15429v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.08421v1","updated":"2024-03-13T11:13:56Z","published":"2024-03-13T11:13:56Z","title":"Measures of relevance to the success of streaming platforms","summary":"  Digital streaming platforms, including Twitch, Spotify, Netflix, Disney, and\nKindle, have emerged as one of the main sources of entertainment with\nsignificant growth potential. Many of these platforms distribute royalties\namong streamers, artists, producers, or writers based on their impact. In this\npaper, we measure the relevance of each of these contributors to the overall\nsuccess of the platform, which is information that can play a key role in\nrevenue allocation. We perform an axiomatic analysis to provide normative\nfoundations for three relevance metrics: the uniform, the proportional, and the\nsubscriber-proportional indicators. The last two indicators implement the\nso-called pro-rata and user-centric models, which are extensively applied to\ndistribute revenues in the music streaming market. The axioms we propose\nformalize different principles of fairness, stability, and non-manipulability,\nand are tailor-made for the streaming context. We complete our analysis with a\ncase study that measures the influence of the 19 most-followed streamers\nworldwide on the Twitch platform.\n","authors":["Juan Carlos Gonçalves-Dosantos","Ricardo Martínez","Joaquín Sánchez-Soriano"],"pdf_url":"https://arxiv.org/pdf/2403.08421v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.02323v4","updated":"2024-03-13T09:45:31Z","published":"2022-01-07T04:28:52Z","title":"Distributed Nash Equilibrium Seeking over Time-Varying Directed\n  Communication Networks","summary":"  We study distributed algorithms for finding a Nash equilibrium (NE) in a\nclass of non-cooperative convex games under partial information. Specifically,\neach agent has access only to its own smooth local cost function and can\nreceive information from its neighbors in a time-varying directed communication\nnetwork. To this end, we propose a distributed gradient play algorithm to\ncompute a NE by utilizing local information exchange among the players. In this\nalgorithm, every agent performs a gradient step to minimize its own cost\nfunction while sharing and retrieving information locally among its neighbors.\nThe existing methods impose strong assumptions such as balancedness of the\nmixing matrices and global knowledge of the network communication structure,\nincluding Perron-Frobenius eigenvector of the adjacency matrix and other graph\nconnectivity constants. In contrast, our approach relies only on a reasonable\nand widely-used assumption of row-stochasticity of the mixing matrices. We\nanalyze the algorithm for time-varying directed graphs and prove its\nconvergence to the NE, when the agents' cost functions are strongly convex and\nhave Lipschitz continuous gradients. Numerical simulations are performed for a\nNash-Cournot game to illustrate the efficacy of the proposed algorithm.\n","authors":["Duong Thuy Anh Nguyen","Duong Tung Nguyen","Angelia Nedić"],"pdf_url":"https://arxiv.org/pdf/2201.02323v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.06622v2","updated":"2024-03-13T08:15:50Z","published":"2023-12-08T12:13:26Z","title":"Search and Rescue on a Poset","summary":"  A Search and Rescue game (SR game) is a new type of game on a graph that has\nquickly found applications in scheduling, object detection, and adaptive\nsearch. In this paper, we broaden the definition of SR games by putting them\ninto the context of ordered sets and Bayesian networks, extending known\nsolutions of these games and opening up the way to further applications.\n","authors":["Jan-Tino Brethouwer","Robbert Fokkink"],"pdf_url":"https://arxiv.org/pdf/2312.06622v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.08171v1","updated":"2024-03-13T01:51:30Z","published":"2024-03-13T01:51:30Z","title":"Tractable Local Equilibria in Non-Concave Games","summary":"  While Online Gradient Descent and other no-regret learning procedures are\nknown to efficiently converge to coarse correlated equilibrium in games where\neach agent's utility is concave in their own strategy, this is not the case\nwhen the utilities are non-concave, a situation that is common in machine\nlearning applications where the agents' strategies are parameterized by deep\nneural networks, or the agents' utilities are computed by a neural network, or\nboth. Indeed, non-concave games present a host of game-theoretic and\noptimization challenges: (i) Nash equilibria may fail to exist; (ii) local Nash\nequilibria exist but are intractable; and (iii) mixed Nash, correlated, and\ncoarse correlated equilibria have infinite support in general, and are\nintractable. To sidestep these challenges we propose a new solution concept,\ntermed $(\\varepsilon, \\Phi(\\delta))$-local equilibrium, which generalizes local\nNash equilibrium in non-concave games, as well as (coarse) correlated\nequilibrium in concave games. Importantly, we show that two instantiations of\nthis solution concept capture the convergence guarantees of Online Gradient\nDescent and no-regret learning, which we show efficiently converge to this type\nof equilibrium in non-concave games with smooth utilities.\n","authors":["Yang Cai","Constantinos Daskalakis","Haipeng Luo","Chen-Yu Wei","Weiqiang Zheng"],"pdf_url":"https://arxiv.org/pdf/2403.08171v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.08145v1","updated":"2024-03-13T00:11:27Z","published":"2024-03-13T00:11:27Z","title":"Algorithmic Information Disclosure in Optimal Auctions","summary":"  This paper studies a joint design problem where a seller can design both the\nsignal structures for the agents to learn their values, and the allocation and\npayment rules for selling the item. In his seminal work, Myerson (1981) shows\nhow to design the optimal auction with exogenous signals. We show that the\nproblem becomes NP-hard when the seller also has the ability to design the\nsignal structures. Our main result is a polynomial-time approximation scheme\n(PTAS) for computing the optimal joint design with at most an $\\epsilon$\nmultiplicative loss in expected revenue. Moreover, we show that in our joint\ndesign problem, the seller can significantly reduce the information rent of the\nagents by providing partial information, which ensures a revenue that is at\nleast $1 - \\frac{1}{e}$ of the optimal welfare for all valuation distributions.\n","authors":["Yang Cai","Yingkai Li","Jinzhao Wu"],"pdf_url":"https://arxiv.org/pdf/2403.08145v1.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2403.08549v1","updated":"2024-03-13T14:00:18Z","published":"2024-03-13T14:00:18Z","title":"Wet TinyML: Chemical Neural Network Using Gene Regulation and Cell\n  Plasticity","summary":"  In our earlier work, we introduced the concept of Gene Regulatory Neural\nNetwork (GRNN), which utilizes natural neural network-like structures inherent\nin biological cells to perform computing tasks using chemical inputs. We define\nthis form of chemical-based neural network as Wet TinyML. The GRNN structures\nare based on the gene regulatory network and have weights associated with each\nlink based on the estimated interactions between the genes. The GRNNs can be\nused for conventional computing by employing an application-based search\nprocess similar to the Network Architecture Search. This study advances this\nconcept by incorporating cell plasticity, to further exploit natural cell's\nadaptability, in order to diversify the GRNN search that can match larger\nspectrum as well as dynamic computing tasks. As an example application, we show\nthat through the directed cell plasticity, we can extract the mathematical\nregression evolution enabling it to match to dynamic system applications. We\nalso conduct energy analysis by comparing the chemical energy of the GRNN to\nits silicon counterpart, where this analysis includes both artificial neural\nnetwork algorithms executed on von Neumann architecture as well as neuromorphic\nprocessors. The concept of Wet TinyML can pave the way for the new emergence of\nchemical-based, energy-efficient and miniature Biological AI.\n","authors":["Samitha Somathilaka","Adrian Ratwatte","Sasitharan Balasubramaniam","Mehmet Can Vuran","Witawas Srisa-an","Pietro Liò"],"pdf_url":"https://arxiv.org/pdf/2403.08549v1.pdf","comment":"Accepted as a full paper by the tinyML Research Symposium 2024"},{"id":"http://arxiv.org/abs/2403.08352v1","updated":"2024-03-13T09:00:38Z","published":"2024-03-13T09:00:38Z","title":"Data augmentation with automated machine learning: approaches and\n  performance comparison with classical data augmentation methods","summary":"  Data augmentation is arguably the most important regularization technique\ncommonly used to improve generalization performance of machine learning models.\nIt primarily involves the application of appropriate data transformation\noperations to create new data samples with desired properties. Despite its\neffectiveness, the process is often challenging because of the time-consuming\ntrial and error procedures for creating and testing different candidate\naugmentations and their hyperparameters manually. Automated data augmentation\nmethods aim to automate the process. State-of-the-art approaches typically rely\non automated machine learning (AutoML) principles. This work presents a\ncomprehensive survey of AutoML-based data augmentation techniques. We discuss\nvarious approaches for accomplishing data augmentation with AutoML, including\ndata manipulation, data integration and data synthesis techniques. We present\nextensive discussion of techniques for realizing each of the major subtasks of\nthe data augmentation process: search space design, hyperparameter optimization\nand model evaluation. Finally, we carried out an extensive comparison and\nanalysis of the performance of automated data augmentation techniques and\nstate-of-the-art methods based on classical augmentation approaches. The\nresults show that AutoML methods for data augmentation currently outperform\nstate-of-the-art techniques based on conventional approaches.\n","authors":["Alhassan Mumuni","Fuseini Mumuni"],"pdf_url":"https://arxiv.org/pdf/2403.08352v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.08837v1","updated":"2024-03-13T08:39:21Z","published":"2024-03-13T08:39:21Z","title":"Cyclic Data Parallelism for Efficient Parallelism of Deep Neural\n  Networks","summary":"  Training large deep learning models requires parallelization techniques to\nscale. In existing methods such as Data Parallelism or ZeRO-DP, micro-batches\nof data are processed in parallel, which creates two drawbacks: the total\nmemory required to store the model's activations peaks at the end of the\nforward pass, and gradients must be simultaneously averaged at the end of the\nbackpropagation step. We propose Cyclic Data Parallelism, a novel paradigm\nshifting the execution of the micro-batches from simultaneous to sequential,\nwith a uniform delay. At the cost of a slight gradient delay, the total memory\ntaken by activations is constant, and the gradient communications are balanced\nduring the training step. With Model Parallelism, our technique reduces the\nnumber of GPUs needed, by sharing GPUs across micro-batches. Within the ZeRO-DP\nframework, our technique allows communication of the model states with\npoint-to-point operations rather than a collective broadcast operation. We\nillustrate the strength of our approach on the CIFAR-10 and ImageNet datasets.\n","authors":["Louis Fournier","Edouard Oyallon"],"pdf_url":"https://arxiv.org/pdf/2403.08837v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.06998v2","updated":"2024-03-13T01:19:40Z","published":"2024-03-04T08:59:12Z","title":"High-speed Low-consumption sEMG-based Transient-state micro-Gesture\n  Recognition","summary":"  Gesture recognition on wearable devices is extensively applied in\nhuman-computer interaction. Electromyography (EMG) has been used in many\ngesture recognition systems for its rapid perception of muscle signals.\nHowever, analyzing EMG signals on devices, like smart wristbands, usually needs\ninference models to have high performances, such as low inference latency, low\npower consumption, and low memory occupation. Therefore, this paper proposes an\nimproved spiking neural network (SNN) to achieve these goals. We propose an\nadaptive multi-delta coding as a spiking coding method to improve recognition\naccuracy. We propose two additive solvers for SNN, which can reduce inference\nenergy consumption and amount of parameters significantly, and improve the\nrobustness of temporal differences. In addition, we propose a linear action\ndetection method TAD-LIF, which is suitable for SNNs. TAD-LIF is an improved\nLIF neuron that can detect transient-state gestures quickly and accurately. We\ncollected two datasets from 20 subjects including 6 micro gestures. The\ncollection devices are two designed lightweight consumer-level sEMG wristbands\n(3 and 8 electrode channels respectively). Compared to CNN, FCN, and normal\nSNN-based methods, the proposed SNN has higher recognition accuracy. The\naccuracy of the proposed SNN is 83.85% and 93.52% on the two datasets\nrespectively. In addition, the inference latency of the proposed SNN is about\n1% of CNN, the power consumption is about 0.1% of CNN, and the memory\noccupation is about 20% of CNN. The proposed methods can be used for precise,\nhigh-speed, and low-power micro-gesture recognition tasks, and are suitable for\nconsumer-level intelligent wearable devices, which is a general way to achieve\nubiquitous computing.\n","authors":["Youfang Han","Wei Zhao","Xiangjin Chen","Xin Meng"],"pdf_url":"https://arxiv.org/pdf/2403.06998v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.04161v3","updated":"2024-03-13T00:40:52Z","published":"2024-03-07T02:40:42Z","title":"SWAP-NAS: Sample-Wise Activation Patterns for Ultra-fast NAS","summary":"  Training-free metrics (a.k.a. zero-cost proxies) are widely used to avoid\nresource-intensive neural network training, especially in Neural Architecture\nSearch (NAS). Recent studies show that existing training-free metrics have\nseveral limitations, such as limited correlation and poor generalisation across\ndifferent search spaces and tasks. Hence, we propose Sample-Wise Activation\nPatterns and its derivative, SWAP-Score, a novel high-performance training-free\nmetric. It measures the expressivity of networks over a batch of input samples.\nThe SWAP-Score is strongly correlated with ground-truth performance across\nvarious search spaces and tasks, outperforming 15 existing training-free\nmetrics on NAS-Bench-101/201/301 and TransNAS-Bench-101. The SWAP-Score can be\nfurther enhanced by regularisation, which leads to even higher correlations in\ncell-based search space and enables model size control during the search. For\nexample, Spearman's rank correlation coefficient between regularised SWAP-Score\nand CIFAR-100 validation accuracies on NAS-Bench-201 networks is 0.90,\nsignificantly higher than 0.80 from the second-best metric, NWOT. When\nintegrated with an evolutionary algorithm for NAS, our SWAP-NAS achieves\ncompetitive performance on CIFAR-10 and ImageNet in approximately 6 minutes and\n9 minutes of GPU time respectively.\n","authors":["Yameng Peng","Andy Song","Haytham M. Fayek","Vic Ciesielski","Xiaojun Chang"],"pdf_url":"https://arxiv.org/pdf/2403.04161v3.pdf","comment":"ICLR2024 Spotlight"},{"id":"http://arxiv.org/abs/2403.08151v1","updated":"2024-03-13T00:27:19Z","published":"2024-03-13T00:27:19Z","title":"Measuring the Energy Consumption and Efficiency of Deep Neural Networks:\n  An Empirical Analysis and Design Recommendations","summary":"  Addressing the so-called ``Red-AI'' trend of rising energy consumption by\nlarge-scale neural networks, this study investigates the actual energy\nconsumption, as measured by node-level watt-meters, of training various fully\nconnected neural network architectures. We introduce the BUTTER-E dataset, an\naugmentation to the BUTTER Empirical Deep Learning dataset, containing energy\nconsumption and performance data from 63,527 individual experimental runs\nspanning 30,582 distinct configurations: 13 datasets, 20 sizes (number of\ntrainable parameters), 8 network ``shapes'', and 14 depths on both CPU and GPU\nhardware collected using node-level watt-meters. This dataset reveals the\ncomplex relationship between dataset size, network structure, and energy use,\nand highlights the impact of cache effects. We propose a straightforward and\neffective energy model that accounts for network size, computing, and memory\nhierarchy. Our analysis also uncovers a surprising, hardware-mediated\nnon-linear relationship between energy efficiency and network design,\nchallenging the assumption that reducing the number of parameters or FLOPs is\nthe best way to achieve greater energy efficiency. Highlighting the need for\ncache-considerate algorithm development, we suggest a combined approach to\nenergy efficient network, algorithm, and hardware design. This work contributes\nto the fields of sustainable computing and Green AI, offering practical\nguidance for creating more energy-efficient neural networks and promoting\nsustainable AI.\n","authors":["Charles Edison Tripp","Jordan Perr-Sauer","Jamil Gafur","Amabarish Nag","Avi Purkayastha","Sagi Zisman","Erik A. Bensen"],"pdf_url":"https://arxiv.org/pdf/2403.08151v1.pdf","comment":"25 pages, 8 figures, for associated dataset see\n  https://data.openei.org/submissions/5991"}]},"2024-03-12T00:00:00Z":{"Computer Science and Game Theory":[{"id":"http://arxiv.org/abs/2403.08051v1","updated":"2024-03-12T19:53:50Z","published":"2024-03-12T19:53:50Z","title":"Multi-Apartment Rent Division","summary":"  Rent division is the well-studied problem of fairly assigning rooms and\ndividing rent among a set of roommates within a single apartment. A shortcoming\nof existing solutions is that renters are assumed to be considering apartments\nin isolation, whereas in reality, renters can choose among multiple apartments.\nIn this paper, we generalize the rent division problem to the multi-apartment\nsetting, where the goal is to both fairly choose an apartment among a set of\nalternatives and fairly assign rooms and rents within the chosen apartment. Our\nmain contribution is a generalization of envy-freeness called rearrangeable\nenvy-freeness. We show that a solution satisfying rearrangeable envy-freeness\nis guaranteed to exist and that it is possible to optimize over all\nrearrangeable envy-free solutions in polynomial time. We also define an even\nstronger fairness notion called universal envy-freeness and study its existence\nwhen values are drawn randomly.\n","authors":["Ariel D. Procaccia","Benjamin Schiffer","Shirley Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.08051v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.07799v1","updated":"2024-03-12T16:35:34Z","published":"2024-03-12T16:35:34Z","title":"Equitable Pricing in Auctions","summary":"  We study how pricing affects the division of surplus among buyers in auctions\nfor multiple units. Our equity objective may be important, e.g., for\ncompetition concerns in downstream markets, complementing the long-standing\ndebate on revenue and efficiency. We study a canonical model of auctions for\nmultiple indivisible units with unit demand buyers and valuations with a\nprivate and a common component and consider all pricing rules that are a\nmixture (i.e., a convex combination) of pay-as-bid and uniform pricing. We\npropose the winners' empirical variance (WEV), the expected empirical variance\nof surplus among the winners, as a metric for surplus equity. We show that, for\na range of private-common value proportions, a strictly interior mix of\npay-as-bid and uniform pricing minimizes WEV. From an equity perspective,\nauctions with a higher private value component benefit from more price\ndiscrimination, whereas only auctions with a sufficiently high common value\njustify a more uniform pricing rule. We provide a criterion under which\nstrictly mixed pricing dominates uniform pricing, a partial ranking of\ndifferent mixed pricing formats, and bounds on the WEV-minimizing pricing under\nthe assumption of log-concave signal distributions. In numerical experiments,\nwe further illustrate the WEV-minimal pricing as a function of the\nprivate-common-value mix.\n","authors":["Simon Finster","Patrick Loiseau","Simon Mauras","Mathieu Molina","Bary Pradelski"],"pdf_url":"https://arxiv.org/pdf/2403.07799v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.19985v4","updated":"2024-03-12T16:24:20Z","published":"2023-05-31T16:08:10Z","title":"On the Existence of Reactive Strategies Resilient to Delay","summary":"  We compare games under delayed control and delay games, two types of infinite\ngames modelling asynchronicity in reactive synthesis. In games under delayed\ncontrol both players suffer from partial informedness due to symmetrically\ndelayed communication, while in delay games, the protagonist has to grant\nlookahead to the alter player. Our first main result, the interreducibility of\nthe existence of sure winning strategies for the protagonist, allows to\ntransfer known complexity results and bounds on the delay from delay games to\ngames under delayed control, for which no such results had been known. We\nfurthermore analyse existence of randomized strategies that win almost surely,\nwhere this correspondence between the two types of games breaks down. In this\nsetting, some games surely won by the alter player in delay games can now be\nwon almost surely by the protagonist in the corresponding game under delayed\ncontrol, showing that it indeed makes a difference whether the protagonist has\nto grant lookahead or both players suffer from partial informedness. These\nresults get even more pronounced when we finally address the quantitative goal\nof winning with a probability in $[0,1]$. We show that for any rational\nthreshold $\\theta \\in [0,1]$ there is a game that can be won by the protagonist\nwith exactly probability $\\theta$ under delayed control, while being surely won\nby alter in the delay game setting. All these findings refine our original\nresult that games under delayed control are not determined.\n","authors":["Martin Fränzle","Paul Kröger","Sarah Winter","Martin Zimmermann"],"pdf_url":"https://arxiv.org/pdf/2305.19985v4.pdf","comment":"Full version of arXiv:2310.01010, contains all proofs omitted in the\n  conference version as well as a new section on winning games under delayed\n  control with mixed strategies with respect to a fixed threshold"},{"id":"http://arxiv.org/abs/2309.02862v3","updated":"2024-03-12T15:20:20Z","published":"2023-09-06T09:42:31Z","title":"TSO Games -- On the decidability of safety games under the total store\n  order semantics (extended LMCS version with appendix)","summary":"  We consider an extension of the classical Total Store Order (TSO) semantics\nby expanding it to turn-based 2-player safety games. During her turn, a player\ncan select any of the communicating processes and perform its next transition.\nWe consider different formulations of the safety game problem depending on\nwhether one player or both of them transfer messages from the process buffers\nto the shared memory. We give the complete decidability picture for all the\npossible alternatives.\n","authors":["Stephan Spengler","Sanchari Sil"],"pdf_url":"https://arxiv.org/pdf/2309.02862v3.pdf","comment":"36 pages, 11 figures, presented at GandALF 2023, submitted to LMCS\n  2024"},{"id":"http://arxiv.org/abs/2307.11428v2","updated":"2024-03-12T14:37:46Z","published":"2023-07-21T08:43:02Z","title":"Bidding efficiently in Simultaneous Ascending Auctions with budget and\n  eligibility constraints using Simultaneous Move Monte Carlo Tree Search","summary":"  For decades, Simultaneous Ascending Auction (SAA) has been the most popular\nmechanism used for spectrum auctions. It has recently been employed by many\ncountries for the allocation of 5G licences. Although SAA presents relatively\nsimple rules, it induces a complex strategic game for which the optimal bidding\nstrategy is unknown. Considering the fact that sometimes billions of euros are\nat stake in an SAA, establishing an efficient bidding strategy is crucial. In\nthis work, we model the auction as a $n$-player simultaneous move game with\ncomplete information and propose the first efficient bidding algorithm that\ntackles simultaneously its four main strategic issues: the $\\textit{exposure\nproblem}$, the $\\textit{own price effect}$, $\\textit{budget constraints}$ and\nthe $\\textit{eligibility management problem}$. Our solution, called\n$SMS^\\alpha$, is based on Simultaneous Move Monte Carlo Tree Search (SM-MCTS)\nand relies on a new method for the prediction of closing prices. By introducing\na new reward function in $SMS^\\alpha$, we give the possibility to bidders to\ndefine their own level of risk-aversion. Through extensive numerical\nexperiments on instances of realistic size, we show that $SMS^\\alpha$ largely\noutperforms state-of-the-art algorithms, notably by achieving higher expected\nutility while taking less risks.\n","authors":["Alexandre Pacaud","Aurelien Bechler","Marceau Coupechoux"],"pdf_url":"https://arxiv.org/pdf/2307.11428v2.pdf","comment":"20 pages, 19 figures, The paper has been submitted to IEEE journal\n  for possible publication"},{"id":"http://arxiv.org/abs/2307.00543v3","updated":"2024-03-12T13:44:55Z","published":"2023-07-02T11:23:33Z","title":"Defending Against Poisoning Attacks in Federated Learning with\n  Blockchain","summary":"  In the era of deep learning, federated learning (FL) presents a promising\napproach that allows multi-institutional data owners, or clients, to\ncollaboratively train machine learning models without compromising data\nprivacy. However, most existing FL approaches rely on a centralized server for\nglobal model aggregation, leading to a single point of failure. This makes the\nsystem vulnerable to malicious attacks when dealing with dishonest clients. In\nthis work, we address this problem by proposing a secure and reliable FL system\nbased on blockchain and distributed ledger technology. Our system incorporates\na peer-to-peer voting mechanism and a reward-and-slash mechanism, which are\npowered by on-chain smart contracts, to detect and deter malicious behaviors.\nBoth theoretical and empirical analyses are presented to demonstrate the\neffectiveness of the proposed approach, showing that our framework is robust\nagainst malicious client-side behaviors.\n","authors":["Nanqing Dong","Zhipeng Wang","Jiahao Sun","Michael Kampffmeyer","William Knottenbelt","Eric Xing"],"pdf_url":"https://arxiv.org/pdf/2307.00543v3.pdf","comment":"Accepted by IEEE Transactions on Artificial Intelligence"},{"id":"http://arxiv.org/abs/2403.07558v1","updated":"2024-03-12T11:42:42Z","published":"2024-03-12T11:42:42Z","title":"Controlling Delegations in Liquid Democracy","summary":"  In liquid democracy, agents can either vote directly or delegate their vote\nto a different agent of their choice. This results in a power structure in\nwhich certain agents possess more voting weight than others. As a result, it\nopens up certain possibilities of vote manipulation, including control and\nbribery, that do not exist in standard voting scenarios of direct democracy.\nHere we formalize a certain kind of election control -- in which an external\nagent may change certain delegation arcs -- and study the computational\ncomplexity of the corresponding combinatorial problem.\n","authors":["Shiri Alouf-Heffetz","Tanmay Inamdar","Pallavi Jain","Yash More","Nimrod Talmon"],"pdf_url":"https://arxiv.org/pdf/2403.07558v1.pdf","comment":"Accepted in 23rd International Conference on Autonomous Agents and\n  Multiagent Systems(AAMAS 2024)"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2403.04861v2","updated":"2024-03-12T18:35:48Z","published":"2024-03-07T19:27:01Z","title":"A Survey of Lottery Ticket Hypothesis","summary":"  The Lottery Ticket Hypothesis (LTH) states that a dense neural network model\ncontains a highly sparse subnetwork (i.e., winning tickets) that can achieve\neven better performance than the original model when trained in isolation.\nWhile LTH has been proved both empirically and theoretically in many works,\nthere still are some open issues, such as efficiency and scalability, to be\naddressed. Also, the lack of open-source frameworks and consensual experimental\nsetting poses a challenge to future research on LTH. We, for the first time,\nexamine previous research and studies on LTH from different perspectives. We\nalso discuss issues in existing works and list potential directions for further\nexploration. This survey aims to provide an in-depth look at the state of LTH\nand develop a duly maintained platform to conduct experiments and compare with\nthe most updated baselines.\n","authors":["Bohan Liu","Zijie Zhang","Peixiong He","Zhensen Wang","Yang Xiao","Ruimeng Ye","Yang Zhou","Wei-Shinn Ku","Bo Hui"],"pdf_url":"https://arxiv.org/pdf/2403.04861v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.04257v2","updated":"2024-03-12T17:16:29Z","published":"2023-10-06T14:02:34Z","title":"On Solving Close Enough Orienteering Problem with Overlapped\n  Neighborhoods","summary":"  Close Enough Traveling Salesman Problem (CETSP) is a well-known variant of\nTSP whereby the agent may complete its mission at any point within a target\nneighborhood. Heuristics based on overlapped neighborhoods, known as Steiner\nZones (SZ), have gained attention in addressing CETSP. While SZs offer\neffective approximations to the original graph, their inherent overlap imposes\nconstraints on search space, potentially conflicting with global optimization\nobjectives. Here we show how such limitations can be converted into advantages\nin a Close Enough Orienteering Problem (CEOP) by aggregating prizes across\noverlapped neighborhoods. We further extend classic CEOP with Non-uniform\nNeighborhoods (CEOP-N) by introducing non-uniform costs for prize collection.\nTo tackle CEOP and CEOP-N, we develop a new approach featuring a Randomized\nSteiner Zone Discretization (RSZD) scheme coupled with a hybrid algorithm based\non Particle Swarm Optimization (PSO) and Ant Colony System (ACS), CRaSZe-AntS.\nThe RSZD scheme identifies sub-regions for PSO exploration, and ACS determines\nthe discrete visiting sequence. We evaluate the RSZD's discretization\nperformance on CEOP instances derived from established CETSP instances and\ncompare CRaSZe-AntS against the most relevant state-of-the-art heuristic\nfocused on single-neighborhood optimization for CEOP instances. We also compare\nthe performance of the interior search within SZs and the boundary search on\nindividual neighborhoods in the context of CEOP-N. Our experimental results\nshow that CRaSZe-AntS can yield comparable solution quality with significantly\nreduced computation time compared to the single neighborhood strategy, where we\nobserve an average 140.44% increase in prize collection and a 55.18% reduction\nin algorithm execution time. CRaSZe-AntS is thus highly effective in solving\nemerging CEOP-N, examples of which include truck-and-drone delivery scenarios.\n","authors":["Qiuchen Qian","Yanran Wang","David Boyle"],"pdf_url":"https://arxiv.org/pdf/2310.04257v2.pdf","comment":"30 pages, 11 figures"},{"id":"http://arxiv.org/abs/2403.06572v2","updated":"2024-03-12T10:46:33Z","published":"2024-03-11T10:20:44Z","title":"Lander.AI: Adaptive Landing Behavior Agent for Expertise in 3D Dynamic\n  Platform Landings","summary":"  Mastering autonomous drone landing on dynamic platforms presents formidable\nchallenges due to unpredictable velocities and external disturbances caused by\nthe wind, ground effect, turbines or propellers of the docking platform. This\nstudy introduces an advanced Deep Reinforcement Learning (DRL) agent,\nLander:AI, designed to navigate and land on platforms in the presence of windy\nconditions, thereby enhancing drone autonomy and safety. Lander:AI is\nrigorously trained within the gym-pybullet-drone simulation, an environment\nthat mirrors real-world complexities, including wind turbulence, to ensure the\nagent's robustness and adaptability.\n  The agent's capabilities were empirically validated with Crazyflie 2.1 drones\nacross various test scenarios, encompassing both simulated environments and\nreal-world conditions. The experimental results showcased Lander:AI's\nhigh-precision landing and its ability to adapt to moving platforms, even under\nwind-induced disturbances. Furthermore, the system performance was benchmarked\nagainst a baseline PID controller augmented with an Extended Kalman Filter,\nillustrating significant improvements in landing precision and error recovery.\nLander:AI leverages bio-inspired learning to adapt to external forces like\nbirds, enhancing drone adaptability without knowing force magnitudes.This\nresearch not only advances drone landing technologies, essential for inspection\nand emergency applications, but also highlights the potential of DRL in\naddressing intricate aerodynamic challenges.\n","authors":["Robinroy Peter","Lavanya Ratnabala","Demetros Aschu","Aleksey Fedoseev","Dzmitry Tsetserukou"],"pdf_url":"https://arxiv.org/pdf/2403.06572v2.pdf","comment":null}]},"2024-03-11T00:00:00Z":{"Computer Science and Game Theory":[{"id":"http://arxiv.org/abs/2403.07949v1","updated":"2024-03-11T23:03:04Z","published":"2024-03-11T23:03:04Z","title":"Algorithmic Bayesian Epistemology","summary":"  One aspect of the algorithmic lens in theoretical computer science is a view\non other scientific disciplines that focuses on satisfactory solutions that\nadhere to real-world constraints, as opposed to solutions that would be optimal\nignoring such constraints. The algorithmic lens has provided a unique and\nimportant perspective on many academic fields, including molecular biology,\necology, neuroscience, quantum physics, economics, and social science.\n  This thesis applies the algorithmic lens to Bayesian epistemology.\nTraditional Bayesian epistemology provides a comprehensive framework for how an\nindividual's beliefs should evolve upon receiving new information. However,\nthese methods typically assume an exhaustive model of such information,\nincluding the correlation structure between different pieces of evidence. In\nreality, individuals might lack such an exhaustive model, while still needing\nto form beliefs. Beyond such informational constraints, an individual may be\nbounded by limited computation, or by limited communication with agents that\nhave access to information, or by the strategic behavior of such agents. Even\nwhen these restrictions prevent the formation of a *perfectly* accurate belief,\narriving at a *reasonably* accurate belief remains crucial. In this thesis, we\nestablish fundamental possibility and impossibility results about belief\nformation under a variety of restrictions, and lay the groundwork for further\nexploration.\n","authors":["Eric Neyman"],"pdf_url":"https://arxiv.org/pdf/2403.07949v1.pdf","comment":"385 pages, PhD thesis, 14 figures, 4 tables"},{"id":"http://arxiv.org/abs/2403.07148v1","updated":"2024-03-11T20:35:52Z","published":"2024-03-11T20:35:52Z","title":"Stochastic Extragradient with Random Reshuffling: Improved Convergence\n  for Variational Inequalities","summary":"  The Stochastic Extragradient (SEG) method is one of the most popular\nalgorithms for solving finite-sum min-max optimization and variational\ninequality problems (VIPs) appearing in various machine learning tasks.\nHowever, existing convergence analyses of SEG focus on its with-replacement\nvariants, while practical implementations of the method randomly reshuffle\ncomponents and sequentially use them. Unlike the well-studied with-replacement\nvariants, SEG with Random Reshuffling (SEG-RR) lacks established theoretical\nguarantees. In this work, we provide a convergence analysis of SEG-RR for three\nclasses of VIPs: (i) strongly monotone, (ii) affine, and (iii) monotone. We\nderive conditions under which SEG-RR achieves a faster convergence rate than\nthe uniform with-replacement sampling SEG. In the monotone setting, our\nanalysis of SEG-RR guarantees convergence to an arbitrary accuracy without\nlarge batch sizes, a strong requirement needed in the classical\nwith-replacement SEG. As a byproduct of our results, we provide convergence\nguarantees for Shuffle Once SEG (shuffles the data only at the beginning of the\nalgorithm) and the Incremental Extragradient (does not shuffle the data). We\nsupplement our analysis with experiments validating empirically the superior\nperformance of SEG-RR over the classical with-replacement sampling SEG.\n","authors":["Konstantinos Emmanouilidis","René Vidal","Nicolas Loizou"],"pdf_url":"https://arxiv.org/pdf/2403.07148v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.07143v1","updated":"2024-03-11T20:28:23Z","published":"2024-03-11T20:28:23Z","title":"New Perspectives in Online Contract Design: Heterogeneous, Homogeneous,\n  Non-myopic Agents and Team Production","summary":"  This work studies the repeated principal-agent problem from an online\nlearning perspective. The principal's goal is to learn the optimal contract\nthat maximizes her utility through repeated interactions, without prior\nknowledge of the agent's type (i.e., the agent's cost and production\nfunctions).\n  I study three different settings when the principal contracts with a\n$\\textit{single}$ agent each round: 1. The agents are heterogeneous; 2. the\nagents are homogenous; 3. the principal interacts with the same agent and the\nagent is non-myopic. I present different approaches and techniques for\ndesigning learning algorithms in each setting. For heterogeneous agent types, I\nidentify a condition that allows the problem to be reduced to Lipschitz bandits\ndirectly. For identical agents, I give a polynomial sample complexity scheme to\nlearn the optimal contract based on inverse game theory. For strategic\nnon-myopic agents, I design a low strategic-regret mechanism. Also, I identify\na connection between linear contracts and posted-price auctions, showing the\ntwo can be reduced to one another, and give a regret lower bound on learning\nthe optimal linear contract based on this observation.\n  I also study a $\\textit{team production}$ model. I identify a condition under\nwhich the principal's learning problem can be reformulated as solving a family\nof convex programs, thereby showing the optimal contract can be found\nefficiently.\n","authors":["Shiliang Zuo"],"pdf_url":"https://arxiv.org/pdf/2403.07143v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.06921v1","updated":"2024-03-11T17:08:55Z","published":"2024-03-11T17:08:55Z","title":"Synthesis of Robust Optimal Strategies in Weighted Timed Games","summary":"  Weighted Timed Games (WTG for short) are the most widely used model to\ndescribe controller synthesis problems involving real-time issues. The\nsynthesized strategies rely on a perfect measure of time elapse, which is not\nrealistic in practice. In order to produce strategies tolerant to timing\nimprecisions, we rely on a notion of robustness first introduced for timed\nautomata. More precisely, WTGs are two-player zero-sum games played in a timed\nautomaton equipped with integer weights in which one of the players, that we\ncall Min, wants to reach a target location while minimising the cumulated\nweight. In this work, we equip the underlying timed automaton with a semantics\ndepending on some parameter (representing the maximal possible perturbation) in\nwhich the opponent of Min can in addition perturb delays chosen by Min.\n  The robust value problem can then be stated as follows: given some threshold,\ndetermine whether there exists a positive perturbation and a strategy for Min\nensuring to reach the target, with an accumulated weight below the threshold,\nwhatever the opponent does.\n  We provide the first decidability result for this robust value problem by\ncomputing the robust value function, in a parametric way, for the class of\ndivergent WTGs (introduced to obtain decidability of the (classical) value\nproblem in WTGs without bounding the number of clocks). To this end, we show\nthat the robust value is the fixpoint of some operators, as is classically done\nfor value iteration algorithms. We then combine in a very careful way two\nrepresentations: piecewise affine functions introduced in [1] to analyse WTGs,\nand shrunk Difference Bound Matrices considered in [29] to analyse robustness\nin timed automata. Last, we also study qualitative decision problems and close\nan open problem on robust reachability, showing it is EXPTIME-complete for\ngeneral WTGs.\n","authors":["Benjamin Monmege","Julie Parreaux","Pierre-Alain Reynier"],"pdf_url":"https://arxiv.org/pdf/2403.06921v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.06796v1","updated":"2024-03-11T15:14:04Z","published":"2024-03-11T15:14:04Z","title":"Defaults: a double-edged sword in governing common resources","summary":"  Extracting from shared resources requires making choices to balance personal\nprofit and sustainability. We present the results of a behavioural experiment\nwherein we manipulate the default extraction from a finite resource.\nParticipants were exposed to two treatments -- pro-social or self-serving\nextraction defaults -- and a control without defaults. We examined the\npersistence of these nudges by removing the default after five rounds. Results\nreveal that a self-serving default increased the average extraction while\npresent, whereas a pro-social default only decreased extraction for the first\ntwo rounds. Notably, the influence of defaults depended on individual\ninclinations, with cooperative individuals extracting more under a self-serving\ndefault, and selfish individuals less under a pro-social default. After the\nremoval of the default, we observed no significant differences with the control\ntreatment. Our research highlights the potential of defaults as cost-effective\ntools for promoting sustainability, while also advocating for a careful use to\navoid adverse effects.\n","authors":["Eladio Montero-Porras","Rémi Suchon","Tom Lenaerts","Elias Fernández Domingos"],"pdf_url":"https://arxiv.org/pdf/2403.06796v1.pdf","comment":"36 pages, 11 pages of Supplementary Information, 11 figures"},{"id":"http://arxiv.org/abs/2403.06672v1","updated":"2024-03-11T12:43:44Z","published":"2024-03-11T12:43:44Z","title":"Provable Mutual Benefits from Federated Learning in Privacy-Sensitive\n  Domains","summary":"  Cross-silo federated learning (FL) allows data owners to train accurate\nmachine learning models by benefiting from each others private datasets.\nUnfortunately, the model accuracy benefits of collaboration are often\nundermined by privacy defenses. Therefore, to incentivize client participation\nin privacy-sensitive domains, a FL protocol should strike a delicate balance\nbetween privacy guarantees and end-model accuracy. In this paper, we study the\nquestion of when and how a server could design a FL protocol provably\nbeneficial for all participants. First, we provide necessary and sufficient\nconditions for the existence of mutually beneficial protocols in the context of\nmean estimation and convex stochastic optimization. We also derive protocols\nthat maximize the total clients' utility, given symmetric privacy preferences.\nFinally, we design protocols maximizing end-model accuracy and demonstrate\ntheir benefits in synthetic experiments.\n","authors":["Nikita Tsoy","Anna Mihalkova","Teodora Todorova","Nikola Konstantinov"],"pdf_url":"https://arxiv.org/pdf/2403.06672v1.pdf","comment":"AISTATS 2024; Camera-ready version"},{"id":"http://arxiv.org/abs/2109.03396v3","updated":"2024-03-11T10:06:17Z","published":"2021-09-08T02:05:40Z","title":"A Bayesian Learning Algorithm for Unknown Zero-sum Stochastic Games with\n  an Arbitrary Opponent","summary":"  In this paper, we propose Posterior Sampling Reinforcement Learning for\nZero-sum Stochastic Games (PSRL-ZSG), the first online learning algorithm that\nachieves Bayesian regret bound of $O(HS\\sqrt{AT})$ in the infinite-horizon\nzero-sum stochastic games with average-reward criterion. Here $H$ is an upper\nbound on the span of the bias function, $S$ is the number of states, $A$ is the\nnumber of joint actions and $T$ is the horizon. We consider the online setting\nwhere the opponent can not be controlled and can take any arbitrary\ntime-adaptive history-dependent strategy. Our regret bound improves on the best\nexisting regret bound of $O(\\sqrt[3]{DS^2AT^2})$ by Wei et al. (2017) under the\nsame assumption and matches the theoretical lower bound in $T$.\n","authors":["Mehdi Jafarnia-Jahromi","Rahul Jain","Ashutosh Nayyar"],"pdf_url":"https://arxiv.org/pdf/2109.03396v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.03045v2","updated":"2024-03-11T07:41:48Z","published":"2023-06-05T17:15:26Z","title":"Designing Equilibria in Concurrent Games with Social Welfare and\n  Temporal Logic Constraints","summary":"  In game theory, mechanism design is concerned with the design of incentives\nso that a desired outcome of the game can be achieved. In this paper, we\nexplore the concept of equilibrium design, where incentives are designed to\nobtain a desirable equilibrium that satisfies a specific temporal logic\nproperty. Our study is based on a framework where system specifications are\nrepresented as temporal logic formulae, games as quantitative concurrent game\nstructures, and players' goals as mean-payoff objectives. We consider system\nspecifications given by LTL and GR(1) formulae, and show that designing\nincentives to ensure that a given temporal logic property is satisfied on\nsome/every Nash equilibrium of the game can be achieved in PSPACE for LTL\nproperties and in NP/{\\Sigma}P 2 for GR(1) specifications. We also examine the\ncomplexity of related decision and optimisation problems, such as optimality\nand uniqueness of solutions, as well as considering social welfare, and show\nthat the complexities of these problems lie within the polynomial hierarchy.\nEquilibrium design can be used as an alternative solution to rational synthesis\nand verification problems for concurrent games with mean-payoff objectives when\nno solution exists or as a technique to repair concurrent games with\nundesirable Nash equilibria in an optimal way.\n","authors":["Julian Gutierrez","Muhammad Najib","Giuseppe Perelli","Michael Wooldridge"],"pdf_url":"https://arxiv.org/pdf/2306.03045v2.pdf","comment":"The manuscript is going to be submitted to the Journal on Logical\n  Methods in Computer Science. arXiv admin note: substantial text overlap with\n  arXiv:2106.10192"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2403.07182v1","updated":"2024-03-11T21:50:22Z","published":"2024-03-11T21:50:22Z","title":"MAP-Elites with Transverse Assessment for Multimodal Problems in\n  Creative Domains","summary":"  The recent advances in language-based generative models have paved the way\nfor the orchestration of multiple generators of different artefact types (text,\nimage, audio, etc.) into one system. Presently, many open-source pre-trained\nmodels combine text with other modalities, thus enabling shared vector\nembeddings to be compared across different generators. Within this context we\npropose a novel approach to handle multimodal creative tasks using Quality\nDiversity evolution. Our contribution is a variation of the MAP-Elites\nalgorithm, MAP-Elites with Transverse Assessment (MEliTA), which is tailored\nfor multimodal creative tasks and leverages deep learned models that assess\ncoherence across modalities. MEliTA decouples the artefacts' modalities and\npromotes cross-pollination between elites. As a test bed for this algorithm, we\ngenerate text descriptions and cover images for a hypothetical video game and\nassign each artefact a unique modality-specific behavioural characteristic.\nResults indicate that MEliTA can improve text-to-image mappings within the\nsolution space, compared to a baseline MAP-Elites algorithm that strictly\ntreats each image-text pair as one solution. Our approach represents a\nsignificant step forward in multimodal bottom-up orchestration and lays the\ngroundwork for more complex systems coordinating multimodal creative agents in\nthe future.\n","authors":["Marvin Zammit","Antonios Liapis","Georgios N. Yannakakis"],"pdf_url":"https://arxiv.org/pdf/2403.07182v1.pdf","comment":"18 pages, 5 figures To be published in the proceedings of the 13th\n  International Conference on Artificial Intelligence in Music, Sound, Art and\n  Design (EvoMUSART) 2024"},{"id":"http://arxiv.org/abs/2307.11888v2","updated":"2024-03-11T17:30:54Z","published":"2023-07-21T20:09:06Z","title":"Universality of Linear Recurrences Followed by Non-linear Projections:\n  Finite-Width Guarantees and Benefits of Complex Eigenvalues","summary":"  Deep neural networks based on linear complex-valued RNNs interleaved with\nposition-wise MLPs are gaining traction as competitive approaches to sequence\nmodeling. Examples of such architectures include state-space models (SSMs) like\nS4, LRU, and Mamba: recently proposed models that achieve promising performance\non text, genetics, and other data that require long-range reasoning. Despite\nexperimental evidence highlighting these architectures' effectiveness and\ncomputational efficiency, their expressive power remains relatively unexplored,\nespecially in connection to specific choices crucial in practice - e.g.,\ncarefully designed initialization distribution and use of complex numbers. In\nthis paper, we show that combining MLPs with both real or complex linear\ndiagonal recurrences leads to arbitrarily precise approximation of regular\ncausal sequence-to-sequence maps. At the heart of our proof, we rely on a\nseparation of concerns: the linear RNN provides a lossless encoding of the\ninput sequence, and the MLP performs non-linear processing on this encoding.\nWhile we show that using real diagonal linear recurrences is enough to achieve\nuniversality in this architecture, we prove that employing complex eigenvalues\nnear unit disk - i.e., empirically the most successful strategy in SSMs -\ngreatly helps the RNN in storing information. We connect this finding with the\nvanishing gradient issue and provide experimental evidence supporting our\nclaims.\n","authors":["Antonio Orvieto","Soham De","Caglar Gulcehre","Razvan Pascanu","Samuel L. Smith"],"pdf_url":"https://arxiv.org/pdf/2307.11888v2.pdf","comment":"v1: Accepted at HLD 2023: 1st Workshop on High-dimensional Learning\n  Dynamics v2: Preprint"},{"id":"http://arxiv.org/abs/2403.07041v1","updated":"2024-03-11T16:26:06Z","published":"2024-03-11T16:26:06Z","title":"Ant Colony Sampling with GFlowNets for Combinatorial Optimization","summary":"  This paper introduces the Generative Flow Ant Colony Sampler (GFACS), a novel\nneural-guided meta-heuristic algorithm for combinatorial optimization. GFACS\nintegrates generative flow networks (GFlowNets) with the ant colony\noptimization (ACO) methodology. GFlowNets, a generative model that learns a\nconstructive policy in combinatorial spaces, enhance ACO by providing an\ninformed prior distribution of decision variables conditioned on input graph\ninstances. Furthermore, we introduce a novel combination of training tricks,\nincluding search-guided local exploration, energy normalization, and energy\nshaping to improve GFACS. Our experimental results demonstrate that GFACS\noutperforms baseline ACO algorithms in seven CO tasks and is competitive with\nproblem-specific heuristics for vehicle routing problems. The source code is\navailable at \\url{https://github.com/ai4co/gfacs}.\n","authors":["Minsu Kim","Sanghyeok Choi","Jiwoo Son","Hyeonah Kim","Jinkyoo Park","Yoshua Bengio"],"pdf_url":"https://arxiv.org/pdf/2403.07041v1.pdf","comment":"19 pages, 6 figures"},{"id":"http://arxiv.org/abs/2403.06805v1","updated":"2024-03-11T15:23:35Z","published":"2024-03-11T15:23:35Z","title":"On the Robustness of Lexicase Selection to Contradictory Objectives","summary":"  Lexicase and epsilon-lexicase selection are state of the art parent selection\ntechniques for problems featuring multiple selection criteria. Originally,\nlexicase selection was developed for cases where these selection criteria are\nunlikely to be in conflict with each other, but preliminary work suggests it is\nalso a highly effective many-objective optimization algorithm. However, to\npredict whether these results generalize, we must understand lexicase\nselection's performance on contradictory objectives. Prior work has shown mixed\nresults on this question. Here, we develop theory identifying circumstances\nunder which lexicase selection will succeed or fail to find a Pareto-optimal\nsolution. To make this analysis tractable, we restrict our investigation to a\ntheoretical problem with maximally contradictory objectives. Ultimately, we\nfind that lexicase and epsilon-lexicase selection each have a region of\nparameter space where they are incapable of optimizing contradictory\nobjectives. Outside of this region, however, they perform well despite the\npresence of contradictory objectives. Based on these findings, we propose\ntheoretically-backed guidelines for parameter choice. Additionally, we identify\nother properties that may affect whether a many-objective optimization problem\nis a good fit for lexicase or epsilon-lexicase selection.\n","authors":["Shakiba Shahbandegan","Emily Dolson"],"pdf_url":"https://arxiv.org/pdf/2403.06805v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.02331v3","updated":"2024-03-11T09:55:33Z","published":"2024-03-04T18:58:09Z","title":"Toward Neuromic Computing: Neurons as Autoencoders","summary":"  This short paper presents the idea that neural backpropagation is using\ndendritic processing to enable individual neurons to perform autoencoding.\nUsing a very simple connection weight search heuristic and artificial neural\nnetwork model, the effects of interleaving autoencoding for each neuron in a\nhidden layer of a feedforward network are explored. This is contrasted to the\nstandard layered approach to autoencoding. It is shown that such individualised\nprocessing is not detrimental and can improve network learning.\n","authors":["Larry Bull"],"pdf_url":"https://arxiv.org/pdf/2403.02331v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.01150v4","updated":"2024-03-11T09:26:03Z","published":"2023-12-02T14:38:58Z","title":"Pointer Networks Trained Better via Evolutionary Algorithms","summary":"  Pointer Network (PtrNet) is a specific neural network for solving\nCombinatorial Optimization Problems (COPs). While PtrNets offer real-time\nfeed-forward inference for complex COPs instances, its quality of the results\ntends to be less satisfactory. One possible reason is that such issue suffers\nfrom the lack of global search ability of the gradient descent, which is\nfrequently employed in traditional PtrNet training methods including both\nsupervised learning and reinforcement learning. To improve the performance of\nPtrNet, this paper delves deeply into the advantages of training PtrNet with\nEvolutionary Algorithms (EAs), which have been widely acknowledged for not\neasily getting trapped by local optima. Extensive empirical studies based on\nthe Travelling Salesman Problem (TSP) have been conducted. Results demonstrate\nthat PtrNet trained with EA can consistently perform much better inference\nresults than eight state-of-the-art methods on various problem scales. Compared\nwith gradient descent based PtrNet training methods, EA achieves up to 30.21\\%\nimprovement in quality of the solution with the same computational time. With\nthis advantage, this paper is able to at the first time report the results of\nsolving 1000-dimensional TSPs by training a PtrNet on the same dimensionality,\nwhich strongly suggests that scaling up the training instances is in need to\nimprove the performance of PtrNet on solving higher-dimensional COPs.\n","authors":["Muyao Zhong","Shengcai Liu","Bingdong Li","Haobo Fu","Ke Tang","Peng Yang"],"pdf_url":"https://arxiv.org/pdf/2312.01150v4.pdf","comment":"None"},{"id":"http://arxiv.org/abs/2403.07035v1","updated":"2024-03-11T08:05:01Z","published":"2024-03-11T08:05:01Z","title":"Multiple Population Alternate Evolution Neural Architecture Search","summary":"  The effectiveness of Evolutionary Neural Architecture Search (ENAS) is\ninfluenced by the design of the search space. Nevertheless, common methods\nincluding the global search space, scalable search space and hierarchical\nsearch space have certain limitations. Specifically, the global search space\nrequires a significant amount of computational resources and time, the scalable\nsearch space sacrifices the diversity of network structures and the\nhierarchical search space increases the search cost in exchange for network\ndiversity. To address above limitation, we propose a novel paradigm of\nsearching neural network architectures and design the Multiple Population\nAlternate Evolution Neural Architecture Search (MPAE), which can achieve module\ndiversity with a smaller search cost. MPAE converts the search space into L\ninterconnected units and sequentially searches the units, then the above search\nof the entire network be cycled several times to reduce the impact of previous\nunits on subsequent units. To accelerate the population evolution process, we\nalso propose the the population migration mechanism establishes an excellent\nmigration archive and transfers the excellent knowledge and experience in the\nmigration archive to new populations. The proposed method requires only 0.3 GPU\ndays to search a neural network on the CIFAR dataset and achieves the\nstate-of-the-art results.\n","authors":["Juan Zou","Han Chu","Yizhang Xia","Junwen Xu","Yuan Liu","Zhanglu Hou"],"pdf_url":"https://arxiv.org/pdf/2403.07035v1.pdf","comment":null}]},"2024-03-10T00:00:00Z":{"Computer Science and Game Theory":[{"id":"http://arxiv.org/abs/2402.07860v2","updated":"2024-03-10T23:46:41Z","published":"2024-02-12T18:12:09Z","title":"On the Detection of Reviewer-Author Collusion Rings From Paper Bidding","summary":"  A major threat to the peer-review systems of computer science conferences is\nthe existence of \"collusion rings\" between reviewers. In such collusion rings,\nreviewers who have also submitted their own papers to the conference work\ntogether to manipulate the conference's paper assignment, with the aim of being\nassigned to review each other's papers. The most straightforward way that\ncolluding reviewers can manipulate the paper assignment is by indicating their\ninterest in each other's papers through strategic paper bidding. One potential\napproach to solve this important problem would be to detect the colluding\nreviewers from their manipulated bids, after which the conference can take\nappropriate action. While prior work has developed effective techniques to\ndetect other kinds of fraud, no research has yet established that detecting\ncollusion rings is even possible. In this work, we tackle the question of\nwhether it is feasible to detect collusion rings from the paper bidding. To\nanswer this question, we conduct empirical analysis of two realistic conference\nbidding datasets, including evaluations of existing algorithms for fraud\ndetection in other applications. We find that collusion rings can achieve\nconsiderable success at manipulating the paper assignment while remaining\nhidden from detection: for example, in one dataset, undetected colluders are\nable to achieve assignment to up to 30% of the papers authored by other\ncolluders. In addition, when 10 colluders bid on all of each other's papers, no\ndetection algorithm outputs a group of reviewers with more than 31% overlap\nwith the true colluders. These results suggest that collusion cannot be\neffectively detected from the bidding using popular existing tools,\ndemonstrating the need to develop more complex detection algorithms as well as\nthose that leverage additional metadata (e.g., reviewer-paper text-similarity\nscores).\n","authors":["Steven Jecmen","Nihar B. Shah","Fei Fang","Leman Akoglu"],"pdf_url":"https://arxiv.org/pdf/2402.07860v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.06299v1","updated":"2024-03-10T20:09:23Z","published":"2024-03-10T20:09:23Z","title":"Disentangling Resilience from Robustness: Contextual Dualism,\n  Interactionism, and Game-Theoretic Paradigms","summary":"  This article explains the distinctions between robustness and resilience in\ncontrol systems. Resilience confronts a distinct set of challenges, posing new\nones for designing controllers for feedback systems, networks, and machines\nthat prioritize resilience over robustness. The concept of resilience is\nexplored through a three-stage model, emphasizing the need for a proactive\npreparation and automated response to elastic events. A toy model is first used\nto illustrate the tradeoffs between resilience and robustness. Then, it delves\ninto contextual dualism and interactionism, and introduces game-theoretic\nparadigms as a unifying framework to consolidate resilience and robustness. The\narticle concludes by discussing the interplay between robustness and\nresilience, suggesting that a comprehensive theory of resilience and\nquantification metrics, and formalization through game-theoretic frameworks are\nnecessary. The exploration extends to system-of-systems resilience and various\nmechanisms, including the integration of AI techniques and non-technical\nsolutions, like cyber insurance, to achieve comprehensive resilience in control\nsystems. As we approach 2030, the systems and control community is at the\nopportune moment to lay scientific foundations of resilience by bridging\nfeedback control theory, game theory, and learning theory. Resilient control\nsystems will enhance overall quality of life, enable the development of a\nresilient society, and create a societal-scale impact amid global challenges\nsuch as climate change, conflicts, and cyber insecurity.\n","authors":["Quanyan Zhu","Tamer Basar"],"pdf_url":"https://arxiv.org/pdf/2403.06299v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.06278v1","updated":"2024-03-10T18:09:21Z","published":"2024-03-10T18:09:21Z","title":"Pre- and Post-Auction Discounts in First-Price Auctions","summary":"  One method to offer some bidders a discount in a first-price auction is to\naugment their bids when selecting a winner but only charge them their original\nbids should they win. Another method is to use their original bids to select a\nwinner, then charge them a discounted price that is lower than their bid should\nthey win. We show that the two methods have equivalent auction outcomes, for\nequal additive discounts and for multiplicative ones with appropriate\nadjustments to discount amounts. As a result, they have corresponding\nequilibria when equilibria exist. We also show that with the same level of\nmultiplicative adjustments, bidders with discounts should prefer an augmented\nbid to a discounted price. Then we estimate optimal bid functions for valuation\ndistributions based on data from online advertising auctions, and show how\ndifferent discount levels affect auction outcomes for those bid functions.\n","authors":["Miguel Alcobendas","Eric Bax"],"pdf_url":"https://arxiv.org/pdf/2403.06278v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.06202v1","updated":"2024-03-10T12:52:31Z","published":"2024-03-10T12:52:31Z","title":"Pursuit Winning Strategies for Reach-Avoid Games with Polygonal\n  Obstacles","summary":"  This paper studies a multiplayer reach-avoid differential game in the\npresence of general polygonal obstacles that block the players' motions. The\npursuers cooperate to protect a convex region from the evaders who try to reach\nthe region. We propose a multiplayer onsite and close-to-goal (MOCG) pursuit\nstrategy that can tell and achieve an increasing lower bound on the number of\nguaranteed defeated evaders. This pursuit strategy fuses the subgame outcomes\nfor multiple pursuers against one evader with hierarchical optimal task\nallocation in the receding-horizon manner. To determine the qualitative subgame\noutcomes that who is the game winner, we construct three pursuit winning\nregions and strategies under which the pursuers guarantee to win against the\nevader, regardless of the unknown evader strategy. First, we utilize the\nexpanded Apollonius circles and propose the onsite pursuit winning that\nachieves the capture in finite time. Second, we introduce convex goal-covering\npolygons (GCPs) and propose the close-to-goal pursuit winning for the pursuers\nwhose visibility region contains the whole protected region, and the\ngoal-visible property will be preserved afterwards. Third, we employ Euclidean\nshortest paths (ESPs) and construct a pursuit winning region and strategy for\nthe non-goal-visible pursuers, where the pursuers are firstly steered to\npositions with goal visibility along ESPs. In each horizon, the hierarchical\noptimal task allocation maximizes the number of defeated evaders and consists\nof four sequential matchings: capture, enhanced, non-dominated and closest\nmatchings. Numerical examples are presented to illustrate the results.\n","authors":["Rui Yan","Shuai Mi","Xiaoming Duan","Jintao Chen","Xiangyang Ji"],"pdf_url":"https://arxiv.org/pdf/2403.06202v1.pdf","comment":"16 pages, 10 figures"},{"id":"http://arxiv.org/abs/2311.05644v3","updated":"2024-03-10T09:32:36Z","published":"2023-11-06T07:19:58Z","title":"On the tractability of Nash equilibrium","summary":"  In this paper, we propose a method for solving a PPAD-complete problem\n[Papadimitriou, 1994]. Given is the payoff matrix $C$ of a symmetric bimatrix\ngame $(C, C^T)$ and our goal is to compute a Nash equilibrium of $(C, C^T)$. In\nthis paper, we devise a nonlinear replicator dynamic (whose right-hand-side can\nbe obtained by solving a pair of convex optimization problems) with the\nfollowing property: Under any invertible $0 < C \\leq 1$, every orbit of our\ndynamic starting at an interior strategy of the standard simplex approaches a\nset of strategies of $(C, C^T)$ such that, for each strategy in this set, a\nsymmetric Nash equilibrium strategy can be computed by solving the\naforementioned convex mathematical programs. We prove convergence using results\nin analysis (the analytic implicit function theorem), nonlinear optimization\ntheory (duality theory, Berge's maximum principle, and a theorem of Robinson\n[1980] on the Lipschitz continuity of parametric nonlinear programs), and\ndynamical systems theory (such as the LaSalle invariance principle).\n","authors":["Ioannis Avramopoulos"],"pdf_url":"https://arxiv.org/pdf/2311.05644v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.06626v2","updated":"2024-03-10T09:10:57Z","published":"2024-02-09T18:59:20Z","title":"Computing Optimal Commitments to Strategies and Outcome-Conditional\n  Utility Transfers","summary":"  Prior work has studied the computational complexity of computing optimal\nstrategies to commit to in Stackelberg or leadership games, where a leader\ncommits to a strategy which is observed by one or more followers. We extend\nthis setting to one where the leader can additionally commit to\noutcome-conditional utility transfers. We characterize the computational\ncomplexity of finding optimal strategies in normal-form and Bayesian games,\ngiving a mix of efficient algorithms and NP-hardness results. Finally, we allow\nthe leader to also commit to a signaling scheme which induces a correlated\nequilibrium. In this setting, optimal commitments can be found in polynomial\ntime for arbitrarily many players.\n","authors":["Nathaniel Sauerberg","Caspar Oesterheld"],"pdf_url":"https://arxiv.org/pdf/2402.06626v2.pdf","comment":"AAMAS 2024"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2403.06235v1","updated":"2024-03-10T15:25:49Z","published":"2024-03-10T15:25:49Z","title":"Probabilistic Neural Circuits","summary":"  Probabilistic circuits (PCs) have gained prominence in recent years as a\nversatile framework for discussing probabilistic models that support tractable\nqueries and are yet expressive enough to model complex probability\ndistributions. Nevertheless, tractability comes at a cost: PCs are less\nexpressive than neural networks. In this paper we introduce probabilistic\nneural circuits (PNCs), which strike a balance between PCs and neural nets in\nterms of tractability and expressive power. Theoretically, we show that PNCs\ncan be interpreted as deep mixtures of Bayesian networks. Experimentally, we\ndemonstrate that PNCs constitute powerful function approximators.\n","authors":["Pedro Zuidberg Dos Martires"],"pdf_url":"https://arxiv.org/pdf/2403.06235v1.pdf","comment":"Proceedings of the AAAI Conference on Artificial Intelligence"},{"id":"http://arxiv.org/abs/2201.09754v2","updated":"2024-03-10T08:02:12Z","published":"2022-01-21T16:42:11Z","title":"Deep Reinforcement Learning with Spiking Q-learning","summary":"  With the help of special neuromorphic hardware, spiking neural networks\n(SNNs) are expected to realize artificial intelligence (AI) with less energy\nconsumption. It provides a promising energy-efficient way for realistic control\ntasks by combining SNNs with deep reinforcement learning (RL). There are only a\nfew existing SNN-based RL methods at present. Most of them either lack\ngeneralization ability or employ Artificial Neural Networks (ANNs) to estimate\nvalue function in training. The former needs to tune numerous hyper-parameters\nfor each scenario, and the latter limits the application of different types of\nRL algorithm and ignores the large energy consumption in training. To develop a\nrobust spike-based RL method, we draw inspiration from non-spiking interneurons\nfound in insects and propose the deep spiking Q-network (DSQN), using the\nmembrane voltage of non-spiking neurons as the representation of Q-value, which\ncan directly learn robust policies from high-dimensional sensory inputs using\nend-to-end RL. Experiments conducted on 17 Atari games demonstrate the DSQN is\neffective and even outperforms the ANN-based deep Q-network (DQN) in most\ngames. Moreover, the experiments show superior learning stability and\nrobustness to adversarial attacks of DSQN.\n","authors":["Ding Chen","Peixi Peng","Tiejun Huang","Yonghong Tian"],"pdf_url":"https://arxiv.org/pdf/2201.09754v2.pdf","comment":"15 pages, 7 figures"}]},"2024-03-09T00:00:00Z":{"Computer Science and Game Theory":[{"id":"http://arxiv.org/abs/2403.06037v1","updated":"2024-03-09T23:05:47Z","published":"2024-03-09T23:05:47Z","title":"The Flow Game: Leximin and Leximax Core Imputations","summary":"  Recently [Vaz24] gave mechanisms for finding leximin and leximax core\nimputations for the assignment game and remarked, \"Within the area of algorithm\ndesign, the \"right\" technique for solving several types of algorithmic\nquestions was first discovered in the context of matching and later these\ninsights were applied to other problems. We expect a similar phenomenon here.\"\nOne of the games explicitly mentioned in this context was the flow game of\nKalai and Zemel [KZ82]. In this paper, we give strongly polynomial time\nmechanisms for computing the leximin and leximax core imputations for the flow\ngame, among the set of core imputations that are captured as optimal solutions\nto the dual LP. We address two versions: 1. The imputations are leximin and\nleximax with respect to the distance labels of edges. 2. The imputations are\nleximin and leximax with respect to the product of capacities of edges and\ntheir distance labels.\n","authors":["Rohith R. Gangam","Naveen Garg","Parnian Shahkar","Vijay V. Vazirani"],"pdf_url":"https://arxiv.org/pdf/2403.06037v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2210.00954v3","updated":"2024-03-09T18:43:45Z","published":"2022-10-03T14:11:33Z","title":"Machine Learning-Powered Course Allocation","summary":"  We study the course allocation problem, where universities assign course\nschedules to students. The current state-of-the-art mechanism, Course Match,\nhas one major shortcoming: students make significant mistakes when reporting\ntheir preferences, which negatively affects welfare and fairness. To address\nthis issue, we introduce a new mechanism, Machine Learning-powered Course Match\n(MLCM). At the core of MLCM is a machine learning-powered preference\nelicitation module that iteratively asks personalized pairwise comparison\nqueries to alleviate students' reporting mistakes. Extensive computational\nexperiments, grounded in real-world data, demonstrate that MLCM, with only ten\ncomparison queries, significantly increases both average and minimum student\nutility by 7%-11% and 17%-29%, respectively. Finally, we highlight MLCM's\nrobustness to changes in the environment and show how our design minimizes the\nrisk of upgrading to MLCM while making the upgrade process simple for\nuniversities and seamless for their students.\n","authors":["Ermis Soumalias","Behnoosh Zamanlooy","Jakob Weissteiner","Sven Seuken"],"pdf_url":"https://arxiv.org/pdf/2210.00954v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.12553v5","updated":"2024-03-09T18:41:01Z","published":"2023-05-21T19:27:31Z","title":"Markov $α$-Potential Games","summary":"  This paper proposes a new framework of Markov $\\alpha$-potential games to\nstudy Markov games. In this new framework, Markov games are shown to be Markov\n$\\alpha$-potential games, and the existence of an associated $\\alpha$-potential\nfunction is established. Any optimizer of an $\\alpha$-potential function is\nshown to be an $\\alpha$-stationary NE. Two important classes of practically\nsignificant Markov games, Markov congestion games and the perturbed Markov team\ngames, are studied via this framework of Markov $\\alpha$-potential games, with\nexplicit characterization of an upper bound for $\\alpha$ and its relation to\ngame parameters. Additionally, a semi-infinite linear programming based\nformulation is presented to obtain an upper bound for $\\alpha$ for any Markov\ngame. Furthermore, two equilibrium approximation algorithms, namely the\nprojected gradient-ascent algorithm and the sequential maximum improvement\nalgorithm, are presented along with their Nash regret analysis, and\ncorroborated by numerical experiments.\n","authors":["Xin Guo","Xinyu Li","Chinmay Maheshwari","Shankar Sastry","Manxi Wu"],"pdf_url":"https://arxiv.org/pdf/2305.12553v5.pdf","comment":"32 pages, 3 figures"},{"id":"http://arxiv.org/abs/2403.07017v1","updated":"2024-03-09T17:36:54Z","published":"2024-03-09T17:36:54Z","title":"Mathematics of multi-agent learning systems at the interface of game\n  theory and artificial intelligence","summary":"  Evolutionary Game Theory (EGT) and Artificial Intelligence (AI) are two\nfields that, at first glance, might seem distinct, but they have notable\nconnections and intersections. The former focuses on the evolution of behaviors\n(or strategies) in a population, where individuals interact with others and\nupdate their strategies based on imitation (or social learning). The more\nsuccessful a strategy is, the more prevalent it becomes over time. The latter,\nmeanwhile, is centered on machine learning algorithms and (deep) neural\nnetworks. It is often from a single-agent perspective but increasingly involves\nmulti-agent environments, in which intelligent agents adjust their strategies\nbased on feedback and experience, somewhat akin to the evolutionary process yet\ndistinct in their self-learning capacities. In light of the key components\nnecessary to address real-world problems, including (i) learning and\nadaptation, (ii) cooperation and competition, (iii) robustness and stability,\nand altogether (iv) population dynamics of individual agents whose strategies\nevolve, the cross-fertilization of ideas between both fields will contribute to\nthe advancement of mathematics of multi-agent learning systems, in particular,\nto the nascent domain of ``collective cooperative intelligence'' bridging\nevolutionary dynamics and multi-agent reinforcement learning.\n","authors":["Long Wang","Feng Fu","Xingru Chen"],"pdf_url":"https://arxiv.org/pdf/2403.07017v1.pdf","comment":"8 pages, 1 figure"},{"id":"http://arxiv.org/abs/2202.06255v6","updated":"2024-03-09T12:40:21Z","published":"2022-02-13T08:39:00Z","title":"Strategy Synthesis for Zero-Sum Neuro-Symbolic Concurrent Stochastic\n  Games","summary":"  Neuro-symbolic approaches to artificial intelligence, which combine neural\nnetworks with classical symbolic techniques, are growing in prominence,\nnecessitating formal approaches to reason about their correctness. We propose a\nnovel modelling formalism called neuro-symbolic concurrent stochastic games\n(NS-CSGs), which comprise two probabilistic finite-state agents interacting in\na shared continuous-state environment. Each agent observes the environment\nusing a neural perception mechanism, which converts inputs such as images into\nsymbolic percepts, and makes decisions symbolically. We focus on the class of\nNS-CSGs with Borel state spaces and prove the existence and measurability of\nthe value function for zero-sum discounted cumulative rewards under\npiecewise-constant restrictions on the components of this class of models. To\ncompute values and synthesise strategies, we present, for the first time,\npractical value iteration (VI) and policy iteration (PI) algorithms to solve\nthis new subclass of continuous-state CSGs. These require a finite\ndecomposition of the environment induced by the neural perception mechanisms of\nthe agents and rely on finite abstract representations of value functions and\nstrategies closed under VI or PI. First, we introduce a Borel measurable\npiecewise-constant (B-PWC) representation of value functions, extend minimax\nbackups to this representation and propose a value iteration algorithm called\nB-PWC VI. Second, we introduce two novel representations for the value\nfunctions and strategies, constant-piecewise-linear (CON-PWL) and\nconstant-piecewise-constant (CON-PWC) respectively, and propose\nMinimax-action-free PI by extending a recent PI method based on alternating\nplayer choices for finite state spaces to Borel state spaces, which does not\nrequire normal-form games to be solved.\n","authors":["Rui Yan","Gabriel Santos","Gethin Norman","David Parker","Marta Kwiatkowska"],"pdf_url":"https://arxiv.org/pdf/2202.06255v6.pdf","comment":"58 pages, 7 figures"},{"id":"http://arxiv.org/abs/2403.05738v1","updated":"2024-03-09T00:20:33Z","published":"2024-03-09T00:20:33Z","title":"Provable Policy Gradient Methods for Average-Reward Markov Potential\n  Games","summary":"  We study Markov potential games under the infinite horizon average reward\ncriterion. Most previous studies have been for discounted rewards. We prove\nthat both algorithms based on independent policy gradient and independent\nnatural policy gradient converge globally to a Nash equilibrium for the average\nreward criterion. To set the stage for gradient-based methods, we first\nestablish that the average reward is a smooth function of policies and provide\nsensitivity bounds for the differential value functions, under certain\nconditions on ergodicity and the second largest eigenvalue of the underlying\nMarkov decision process (MDP). We prove that three algorithms, policy gradient,\nproximal-Q, and natural policy gradient (NPG), converge to an $\\epsilon$-Nash\nequilibrium with time complexity $O(\\frac{1}{\\epsilon^2})$, given a\ngradient/differential Q function oracle. When policy gradients have to be\nestimated, we propose an algorithm with\n$\\tilde{O}(\\frac{1}{\\min_{s,a}\\pi(a|s)\\delta})$ sample complexity to achieve\n$\\delta$ approximation error w.r.t~the $\\ell_2$ norm. Equipped with the\nestimator, we derive the first sample complexity analysis for a policy gradient\nascent algorithm, featuring a sample complexity of $\\tilde{O}(1/\\epsilon^5)$.\nSimulation studies are presented.\n","authors":["Min Cheng","Ruida Zhou","P. R. Kumar","Chao Tian"],"pdf_url":"https://arxiv.org/pdf/2403.05738v1.pdf","comment":"38 pages, 7 figures, published to AISTAT-24"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2403.05877v1","updated":"2024-03-09T11:02:47Z","published":"2024-03-09T11:02:47Z","title":"A Performance Analysis of Basin Hopping Compared to Established\n  Metaheuristics for Global Optimization","summary":"  During the last decades many metaheuristics for global numerical optimization\nhave been proposed. Among them, Basin Hopping is very simple and\nstraightforward to implement, although rarely used outside its original\nPhysical Chemistry community. In this work, our aim is to compare Basin\nHopping, and two population variants of it, with readily available\nimplementations of the well known metaheuristics Differential Evolution,\nParticle Swarm Optimization, and Covariance Matrix Adaptation Evolution\nStrategy. We perform numerical experiments using the IOH profiler environment\nwith the BBOB test function set and two difficult real-world problems. The\nexperiments were carried out in two different but complementary ways: by\nmeasuring the performance under a fixed budget of function evaluations and by\nconsidering a fixed target value. The general conclusion is that Basin Hopping\nand its newly introduced population variant are almost as good as Covariance\nMatrix Adaptation on the synthetic benchmark functions and better than it on\nthe two hard cluster energy minimization problems. Thus, the proposed analyses\nshow that Basin Hopping can be considered a good candidate for global numerical\noptimization problems along with the more established metaheuristics,\nespecially if one wants to obtain quick and reliable results on an unknown\nproblem.\n","authors":["Marco Baioletti","Valentino Santucci","Marco Tomassini"],"pdf_url":"https://arxiv.org/pdf/2403.05877v1.pdf","comment":"32 pages, 7 figures"},{"id":"http://arxiv.org/abs/2403.05839v1","updated":"2024-03-09T08:49:50Z","published":"2024-03-09T08:49:50Z","title":"Long-term Frame-Event Visual Tracking: Benchmark Dataset and Baseline","summary":"  Current event-/frame-event based trackers undergo evaluation on short-term\ntracking datasets, however, the tracking of real-world scenarios involves\nlong-term tracking, and the performance of existing tracking algorithms in\nthese scenarios remains unclear. In this paper, we first propose a new\nlong-term and large-scale frame-event single object tracking dataset, termed\nFELT. It contains 742 videos and 1,594,474 RGB frames and event stream pairs\nand has become the largest frame-event tracking dataset to date. We re-train\nand evaluate 15 baseline trackers on our dataset for future works to compare.\nMore importantly, we find that the RGB frames and event streams are naturally\nincomplete due to the influence of challenging factors and spatially sparse\nevent flow. In response to this, we propose a novel associative memory\nTransformer network as a unified backbone by introducing modern Hopfield layers\ninto multi-head self-attention blocks to fuse both RGB and event data.\nExtensive experiments on both FELT and RGB-T tracking dataset LasHeR fully\nvalidated the effectiveness of our model. The dataset and source code can be\nfound at \\url{https://github.com/Event-AHU/FELT_SOT_Benchmark}.\n","authors":["Xiao Wang","Ju Huang","Shiao Wang","Chuanming Tang","Bo Jiang","Yonghong Tian","Jin Tang","Bin Luo"],"pdf_url":"https://arxiv.org/pdf/2403.05839v1.pdf","comment":"In Peer Review"},{"id":"http://arxiv.org/abs/2403.05772v1","updated":"2024-03-09T02:55:44Z","published":"2024-03-09T02:55:44Z","title":"sVAD: A Robust, Low-Power, and Light-Weight Voice Activity Detection\n  with Spiking Neural Networks","summary":"  Speech applications are expected to be low-power and robust under noisy\nconditions. An effective Voice Activity Detection (VAD) front-end lowers the\ncomputational need. Spiking Neural Networks (SNNs) are known to be biologically\nplausible and power-efficient. However, SNN-based VADs have yet to achieve\nnoise robustness and often require large models for high performance. This\npaper introduces a novel SNN-based VAD model, referred to as sVAD, which\nfeatures an auditory encoder with an SNN-based attention mechanism.\nParticularly, it provides effective auditory feature representation through\nSincNet and 1D convolution, and improves noise robustness with attention\nmechanisms. The classifier utilizes Spiking Recurrent Neural Networks (sRNN) to\nexploit temporal speech information. Experimental results demonstrate that our\nsVAD achieves remarkable noise robustness and meanwhile maintains low power\nconsumption and a small footprint, making it a promising solution for\nreal-world VAD applications.\n","authors":["Qu Yang","Qianhui Liu","Nan Li","Meng Ge","Zeyang Song","Haizhou Li"],"pdf_url":"https://arxiv.org/pdf/2403.05772v1.pdf","comment":"Accepted by ICASSP 2024"}]},"2024-03-08T00:00:00Z":{"Computer Science and Game Theory":[{"id":"http://arxiv.org/abs/2402.18781v3","updated":"2024-03-08T21:36:48Z","published":"2024-02-29T01:07:29Z","title":"Conjectural Online Learning with First-order Beliefs in Asymmetric\n  Information Stochastic Games","summary":"  Asymmetric information stochastic games (\\textsc{aisg}s) arise in many\ncomplex socio-technical systems, such as cyber-physical systems and IT\ninfrastructures. Existing computational methods for \\textsc{aisg}s are\nprimarily offline and can not adapt to equilibrium deviations. Further, current\nmethods are limited to special classes of \\textsc{aisg}s to avoid belief\nhierarchies. To address these limitations, we propose conjectural online\nlearning (\\textsc{col}), an online method for generic \\textsc{aisg}s.\n\\textsc{col} uses a forecaster-actor-critic (\\textsc{fac}) architecture where\nsubjective forecasts are used to conjecture the opponents' strategies within a\nlookahead horizon, and Bayesian learning is used to calibrate the conjectures.\nTo adapt strategies to nonstationary environments, \\textsc{col} uses online\nrollout with cost function approximation (actor-critic). We prove that the\nconjectures produced by \\textsc{col} are asymptotically consistent with the\ninformation feedback in the sense of a relaxed Bayesian consistency. We also\nprove that the empirical strategy profile induced by \\textsc{col} converges to\nthe Berk-Nash equilibrium, a solution concept characterizing rationality under\nsubjectivity. Experimental results from an intrusion response use case\ndemonstrate \\textsc{col}'s superiority over state-of-the-art reinforcement\nlearning methods against nonstationary attacks.\n","authors":["Tao Li","Kim Hammar","Rolf Stadler","Quanyan Zhu"],"pdf_url":"https://arxiv.org/pdf/2402.18781v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.16422v2","updated":"2024-03-08T21:01:08Z","published":"2024-01-29T18:59:22Z","title":"Strategic Usage in a Multi-Learner Setting","summary":"  Real-world systems often involve some pool of users choosing between a set of\nservices. With the increase in popularity of online learning algorithms, these\nservices can now self-optimize, leveraging data collected on users to maximize\nsome reward such as service quality. On the flipside, users may strategically\nchoose which services to use in order to pursue their own reward functions, in\nthe process wielding power over which services can see and use their data.\nExtensive prior research has been conducted on the effects of strategic users\nin single-service settings, with strategic behavior manifesting in the\nmanipulation of observable features to achieve a desired classification;\nhowever, this can often be costly or unattainable for users and fails to\ncapture the full behavior of multi-service dynamic systems. As such, we analyze\na setting in which strategic users choose among several available services in\norder to pursue positive classifications, while services seek to minimize loss\nfunctions on their observations. We focus our analysis on realizable settings,\nand show that naive retraining can still lead to oscillation even if all users\nare observed at different times; however, if this retraining uses memory of\npast observations, convergent behavior can be guaranteed for certain loss\nfunction classes. We provide results obtained from synthetic and real-world\ndata to empirically validate our theoretical findings.\n","authors":["Eliot Shekhtman","Sarah Dean"],"pdf_url":"https://arxiv.org/pdf/2401.16422v2.pdf","comment":"18 pages, 9 figures"},{"id":"http://arxiv.org/abs/1807.05477v2","updated":"2024-03-08T18:39:58Z","published":"2018-07-15T02:19:33Z","title":"Linear Programming Based Near-Optimal Pricing for Laminar Bayesian\n  Online Selection","summary":"  The Bayesian online selection problem aims to design a pricing scheme for a\nsequence of arriving buyers that maximizes the expected social welfare (or\nrevenue) subject to different structural constraints. Inspired by applications\nwith a hierarchy of service, this paper focuses on the cases where a laminar\nmatroid characterizes the set of served buyers. We give the first\nPolynomial-Time Approximation Scheme (PTAS) for the problem when the laminar\nmatroid has constant depth. Our approach is based on rounding the solution of a\nhierarchy of linear programming relaxations that approximate the optimum online\nsolution with any degree of accuracy, plus a concentration argument showing\nthat rounding incurs a small loss. We also study another variation, which we\ncall the production-constrained problem. The allowable set of served buyers is\ncharacterized by a collection of production and shipping constraints that form\na particular example of a laminar matroid. Using a similar LP-based approach,\nwe design a PTAS for this problem, although in this special case the depth of\nthe underlying laminar matroid is not necessarily a constant. The analysis\nexploits the negative dependency of the optimum selection rule in the lower\nlevels of the laminar family. Finally, to demonstrate the generality of our\ntechnique, we employ the linear programming-based approach employed in the\npaper to re-derive some of the classic prophet inequalities known in the\nliterature -- as a side result.\n","authors":["Nima Anari","Rad Niazadeh","Amin Saberi","Ali Shameli"],"pdf_url":"https://arxiv.org/pdf/1807.05477v2.pdf","comment":"conference version of this paper appeared as one-page abstract in ACM\n  EC 2019"},{"id":"http://arxiv.org/abs/2401.12321v2","updated":"2024-03-08T18:21:26Z","published":"2024-01-22T19:28:34Z","title":"The outcomes of generative AI are exactly the Nash equilibria of a\n  non-potential game","summary":"  In this article we show that the asymptotic outcomes of both shallow and deep\nneural networks such as those used in BloombergGPT to generate economic time\nseries are exactly the Nash equilibria of a non-potential game. We then design\nand analyze deep neural network algorithms that converge to these equilibria.\nThe methodology is extended to federated deep neural networks between clusters\nof regional servers and on-device clients. Finally, the variational\ninequalities behind large language models including encoder-decoder related\ntransformers are established.\n","authors":["Boualem Djehiche","Hamidou Tembine"],"pdf_url":"https://arxiv.org/pdf/2401.12321v2.pdf","comment":"Updated version 1. 24 pages. Accepted and to appear in: International\n  Econometric Conference of Vietnam"},{"id":"http://arxiv.org/abs/2302.08434v3","updated":"2024-03-08T18:01:00Z","published":"2023-02-16T17:18:03Z","title":"On marginal feature attributions of tree-based models","summary":"  Due to their power and ease of use, tree-based machine learning models, such\nas random forests and gradient-boosted tree ensembles, have become very\npopular. To interpret them, local feature attributions based on marginal\nexpectations, e.g. marginal (interventional) Shapley, Owen or Banzhaf values,\nmay be employed. Such methods are true to the model and implementation\ninvariant, i.e. dependent only on the input-output function of the model. We\ncontrast this with the popular TreeSHAP algorithm by presenting two\n(statistically similar) decision trees that compute the exact same function for\nwhich the \"path-dependent\" TreeSHAP yields different rankings of features,\nwhereas the marginal Shapley values coincide. Furthermore, we discuss how the\ninternal structure of tree-based models may be leveraged to help with computing\ntheir marginal feature attributions according to a linear game value. One\nimportant observation is that these are simple (piecewise-constant) functions\nwith respect to a certain grid partition of the input space determined by the\ntrained model. Another crucial observation, showcased by experiments with\nXGBoost, LightGBM and CatBoost libraries, is that only a portion of all\nfeatures appears in a tree from the ensemble. Thus, the complexity of computing\nmarginal Shapley (or Owen or Banzhaf) feature attributions may be reduced. This\nremains valid for a broader class of game values which we shall axiomatically\ncharacterize. A prime example is the case of CatBoost models where the trees\nare oblivious (symmetric) and the number of features in each of them is no\nlarger than the depth. We exploit the symmetry to derive an explicit formula,\nwith improved complexity and only in terms of the internal model parameters,\nfor marginal Shapley (and Banzhaf and Owen) values of CatBoost models. This\nresults in a fast, accurate algorithm for estimating these feature\nattributions.\n","authors":["Khashayar Filom","Alexey Miroshnikov","Konstandinos Kotsiopoulos","Arjun Ravi Kannan"],"pdf_url":"https://arxiv.org/pdf/2302.08434v3.pdf","comment":"Typos corrected. Section 4 is reorganized and new experiments on Owen\n  values are added. Minor changes in the Introduction. 30 pages+appendix (64\n  pages in total), 10 figures"},{"id":"http://arxiv.org/abs/2403.05378v1","updated":"2024-03-08T15:11:22Z","published":"2024-03-08T15:11:22Z","title":"Online Contention Resolution Schemes for Network Revenue Management and\n  Combinatorial Auctions","summary":"  In the Network Revenue Management (NRM) problem, products composed of up to L\nresources are sold to stochastically arriving customers. We take a randomized\nrounding approach to NRM, motivated by developments in Online Contention\nResolution Schemes (OCRS). The goal is to take a fractional solution to NRM\nthat satisfies the resource constraints in expectation, and implement it in an\nonline policy that satisfies the resource constraints in any state, while\n(approximately) preserving all of the sales that were prescribed by the\nfractional solution.\n  OCRS cannot be naively applied to NRM or revenue management problems in\ngeneral, because customer substitution induces a negative correlation in\nproducts being demanded. We start by deriving an OCRS that achieves a guarantee\nof 1/(1+L) for NRM with customer substitution, matching a common benchmark in\nthe literature. We then show how to beat this benchmark for all integers L>1\nassuming no substitution, i.e., in the standard OCRS setting. By contrast, we\nshow that this benchmark is unbeatable using OCRS or any fractional relaxation\nif there is customer substitution, for all integers L that are the power of a\nprime number. Finally, we show how to beat 1/(1+L) even with customer\nsubstitution, if the products comprise one item from each of up to L groups.\n  Our results have corresponding implications for Online Combinatorial\nAuctions, in which buyers bid for bundles of up to L items, and buyers being\nsingle-minded is akin to no substitution. Our final result also beats 1/(1+L)\nfor Prophet Inequality on the intersection of L partition matroids. All in all,\nour paper provides a unifying framework for applying OCRS to these problems,\ndelineating the impact of substitution, and establishing a separation between\nthe guarantees achievable with vs. without substitution under general resource\nconstraints parametrized by L.\n","authors":["Will Ma","Calum MacRury","Jingwei Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.05378v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.05273v1","updated":"2024-03-08T12:52:11Z","published":"2024-03-08T12:52:11Z","title":"Elections in the Post-Quantum Era: Is the Complexity Shield Strong\n  Enough?","summary":"  The election, a cornerstone of democracy, is one of the best-recognizable\nsymbols of democratic governance. Voters' confidence in elections is essential,\nand these days, we can watch practically in live broadcast what consequences\ndistrust in the fairness of elections may have. From the times of the\ncelebrated Gibbard-Satterthwaite theorem, it is well-known in the social-choice\ncommunity that most voting systems are vulnerable to the efforts of various\nplayers to influence elections. Luckily for us, computing such influence to\naffect election outcomes is a hard problem from the computational complexity\nperspective. This intractability is regarded as a ``complexity shield'' that\nsecures voting rules against this malicious behavior.\n  In this work, we consider quantum computers to be a new threat to the\ncomplexity shield described above, as they break out of standard computing\nparadigms and unlock additional computational resources. To this end, we\nprovide an overview of possible attacks on election, discuss the abilities of\nquantum computing, and chart possible directions for future research in this\narea.\n","authors":["Šimon Schierreich"],"pdf_url":"https://arxiv.org/pdf/2403.05273v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.16532v3","updated":"2024-03-08T07:12:39Z","published":"2024-02-26T12:26:54Z","title":"Fast, Fair and Truthful Distributed Stable Matching for Common\n  Preferences","summary":"  Stable matching is a fundamental problem studied both in economics and\ncomputer science. The task is to find a matching between two sides of agents\nthat have preferences over who they want to be matched with. A matching is\nstable if no pair of agents prefer each other over their current matches. The\ndeferred acceptance algorithm of Gale and Shapley solves this problem in\npolynomial time. Further, it is a mechanism: the proposing side in the\nalgorithm is always incentivised to report their preferences truthfully. The\ndeferred acceptance algorithm has a natural interpretation as a distributed\nalgorithm (and thus a distributed mechanism). However, the algorithm is slow in\nthe worst case and it is known that the stable matching problem cannot be\nsolved efficiently in the distributed setting. In this work we study a natural\nspecial case of the stable matching problem where all agents on one side share\ncommon preferences. We show that in this case the deferred acceptance algorithm\ndoes yield a fast and truthful distributed mechanism for finding a stable\nmatching. We show how algorithms for sampling random colorings can be used to\nbreak ties fairly and extend the results to fractional stable matching.\n","authors":["Juho Hirvonen","Sara Ranjbaran"],"pdf_url":"https://arxiv.org/pdf/2402.16532v3.pdf","comment":"16 pages"},{"id":"http://arxiv.org/abs/2403.05108v1","updated":"2024-03-08T07:10:46Z","published":"2024-03-08T07:10:46Z","title":"A Task-Driven Multi-UAV Coalition Formation Mechanism","summary":"  With the rapid advancement of UAV technology, the problem of UAV coalition\nformation has become a hotspot. Therefore, designing task-driven multi-UAV\ncoalition formation mechanism has become a challenging problem. However,\nexisting coalition formation mechanisms suffer from low relevance between UAVs\nand task requirements, resulting in overall low coalition utility and unstable\ncoalition structures. To address these problems, this paper proposed a novel\nmulti-UAV coalition network collaborative task completion model, considering\nboth coalition work capacity and task-requirement relationships. This model\nstimulated the formation of coalitions that match task requirements by using a\nrevenue function based on the coalition's revenue threshold. Subsequently, an\nalgorithm for coalition formation based on marginal utility was proposed.\nSpecifically, the algorithm utilized Shapley value to achieve fair utility\ndistribution within the coalition, evaluated coalition values based on marginal\nutility preference order, and achieved stable coalition partition through a\nlimited number of iterations. Additionally, we theoretically proved that this\nalgorithm has Nash equilibrium solution. Finally, experimental results\ndemonstrated that the proposed algorithm, compared to currently classical\nalgorithms, not only forms more stable coalitions but also further enhances the\noverall utility of coalitions effectively.\n","authors":["Xinpeng Lu","Heng Song","Huailing Ma","Junwu Zhu"],"pdf_url":"https://arxiv.org/pdf/2403.05108v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.05103v1","updated":"2024-03-08T07:07:47Z","published":"2024-03-08T07:07:47Z","title":"Safe Pareto Improvements for Expected Utility Maximizers in Program\n  Games","summary":"  Agents in mixed-motive coordination problems such as Chicken may fail to\ncoordinate on a Pareto-efficient outcome. Safe Pareto improvements (SPIs) were\noriginally proposed to mitigate miscoordination in cases where players lack\nprobabilistic beliefs as to how their delegates will play a game; delegates are\ninstructed to behave so as to guarantee a Pareto improvement on how they would\nplay by default. More generally, SPIs may be defined as transformations of\nstrategy profiles such that all players are necessarily better off under the\ntransformed profile. In this work, we investigate the extent to which SPIs can\nreduce downsides of miscoordination between expected utility-maximizing agents.\nWe consider games in which players submit computer programs that can condition\ntheir decisions on each other's code, and use this property to construct SPIs\nusing programs capable of renegotiation. We first show that under mild\nconditions on players' beliefs, each player always prefers to use\nrenegotiation. Next, we show that under similar assumptions, each player always\nprefers to be willing to renegotiate at least to the point at which they\nreceive the lowest payoff they can attain in any efficient outcome. Thus\nsubjectively optimal play guarantees players at least these payoffs, without\nthe need for coordination on specific Pareto improvements. Lastly, we prove\nthat renegotiation does not guarantee players any improvements on this bound.\n","authors":["Anthony DiGiovanni","Jesse Clifton"],"pdf_url":"https://arxiv.org/pdf/2403.05103v1.pdf","comment":"19 pages, 4 figures"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2402.12263v2","updated":"2024-03-08T21:16:13Z","published":"2024-02-19T16:24:20Z","title":"Towards a tailored mixed-precision sub-8-bit quantization scheme for\n  Gated Recurrent Units using Genetic Algorithms","summary":"  Despite the recent advances in model compression techniques for deep neural\nnetworks, deploying such models on ultra-low-power embedded devices still\nproves challenging. In particular, quantization schemes for Gated Recurrent\nUnits (GRU) are difficult to tune due to their dependence on an internal state,\npreventing them from fully benefiting from sub-8bit quantization. In this work,\nwe propose a modular integer quantization scheme for GRUs where the bit width\nof each operator can be selected independently. We then employ Genetic\nAlgorithms (GA) to explore the vast search space of possible bit widths,\nsimultaneously optimising for model size and accuracy. We evaluate our methods\non four different sequential tasks and demonstrate that mixed-precision\nsolutions exceed homogeneous-precision ones in terms of Pareto efficiency. In\nour results, we achieve a model size reduction between 25% and 55% while\nmaintaining an accuracy comparable with the 8-bit homogeneous equivalent.\n","authors":["Riccardo Miccini","Alessandro Cerioli","Clément Laroche","Tobias Piechowiak","Jens Sparsø","Luca Pezzarossa"],"pdf_url":"https://arxiv.org/pdf/2402.12263v2.pdf","comment":"Accepted as a full paper by the tinyML Research Symposium 2024"},{"id":"http://arxiv.org/abs/2403.01192v2","updated":"2024-03-08T15:18:19Z","published":"2024-03-02T12:12:04Z","title":"A Composite Decomposition Method for Large-Scale Global Optimization","summary":"  Cooperative co-evolution (CC) algorithms, based on the divide-and-conquer\nstrategy, have emerged as the predominant approach to solving large-scale\nglobal optimization (LSGO) problems. The efficiency and accuracy of the\ngrouping stage significantly impact the performance of the optimization\nprocess. While the general separability grouping (GSG) method has overcome the\nlimitation of previous differential grouping (DG) methods by enabling the\ndecomposition of non-additively separable functions, it suffers from high\ncomputational complexity. To address this challenge, this article proposes a\ncomposite separability grouping (CSG) method, seamlessly integrating DG and GSG\ninto a problem decomposition framework to utilize the strengths of both\napproaches. CSG introduces a step-by-step decomposition framework that\naccurately decomposes various problem types using fewer computational\nresources. By sequentially identifying additively, multiplicatively and\ngenerally separable variables, CSG progressively groups non-separable variables\nby recursively considering the interactions between each non-separable variable\nand the formed non-separable groups. Furthermore, to enhance the efficiency and\naccuracy of CSG, we introduce two innovative methods: a multiplicatively\nseparable variable detection method and a non-separable variable grouping\nmethod. These two methods are designed to effectively detect multiplicatively\nseparable variables and efficiently group non-separable variables,\nrespectively. Extensive experimental results demonstrate that CSG achieves more\naccurate variable grouping with lower computational complexity compared to GSG\nand state-of-the-art DG series designs.\n","authors":["Maojiang Tian","Minyang Chen","Wei Du","Yang Tang","Yaochu Jin","Gary G. Yen"],"pdf_url":"https://arxiv.org/pdf/2403.01192v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.17848v2","updated":"2024-03-08T11:05:17Z","published":"2024-02-27T19:28:18Z","title":"Looking for Complexity at Phase Boundaries in Continuous Cellular\n  Automata","summary":"  One key challenge in Artificial Life is designing systems that display an\nemergence of complex behaviors. Many such systems depend on a high-dimensional\nparameter space, only a small subset of which displays interesting dynamics.\nFocusing on the case of continuous systems, we introduce the 'Phase Transition\nFinder'(PTF) algorithm, which can be used to efficiently generate parameters\nlying at the border between two phases. We argue that such points are more\nlikely to display complex behaviors, and confirm this by applying PTF to Lenia\nshowing it can increase the frequency of interesting behaviors more than\ntwo-fold, while remaining efficient enough for large-scale searches.\n","authors":["Vassilis Papadopoulos","Guilhem Doat","Arthur Renard","Clément Hongler"],"pdf_url":"https://arxiv.org/pdf/2402.17848v2.pdf","comment":"5 pages"},{"id":"http://arxiv.org/abs/2403.05123v1","updated":"2024-03-08T07:36:46Z","published":"2024-03-08T07:36:46Z","title":"ECToNAS: Evolutionary Cross-Topology Neural Architecture Search","summary":"  We present ECToNAS, a cost-efficient evolutionary cross-topology neural\narchitecture search algorithm that does not require any pre-trained meta\ncontrollers. Our framework is able to select suitable network architectures for\ndifferent tasks and hyperparameter settings, independently performing\ncross-topology optimisation where required. It is a hybrid approach that fuses\ntraining and topology optimisation together into one lightweight,\nresource-friendly process. We demonstrate the validity and power of this\napproach with six standard data sets (CIFAR-10, CIFAR-100, EuroSAT, Fashion\nMNIST, MNIST, SVHN), showcasing the algorithm's ability to not only optimise\nthe topology within an architectural type, but also to dynamically add and\nremove convolutional cells when and where required, thus crossing boundaries\nbetween different network types. This enables researchers without a background\nin machine learning to make use of appropriate model types and topologies and\nto apply machine learning methods in their domains, with a computationally\ncheap, easy-to-use cross-topology neural architecture search framework that\nfully encapsulates the topology optimisation within the training process.\n","authors":["Elisabeth J. Schiessler","Roland C. Aydin","Christian J. Cyron"],"pdf_url":"https://arxiv.org/pdf/2403.05123v1.pdf","comment":"15 pages, 7 figures, 6 tables"},{"id":"http://arxiv.org/abs/2403.13833v1","updated":"2024-03-08T01:01:24Z","published":"2024-03-08T01:01:24Z","title":"Linearly Constrained Weights: Reducing Activation Shift for Faster\n  Training of Neural Networks","summary":"  In this paper, we first identify activation shift, a simple but remarkable\nphenomenon in a neural network in which the preactivation value of a neuron has\nnon-zero mean that depends on the angle between the weight vector of the neuron\nand the mean of the activation vector in the previous layer. We then propose\nlinearly constrained weights (LCW) to reduce the activation shift in both fully\nconnected and convolutional layers. The impact of reducing the activation shift\nin a neural network is studied from the perspective of how the variance of\nvariables in the network changes through layer operations in both forward and\nbackward chains. We also discuss its relationship to the vanishing gradient\nproblem. Experimental results show that LCW enables a deep feedforward network\nwith sigmoid activation functions to be trained efficiently by resolving the\nvanishing gradient problem. Moreover, combined with batch normalization, LCW\nimproves generalization performance of both feedforward and convolutional\nnetworks.\n","authors":["Takuro Kutsuna"],"pdf_url":"https://arxiv.org/pdf/2403.13833v1.pdf","comment":"19 pages"}]},"2024-03-07T00:00:00Z":{"Computer Science and Game Theory":[{"id":"http://arxiv.org/abs/2403.04910v1","updated":"2024-03-07T21:46:18Z","published":"2024-03-07T21:46:18Z","title":"Stochastic Games for Interactive Manipulation Domains","summary":"  As robots become more prevalent, the complexity of robot-robot, robot-human,\nand robot-environment interactions increases. In these interactions, a robot\nneeds to consider not only the effects of its own actions, but also the effects\nof other agents' actions and the possible interactions between agents. Previous\nworks have considered reactive synthesis, where the human/environment is\nmodeled as a deterministic, adversarial agent; as well as probabilistic\nsynthesis, where the human/environment is modeled via a Markov chain. While\nthey provide strong theoretical frameworks, there are still many aspects of\nhuman-robot interaction that cannot be fully expressed and many assumptions\nthat must be made in each model. In this work, we propose stochastic games as a\ngeneral model for human-robot interaction, which subsumes the expressivity of\nall previous representations. In addition, it allows us to make fewer modeling\nassumptions and leads to more natural and powerful models of interaction. We\nintroduce the semantics of this abstraction and show how existing tools can be\nutilized to synthesize strategies to achieve complex tasks with guarantees.\nFurther, we discuss the current computational limitations and improve the\nscalability by two orders of magnitude by a new way of constructing models for\nPRISM-games.\n","authors":["Karan Muvvala","Andrew M. Wells","Morteza Lahijanian","Lydia E. Kavraki","Moshe Y. Vardi"],"pdf_url":"https://arxiv.org/pdf/2403.04910v1.pdf","comment":"Accepted: ICRA 2024"},{"id":"http://arxiv.org/abs/2403.04856v1","updated":"2024-03-07T19:12:05Z","published":"2024-03-07T19:12:05Z","title":"Winner-Pays-Bid Auctions Minimize Variance","summary":"  Any social choice function (e.g the efficient allocation) can be implemented\nusing different payment rules: first price, second price, all-pay, etc. All of\nthese payment rules are guaranteed to have the same expected revenue by the\nrevenue equivalence theorem, but have different distributions of revenue,\nleading to a question of which one is best. We prove that among all possible\npayment rules, winner-pays-bid minimizes the variance in revenue and, in fact,\nminimizes any convex risk measure.\n","authors":["Preston McAfee","Renato Paes Leme","Balasubramanian Sivan","Sergei Vassilvitskii"],"pdf_url":"https://arxiv.org/pdf/2403.04856v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.04753v1","updated":"2024-03-07T18:54:59Z","published":"2024-03-07T18:54:59Z","title":"Mechanism for Decision-aware Collaborative Federated Learning: A Pitfall\n  of Shapley Values","summary":"  This paper investigates mechanism design for decision-aware collaboration via\nfederated learning (FL) platforms. Our framework consists of a digital platform\nand multiple decision-aware agents, each endowed with proprietary data sets.\nThe platform offers an infrastructure that enables access to the data, creates\nincentives for collaborative learning aimed at operational decision-making, and\nconducts FL to avoid direct raw data sharing. The computation and communication\nefficiency of the FL process is inherently influenced by the agent\nparticipation equilibrium induced by the mechanism. Therefore, assessing the\nsystem's efficiency involves two critical factors: the surplus created by\ncoalition formation and the communication costs incurred across the coalition\nduring FL. To evaluate the system efficiency under the intricate interplay\nbetween mechanism design, agent participation, operational decision-making, and\nthe performance of FL algorithms, we introduce a multi-action collaborative\nfederated learning (MCFL) framework for decision-aware agents. Under this\nframework, we further analyze the equilibrium for the renowned Shapley value\nbased mechanisms. Specifically, we examine the issue of false-name\nmanipulation, a form of dishonest behavior where participating agents create\nduplicate fake identities to split their original data among these identities.\nBy solving the agent participation equilibrium, we demonstrate that while\nShapley value effectively maximizes coalition-generated surplus by encouraging\nfull participation, it inadvertently promotes false-name manipulation. This\nfurther significantly increases the communication costs when the platform\nconducts FL. Thus, we highlight a significant pitfall of Shapley value based\nmechanisms, which implicitly incentivizes data splitting and identity\nduplication, ultimately impairing the overall efficiency in FL systems.\n","authors":["Meng Qi","Mingxi Zhu"],"pdf_url":"https://arxiv.org/pdf/2403.04753v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.04680v1","updated":"2024-03-07T17:24:50Z","published":"2024-03-07T17:24:50Z","title":"Extensive-Form Game Solving via Blackwell Approachability on Treeplexes","summary":"  In this paper, we introduce the first algorithmic framework for Blackwell\napproachability on the sequence-form polytope, the class of convex polytopes\ncapturing the strategies of players in extensive-form games (EFGs). This leads\nto a new class of regret-minimization algorithms that are stepsize-invariant,\nin the same sense as the Regret Matching and Regret Matching$^+$ algorithms for\nthe simplex. Our modular framework can be combined with any existing regret\nminimizer over cones to compute a Nash equilibrium in two-player zero-sum EFGs\nwith perfect recall, through the self-play framework. Leveraging predictive\nonline mirror descent, we introduce Predictive Treeplex Blackwell$^+$\n(PTB$^+$), and show a $O(1/\\sqrt{T})$ convergence rate to Nash equilibrium in\nself-play. We then show how to stabilize PTB$^+$ with a stepsize, resulting in\nan algorithm with a state-of-the-art $O(1/T)$ convergence rate. We provide an\nextensive set of experiments to compare our framework with several algorithmic\nbenchmarks, including CFR$^+$ and its predictive variant, and we highlight\ninteresting connections between practical performance and the\nstepsize-dependence or stepsize-invariance properties of classical algorithms.\n","authors":["Darshan Chakrabarti","Julien Grand-Clément","Christian Kroer"],"pdf_url":"https://arxiv.org/pdf/2403.04680v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.17435v3","updated":"2024-03-07T16:47:00Z","published":"2024-01-30T20:49:47Z","title":"Can Large Language Models Replace Economic Choice Prediction Labs?","summary":"  Economic choice prediction is an essential challenging task, often\nconstrained by the difficulties in acquiring human choice data. Indeed,\nexperimental economics studies had focused mostly on simple choice settings.\nThe AI community has recently contributed to that effort in two ways:\nconsidering whether LLMs can substitute for humans in the above-mentioned\nsimple choice prediction settings, and the study through ML lens of more\nelaborated but still rigorous experimental economics settings, employing\nincomplete information, repetitive play, and natural language communication,\nnotably language-based persuasion games. This leaves us with a major\ninspiration: can LLMs be used to fully simulate the economic environment and\ngenerate data for efficient human choice prediction, substituting for the\nelaborated economic lab studies? We pioneer the study of this subject,\ndemonstrating its feasibility. In particular, we show that a model trained\nsolely on LLM-generated data can effectively predict human behavior in a\nlanguage-based persuasion game, and can even outperform models trained on\nactual human data.\n","authors":["Eilam Shapira","Omer Madmon","Roi Reichart","Moshe Tennenholtz"],"pdf_url":"https://arxiv.org/pdf/2401.17435v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.04616v1","updated":"2024-03-07T16:01:08Z","published":"2024-03-07T16:01:08Z","title":"Modeling reputation-based behavioral biases in school choice","summary":"  A fundamental component in the theoretical school choice literature is the\nproblem a student faces in deciding which schools to apply to. Recent models\nhave considered a set of schools of different selectiveness and a student who\nis unsure of their strength and can apply to at most $k$ schools. Such models\nassume that the student cares solely about maximizing the quality of the school\nthat they attend, but experience suggests that students' decisions are also\ninfluenced by a set of behavioral biases based on reputational effects: a\nsubjective reputational benefit when admitted to a selective school, whether or\nnot they attend; and a subjective loss based on disappointment when rejected.\nGuided by these observations, and inspired by recent behavioral economics work\non loss aversion relative to expectations, we propose a behavioral model by\nwhich a student chooses schools to balance these behavioral effects with the\nquality of the school they attend.\n  Our main results show that a student's choices change in dramatic ways when\nthese reputation-based behavioral biases are taken into account. In particular,\nwhere a rational applicant spreads their applications evenly, a biased student\napplies very sparsely to highly selective schools, such that above a certain\nthreshold they apply to only an absolute constant number of schools even as\ntheir budget of applications grows to infinity. Consequently, a biased student\nunderperforms a rational student even when the rational student is restricted\nto a sufficiently large upper bound on applications and the biased student can\napply to arbitrarily many. Our analysis shows that the reputation-based model\nis rich enough to cover a range of different ways that biased students cope\nwith fear of rejection, including not just targeting less selective schools,\nbut also occasionally applying to schools that are too selective, compared to\nrational students.\n","authors":["Jon Kleinberg","Sigal Oren","Emily Ryu","Éva Tardos"],"pdf_url":"https://arxiv.org/pdf/2403.04616v1.pdf","comment":"22 pages, 8 figures"},{"id":"http://arxiv.org/abs/2403.04530v1","updated":"2024-03-07T14:28:28Z","published":"2024-03-07T14:28:28Z","title":"Multi-District School Choice: Playing on Several Fields","summary":"  We extend the seminal model of Pathak and S\\\"onmez (2008) to a setting with\nmultiple school districts, each running its own separate centralized match, and\nfocus on the case of two districts. In our setting, in addition to each student\nbeing either sincere or sophisticated, she is also either constrained - able to\napply only to schools within her own district of residence - or unconstrained -\nable to choose any single district within which to apply. We show that several\nkey results from Pathak and S\\\"onmez (2008) qualitatively flip: A sophisticated\nstudent may prefer for a sincere student to become sophisticated, and a\nsophisticated student may prefer for her own district to use Deferred\nAcceptance over the Boston Mechanism, irrespective of the mechanism used by the\nother district. We furthermore investigate the preferences of students over the\nconstraint levels of other students. Many of these phenomena appear abundantly\nin large random markets.\n","authors":["Yannai A. Gonczarowski","Michael Yin","Shirley Zhang"],"pdf_url":"https://arxiv.org/pdf/2403.04530v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.03618v2","updated":"2024-03-07T09:27:31Z","published":"2023-12-06T17:04:08Z","title":"Beyond discounted returns: Robust Markov decision processes with average\n  and Blackwell optimality","summary":"  Robust Markov Decision Processes (RMDPs) are a widely used framework for\nsequential decision-making under parameter uncertainty. RMDPs have been\nextensively studied when the objective is to maximize the discounted return,\nbut little is known for average optimality (optimizing the long-run average of\nthe rewards obtained over time) and Blackwell optimality (remaining discount\noptimal for all discount factors sufficiently close to 1). In this paper, we\nprove several foundational results for RMDPs beyond the discounted return. We\nshow that average optimal policies can be chosen stationary and deterministic\nfor sa-rectangular RMDPs but, perhaps surprisingly, that history-dependent\n(Markovian) policies strictly outperform stationary policies for average\noptimality in s-rectangular RMDPs. We also study Blackwell optimality for\nsa-rectangular RMDPs, where we show that {\\em approximate} Blackwell optimal\npolicies always exist, although Blackwell optimal policies may not exist. We\nalso provide a sufficient condition for their existence, which encompasses\nvirtually any examples from the literature. We then discuss the connection\nbetween average and Blackwell optimality, and we describe several algorithms to\ncompute the optimal average return. Interestingly, our approach leverages the\nconnections between RMDPs and stochastic games.\n","authors":["Julien Grand-Clement","Marek Petrik","Nicolas Vieille"],"pdf_url":"https://arxiv.org/pdf/2312.03618v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.04344v1","updated":"2024-03-07T09:12:23Z","published":"2024-03-07T09:12:23Z","title":"RL-CFR: Improving Action Abstraction for Imperfect Information\n  Extensive-Form Games with Reinforcement Learning","summary":"  Effective action abstraction is crucial in tackling challenges associated\nwith large action spaces in Imperfect Information Extensive-Form Games\n(IIEFGs). However, due to the vast state space and computational complexity in\nIIEFGs, existing methods often rely on fixed abstractions, resulting in\nsub-optimal performance. In response, we introduce RL-CFR, a novel\nreinforcement learning (RL) approach for dynamic action abstraction. RL-CFR\nbuilds upon our innovative Markov Decision Process (MDP) formulation, with\nstates corresponding to public information and actions represented as feature\nvectors indicating specific action abstractions. The reward is defined as the\nexpected payoff difference between the selected and default action\nabstractions. RL-CFR constructs a game tree with RL-guided action abstractions\nand utilizes counterfactual regret minimization (CFR) for strategy derivation.\nImpressively, it can be trained from scratch, achieving higher expected payoff\nwithout increased CFR solving time. In experiments on Heads-up No-limit Texas\nHold'em, RL-CFR outperforms ReBeL's replication and Slumbot, demonstrating\nsignificant win-rate margins of $64\\pm 11$ and $84\\pm 17$ mbb/hand,\nrespectively.\n","authors":["Boning Li","Zhixuan Fang","Longbo Huang"],"pdf_url":"https://arxiv.org/pdf/2403.04344v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.04265v1","updated":"2024-03-07T06:57:20Z","published":"2024-03-07T06:57:20Z","title":"Conflict and Fairness in Resource Allocation","summary":"  In the standard model of fair allocation of resources to agents, every agent\nhas some utility for every resource, and the goal is to assign resources to\nagents so that the agents' welfare is maximized. Motivated by job scheduling,\ninterest in this problem dates back to the work of Deuermeyer et al. [SIAM J.\non Algebraic Discrete Methods'82]. Recent works consider the compatibility\nbetween resources and assign only mutually compatible resources to an agent. We\nstudy a fair allocation problem in which we are given a set of agents, a set of\nresources, a utility function for every agent over a set of resources, and a\n{\\it conflict graph} on the set of resources (where an edge denotes\nincompatibility). The goal is to assign resources to the agents such that $(i)$\nthe set of resources allocated to an agent are compatible with each other, and\n$(ii)$ the minimum satisfaction of an agent is maximized, where the\nsatisfaction of an agent is the sum of the utility of the assigned resources.\nChiarelli et al. [Algorithmica'22] explore this problem from the classical\ncomplexity perspective to draw the boundary between the cases that are\npolynomial-time solvable and those that are \\NP-hard. In this article, we study\nthe parameterized complexity of the problem (and its variants) by considering\nseveral natural and structural parameters.\n","authors":["Susobhan Bandopadhyay","Aritra Banik","Sushmita Gupta","Pallavi Jain","Abhishek Sahu","Saket Saurabh","Prafullkumar Tale"],"pdf_url":"https://arxiv.org/pdf/2403.04265v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2309.04995"},{"id":"http://arxiv.org/abs/2207.04192v3","updated":"2024-03-07T00:48:43Z","published":"2022-07-09T04:32:44Z","title":"Efficient Stackelberg Strategies for Finitely Repeated Games","summary":"  We study Stackelberg equilibria in finitely repeated games, where the leader\ncommits to a strategy that picks actions in each round and can be adaptive to\nthe history of play (i.e. they commit to an algorithm). In particular, we study\nstatic repeated games with no discounting. We give efficient algorithms for\nfinding approximate Stackelberg equilibria in this setting, along with rates of\nconvergence depending on the time horizon $T$. In many cases, these algorithms\nallow the leader to do much better on average than they can in the single-round\nStackelberg. We give two algorithms, one computing strategies with an optimal\n$\\frac{1}{T}$ rate at the expense of an exponential dependence on the number of\nactions, and another (randomized) approach computing strategies with no\ndependence on the number of actions but a worse dependence on $T$ of\n$\\frac{1}{T^{0.25}}$. Both algorithms build upon a linear program to produce\nsimple automata leader strategies and induce corresponding automata\nbest-responses for the follower. We complement these results by showing that\napproximating the Stackelberg value in three-player finite-horizon repeated\ngames is a computationally hard problem via a reduction from balanced vertex\ncover.\n","authors":["Natalie Collina","Eshwar Ram Arunachaleswaran","Michael Kearns"],"pdf_url":"https://arxiv.org/pdf/2207.04192v3.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2403.04929v1","updated":"2024-03-07T22:35:22Z","published":"2024-03-07T22:35:22Z","title":"On the Markov Property of Neural Algorithmic Reasoning: Analyses and\n  Methods","summary":"  Neural algorithmic reasoning is an emerging research direction that endows\nneural networks with the ability to mimic algorithmic executions step-by-step.\nA common paradigm in existing designs involves the use of historical embeddings\nin predicting the results of future execution steps. Our observation in this\nwork is that such historical dependence intrinsically contradicts the Markov\nnature of algorithmic reasoning tasks. Based on this motivation, we present our\nForgetNet, which does not use historical embeddings and thus is consistent with\nthe Markov nature of the tasks. To address challenges in training ForgetNet at\nearly stages, we further introduce G-ForgetNet, which uses a gating mechanism\nto allow for the selective integration of historical embeddings. Such an\nenhanced capability provides valuable computational pathways during the model's\nearly training phase. Our extensive experiments, based on the CLRS-30\nalgorithmic reasoning benchmark, demonstrate that both ForgetNet and\nG-ForgetNet achieve better generalization capability than existing methods.\nFurthermore, we investigate the behavior of the gating mechanism, highlighting\nits degree of alignment with our intuitions and its effectiveness for robust\nperformance.\n","authors":["Montgomery Bohde","Meng Liu","Alexandra Saxton","Shuiwang Ji"],"pdf_url":"https://arxiv.org/pdf/2403.04929v1.pdf","comment":"To appear at ICLR 2024 (Spotlight paper). 17 pages, 10 figures"},{"id":"http://arxiv.org/abs/2403.04759v1","updated":"2024-03-07T18:56:33Z","published":"2024-03-07T18:56:33Z","title":"Lifelong Intelligence Beyond the Edge using Hyperdimensional Computing","summary":"  On-device learning has emerged as a prevailing trend that avoids the slow\nresponse time and costly communication of cloud-based learning. The ability to\nlearn continuously and indefinitely in a changing environment, and with\nresource constraints, is critical for real sensor deployments. However,\nexisting designs are inadequate for practical scenarios with (i) streaming data\ninput, (ii) lack of supervision and (iii) limited on-board resources. In this\npaper, we design and deploy the first on-device lifelong learning system called\nLifeHD for general IoT applications with limited supervision. LifeHD is\ndesigned based on a novel neurally-inspired and lightweight learning paradigm\ncalled Hyperdimensional Computing (HDC). We utilize a two-tier associative\nmemory organization to intelligently store and manage high-dimensional,\nlow-precision vectors, which represent the historical patterns as cluster\ncentroids. We additionally propose two variants of LifeHD to cope with scarce\nlabeled inputs and power constraints. We implement LifeHD on off-the-shelf edge\nplatforms and perform extensive evaluations across three scenarios. Our\nmeasurements show that LifeHD improves the unsupervised clustering accuracy by\nup to 74.8% compared to the state-of-the-art NN-based unsupervised lifelong\nlearning baselines with as much as 34.3x better energy efficiency. Our code is\navailable at https://github.com/Orienfish/LifeHD.\n","authors":["Xiaofan Yu","Anthony Thomas","Ivannia Gomez Moreno","Louis Gutierrez","Tajana Rosing"],"pdf_url":"https://arxiv.org/pdf/2403.04759v1.pdf","comment":"Accepted by IPSN'24"},{"id":"http://arxiv.org/abs/2403.02131v3","updated":"2024-03-07T09:42:47Z","published":"2024-03-04T15:40:28Z","title":"Deep Reinforcement Learning for Dynamic Algorithm Selection: A\n  Proof-of-Principle Study on Differential Evolution","summary":"  Evolutionary algorithms, such as Differential Evolution, excel in solving\nreal-parameter optimization challenges. However, the effectiveness of a single\nalgorithm varies across different problem instances, necessitating considerable\nefforts in algorithm selection or configuration. This paper aims to address the\nlimitation by leveraging the complementary strengths of a group of algorithms\nand dynamically scheduling them throughout the optimization progress for\nspecific problems. We propose a deep reinforcement learning-based dynamic\nalgorithm selection framework to accomplish this task. Our approach models the\ndynamic algorithm selection a Markov Decision Process, training an agent in a\npolicy gradient manner to select the most suitable algorithm according to the\nfeatures observed during the optimization process. To empower the agent with\nthe necessary information, our framework incorporates a thoughtful design of\nlandscape and algorithmic features. Meanwhile, we employ a sophisticated deep\nneural network model to infer the optimal action, ensuring informed algorithm\nselections. Additionally, an algorithm context restoration mechanism is\nembedded to facilitate smooth switching among different algorithms. These\nmechanisms together enable our framework to seamlessly select and switch\nalgorithms in a dynamic online fashion. Notably, the proposed framework is\nsimple and generic, offering potential improvements across a broad spectrum of\nevolutionary algorithms. As a proof-of-principle study, we apply this framework\nto a group of Differential Evolution algorithms. The experimental results\nshowcase the remarkable effectiveness of the proposed framework, not only\nenhancing the overall optimization performance but also demonstrating favorable\ngeneralization ability across different problem classes.\n","authors":["Hongshu Guo","Yining Ma","Zeyuan Ma","Jiacheng Chen","Xinglin Zhang","Zhiguang Cao","Jun Zhang","Yue-Jiao Gong"],"pdf_url":"https://arxiv.org/pdf/2403.02131v3.pdf","comment":"Accepted by IEEE Transactions on Systems, Man, and Cybernetics:\n  Systems at Thu, Feb 29, 2024"},{"id":"http://arxiv.org/abs/2403.04322v1","updated":"2024-03-07T08:37:36Z","published":"2024-03-07T08:37:36Z","title":"Memetic Differential Evolution Methods for Semi-Supervised Clustering","summary":"  In this paper, we deal with semi-supervised Minimum Sum-of-Squares Clustering\n(MSSC) problems where background knowledge is given in the form of\ninstance-level constraints. In particular, we take into account \"must-link\" and\n\"cannot-link\" constraints, each of which indicates if two dataset points should\nbe associated to the same or to a different cluster. The presence of such\nconstraints makes the problem at least as hard as its unsupervised version: it\nis no more true that each point is associated to its nearest cluster center,\nthus requiring some modifications in crucial operations, such as the assignment\nstep. In this scenario, we propose a novel memetic strategy based on the\nDifferential Evolution paradigm, directly extending a state-of-the-art\nframework recently proposed in the unsupervised clustering literature. As far\nas we know, our contribution represents the first attempt to define a memetic\nmethodology designed to generate a (hopefully) optimal feasible solution for\nthe semi-supervised MSSC problem. The proposal is compared with some\nstate-of-the-art algorithms from the literature on a set of well-known\ndatasets, highlighting its effectiveness and efficiency in finding good quality\nclustering solutions.\n","authors":["Pierluigi Mansueto","Fabio Schoen"],"pdf_url":"https://arxiv.org/pdf/2403.04322v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.02772v5","updated":"2024-03-07T04:18:20Z","published":"2023-10-04T12:42:21Z","title":"Spike Accumulation Forwarding for Effective Training of Spiking Neural\n  Networks","summary":"  In this article, we propose a new paradigm for training spiking neural\nnetworks (SNNs), spike accumulation forwarding (SAF). It is known that SNNs are\nenergy-efficient but difficult to train. Consequently, many researchers have\nproposed various methods to solve this problem, among which online training\nthrough time (OTTT) is a method that allows inferring at each time step while\nsuppressing the memory cost. However, to compute efficiently on GPUs, OTTT\nrequires operations with spike trains and weighted summation of spike trains\nduring forwarding. In addition, OTTT has shown a relationship with the Spike\nRepresentation, an alternative training method, though theoretical agreement\nwith Spike Representation has yet to be proven. Our proposed method can solve\nthese problems; namely, SAF can halve the number of operations during the\nforward process, and it can be theoretically proven that SAF is consistent with\nthe Spike Representation and OTTT, respectively. Furthermore, we confirmed the\nabove contents through experiments and showed that it is possible to reduce\nmemory and training time while maintaining accuracy.\n","authors":["Ryuji Saiin","Tomoya Shirakawa","Sota Yoshihara","Yoshihide Sawada","Hiroyuki Kusumoto"],"pdf_url":"https://arxiv.org/pdf/2310.02772v5.pdf","comment":"12 pages, 5 figures, Appendix:8 pages, 2 figures, v5:We added\n  experimental results and considered the situation the SNN have a feedforward\n  or feedback connection"},{"id":"http://arxiv.org/abs/2403.04162v1","updated":"2024-03-07T02:47:08Z","published":"2024-03-07T02:47:08Z","title":"Noisy Spiking Actor Network for Exploration","summary":"  As a general method for exploration in deep reinforcement learning (RL),\nNoisyNet can produce problem-specific exploration strategies. Spiking neural\nnetworks (SNNs), due to their binary firing mechanism, have strong robustness\nto noise, making it difficult to realize efficient exploration with local\ndisturbances. To solve this exploration problem, we propose a noisy spiking\nactor network (NoisySAN) that introduces time-correlated noise during charging\nand transmission. Moreover, a noise reduction method is proposed to find a\nstable policy for the agent. Extensive experimental results demonstrate that\nour method outperforms the state-of-the-art performance on a wide range of\ncontinuous control tasks from OpenAI gym.\n","authors":["Ding Chen","Peixi Peng","Tiejun Huang","Yonghong Tian"],"pdf_url":"https://arxiv.org/pdf/2403.04162v1.pdf","comment":"13 pages, 6 figures"}]},"2024-03-06T00:00:00Z":{"Computer Science and Game Theory":[{"id":"http://arxiv.org/abs/2403.04057v1","updated":"2024-03-06T21:08:54Z","published":"2024-03-06T21:08:54Z","title":"To Spend or to Gain: Online Learning in Repeated Karma Auctions","summary":"  Recent years have seen a surge of artificial currency-based mechanisms in\ncontexts where monetary instruments are deemed unfair or inappropriate, e.g.,\nin allocating food donations to food banks, course seats to students, and, more\nrecently, even for traffic congestion management. Yet the applicability of\nthese mechanisms remains limited in repeated auction settings, as it is\nchallenging for users to learn how to bid an artificial currency that has no\nvalue outside the auctions. Indeed, users must jointly learn the value of the\ncurrency in addition to how to spend it optimally. In this work, we study the\nproblem of learning to bid in two prominent classes of artificial currency\nauctions: those in which currency, which users spend to obtain public\nresources, is only issued at the beginning of a finite period; and those where,\nin addition to the initial currency endowment, currency payments are\nredistributed to users at each time step. In the latter class, the currency has\nbeen referred to as karma, since users do not only spend karma to obtain public\nresources but also gain karma for yielding them. In both classes, we propose a\nsimple learning strategy, called adaptive karma pacing, and show that this\nstrategy a) is asymptotically optimal for a single user bidding against\ncompeting bids drawn from a stationary distribution; b) leads to convergent\nlearning dynamics when all users adopt it; and c) constitutes an approximate\nNash equilibrium as the number of users grows. Our results require a novel\nanalysis in comparison to adaptive pacing strategies in monetary auctions,\nsince we depart from the classical assumption that the currency has known value\noutside the auctions, and moreover consider that the currency is both spent and\ngained in the class of auctions with redistribution.\n","authors":["Damien Berriaud","Ezzat Elokda","Devansh Jalota","Emilio Frazzoli","Marco Pavone","Florian Dörfler"],"pdf_url":"https://arxiv.org/pdf/2403.04057v1.pdf","comment":"Manuscript submitted for review to the 25th ACM Conference on\n  Economics & Computation (EC'24)"},{"id":"http://arxiv.org/abs/2403.04018v1","updated":"2024-03-06T20:01:44Z","published":"2024-03-06T20:01:44Z","title":"Empirical Game-Theoretic Analysis: A Survey","summary":"  In the empirical approach to game-theoretic analysis (EGTA), the model of the\ngame comes not from declarative representation, but is derived by interrogation\nof a procedural description of the game environment. The motivation for\ndeveloping this approach was to enable game-theoretic reasoning about strategic\nsituations too complex for analytic specification and solution. Since its\nintroduction over twenty years ago, EGTA has been applied to a wide range of\nmultiagent domains, from auctions and markets to recreational games to\ncyber-security. We survey the extensive methodology developed for EGTA over the\nyears, organized by the elemental subproblems comprising the EGTA process. We\ndescribe key EGTA concepts and techniques, and the questions at the frontier of\nEGTA research. Recent advances in machine learning have accelerated progress in\nEGTA, and promise to significantly expand our capacities for reasoning about\ncomplex game situations.\n","authors":["Michael P. Wellman","Karl Tuyls","Amy Greenwald"],"pdf_url":"https://arxiv.org/pdf/2403.04018v1.pdf","comment":"72 pages, 17 figures"},{"id":"http://arxiv.org/abs/2403.03999v1","updated":"2024-03-06T19:16:57Z","published":"2024-03-06T19:16:57Z","title":"Fair Artificial Currency Incentives in Repeated Weighted Congestion\n  Games: Equity vs. Equality","summary":"  When users access shared resources in a selfish manner, the resulting\nsocietal cost and perceived users' cost is often higher than what would result\nfrom a centrally coordinated optimal allocation. While several contributions in\nmechanism design manage to steer the aggregate users choices to the desired\noptimum by using monetary tolls, such approaches bear the inherent drawback of\ndiscriminating against users with a lower income. More recently, incentive\nschemes based on artificial currencies have been studied with the goal of\nachieving a system-optimal resource allocation that is also fair. In this\nresource-sharing context, this paper focuses on repeated weighted congestion\ngame with two resources, where users contribute to the congestion to different\nextents that are captured by individual weights. First, we address the broad\nconcept of fairness by providing a rigorous mathematical characterization of\nthe distinct societal metrics of equity and equality, i.e., the concepts of\nproviding equal outcomes and equal opportunities, respectively. Second, we\ndevise weight-dependent and time-invariant optimal pricing policies to maximize\nequity and equality, and prove convergence of the aggregate user choices to the\nsystem-optimum. In our framework it is always possible to achieve\nsystem-optimal allocations with perfect equity, while the maximum equality that\ncan be reached may not be perfect, which is also shown via numerical\nsimulations.\n","authors":["Leonardo Pedroso","Andrea Agazzi","W. P. M. H. Heemels","Mauro Salazar"],"pdf_url":"https://arxiv.org/pdf/2403.03999v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.03937v1","updated":"2024-03-06T18:47:11Z","published":"2024-03-06T18:47:11Z","title":"Settling the Competition Complexity of Additive Buyers over Independent\n  Items","summary":"  The competition complexity of an auction setting is the number of additional\nbidders needed such that the simple mechanism of selling items separately (with\nadditional bidders) achieves greater revenue than the optimal but complex\n(randomized, prior-dependent, Bayesian-truthful) optimal mechanism without the\nadditional bidders. Our main result settles the competition complexity of $n$\nbidders with additive values over $m < n$ independent items at\n$\\Theta(\\sqrt{nm})$. The $O(\\sqrt{nm})$ upper bound is due to [BW19], and our\nmain result improves the prior lower bound of $\\Omega(\\ln n)$ to\n$\\Omega(\\sqrt{nm})$.\n  Our main result follows from an explicit construction of a Bayesian IC\nauction for $n$ bidders with additive values over $m<n$ independent items drawn\nfrom the Equal Revenue curve truncated at $\\sqrt{nm}$ ($\\mathcal{ER}_{\\le\n\\sqrt{nm}}$), which achieves revenue that exceeds\n$\\text{SRev}_{n+\\sqrt{nm}}(\\mathcal{ER}_{\\le \\sqrt{nm}}^m)$.\n  Along the way, we show that the competition complexity of $n$ bidders with\nadditive values over $m$ independent items is exactly equal to the minimum $c$\nsuch that $\\text{SRev}_{n+c}(\\mathcal{ER}_{\\le p}^m) \\geq\n\\text{Rev}_n(\\mathcal{ER}_{\\le p}^m)$ for all $p$ (that is, some truncated\nEqual Revenue witnesses the worst-case competition complexity). Interestingly,\nwe also show that the untruncated Equal Revenue curve does not witness the\nworst-case competition complexity when $n > m$: $\\text{SRev}_n(\\mathcal{ER}^m)\n= nm+O_m(\\ln (n)) \\leq \\text{SRev}_{n+O_m(\\ln (n))}(\\mathcal{ER}^m)$, and\ntherefore our result can only follow by considering all possible truncations.\n","authors":["Mahsa Derakhshan","Emily Ryu","S. Matthew Weinberg","Eric Xue"],"pdf_url":"https://arxiv.org/pdf/2403.03937v1.pdf","comment":"50 pages"},{"id":"http://arxiv.org/abs/2307.01174v2","updated":"2024-03-06T17:22:57Z","published":"2023-07-03T17:38:38Z","title":"Anonymous and Copy-Robust Delegations for Liquid Democracy","summary":"  Liquid democracy with ranked delegations is a novel voting scheme that unites\nthe practicability of representative democracy with the idealistic appeal of\ndirect democracy: Every voter decides between casting their vote on a question\nat hand or delegating their voting weight to some other, trusted agent.\nDelegations are transitive, and since voters may end up in a delegation cycle,\nthey are encouraged to indicate not only a single delegate, but a set of\npotential delegates and a ranking among them. Based on the delegation\npreferences of all voters, a delegation rule selects one representative per\nvoter. Previous work has revealed a trade-off between two properties of\ndelegation rules called anonymity and copy-robustness.\n  To overcome this issue we study two fractional delegation rules: Mixed Borda\nbranching, which generalizes a rule satisfying copy-robustness, and the random\nwalk rule, which satisfies anonymity. Using the Markov chain tree theorem, we\nshow that the two rules are in fact equivalent, and simultaneously satisfy\ngeneralized versions of the two properties. Combining the same theorem with\nFulkerson's algorithm, we develop a polynomial-time algorithm for computing the\noutcome of the studied delegation rule. This algorithm is of independent\ninterest, having applications in semi-supervised learning and graph theory.\n","authors":["Markus Utke","Ulrike Schmidt-Kraepelin"],"pdf_url":"https://arxiv.org/pdf/2307.01174v2.pdf","comment":"Presented at NeurIPS 2023"},{"id":"http://arxiv.org/abs/2403.03811v1","updated":"2024-03-06T16:00:46Z","published":"2024-03-06T16:00:46Z","title":"Incentivized Learning in Principal-Agent Bandit Games","summary":"  This work considers a repeated principal-agent bandit game, where the\nprincipal can only interact with her environment through the agent. The\nprincipal and the agent have misaligned objectives and the choice of action is\nonly left to the agent. However, the principal can influence the agent's\ndecisions by offering incentives which add up to his rewards. The principal\naims to iteratively learn an incentive policy to maximize her own total\nutility. This framework extends usual bandit problems and is motivated by\nseveral practical applications, such as healthcare or ecological taxation,\nwhere traditionally used mechanism design theories often overlook the learning\naspect of the problem. We present nearly optimal (with respect to a horizon\n$T$) learning algorithms for the principal's regret in both multi-armed and\nlinear contextual settings. Finally, we support our theoretical guarantees\nthrough numerical experiments.\n","authors":["Antoine Scheid","Daniil Tiapkin","Etienne Boursier","Aymeric Capitaine","El Mahdi El Mhamdi","Eric Moulines","Michael I. Jordan","Alain Durmus"],"pdf_url":"https://arxiv.org/pdf/2403.03811v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.16793v2","updated":"2024-03-06T15:16:51Z","published":"2023-05-26T10:15:02Z","title":"Incentive Mechanism for Uncertain Tasks under Differential Privacy","summary":"  Mobile crowd sensing (MCS) has emerged as an increasingly popular sensing\nparadigm due to its cost-effectiveness. This approach relies on platforms to\noutsource tasks to participating workers when prompted by task publishers.\nAlthough incentive mechanisms have been devised to foster widespread\nparticipation in MCS, most of them focus only on static tasks (i.e., tasks for\nwhich the timing and type are known in advance) and do not protect the privacy\nof worker bids. In a dynamic and resource-constrained environment, tasks are\noften uncertain (i.e., the platform lacks a priori knowledge about the tasks)\nand worker bids may be vulnerable to inference attacks. This paper presents\nHERALD*, an incentive mechanism that addresses these issues through the use of\nuncertainty and hidden bids. Theoretical analysis reveals that HERALD*\nsatisfies a range of critical criteria, including truthfulness, individual\nrationality, differential privacy, low computational complexity, and low social\ncost. These properties are then corroborated through a series of evaluations.\n","authors":["Xikun Jiang","Chenhao Ying","Lei Li","Boris Düdder","Haiqin Wu","Haiming Jin","Yuan Luo"],"pdf_url":"https://arxiv.org/pdf/2305.16793v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01815v2","updated":"2024-03-06T14:43:30Z","published":"2023-02-03T15:37:53Z","title":"Optimal Capacity Modification for Many-To-One Matching Problems","summary":"  We consider many-to-one matching problems, where one side consists of\nstudents and the other side of schools with capacity constraints. We study how\nto optimally increase the capacities of the schools so as to obtain a stable\nand perfect matching (i.e., every student is matched) or a matching that is\nstable and Pareto-efficient for the students. We consider two common optimality\ncriteria, one aiming to minimize the sum of capacity increases of all schools\n(abbrv. as MinSum) and the other aiming to minimize the maximum capacity\nincrease of any school (abbrv. as MinMax). We obtain a complete picture in\nterms of computational complexity: Except for stable and perfect matchings\nusing the MinMax criteria which is polynomial-time solvable, all three\nremaining problems are NP-hard. We further investigate the parameterized\ncomplexity and approximability and find that achieving stable and\nPareto-efficient matchings via minimal capacity increases is much harder than\nachieving stable and perfect matchings.\n","authors":["Jiehua Chen","Gergely Csáji"],"pdf_url":"https://arxiv.org/pdf/2302.01815v2.pdf","comment":"Extended abstract accepted at AAMAS 2023"},{"id":"http://arxiv.org/abs/2403.03725v1","updated":"2024-03-06T14:15:18Z","published":"2024-03-06T14:15:18Z","title":"To Trust or Not to Trust: Assignment Mechanisms with Predictions in the\n  Private Graph Model","summary":"  The realm of algorithms with predictions has led to the development of\nseveral new algorithms that leverage (potentially erroneous) predictions to\nenhance their performance guarantees. The challenge is to devise algorithms\nthat achieve optimal approximation guarantees as the prediction quality varies\nfrom perfect (consistency) to imperfect (robustness). This framework is\nparticularly appealing in mechanism design contexts, where predictions might\nconvey private information about the agents. In this paper, we design\nstrategyproof mechanisms that leverage predictions to achieve improved\napproximation guarantees for several variants of the Generalized Assignment\nProblem (GAP) in the private graph model. In this model, first introduced by\nDughmi & Ghosh (2010), the set of resources that an agent is compatible with is\nprivate information. For the Bipartite Matching Problem (BMP), we give a\ndeterministic group-strategyproof (GSP) mechanism that is $(1\n+1/\\gamma)$-consistent and $(1 + \\gamma)$-robust, where $\\gamma \\ge 1$ is some\nconfidence parameter. We also prove that this is best possible. Remarkably, our\nmechanism draws inspiration from the renowned Gale-Shapley algorithm,\nincorporating predictions as a crucial element. Additionally, we give a\nrandomized mechanism that is universally GSP and improves on the guarantees in\nexpectation. The other GAP variants that we consider all make use of a unified\ngreedy mechanism that adds edges to the assignment according to a specific\norder. Our universally GSP mechanism randomizes over the greedy mechanism, our\nmechanism for BMP and the predicted assignment, leading to\n$(1+3/\\gamma)$-consistency and $(3+\\gamma)$-robustness in expectation. All our\nmechanisms also provide more fine-grained approximation guarantees that\ninterpolate between the consistency and the robustness, depending on some\nnatural error measure of the prediction.\n","authors":["Riccardo Colini-Baldeschi","Sophie Klumper","Guido Schäfer","Artem Tsikiridis"],"pdf_url":"https://arxiv.org/pdf/2403.03725v1.pdf","comment":"40 pages, 7 figures"},{"id":"http://arxiv.org/abs/2306.05366v4","updated":"2024-03-06T13:28:48Z","published":"2023-06-08T17:08:52Z","title":"Ordinal Potential-based Player Rating","summary":"  It was recently observed that Elo ratings fail at preserving transitive\nrelations among strategies and therefore cannot correctly extract the\ntransitive component of a game. We provide a characterization of transitive\ngames as a weak variant of ordinal potential games and show that Elo ratings\nactually do preserve transitivity when computed in the right space, using\nsuitable invertible mappings. Leveraging this insight, we introduce a new game\ndecomposition of an arbitrary game into transitive and cyclic components that\nis learnt using a neural network-based architecture and that prioritises\ncapturing the sign pattern of the game, namely transitive and cyclic relations\namong strategies. We link our approach to the known concept of sign-rank, and\nevaluate our methodology using both toy examples and empirical data from\nreal-world games.\n","authors":["Nelson Vadori","Rahul Savani"],"pdf_url":"https://arxiv.org/pdf/2306.05366v4.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2403.04017v1","updated":"2024-03-06T19:59:17Z","published":"2024-03-06T19:59:17Z","title":"Learning Guided Automated Reasoning: A Brief Survey","summary":"  Automated theorem provers and formal proof assistants are general reasoning\nsystems that are in theory capable of proving arbitrarily hard theorems, thus\nsolving arbitrary problems reducible to mathematics and logical reasoning. In\npractice, such systems however face large combinatorial explosion, and\ntherefore include many heuristics and choice points that considerably influence\ntheir performance. This is an opportunity for trained machine learning\npredictors, which can guide the work of such reasoning systems. Conversely,\ndeductive search supported by the notion of logically valid proof allows one to\ntrain machine learning systems on large reasoning corpora. Such bodies of proof\nare usually correct by construction and when combined with more and more\nprecise trained guidance they can be boostrapped into very large corpora, with\nincreasingly long reasoning chains and possibly novel proof ideas. In this\npaper we provide an overview of several automated reasoning and theorem proving\ndomains and the learning and AI methods that have been so far developed for\nthem. These include premise selection, proof guidance in several settings, AI\nsystems and feedback loops iterating between reasoning and learning, and\nsymbolic classification problems.\n","authors":["Lasse Blaauwbroek","David Cerna","Thibault Gauthier","Jan Jakubův","Cezary Kaliszyk","Martin Suda","Josef Urban"],"pdf_url":"https://arxiv.org/pdf/2403.04017v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.03781v1","updated":"2024-03-06T15:23:26Z","published":"2024-03-06T15:23:26Z","title":"Neural Architecture Search using Particle Swarm and Ant Colony\n  Optimization","summary":"  Neural network models have a number of hyperparameters that must be chosen\nalong with their architecture. This can be a heavy burden on a novice user,\nchoosing which architecture and what values to assign to parameters. In most\ncases, default hyperparameters and architectures are used. Significant\nimprovements to model accuracy can be achieved through the evaluation of\nmultiple architectures. A process known as Neural Architecture Search (NAS) may\nbe applied to automatically evaluate a large number of such architectures. A\nsystem integrating open source tools for Neural Architecture Search (OpenNAS),\nin the classification of images, has been developed as part of this research.\nOpenNAS takes any dataset of grayscale, or RBG images, and generates\nConvolutional Neural Network (CNN) architectures based on a range of\nmetaheuristics using either an AutoKeras, a transfer learning or a Swarm\nIntelligence (SI) approach. Particle Swarm Optimization (PSO) and Ant Colony\nOptimization (ACO) are used as the SI algorithms. Furthermore, models developed\nthrough such metaheuristics may be combined using stacking ensembles. In the\ncontext of this paper, we focus on training and optimizing CNNs using the Swarm\nIntelligence (SI) components of OpenNAS. Two major types of SI algorithms,\nnamely PSO and ACO, are compared to see which is more effective in generating\nhigher model accuracies. It is shown, with our experimental design, that the\nPSO algorithm performs better than ACO. The performance improvement of PSO is\nmost notable with a more complex dataset. As a baseline, the performance of\nfine-tuned pre-trained models is also evaluated.\n","authors":["Séamus Lankford","Diarmuid Grimes"],"pdf_url":"https://arxiv.org/pdf/2403.03781v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.11146v2","updated":"2024-03-06T13:46:06Z","published":"2023-01-26T14:54:17Z","title":"Two-step interpretable modeling of Intensive Care Acquired Infections","summary":"  We present a novel methodology for integrating high resolution longitudinal\ndata with the dynamic prediction capabilities of survival models. The aim is\ntwo-fold: to improve the predictive power while maintaining interpretability of\nthe models. To go beyond the black box paradigm of artificial neural networks,\nwe propose a parsimonious and robust semi-parametric approach (i.e., a\nlandmarking competing risks model) that combines routinely collected\nlow-resolution data with predictive features extracted from a convolutional\nneural network, that was trained on high resolution time-dependent information.\nWe then use saliency maps to analyze and explain the extra predictive power of\nthis model. To illustrate our methodology, we focus on healthcare-associated\ninfections in patients admitted to an intensive care unit.\n","authors":["Giacomo Lancia","Meri Varkila","Olaf Cremer","Cristian Spitoni"],"pdf_url":"https://arxiv.org/pdf/2301.11146v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.03511v1","updated":"2024-03-06T07:38:31Z","published":"2024-03-06T07:38:31Z","title":"Illuminating the property space in crystal structure prediction using\n  Quality-Diversity algorithms","summary":"  The identification of materials with exceptional properties is an essential\nobjective to enable technological progress. We propose the application of\n\\textit{Quality-Diversity} algorithms to the field of crystal structure\nprediction. The objective of these algorithms is to identify a diverse set of\nhigh-performing solutions, which has been successful in a range of fields such\nas robotics, architecture and aeronautical engineering. As these methods rely\non a high number of evaluations, we employ machine-learning surrogate models to\ncompute the interatomic potential and material properties that are used to\nguide optimisation. Consequently, we also show the value of using neural\nnetworks to model crystal properties and enable the identification of novel\ncomposition--structure combinations. In this work, we specifically study the\napplication of the MAP-Elites algorithm to predict polymorphs of TiO$_2$. We\nrediscover the known ground state, in addition to a set of other polymorphs\nwith distinct properties. We validate our method for C, SiO$_2$ and SiC\nsystems, where we show that the algorithm can uncover multiple local minima\nwith distinct electronic and mechanical properties.\n","authors":["Marta Wolinska","Aron Walsh","Antoine Cully"],"pdf_url":"https://arxiv.org/pdf/2403.03511v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.00194v3","updated":"2024-03-06T03:24:45Z","published":"2023-09-30T00:10:14Z","title":"A Prefrontal Cortex-inspired Architecture for Planning in Large Language\n  Models","summary":"  Large language models (LLMs) demonstrate impressive performance on a wide\nvariety of tasks, but they often struggle with tasks that require multi-step\nreasoning or goal-directed planning. To address this, we take inspiration from\nthe human brain, in which planning is accomplished via the recurrent\ninteraction of specialized modules in the prefrontal cortex (PFC). These\nmodules perform functions such as conflict monitoring, state prediction, state\nevaluation, task decomposition, and task coordination. We find that LLMs are\nsometimes capable of carrying out these functions in isolation, but struggle to\nautonomously coordinate them in the service of a goal. Therefore, we propose a\nblack box architecture with multiple LLM-based (GPT-4) modules. The\narchitecture improves planning through the interaction of specialized\nPFC-inspired modules that break down a larger problem into multiple brief\nautomated calls to the LLM. We evaluate the combined architecture on three\nchallenging planning tasks -- graph traversal, Tower of Hanoi, and logistics --\nfinding that it yields significant improvements over standard LLM methods\n(e.g., zero-shot prompting, in-context learning, and chain-of-thought). These\nresults demonstrate the benefit of utilizing knowledge from cognitive\nneuroscience to improve planning in LLMs.\n","authors":["Taylor Webb","Shanka Subhra Mondal","Chi Wang","Brian Krabach","Ida Momennejad"],"pdf_url":"https://arxiv.org/pdf/2310.00194v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.03409v1","updated":"2024-03-06T02:36:15Z","published":"2024-03-06T02:36:15Z","title":"Sparse Spiking Neural Network: Exploiting Heterogeneity in Timescales\n  for Pruning Recurrent SNN","summary":"  Recurrent Spiking Neural Networks (RSNNs) have emerged as a computationally\nefficient and brain-inspired learning model. The design of sparse RSNNs with\nfewer neurons and synapses helps reduce the computational complexity of RSNNs.\nTraditionally, sparse SNNs are obtained by first training a dense and complex\nSNN for a target task, and, then, pruning neurons with low activity\n(activity-based pruning) while maintaining task performance. In contrast, this\npaper presents a task-agnostic methodology for designing sparse RSNNs by\npruning a large randomly initialized model. We introduce a novel Lyapunov Noise\nPruning (LNP) algorithm that uses graph sparsification methods and utilizes\nLyapunov exponents to design a stable sparse RSNN from a randomly initialized\nRSNN. We show that the LNP can leverage diversity in neuronal timescales to\ndesign a sparse Heterogeneous RSNN (HRSNN). Further, we show that the same\nsparse HRSNN model can be trained for different tasks, such as image\nclassification and temporal prediction. We experimentally show that, in spite\nof being task-agnostic, LNP increases computational efficiency (fewer neurons\nand synapses) and prediction performance of RSNNs compared to traditional\nactivity-based pruning of trained dense models.\n","authors":["Biswadeep Chakraborty","Beomseok Kang","Harshit Kumar","Saibal Mukhopadhyay"],"pdf_url":"https://arxiv.org/pdf/2403.03409v1.pdf","comment":"Published as a conference paper at ICLR 2024"},{"id":"http://arxiv.org/abs/2403.03397v1","updated":"2024-03-06T01:38:42Z","published":"2024-03-06T01:38:42Z","title":"Explaining Genetic Programming Trees using Large Language Models","summary":"  Genetic programming (GP) has the potential to generate explainable results,\nespecially when used for dimensionality reduction. In this research, we\ninvestigate the potential of leveraging eXplainable AI (XAI) and large language\nmodels (LLMs) like ChatGPT to improve the interpretability of GP-based\nnon-linear dimensionality reduction. Our study introduces a novel XAI dashboard\nnamed GP4NLDR, the first approach to combine state-of-the-art GP with an\nLLM-powered chatbot to provide comprehensive, user-centred explanations. We\nshowcase the system's ability to provide intuitive and insightful narratives on\nhigh-dimensional data reduction processes through case studies. Our study\nhighlights the importance of prompt engineering in eliciting accurate and\npertinent responses from LLMs. We also address important considerations around\ndata privacy, hallucinatory outputs, and the rapid advancements in generative\nAI. Our findings demonstrate its potential in advancing the explainability of\nGP algorithms. This opens the door for future research into explaining GP\nmodels with LLMs.\n","authors":["Paula Maddigan","Andrew Lensen","Bing Xue"],"pdf_url":"https://arxiv.org/pdf/2403.03397v1.pdf","comment":null}]},"2024-03-05T00:00:00Z":{"Information Retrieval":[{"id":"http://arxiv.org/abs/2403.03278v1","updated":"2024-03-05T19:18:44Z","published":"2024-03-05T19:18:44Z","title":"Linear Codes for Hyperdimensional Computing","summary":"  Hyperdimensional Computing (HDC) is an emerging computational paradigm for\nrepresenting compositional information as high-dimensional vectors, and has a\npromising potential in applications ranging from machine learning to\nneuromorphic computing. One of the long-standing challenges in HDC is factoring\na compositional representation to its constituent factors, also known as the\nrecovery problem. In this paper we take a novel approach to solve the recovery\nproblem, and propose the use of random linear codes. These codes are subspaces\nover the Boolean field, and are a well-studied topic in information theory with\nvarious applications in digital communication. We begin by showing that\nhyperdimensional encoding using random linear codes retains favorable\nproperties of the prevalent (ordinary) random codes, and hence HD\nrepresentations using the two methods have comparable information storage\ncapabilities. We proceed to show that random linear codes offer a rich subcode\nstructure that can be used to form key-value stores, which encapsulate most use\ncases of HDC. Most importantly, we show that under the framework we develop,\nrandom linear codes admit simple recovery algorithms to factor (either bundled\nor bound) compositional representations. The former relies on constructing\ncertain linear equation systems over the Boolean field, the solution to which\nreduces the search space dramatically and strictly outperforms exhaustive\nsearch in many cases. The latter employs the subspace structure of these codes\nto achieve provably correct factorization. Both methods are strictly faster\nthan the state-of-the-art resonator networks, often by an order of magnitude.\nWe implemented our techniques in Python using a benchmark software library, and\ndemonstrated promising experimental results.\n","authors":["Netanel Raviv"],"pdf_url":"https://arxiv.org/pdf/2403.03278v1.pdf","comment":"Author's final version. The article has been accepted for publication\n  in Neural Computation (MIT press)"},{"id":"http://arxiv.org/abs/2402.13852v2","updated":"2024-03-05T16:32:24Z","published":"2024-02-21T14:56:36Z","title":"Neural Control System for Continuous Glucose Monitoring and Maintenance","summary":"  Precise glucose level monitoring is critical for people with diabetes to\navoid serious complications. While there are several methods for continuous\nglucose level monitoring, research on maintenance devices is limited. To\nmitigate the gap, we provide a novel neural control system for continuous\nglucose monitoring and management that uses differential predictive control.\nOur approach, led by a sophisticated neural policy and differentiable modeling,\nconstantly adjusts insulin supply in real-time, thereby improving glucose level\noptimization in the body. This end-to-end method maximizes efficiency,\nproviding personalized care and improved health outcomes, as confirmed by\nempirical evidence.\n","authors":["Azmine Toushik Wasi"],"pdf_url":"https://arxiv.org/pdf/2402.13852v2.pdf","comment":"9 Pages, 4 figures, ICLR 2024 Tiny Papers Track\n  https://openreview.net/forum?id=Te4P3Cn54g"},{"id":"http://arxiv.org/abs/2403.03002v1","updated":"2024-03-05T14:28:40Z","published":"2024-03-05T14:28:40Z","title":"Mem-elements based Neuromorphic Hardware for Neural Network Application","summary":"  The thesis investigates the utilization of memristive and memcapacitive\ncrossbar arrays in low-power machine learning accelerators, offering a\ncomprehensive co-design framework for deep neural networks (DNN). The model,\nimplemented through a hybrid Python and PyTorch approach, accounts for various\nnon-idealities, achieving exceptional training accuracies of 90.02% and 91.03%\nfor the CIFAR-10 dataset with memristive and memcapacitive crossbar arrays on\nan 8-layer VGG network. Additionally, the thesis introduces a novel approach to\nemulate meminductor devices using Operational Transconductance Amplifiers (OTA)\nand capacitors, showcasing adjustable behavior. Transistor-level simulations in\n180 nm CMOS technology, operating at 60 MHz, demonstrate the proposed\nmeminductor emulator's viability with a power consumption of 0.337 mW. The\ndesign is further validated in neuromorphic circuits and CNN accelerators,\nachieving training and testing accuracies of 91.04% and 88.82%, respectively.\nNotably, the exclusive use of MOS transistors ensures the feasibility of\nmonolithic IC fabrication. This research significantly contributes to the\nexploration of advanced hardware solutions for efficient and high-performance\nmachine-learning applications.\n","authors":["Ankur Singh"],"pdf_url":"https://arxiv.org/pdf/2403.03002v1.pdf","comment":"Master's Thesis"},{"id":"http://arxiv.org/abs/2403.02985v1","updated":"2024-03-05T14:04:13Z","published":"2024-03-05T14:04:13Z","title":"Evolution Transformer: In-Context Evolutionary Optimization","summary":"  Evolutionary optimization algorithms are often derived from loose biological\nanalogies and struggle to leverage information obtained during the sequential\ncourse of optimization. An alternative promising approach is to leverage data\nand directly discover powerful optimization principles via meta-optimization.\nIn this work, we follow such a paradigm and introduce Evolution Transformer, a\ncausal Transformer architecture, which can flexibly characterize a family of\nEvolution Strategies. Given a trajectory of evaluations and search distribution\nstatistics, Evolution Transformer outputs a performance-improving update to the\nsearch distribution. The architecture imposes a set of suitable inductive\nbiases, i.e. the invariance of the distribution update to the order of\npopulation members within a generation and equivariance to the order of the\nsearch dimensions. We train the model weights using Evolutionary Algorithm\nDistillation, a technique for supervised optimization of sequence models using\nteacher algorithm trajectories. The resulting model exhibits strong in-context\noptimization performance and shows strong generalization capabilities to\notherwise challenging neuroevolution tasks. We analyze the resulting properties\nof the Evolution Transformer and propose a technique to fully\nself-referentially train the Evolution Transformer, starting from a random\ninitialization and bootstrapping its own learning progress. We provide an open\nsource implementation under https://github.com/RobertTLange/evosax.\n","authors":["Robert Tjarko Lange","Yingtao Tian","Yujin Tang"],"pdf_url":"https://arxiv.org/pdf/2403.02985v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.01131v2","updated":"2024-03-05T11:11:41Z","published":"2024-03-02T08:21:59Z","title":"LLaMoCo: Instruction Tuning of Large Language Models for Optimization\n  Code Generation","summary":"  Recent research explores optimization using large language models (LLMs) by\neither iteratively seeking next-step solutions from LLMs or directly prompting\nLLMs for an optimizer. However, these approaches exhibit inherent limitations,\nincluding low operational efficiency, high sensitivity to prompt design, and a\nlack of domain-specific knowledge. We introduce LLaMoCo, the first\ninstruction-tuning framework designed to adapt LLMs for solving optimization\nproblems in a code-to-code manner. Specifically, we establish a comprehensive\ninstruction set containing well-described problem prompts and effective\noptimization codes. We then develop a novel two-phase learning strategy that\nincorporates a contrastive learning-based warm-up procedure before the\ninstruction-tuning phase to enhance the convergence behavior during model\nfine-tuning. The experiment results demonstrate that a CodeGen (350M) model\nfine-tuned by our LLaMoCo achieves superior optimization performance compared\nto GPT-4 Turbo and the other competitors across both synthetic and realistic\nproblem sets. The fine-tuned model and the usage instructions are available at\nhttps://anonymous.4open.science/r/LLaMoCo-722A.\n","authors":["Zeyuan Ma","Hongshu Guo","Jiacheng Chen","Guojun Peng","Zhiguang Cao","Yining Ma","Yue-Jiao Gong"],"pdf_url":"https://arxiv.org/pdf/2403.01131v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.02833v1","updated":"2024-03-05T10:09:31Z","published":"2024-03-05T10:09:31Z","title":"SOFIM: Stochastic Optimization Using Regularized Fisher Information\n  Matrix","summary":"  This paper introduces a new stochastic optimization method based on the\nregularized Fisher information matrix (FIM), named SOFIM, which can efficiently\nutilize the FIM to approximate the Hessian matrix for finding Newton's gradient\nupdate in large-scale stochastic optimization of machine learning models. It\ncan be viewed as a variant of natural gradient descent (NGD), where the\nchallenge of storing and calculating the full FIM is addressed through making\nuse of the regularized FIM and directly finding the gradient update direction\nvia Sherman-Morrison matrix inversion. Additionally, like the popular Adam\nmethod, SOFIM uses the first moment of the gradient to address the issue of\nnon-stationary objectives across mini-batches due to heterogeneous data. The\nutilization of the regularized FIM and Sherman-Morrison matrix inversion leads\nto the improved convergence rate with the same space and time complexities as\nstochastic gradient descent (SGD) with momentum. The extensive experiments on\ntraining deep learning models on several benchmark image classification\ndatasets demonstrate that the proposed SOFIM outperforms SGD with momentum and\nseveral state-of-the-art Newton optimization methods, such as Nystrom-SGD,\nL-BFGS, and AdaHessian, in term of the convergence speed for achieving the\npre-specified objectives of training and test losses as well as test accuracy.\n","authors":["Gayathri C","Mrinmay Sen","A. K. Qin","Raghu Kishore N","Yen-Wei Chen","Balasubramanian Raman"],"pdf_url":"https://arxiv.org/pdf/2403.02833v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.10540v5","updated":"2024-03-05T07:36:09Z","published":"2022-06-21T17:15:45Z","title":"Rethinking Symbolic Regression Datasets and Benchmarks for Scientific\n  Discovery","summary":"  This paper revisits datasets and evaluation criteria for Symbolic Regression\n(SR), specifically focused on its potential for scientific discovery. Focused\non a set of formulas used in the existing datasets based on Feynman Lectures on\nPhysics, we recreate 120 datasets to discuss the performance of symbolic\nregression for scientific discovery (SRSD). For each of the 120 SRSD datasets,\nwe carefully review the properties of the formula and its variables to design\nreasonably realistic sampling ranges of values so that our new SRSD datasets\ncan be used for evaluating the potential of SRSD such as whether or not an SR\nmethod can (re)discover physical laws from such datasets. We also create\nanother 120 datasets that contain dummy variables to examine whether SR methods\ncan choose necessary variables only. Besides, we propose to use normalized edit\ndistances (NED) between a predicted equation and the true equation trees for\naddressing a critical issue that existing SR metrics are either binary or\nerrors between the target values and an SR model's predicted values for a given\ninput. We conduct benchmark experiments on our new SRSD datasets using various\nrepresentative SR methods. The experimental results show that we provide a more\nrealistic performance evaluation, and our user study shows that the NED\ncorrelates with human judges significantly more than an existing SR metric. We\npublish repositories of our code and 240 SRSD datasets.\n","authors":["Yoshitomo Matsubara","Naoya Chiba","Ryo Igarashi","Yoshitaka Ushiku"],"pdf_url":"https://arxiv.org/pdf/2206.10540v5.pdf","comment":"Accepted at DMLR. Code and datasets are available at\n  https://github.com/omron-sinicx/srsd-benchmark\n  https://huggingface.co/datasets/yoshitomo-matsubara/srsd-feynman_easy\n  https://huggingface.co/datasets/yoshitomo-matsubara/srsd-feynman_medium\n  https://huggingface.co/datasets/yoshitomo-matsubara/srsd-feynman_hard and\n  another three sets of SRSD datasets with dummy variables"},{"id":"http://arxiv.org/abs/2304.04497v3","updated":"2024-03-05T07:36:02Z","published":"2023-04-10T10:22:21Z","title":"A Unified Framework for Exploratory Learning-Aided Community Detection\n  Under Topological Uncertainty","summary":"  In social networks, the discovery of community structures has received\nconsiderable attention as a fundamental problem in various network analysis\ntasks. However, due to privacy concerns or access restrictions, the network\nstructure is often uncertain, thereby rendering established community detection\napproaches ineffective without costly network topology acquisition. To tackle\nthis challenge, we present META-CODE, a unified framework for detecting\noverlapping communities via exploratory learning aided by easy-to-collect node\nmetadata when networks are topologically unknown (or only partially known).\nSpecifically, META-CODE consists of three iterative steps in addition to the\ninitial network inference step: 1) node-level community-affiliation embeddings\nbased on graph neural networks (GNNs) trained by our new reconstruction loss,\n2) network exploration via community-affiliation-based node queries, and 3)\nnetwork inference using an edge connectivity-based Siamese neural network model\nfrom the explored network. Through extensive experiments on five real-world\ndatasets including two large networks, we demonstrated: (a) the superiority of\nMETA-CODE over benchmark community detection methods, achieving remarkable\ngains up to 151.27% compared to the best existing competitor, (b) the impact of\neach module in META-CODE, (c) the effectiveness of node queries in META-CODE\nbased on empirical evaluations and theoretical findings, (d) the convergence of\nthe inferred network, and (e) the computational efficiency of META-CODE.\n","authors":["Yu Hou","Cong Tran","Ming Li","Won-Yong Shin"],"pdf_url":"https://arxiv.org/pdf/2304.04497v3.pdf","comment":"17 pages, 9 figures, 6 tables; its conference version was presented\n  at the ACM International Conference on Information and Knowledge Management\n  (CIKM 2022)"}]}}